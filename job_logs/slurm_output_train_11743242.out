task  SA
self.device  cuda
/home/lcur1101/ATCS_group3/marc_data/dataset_fr_train.json
Batch number: 0 , batch size : 32
Time taken to execute prompt gen: 0:00:00.000045
Time taken to execute mapping: 0:00:00.000187
possible_answers  ['negative', 'positive']
Traceback (most recent call last):
  File "/home/lcur1101/ATCS_group3/code/pipeline_file.py", line 185, in <module>
    acc = pipeline(LM_model, task, prompt_generator)
  File "/home/lcur1101/ATCS_group3/code/pipeline_file.py", line 145, in pipeline
    answers_probs_batch, pred_answer_batch = model(
  File "/home/lcur1101/ATCS_group3/code/main_model.py", line 40, in __call__
    outputs = self.model(**inputs, labels=inputs["input_ids"])
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/transformers/models/bloom/modeling_bloom.py", line 913, in forward
    transformer_outputs = self.transformer(
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/transformers/models/bloom/modeling_bloom.py", line 786, in forward
    outputs = block(
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/transformers/models/bloom/modeling_bloom.py", line 439, in forward
    attn_outputs = self.self_attention(
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/transformers/models/bloom/modeling_bloom.py", line 332, in forward
    attn_weights = torch.masked_fill(attention_scores, attention_mask, torch.finfo(attention_scores.dtype).min)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 23.65 GiB total capacity; 21.99 GiB already allocated; 47.56 MiB free; 22.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
srun: error: r34n5: task 0: Exited with exit code 1
