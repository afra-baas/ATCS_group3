self.device  cuda
/home/lcur1101/ATCS_group3/marc_data/dataset_fr_train.json
init marc done
num_lines  200000
num_lines  200000
num_lines  200000
num_lines  200000
Batch number: 0 , batch size : 32
Time taken to execute prompt gen: 0:00:00.000056
Time taken to execute mapping: 0:00:00.000226
Traceback (most recent call last):
  File "/home/lcur1101/ATCS_group3/code/pipeline_file.py", line 169, in <module>
    acc = pipeline(prompt_instructions,
  File "/home/lcur1101/ATCS_group3/code/pipeline_file.py", line 116, in pipeline
    answers_probs_batch, pred_answer_batch = model(
  File "/home/lcur1101/ATCS_group3/code/main_model.py", line 39, in __call__
    outputs = self.model(**inputs, labels=inputs["input_ids"])
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/transformers/models/bloom/modeling_bloom.py", line 913, in forward
    transformer_outputs = self.transformer(
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/transformers/models/bloom/modeling_bloom.py", line 786, in forward
    outputs = block(
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/transformers/models/bloom/modeling_bloom.py", line 463, in forward
    output = self.mlp(layernorm_output, residual)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/transformers/models/bloom/modeling_bloom.py", line 384, in forward
    hidden_states = self.gelu_impl(self.dense_h_to_4h(hidden_states))
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/transformers/models/bloom/modeling_bloom.py", line 208, in forward
    return bloom_gelu_forward(x)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/transformers/models/bloom/modeling_bloom.py", line 158, in bloom_gelu_forward
    return x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 146.00 MiB (GPU 0; 23.65 GiB total capacity; 22.22 GiB already allocated; 1.56 MiB free; 22.90 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
srun: error: r28n2: task 0: Exited with exit code 1
