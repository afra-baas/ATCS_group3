Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
****Start Time: 2023-05-21_17-00-21
Loading model bigscience/bloom-560m
Model bigscience/bloom-560m loaded
Available device is cuda
Model device: cuda:0
----------- 42 de bigscience/bloom-560m NLI active 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 306.05it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5035e-05, 1.6302e-05, 2.1933e-05, 2.5255e-05, 1.9995e-05, 2.0725e-05,
        1.8029e-05, 2.4960e-05, 3.3741e-05, 2.7468e-05, 1.6279e-05, 2.1870e-05,
        1.9436e-05, 1.9096e-05, 2.8200e-05, 2.3363e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.4414e-06, 2.4943e-06, 4.6118e-06, 5.7195e-06, 4.8003e-06, 5.2662e-06,
        3.4016e-06, 3.6942e-06, 7.1140e-06, 6.7853e-06, 3.5808e-06, 4.8733e-06,
        3.0139e-06, 4.1305e-06, 7.4395e-06, 5.7250e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5035e-05, 5.4414e-06],
        [0.0000e+00, 1.6302e-05, 2.4943e-06],
        [0.0000e+00, 2.1933e-05, 4.6118e-06],
        [0.0000e+00, 2.5255e-05, 5.7195e-06],
        [0.0000e+00, 1.9995e-05, 4.8003e-06],
        [0.0000e+00, 2.0725e-05, 5.2662e-06],
        [0.0000e+00, 1.8029e-05, 3.4016e-06],
        [0.0000e+00, 2.4960e-05, 3.6942e-06],
        [0.0000e+00, 3.3741e-05, 7.1140e-06],
        [0.0000e+00, 2.7468e-05, 6.7853e-06],
        [0.0000e+00, 1.6279e-05, 3.5808e-06],
        [0.0000e+00, 2.1870e-05, 4.8733e-06],
        [0.0000e+00, 1.9436e-05, 3.0139e-06],
        [0.0000e+00, 1.9096e-05, 4.1305e-06],
        [0.0000e+00, 2.8200e-05, 7.4395e-06],
        [0.0000e+00, 2.3363e-05, 5.7250e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.6986e-05, 3.2012e-05, 1.6651e-05, 1.7773e-05, 2.2970e-05, 2.2394e-05,
        4.0148e-05, 1.8532e-05, 2.8501e-05, 3.6412e-05, 2.1246e-05, 2.3074e-05,
        3.3091e-05, 1.8534e-05, 1.4379e-05, 2.3671e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.5394e-06, 8.7920e-06, 2.7231e-06, 4.3872e-06, 5.1636e-06, 5.7128e-06,
        9.9495e-06, 2.9200e-06, 5.6040e-06, 9.0789e-06, 3.8879e-06, 4.9318e-06,
        7.6640e-06, 4.5070e-06, 4.2165e-06, 7.2273e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.6986e-05, 5.5394e-06],
        [0.0000e+00, 3.2012e-05, 8.7920e-06],
        [0.0000e+00, 1.6651e-05, 2.7231e-06],
        [0.0000e+00, 1.7773e-05, 4.3872e-06],
        [0.0000e+00, 2.2970e-05, 5.1636e-06],
        [0.0000e+00, 2.2394e-05, 5.7128e-06],
        [0.0000e+00, 4.0148e-05, 9.9495e-06],
        [0.0000e+00, 1.8532e-05, 2.9200e-06],
        [0.0000e+00, 2.8501e-05, 5.6040e-06],
        [0.0000e+00, 3.6412e-05, 9.0789e-06],
        [0.0000e+00, 2.1246e-05, 3.8879e-06],
        [0.0000e+00, 2.3074e-05, 4.9318e-06],
        [0.0000e+00, 3.3091e-05, 7.6640e-06],
        [0.0000e+00, 1.8534e-05, 4.5070e-06],
        [0.0000e+00, 1.4379e-05, 4.2165e-06],
        [0.0000e+00, 2.3671e-05, 7.2273e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4036e-05, 3.8124e-05, 1.6946e-05, 1.8165e-05, 3.2785e-05, 2.0719e-05,
        2.0535e-05, 2.2671e-05, 1.4900e-05, 2.3056e-05, 1.7496e-05, 3.5868e-05,
        2.4720e-05, 2.9321e-05, 3.9868e-05, 2.3504e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([6.2761e-06, 9.0571e-06, 2.4438e-06, 4.3456e-06, 7.3088e-06, 4.8603e-06,
        3.3395e-06, 6.4862e-06, 3.7631e-06, 7.0516e-06, 5.3048e-06, 8.7923e-06,
        5.7165e-06, 6.8789e-06, 1.0048e-05, 4.5193e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4036e-05, 6.2761e-06],
        [0.0000e+00, 3.8124e-05, 9.0571e-06],
        [0.0000e+00, 1.6946e-05, 2.4438e-06],
        [0.0000e+00, 1.8165e-05, 4.3456e-06],
        [0.0000e+00, 3.2785e-05, 7.3088e-06],
        [0.0000e+00, 2.0719e-05, 4.8603e-06],
        [0.0000e+00, 2.0535e-05, 3.3395e-06],
        [0.0000e+00, 2.2671e-05, 6.4862e-06],
        [0.0000e+00, 1.4900e-05, 3.7631e-06],
        [0.0000e+00, 2.3056e-05, 7.0516e-06],
        [0.0000e+00, 1.7496e-05, 5.3048e-06],
        [0.0000e+00, 3.5868e-05, 8.7923e-06],
        [0.0000e+00, 2.4720e-05, 5.7165e-06],
        [0.0000e+00, 2.9321e-05, 6.8789e-06],
        [0.0000e+00, 3.9868e-05, 1.0048e-05],
        [0.0000e+00, 2.3504e-05, 4.5193e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type active, variation 0 and batchsize 16: 0:02:58.135882
path ['42', 'de', 'bloom', 'NLI', 'active', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m NLI active 1 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 283.01it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.2959e-05, 7.1957e-05, 2.0612e-05, 1.4123e-05, 2.2766e-05, 1.9103e-05,
        2.1583e-05, 2.9819e-05, 1.8368e-05, 2.0382e-05, 2.9887e-05, 3.5132e-05,
        4.0942e-05, 2.4149e-05, 2.8259e-05, 2.4130e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.6807e-06, 1.3738e-05, 4.5342e-06, 5.6543e-06, 5.9083e-06, 4.1461e-06,
        7.1584e-06, 7.5704e-06, 5.7117e-06, 3.9215e-06, 7.8160e-06, 5.6585e-06,
        1.4457e-05, 5.8964e-06, 7.0748e-06, 7.9902e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.2959e-05, 4.6807e-06],
        [0.0000e+00, 7.1957e-05, 1.3738e-05],
        [0.0000e+00, 2.0612e-05, 4.5342e-06],
        [0.0000e+00, 1.4123e-05, 5.6543e-06],
        [0.0000e+00, 2.2766e-05, 5.9083e-06],
        [0.0000e+00, 1.9103e-05, 4.1461e-06],
        [0.0000e+00, 2.1583e-05, 7.1584e-06],
        [0.0000e+00, 2.9819e-05, 7.5704e-06],
        [0.0000e+00, 1.8368e-05, 5.7117e-06],
        [0.0000e+00, 2.0382e-05, 3.9215e-06],
        [0.0000e+00, 2.9887e-05, 7.8160e-06],
        [0.0000e+00, 3.5132e-05, 5.6585e-06],
        [0.0000e+00, 4.0942e-05, 1.4457e-05],
        [0.0000e+00, 2.4149e-05, 5.8964e-06],
        [0.0000e+00, 2.8259e-05, 7.0748e-06],
        [0.0000e+00, 2.4130e-05, 7.9902e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4165e-05, 2.3712e-05, 2.6646e-05, 2.6728e-05, 3.3235e-05, 4.0422e-05,
        2.6527e-05, 1.4859e-05, 2.5506e-05, 2.4045e-05, 3.3186e-05, 1.7808e-05,
        2.5685e-05, 1.8348e-05, 4.6883e-05, 3.7384e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.3173e-06, 7.5890e-06, 4.2063e-06, 4.3806e-06, 9.4568e-06, 5.0374e-06,
        5.8722e-06, 4.8236e-06, 7.7000e-06, 4.7432e-06, 9.4838e-06, 2.7849e-06,
        4.7412e-06, 1.0520e-05, 6.3067e-06, 1.2004e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4165e-05, 4.3173e-06],
        [0.0000e+00, 2.3712e-05, 7.5890e-06],
        [0.0000e+00, 2.6646e-05, 4.2063e-06],
        [0.0000e+00, 2.6728e-05, 4.3806e-06],
        [0.0000e+00, 3.3235e-05, 9.4568e-06],
        [0.0000e+00, 4.0422e-05, 5.0374e-06],
        [0.0000e+00, 2.6527e-05, 5.8722e-06],
        [0.0000e+00, 1.4859e-05, 4.8236e-06],
        [0.0000e+00, 2.5506e-05, 7.7000e-06],
        [0.0000e+00, 2.4045e-05, 4.7432e-06],
        [0.0000e+00, 3.3186e-05, 9.4838e-06],
        [0.0000e+00, 1.7808e-05, 2.7849e-06],
        [0.0000e+00, 2.5685e-05, 4.7412e-06],
        [0.0000e+00, 1.8348e-05, 1.0520e-05],
        [0.0000e+00, 4.6883e-05, 6.3067e-06],
        [0.0000e+00, 3.7384e-05, 1.2004e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.3892e-05, 1.7489e-05, 2.7776e-05, 2.9084e-05, 2.8706e-05, 2.0784e-05,
        3.9492e-05, 1.6302e-05, 3.8473e-05, 3.7289e-05, 1.9754e-05, 2.6519e-05,
        2.9698e-05, 4.0426e-05, 2.6628e-05, 1.7842e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([7.8343e-06, 4.3032e-06, 6.2222e-06, 8.0024e-06, 6.8355e-06, 6.0404e-06,
        9.5469e-06, 4.4795e-06, 8.7000e-06, 9.5607e-06, 3.6211e-06, 7.1116e-06,
        7.2672e-06, 1.3315e-05, 5.2093e-06, 3.6375e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.3892e-05, 7.8343e-06],
        [0.0000e+00, 1.7489e-05, 4.3032e-06],
        [0.0000e+00, 2.7776e-05, 6.2222e-06],
        [0.0000e+00, 2.9084e-05, 8.0024e-06],
        [0.0000e+00, 2.8706e-05, 6.8355e-06],
        [0.0000e+00, 2.0784e-05, 6.0404e-06],
        [0.0000e+00, 3.9492e-05, 9.5469e-06],
        [0.0000e+00, 1.6302e-05, 4.4795e-06],
        [0.0000e+00, 3.8473e-05, 8.7000e-06],
        [0.0000e+00, 3.7289e-05, 9.5607e-06],
        [0.0000e+00, 1.9754e-05, 3.6211e-06],
        [0.0000e+00, 2.6519e-05, 7.1116e-06],
        [0.0000e+00, 2.9698e-05, 7.2672e-06],
        [0.0000e+00, 4.0426e-05, 1.3315e-05],
        [0.0000e+00, 2.6628e-05, 5.2093e-06],
        [0.0000e+00, 1.7842e-05, 3.6375e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type active, variation 1 and batchsize 16: 0:03:09.239309
path ['42', 'de', 'bloom', 'NLI', 'active', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m NLI active 2 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 310.22it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([7.5130e-05, 1.0602e-05, 5.2881e-05, 4.5075e-05, 2.4324e-05, 2.2459e-05,
        3.8533e-05, 5.1217e-05, 1.6158e-05, 1.8847e-05, 2.6572e-05, 3.5974e-05,
        1.4035e-04, 4.1429e-05, 2.2107e-05, 2.6432e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.0144e-05, 3.6733e-06, 1.5396e-05, 8.9047e-06, 8.3899e-06, 6.6175e-06,
        1.0249e-05, 8.8177e-06, 4.5952e-06, 6.6466e-06, 1.2022e-05, 8.7928e-06,
        2.9610e-05, 1.2712e-05, 1.3196e-05, 5.4048e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 7.5130e-05, 2.0144e-05],
        [0.0000e+00, 1.0602e-05, 3.6733e-06],
        [0.0000e+00, 5.2881e-05, 1.5396e-05],
        [0.0000e+00, 4.5075e-05, 8.9047e-06],
        [0.0000e+00, 2.4324e-05, 8.3899e-06],
        [0.0000e+00, 2.2459e-05, 6.6175e-06],
        [0.0000e+00, 3.8533e-05, 1.0249e-05],
        [0.0000e+00, 5.1217e-05, 8.8177e-06],
        [0.0000e+00, 1.6158e-05, 4.5952e-06],
        [0.0000e+00, 1.8847e-05, 6.6466e-06],
        [0.0000e+00, 2.6572e-05, 1.2022e-05],
        [0.0000e+00, 3.5974e-05, 8.7928e-06],
        [0.0000e+00, 1.4035e-04, 2.9610e-05],
        [0.0000e+00, 4.1429e-05, 1.2712e-05],
        [0.0000e+00, 2.2107e-05, 1.3196e-05],
        [0.0000e+00, 2.6432e-05, 5.4048e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.3268e-05, 4.3177e-05, 4.7207e-05, 6.1064e-05, 2.2695e-05, 1.8799e-05,
        4.8858e-05, 1.4561e-05, 3.1206e-05, 3.2987e-05, 5.4519e-05, 3.1411e-05,
        9.2791e-05, 2.6031e-05, 1.3757e-05, 5.9915e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.0794e-05, 1.0438e-05, 1.4806e-05, 1.2651e-05, 9.3169e-06, 9.0285e-06,
        1.4895e-05, 1.1952e-05, 1.0309e-05, 6.2155e-06, 6.9833e-06, 9.8488e-06,
        1.3298e-05, 6.7082e-06, 4.7156e-06, 1.3463e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.3268e-05, 1.0794e-05],
        [0.0000e+00, 4.3177e-05, 1.0438e-05],
        [0.0000e+00, 4.7207e-05, 1.4806e-05],
        [0.0000e+00, 6.1064e-05, 1.2651e-05],
        [0.0000e+00, 2.2695e-05, 9.3169e-06],
        [0.0000e+00, 1.8799e-05, 9.0285e-06],
        [0.0000e+00, 4.8858e-05, 1.4895e-05],
        [0.0000e+00, 1.4561e-05, 1.1952e-05],
        [0.0000e+00, 3.1206e-05, 1.0309e-05],
        [0.0000e+00, 3.2987e-05, 6.2155e-06],
        [0.0000e+00, 5.4519e-05, 6.9833e-06],
        [0.0000e+00, 3.1411e-05, 9.8488e-06],
        [0.0000e+00, 9.2791e-05, 1.3298e-05],
        [0.0000e+00, 2.6031e-05, 6.7082e-06],
        [0.0000e+00, 1.3757e-05, 4.7156e-06],
        [0.0000e+00, 5.9915e-05, 1.3463e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.6030e-05, 2.2930e-05, 3.3533e-05, 1.2641e-05, 8.0866e-05, 1.6865e-05,
        2.0723e-05, 3.8202e-05, 5.1390e-05, 7.1028e-05, 1.5779e-05, 2.6186e-05,
        1.5692e-05, 5.2966e-05, 1.3479e-05, 7.8539e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.2963e-05, 9.8311e-06, 1.0785e-05, 5.0805e-06, 1.0812e-05, 5.6001e-06,
        6.4381e-06, 8.2092e-06, 1.0701e-05, 9.2076e-06, 5.2855e-06, 1.2005e-05,
        6.4221e-06, 1.1603e-05, 8.8336e-06, 1.3409e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.6030e-05, 1.2963e-05],
        [0.0000e+00, 2.2930e-05, 9.8311e-06],
        [0.0000e+00, 3.3533e-05, 1.0785e-05],
        [0.0000e+00, 1.2641e-05, 5.0805e-06],
        [0.0000e+00, 8.0866e-05, 1.0812e-05],
        [0.0000e+00, 1.6865e-05, 5.6001e-06],
        [0.0000e+00, 2.0723e-05, 6.4381e-06],
        [0.0000e+00, 3.8202e-05, 8.2092e-06],
        [0.0000e+00, 5.1390e-05, 1.0701e-05],
        [0.0000e+00, 7.1028e-05, 9.2076e-06],
        [0.0000e+00, 1.5779e-05, 5.2855e-06],
        [0.0000e+00, 2.6186e-05, 1.2005e-05],
        [0.0000e+00, 1.5692e-05, 6.4221e-06],
        [0.0000e+00, 5.2966e-05, 1.1603e-05],
        [0.0000e+00, 1.3479e-05, 8.8336e-06],
        [0.0000e+00, 7.8539e-05, 1.3409e-05]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type active, variation 2 and batchsize 16: 0:03:09.032154
path ['42', 'de', 'bloom', 'NLI', 'active', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m NLI passive 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 274.92it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.6234e-05, 5.7518e-05, 8.3081e-05, 2.4300e-05, 2.9459e-05, 3.0592e-05,
        5.9224e-05, 7.0163e-05, 2.9135e-05, 2.8977e-05, 6.5492e-05, 2.7062e-05,
        3.8009e-05, 3.8771e-05, 1.6142e-05, 3.3482e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.4175e-05, 2.3953e-05, 1.7853e-05, 9.0578e-06, 7.7309e-06, 1.0183e-05,
        1.5911e-05, 2.2586e-05, 1.1409e-05, 1.1536e-05, 1.4964e-05, 7.8576e-06,
        1.0692e-05, 7.7410e-06, 5.9273e-06, 5.6271e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.6234e-05, 1.4175e-05],
        [0.0000e+00, 5.7518e-05, 2.3953e-05],
        [0.0000e+00, 8.3081e-05, 1.7853e-05],
        [0.0000e+00, 2.4300e-05, 9.0578e-06],
        [0.0000e+00, 2.9459e-05, 7.7309e-06],
        [0.0000e+00, 3.0592e-05, 1.0183e-05],
        [0.0000e+00, 5.9224e-05, 1.5911e-05],
        [0.0000e+00, 7.0163e-05, 2.2586e-05],
        [0.0000e+00, 2.9135e-05, 1.1409e-05],
        [0.0000e+00, 2.8977e-05, 1.1536e-05],
        [0.0000e+00, 6.5492e-05, 1.4964e-05],
        [0.0000e+00, 2.7062e-05, 7.8576e-06],
        [0.0000e+00, 3.8009e-05, 1.0692e-05],
        [0.0000e+00, 3.8771e-05, 7.7410e-06],
        [0.0000e+00, 1.6142e-05, 5.9273e-06],
        [0.0000e+00, 3.3482e-05, 5.6271e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.1298e-05, 3.9365e-05, 3.2553e-05, 2.3103e-05, 3.1700e-05, 3.8402e-05,
        3.1075e-05, 2.5634e-05, 5.1775e-05, 2.0329e-05, 2.0480e-05, 3.0333e-05,
        4.1261e-05, 2.2855e-05, 7.0701e-05, 7.7855e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.6313e-06, 1.1829e-05, 1.1776e-05, 8.6667e-06, 1.0367e-05, 9.8995e-06,
        1.3491e-05, 1.6957e-05, 2.1250e-05, 6.2067e-06, 6.8247e-06, 8.4405e-06,
        1.6242e-05, 6.5669e-06, 1.3219e-05, 1.9916e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.1298e-05, 5.6313e-06],
        [0.0000e+00, 3.9365e-05, 1.1829e-05],
        [0.0000e+00, 3.2553e-05, 1.1776e-05],
        [0.0000e+00, 2.3103e-05, 8.6667e-06],
        [0.0000e+00, 3.1700e-05, 1.0367e-05],
        [0.0000e+00, 3.8402e-05, 9.8995e-06],
        [0.0000e+00, 3.1075e-05, 1.3491e-05],
        [0.0000e+00, 2.5634e-05, 1.6957e-05],
        [0.0000e+00, 5.1775e-05, 2.1250e-05],
        [0.0000e+00, 2.0329e-05, 6.2067e-06],
        [0.0000e+00, 2.0480e-05, 6.8247e-06],
        [0.0000e+00, 3.0333e-05, 8.4405e-06],
        [0.0000e+00, 4.1261e-05, 1.6242e-05],
        [0.0000e+00, 2.2855e-05, 6.5669e-06],
        [0.0000e+00, 7.0701e-05, 1.3219e-05],
        [0.0000e+00, 7.7855e-05, 1.9916e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.5237e-05, 3.3076e-05, 3.5099e-05, 2.0659e-05, 5.7489e-05, 1.1958e-05,
        3.7476e-05, 3.4773e-05, 3.8056e-05, 2.1172e-05, 5.1546e-05, 3.6481e-05,
        2.9027e-05, 4.3281e-05, 2.9081e-05, 2.5699e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([9.5539e-06, 1.4776e-05, 1.1788e-05, 7.2105e-06, 2.0305e-05, 1.7575e-06,
        1.7266e-05, 9.5343e-06, 1.0037e-05, 5.9768e-06, 1.9842e-05, 1.2487e-05,
        1.0455e-05, 1.4547e-05, 5.3888e-06, 5.2593e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.5237e-05, 9.5539e-06],
        [0.0000e+00, 3.3076e-05, 1.4776e-05],
        [0.0000e+00, 3.5099e-05, 1.1788e-05],
        [0.0000e+00, 2.0659e-05, 7.2105e-06],
        [0.0000e+00, 5.7489e-05, 2.0305e-05],
        [0.0000e+00, 1.1958e-05, 1.7575e-06],
        [0.0000e+00, 3.7476e-05, 1.7266e-05],
        [0.0000e+00, 3.4773e-05, 9.5343e-06],
        [0.0000e+00, 3.8056e-05, 1.0037e-05],
        [0.0000e+00, 2.1172e-05, 5.9768e-06],
        [0.0000e+00, 5.1546e-05, 1.9842e-05],
        [0.0000e+00, 3.6481e-05, 1.2487e-05],
        [0.0000e+00, 2.9027e-05, 1.0455e-05],
        [0.0000e+00, 4.3281e-05, 1.4547e-05],
        [0.0000e+00, 2.9081e-05, 5.3888e-06],
        [0.0000e+00, 2.5699e-05, 5.2593e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type passive, variation 0 and batchsize 16: 0:03:07.665550
path ['42', 'de', 'bloom', 'NLI', 'passive', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m NLI passive 1 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 265.74it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4870e-05, 3.0050e-05, 2.6465e-05, 3.4119e-05, 2.2676e-05, 1.6807e-05,
        2.4687e-05, 1.9306e-05, 1.7883e-05, 2.4671e-05, 2.2474e-05, 1.9717e-05,
        2.5940e-05, 2.7256e-05, 2.2586e-05, 3.0410e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.3090e-06, 7.5118e-06, 4.4307e-06, 7.5256e-06, 4.4989e-06, 4.4633e-06,
        5.5549e-06, 3.4304e-06, 5.0235e-06, 7.2708e-06, 3.9042e-06, 3.2046e-06,
        6.5393e-06, 5.7426e-06, 6.0015e-06, 6.3148e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4870e-05, 5.3090e-06],
        [0.0000e+00, 3.0050e-05, 7.5118e-06],
        [0.0000e+00, 2.6465e-05, 4.4307e-06],
        [0.0000e+00, 3.4119e-05, 7.5256e-06],
        [0.0000e+00, 2.2676e-05, 4.4989e-06],
        [0.0000e+00, 1.6807e-05, 4.4633e-06],
        [0.0000e+00, 2.4687e-05, 5.5549e-06],
        [0.0000e+00, 1.9306e-05, 3.4304e-06],
        [0.0000e+00, 1.7883e-05, 5.0235e-06],
        [0.0000e+00, 2.4671e-05, 7.2708e-06],
        [0.0000e+00, 2.2474e-05, 3.9042e-06],
        [0.0000e+00, 1.9717e-05, 3.2046e-06],
        [0.0000e+00, 2.5940e-05, 6.5393e-06],
        [0.0000e+00, 2.7256e-05, 5.7426e-06],
        [0.0000e+00, 2.2586e-05, 6.0015e-06],
        [0.0000e+00, 3.0410e-05, 6.3148e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.0117e-05, 2.2493e-05, 2.1435e-05, 3.1230e-05, 1.9396e-05, 1.7846e-05,
        2.7551e-05, 1.8057e-05, 2.6796e-05, 2.4478e-05, 3.5125e-05, 2.2725e-05,
        2.1716e-05, 1.9865e-05, 1.6196e-05, 1.7789e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([7.5843e-06, 5.8982e-06, 3.3880e-06, 7.9495e-06, 4.8126e-06, 2.4604e-06,
        5.1728e-06, 3.4751e-06, 4.3747e-06, 5.7722e-06, 7.0293e-06, 4.1703e-06,
        4.2588e-06, 5.4738e-06, 4.9662e-06, 4.0521e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.0117e-05, 7.5843e-06],
        [0.0000e+00, 2.2493e-05, 5.8982e-06],
        [0.0000e+00, 2.1435e-05, 3.3880e-06],
        [0.0000e+00, 3.1230e-05, 7.9495e-06],
        [0.0000e+00, 1.9396e-05, 4.8126e-06],
        [0.0000e+00, 1.7846e-05, 2.4604e-06],
        [0.0000e+00, 2.7551e-05, 5.1728e-06],
        [0.0000e+00, 1.8057e-05, 3.4751e-06],
        [0.0000e+00, 2.6796e-05, 4.3747e-06],
        [0.0000e+00, 2.4478e-05, 5.7722e-06],
        [0.0000e+00, 3.5125e-05, 7.0293e-06],
        [0.0000e+00, 2.2725e-05, 4.1703e-06],
        [0.0000e+00, 2.1716e-05, 4.2588e-06],
        [0.0000e+00, 1.9865e-05, 5.4738e-06],
        [0.0000e+00, 1.6196e-05, 4.9662e-06],
        [0.0000e+00, 1.7789e-05, 4.0521e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.9162e-05, 1.1847e-05, 2.6429e-05, 2.6894e-05, 1.1688e-05, 1.6270e-05,
        1.9260e-05, 2.4460e-05, 2.5505e-05, 2.8824e-05, 1.2507e-05, 1.7304e-05,
        3.3473e-05, 1.7875e-05, 2.1962e-05, 2.4420e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.2520e-06, 2.2968e-06, 6.3479e-06, 6.9128e-06, 4.1769e-06, 2.1619e-06,
        3.2378e-06, 6.7321e-06, 6.1554e-06, 7.1042e-06, 2.3965e-06, 4.4745e-06,
        9.9926e-06, 4.2895e-06, 5.7004e-06, 5.2911e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.9162e-05, 3.2520e-06],
        [0.0000e+00, 1.1847e-05, 2.2968e-06],
        [0.0000e+00, 2.6429e-05, 6.3479e-06],
        [0.0000e+00, 2.6894e-05, 6.9128e-06],
        [0.0000e+00, 1.1688e-05, 4.1769e-06],
        [0.0000e+00, 1.6270e-05, 2.1619e-06],
        [0.0000e+00, 1.9260e-05, 3.2378e-06],
        [0.0000e+00, 2.4460e-05, 6.7321e-06],
        [0.0000e+00, 2.5505e-05, 6.1554e-06],
        [0.0000e+00, 2.8824e-05, 7.1042e-06],
        [0.0000e+00, 1.2507e-05, 2.3965e-06],
        [0.0000e+00, 1.7304e-05, 4.4745e-06],
        [0.0000e+00, 3.3473e-05, 9.9926e-06],
        [0.0000e+00, 1.7875e-05, 4.2895e-06],
        [0.0000e+00, 2.1962e-05, 5.7004e-06],
        [0.0000e+00, 2.4420e-05, 5.2911e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type passive, variation 1 and batchsize 16: 0:03:10.463176
path ['42', 'de', 'bloom', 'NLI', 'passive', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m NLI passive 2 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 302.23it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.6045e-05, 3.4734e-05, 5.0245e-05, 6.0573e-05, 3.0512e-05, 2.8137e-05,
        5.7406e-05, 8.3904e-05, 6.6932e-05, 3.2998e-05, 2.1149e-05, 2.5847e-05,
        4.5626e-05, 3.0434e-05, 4.4061e-05, 3.7133e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([6.6772e-06, 1.0568e-05, 1.7841e-05, 1.6486e-05, 4.9303e-06, 7.7462e-06,
        1.8801e-05, 1.6998e-05, 1.3518e-05, 8.3355e-06, 3.9579e-06, 1.2485e-05,
        1.7318e-05, 7.4722e-06, 6.7277e-06, 8.8281e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.6045e-05, 6.6772e-06],
        [0.0000e+00, 3.4734e-05, 1.0568e-05],
        [0.0000e+00, 5.0245e-05, 1.7841e-05],
        [0.0000e+00, 6.0573e-05, 1.6486e-05],
        [0.0000e+00, 3.0512e-05, 4.9303e-06],
        [0.0000e+00, 2.8137e-05, 7.7462e-06],
        [0.0000e+00, 5.7406e-05, 1.8801e-05],
        [0.0000e+00, 8.3904e-05, 1.6998e-05],
        [0.0000e+00, 6.6932e-05, 1.3518e-05],
        [0.0000e+00, 3.2998e-05, 8.3355e-06],
        [0.0000e+00, 2.1149e-05, 3.9579e-06],
        [0.0000e+00, 2.5847e-05, 1.2485e-05],
        [0.0000e+00, 4.5626e-05, 1.7318e-05],
        [0.0000e+00, 3.0434e-05, 7.4722e-06],
        [0.0000e+00, 4.4061e-05, 6.7277e-06],
        [0.0000e+00, 3.7133e-05, 8.8281e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.8142e-05, 3.9759e-05, 3.0313e-05, 4.1328e-05, 1.8973e-05, 4.7954e-05,
        3.6298e-05, 2.0848e-05, 5.9827e-05, 3.4600e-05, 6.3396e-05, 3.3743e-05,
        3.1580e-05, 4.2785e-05, 3.3983e-05, 2.3932e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.3403e-05, 8.2515e-06, 6.5439e-06, 1.1021e-05, 6.3338e-06, 1.2464e-05,
        9.4282e-06, 4.3123e-06, 1.9763e-05, 5.2352e-06, 1.7580e-05, 9.8351e-06,
        7.1624e-06, 1.0647e-05, 8.9990e-06, 5.9802e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.8142e-05, 1.3403e-05],
        [0.0000e+00, 3.9759e-05, 8.2515e-06],
        [0.0000e+00, 3.0313e-05, 6.5439e-06],
        [0.0000e+00, 4.1328e-05, 1.1021e-05],
        [0.0000e+00, 1.8973e-05, 6.3338e-06],
        [0.0000e+00, 4.7954e-05, 1.2464e-05],
        [0.0000e+00, 3.6298e-05, 9.4282e-06],
        [0.0000e+00, 2.0848e-05, 4.3123e-06],
        [0.0000e+00, 5.9827e-05, 1.9763e-05],
        [0.0000e+00, 3.4600e-05, 5.2352e-06],
        [0.0000e+00, 6.3396e-05, 1.7580e-05],
        [0.0000e+00, 3.3743e-05, 9.8351e-06],
        [0.0000e+00, 3.1580e-05, 7.1624e-06],
        [0.0000e+00, 4.2785e-05, 1.0647e-05],
        [0.0000e+00, 3.3983e-05, 8.9990e-06],
        [0.0000e+00, 2.3932e-05, 5.9802e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.1672e-05, 2.6556e-05, 2.4149e-05, 6.5155e-05, 3.6310e-05, 7.0586e-05,
        3.3969e-05, 4.5068e-05, 1.8149e-05, 2.4889e-05, 3.4226e-05, 3.0658e-05,
        1.8490e-05, 3.1632e-05, 1.3158e-05, 3.0484e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([8.7211e-06, 6.7366e-06, 5.7403e-06, 1.1794e-05, 5.1851e-06, 1.1270e-05,
        9.2606e-06, 1.6338e-05, 4.9072e-06, 4.9281e-06, 8.8143e-06, 9.4233e-06,
        3.7424e-06, 6.4215e-06, 1.5862e-06, 9.3507e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.1672e-05, 8.7211e-06],
        [0.0000e+00, 2.6556e-05, 6.7366e-06],
        [0.0000e+00, 2.4149e-05, 5.7403e-06],
        [0.0000e+00, 6.5155e-05, 1.1794e-05],
        [0.0000e+00, 3.6310e-05, 5.1851e-06],
        [0.0000e+00, 7.0586e-05, 1.1270e-05],
        [0.0000e+00, 3.3969e-05, 9.2606e-06],
        [0.0000e+00, 4.5068e-05, 1.6338e-05],
        [0.0000e+00, 1.8149e-05, 4.9072e-06],
        [0.0000e+00, 2.4889e-05, 4.9281e-06],
        [0.0000e+00, 3.4226e-05, 8.8143e-06],
        [0.0000e+00, 3.0658e-05, 9.4233e-06],
        [0.0000e+00, 1.8490e-05, 3.7424e-06],
        [0.0000e+00, 3.1632e-05, 6.4215e-06],
        [0.0000e+00, 1.3158e-05, 1.5862e-06],
        [0.0000e+00, 3.0484e-05, 9.3507e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type passive, variation 2 and batchsize 16: 0:03:09.434452
path ['42', 'de', 'bloom', 'NLI', 'passive', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m NLI auxiliary 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 307.41it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.3747e-05, 1.5352e-05, 2.5769e-05, 3.7333e-05, 2.6210e-05, 2.6403e-05,
        2.9526e-05, 2.2826e-05, 2.5036e-05, 2.1055e-05, 2.6450e-05, 2.2760e-05,
        1.9972e-05, 3.2641e-05, 2.2988e-05, 2.8801e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.0013e-05, 2.0874e-06, 5.9116e-06, 7.1286e-06, 4.0835e-06, 3.0269e-06,
        4.9725e-06, 3.1956e-06, 5.3274e-06, 2.5021e-06, 5.0506e-06, 5.2008e-06,
        3.9458e-06, 5.2024e-06, 5.9240e-06, 4.5621e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.3747e-05, 1.0013e-05],
        [0.0000e+00, 1.5352e-05, 2.0874e-06],
        [0.0000e+00, 2.5769e-05, 5.9116e-06],
        [0.0000e+00, 3.7333e-05, 7.1286e-06],
        [0.0000e+00, 2.6210e-05, 4.0835e-06],
        [0.0000e+00, 2.6403e-05, 3.0269e-06],
        [0.0000e+00, 2.9526e-05, 4.9725e-06],
        [0.0000e+00, 2.2826e-05, 3.1956e-06],
        [0.0000e+00, 2.5036e-05, 5.3274e-06],
        [0.0000e+00, 2.1055e-05, 2.5021e-06],
        [0.0000e+00, 2.6450e-05, 5.0506e-06],
        [0.0000e+00, 2.2760e-05, 5.2008e-06],
        [0.0000e+00, 1.9972e-05, 3.9458e-06],
        [0.0000e+00, 3.2641e-05, 5.2024e-06],
        [0.0000e+00, 2.2988e-05, 5.9240e-06],
        [0.0000e+00, 2.8801e-05, 4.5621e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.7759e-05, 4.6189e-05, 2.0927e-05, 1.7312e-05, 2.0911e-05, 2.6289e-05,
        2.2441e-05, 2.7104e-05, 3.4957e-05, 3.7628e-05, 1.4243e-05, 2.3771e-05,
        1.7545e-05, 2.1570e-05, 2.1877e-05, 1.8148e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([7.7576e-06, 8.7465e-06, 4.7246e-06, 3.7181e-06, 2.4087e-06, 5.7907e-06,
        4.2240e-06, 4.7025e-06, 8.4496e-06, 6.6593e-06, 3.9590e-06, 5.5207e-06,
        2.2112e-06, 3.5365e-06, 4.2930e-06, 3.6939e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.7759e-05, 7.7576e-06],
        [0.0000e+00, 4.6189e-05, 8.7465e-06],
        [0.0000e+00, 2.0927e-05, 4.7246e-06],
        [0.0000e+00, 1.7312e-05, 3.7181e-06],
        [0.0000e+00, 2.0911e-05, 2.4087e-06],
        [0.0000e+00, 2.6289e-05, 5.7907e-06],
        [0.0000e+00, 2.2441e-05, 4.2240e-06],
        [0.0000e+00, 2.7104e-05, 4.7025e-06],
        [0.0000e+00, 3.4957e-05, 8.4496e-06],
        [0.0000e+00, 3.7628e-05, 6.6593e-06],
        [0.0000e+00, 1.4243e-05, 3.9590e-06],
        [0.0000e+00, 2.3771e-05, 5.5207e-06],
        [0.0000e+00, 1.7545e-05, 2.2112e-06],
        [0.0000e+00, 2.1570e-05, 3.5365e-06],
        [0.0000e+00, 2.1877e-05, 4.2930e-06],
        [0.0000e+00, 1.8148e-05, 3.6939e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.6013e-05, 1.9291e-05, 3.4383e-05, 3.1324e-05, 3.2892e-05, 2.4746e-05,
        2.6472e-05, 2.9501e-05, 2.8635e-05, 2.0756e-05, 3.8350e-05, 2.0662e-05,
        2.4556e-05, 4.2981e-05, 1.8695e-05, 4.0557e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.5061e-06, 2.1756e-06, 6.6278e-06, 5.1802e-06, 6.8641e-06, 4.4471e-06,
        2.8424e-06, 6.3366e-06, 5.0548e-06, 4.0732e-06, 6.7461e-06, 4.6166e-06,
        6.5845e-06, 8.5529e-06, 3.2801e-06, 7.9761e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.6013e-05, 5.5061e-06],
        [0.0000e+00, 1.9291e-05, 2.1756e-06],
        [0.0000e+00, 3.4383e-05, 6.6278e-06],
        [0.0000e+00, 3.1324e-05, 5.1802e-06],
        [0.0000e+00, 3.2892e-05, 6.8641e-06],
        [0.0000e+00, 2.4746e-05, 4.4471e-06],
        [0.0000e+00, 2.6472e-05, 2.8424e-06],
        [0.0000e+00, 2.9501e-05, 6.3366e-06],
        [0.0000e+00, 2.8635e-05, 5.0548e-06],
        [0.0000e+00, 2.0756e-05, 4.0732e-06],
        [0.0000e+00, 3.8350e-05, 6.7461e-06],
        [0.0000e+00, 2.0662e-05, 4.6166e-06],
        [0.0000e+00, 2.4556e-05, 6.5845e-06],
        [0.0000e+00, 4.2981e-05, 8.5529e-06],
        [0.0000e+00, 1.8695e-05, 3.2801e-06],
        [0.0000e+00, 4.0557e-05, 7.9761e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type auxiliary, variation 0 and batchsize 16: 0:03:09.017290
path ['42', 'de', 'bloom', 'NLI', 'auxiliary', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m NLI auxiliary 1 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 276.44it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.6399e-05, 3.5627e-05, 2.8193e-05, 2.0385e-05, 3.6909e-05, 1.7541e-05,
        1.6624e-05, 2.3636e-05, 3.5892e-05, 1.5193e-05, 2.7713e-05, 2.1063e-05,
        4.0375e-05, 2.1428e-05, 2.4869e-05, 3.2379e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.9905e-06, 6.0798e-06, 5.8822e-06, 3.8083e-06, 7.8984e-06, 3.6069e-06,
        3.6537e-06, 4.4352e-06, 5.8269e-06, 1.9575e-06, 5.0468e-06, 2.4478e-06,
        6.8999e-06, 3.1323e-06, 5.7520e-06, 5.2013e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.6399e-05, 3.9905e-06],
        [0.0000e+00, 3.5627e-05, 6.0798e-06],
        [0.0000e+00, 2.8193e-05, 5.8822e-06],
        [0.0000e+00, 2.0385e-05, 3.8083e-06],
        [0.0000e+00, 3.6909e-05, 7.8984e-06],
        [0.0000e+00, 1.7541e-05, 3.6069e-06],
        [0.0000e+00, 1.6624e-05, 3.6537e-06],
        [0.0000e+00, 2.3636e-05, 4.4352e-06],
        [0.0000e+00, 3.5892e-05, 5.8269e-06],
        [0.0000e+00, 1.5193e-05, 1.9575e-06],
        [0.0000e+00, 2.7713e-05, 5.0468e-06],
        [0.0000e+00, 2.1063e-05, 2.4478e-06],
        [0.0000e+00, 4.0375e-05, 6.8999e-06],
        [0.0000e+00, 2.1428e-05, 3.1323e-06],
        [0.0000e+00, 2.4869e-05, 5.7520e-06],
        [0.0000e+00, 3.2379e-05, 5.2013e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.7299e-05, 2.2539e-05, 2.6077e-05, 1.8773e-05, 4.3476e-05, 2.1507e-05,
        1.9604e-05, 2.3439e-05, 2.6215e-05, 1.8719e-05, 1.9491e-05, 2.9215e-05,
        2.3846e-05, 1.8044e-05, 2.2319e-05, 4.0072e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.9860e-06, 5.0143e-06, 5.1054e-06, 4.3215e-06, 8.6517e-06, 3.4661e-06,
        2.0125e-06, 5.7472e-06, 3.9869e-06, 3.1767e-06, 3.5504e-06, 4.6100e-06,
        5.1326e-06, 2.1927e-06, 3.8682e-06, 7.7337e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.7299e-05, 2.9860e-06],
        [0.0000e+00, 2.2539e-05, 5.0143e-06],
        [0.0000e+00, 2.6077e-05, 5.1054e-06],
        [0.0000e+00, 1.8773e-05, 4.3215e-06],
        [0.0000e+00, 4.3476e-05, 8.6517e-06],
        [0.0000e+00, 2.1507e-05, 3.4661e-06],
        [0.0000e+00, 1.9604e-05, 2.0125e-06],
        [0.0000e+00, 2.3439e-05, 5.7472e-06],
        [0.0000e+00, 2.6215e-05, 3.9869e-06],
        [0.0000e+00, 1.8719e-05, 3.1767e-06],
        [0.0000e+00, 1.9491e-05, 3.5504e-06],
        [0.0000e+00, 2.9215e-05, 4.6100e-06],
        [0.0000e+00, 2.3846e-05, 5.1326e-06],
        [0.0000e+00, 1.8044e-05, 2.1927e-06],
        [0.0000e+00, 2.2319e-05, 3.8682e-06],
        [0.0000e+00, 4.0072e-05, 7.7337e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.4261e-05, 3.1092e-05, 2.8290e-05, 2.7781e-05, 2.6934e-05, 3.3398e-05,
        1.8935e-05, 4.3263e-05, 2.5077e-05, 2.5226e-05, 3.3013e-05, 2.1470e-05,
        4.5631e-05, 3.5562e-05, 2.2187e-05, 1.9490e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.7664e-06, 5.1270e-06, 5.2359e-06, 4.3880e-06, 2.6877e-06, 6.7298e-06,
        3.7423e-06, 8.1138e-06, 6.6391e-06, 5.5823e-06, 6.1881e-06, 4.5521e-06,
        7.1074e-06, 8.1916e-06, 3.5909e-06, 2.2757e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.4261e-05, 3.7664e-06],
        [0.0000e+00, 3.1092e-05, 5.1270e-06],
        [0.0000e+00, 2.8290e-05, 5.2359e-06],
        [0.0000e+00, 2.7781e-05, 4.3880e-06],
        [0.0000e+00, 2.6934e-05, 2.6877e-06],
        [0.0000e+00, 3.3398e-05, 6.7298e-06],
        [0.0000e+00, 1.8935e-05, 3.7423e-06],
        [0.0000e+00, 4.3263e-05, 8.1138e-06],
        [0.0000e+00, 2.5077e-05, 6.6391e-06],
        [0.0000e+00, 2.5226e-05, 5.5823e-06],
        [0.0000e+00, 3.3013e-05, 6.1881e-06],
        [0.0000e+00, 2.1470e-05, 4.5521e-06],
        [0.0000e+00, 4.5631e-05, 7.1074e-06],
        [0.0000e+00, 3.5562e-05, 8.1916e-06],
        [0.0000e+00, 2.2187e-05, 3.5909e-06],
        [0.0000e+00, 1.9490e-05, 2.2757e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type auxiliary, variation 1 and batchsize 16: 0:03:09.718002
path ['42', 'de', 'bloom', 'NLI', 'auxiliary', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m NLI auxiliary 2 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 286.56it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.7556e-05, 2.4528e-05, 2.0454e-05, 3.6658e-05, 1.1876e-05, 1.6832e-05,
        2.3218e-05, 2.4928e-05, 2.8484e-05, 3.1292e-05, 2.3176e-05, 2.3197e-05,
        1.5532e-05, 1.7961e-05, 1.7088e-05, 1.6894e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.3035e-06, 4.1552e-06, 3.4563e-06, 8.9637e-06, 3.6831e-06, 3.4068e-06,
        2.4177e-06, 4.6176e-06, 5.1293e-06, 8.4649e-06, 3.8300e-06, 5.7290e-06,
        2.1331e-06, 3.9685e-06, 2.2057e-06, 2.2461e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.7556e-05, 4.3035e-06],
        [0.0000e+00, 2.4528e-05, 4.1552e-06],
        [0.0000e+00, 2.0454e-05, 3.4563e-06],
        [0.0000e+00, 3.6658e-05, 8.9637e-06],
        [0.0000e+00, 1.1876e-05, 3.6831e-06],
        [0.0000e+00, 1.6832e-05, 3.4068e-06],
        [0.0000e+00, 2.3218e-05, 2.4177e-06],
        [0.0000e+00, 2.4928e-05, 4.6176e-06],
        [0.0000e+00, 2.8484e-05, 5.1293e-06],
        [0.0000e+00, 3.1292e-05, 8.4649e-06],
        [0.0000e+00, 2.3176e-05, 3.8300e-06],
        [0.0000e+00, 2.3197e-05, 5.7290e-06],
        [0.0000e+00, 1.5532e-05, 2.1331e-06],
        [0.0000e+00, 1.7961e-05, 3.9685e-06],
        [0.0000e+00, 1.7088e-05, 2.2057e-06],
        [0.0000e+00, 1.6894e-05, 2.2461e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2173e-05, 3.8518e-05, 2.4568e-05, 2.8928e-05, 3.5201e-05, 1.6922e-05,
        2.0455e-05, 2.5140e-05, 3.1471e-05, 4.0396e-05, 1.8203e-05, 2.8982e-05,
        2.5507e-05, 3.1567e-05, 1.9934e-05, 1.7060e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.6418e-06, 9.0421e-06, 4.3915e-06, 6.7207e-06, 8.2747e-06, 2.2016e-06,
        5.3640e-06, 5.8720e-06, 6.7532e-06, 7.1578e-06, 4.2387e-06, 5.1195e-06,
        5.4019e-06, 7.2988e-06, 4.0311e-06, 4.3113e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2173e-05, 5.6418e-06],
        [0.0000e+00, 3.8518e-05, 9.0421e-06],
        [0.0000e+00, 2.4568e-05, 4.3915e-06],
        [0.0000e+00, 2.8928e-05, 6.7207e-06],
        [0.0000e+00, 3.5201e-05, 8.2747e-06],
        [0.0000e+00, 1.6922e-05, 2.2016e-06],
        [0.0000e+00, 2.0455e-05, 5.3640e-06],
        [0.0000e+00, 2.5140e-05, 5.8720e-06],
        [0.0000e+00, 3.1471e-05, 6.7532e-06],
        [0.0000e+00, 4.0396e-05, 7.1578e-06],
        [0.0000e+00, 1.8203e-05, 4.2387e-06],
        [0.0000e+00, 2.8982e-05, 5.1195e-06],
        [0.0000e+00, 2.5507e-05, 5.4019e-06],
        [0.0000e+00, 3.1567e-05, 7.2988e-06],
        [0.0000e+00, 1.9934e-05, 4.0311e-06],
        [0.0000e+00, 1.7060e-05, 4.3113e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.9306e-05, 2.3159e-05, 1.8559e-05, 1.5167e-05, 1.9590e-05, 2.5191e-05,
        3.2567e-05, 3.9576e-05, 2.2870e-05, 2.3353e-05, 1.6446e-05, 1.5962e-05,
        1.9018e-05, 2.0261e-05, 3.0649e-05, 1.6396e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.5486e-06, 3.0176e-06, 2.8885e-06, 3.8198e-06, 5.2324e-06, 5.0946e-06,
        6.2198e-06, 8.6103e-06, 6.5215e-06, 5.4402e-06, 3.6089e-06, 1.8132e-06,
        4.9525e-06, 4.2337e-06, 6.1182e-06, 3.1000e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.9306e-05, 3.5486e-06],
        [0.0000e+00, 2.3159e-05, 3.0176e-06],
        [0.0000e+00, 1.8559e-05, 2.8885e-06],
        [0.0000e+00, 1.5167e-05, 3.8198e-06],
        [0.0000e+00, 1.9590e-05, 5.2324e-06],
        [0.0000e+00, 2.5191e-05, 5.0946e-06],
        [0.0000e+00, 3.2567e-05, 6.2198e-06],
        [0.0000e+00, 3.9576e-05, 8.6103e-06],
        [0.0000e+00, 2.2870e-05, 6.5215e-06],
        [0.0000e+00, 2.3353e-05, 5.4402e-06],
        [0.0000e+00, 1.6446e-05, 3.6089e-06],
        [0.0000e+00, 1.5962e-05, 1.8132e-06],
        [0.0000e+00, 1.9018e-05, 4.9525e-06],
        [0.0000e+00, 2.0261e-05, 4.2337e-06],
        [0.0000e+00, 3.0649e-05, 6.1182e-06],
        [0.0000e+00, 1.6396e-05, 3.1000e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type auxiliary, variation 2 and batchsize 16: 0:02:51.632391
path ['42', 'de', 'bloom', 'NLI', 'auxiliary', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m NLI modal 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 282.31it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.1982e-05, 1.6388e-05, 1.5486e-05, 2.4162e-05, 2.6811e-05, 2.1660e-05,
        1.4121e-05, 1.9657e-05, 2.2302e-05, 3.2715e-05, 2.2610e-05, 2.2279e-05,
        1.8952e-05, 1.9342e-05, 1.4928e-05, 2.5761e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.1809e-06, 3.6975e-06, 1.8837e-06, 4.7254e-06, 2.7164e-06, 3.6965e-06,
        3.4712e-06, 2.8815e-06, 5.0344e-06, 5.9167e-06, 5.5590e-06, 4.1028e-06,
        3.2665e-06, 3.3601e-06, 2.9005e-06, 3.9081e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.1982e-05, 2.1809e-06],
        [0.0000e+00, 1.6388e-05, 3.6975e-06],
        [0.0000e+00, 1.5486e-05, 1.8837e-06],
        [0.0000e+00, 2.4162e-05, 4.7254e-06],
        [0.0000e+00, 2.6811e-05, 2.7164e-06],
        [0.0000e+00, 2.1660e-05, 3.6965e-06],
        [0.0000e+00, 1.4121e-05, 3.4712e-06],
        [0.0000e+00, 1.9657e-05, 2.8815e-06],
        [0.0000e+00, 2.2302e-05, 5.0344e-06],
        [0.0000e+00, 3.2715e-05, 5.9167e-06],
        [0.0000e+00, 2.2610e-05, 5.5590e-06],
        [0.0000e+00, 2.2279e-05, 4.1028e-06],
        [0.0000e+00, 1.8952e-05, 3.2665e-06],
        [0.0000e+00, 1.9342e-05, 3.3601e-06],
        [0.0000e+00, 1.4928e-05, 2.9005e-06],
        [0.0000e+00, 2.5761e-05, 3.9081e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.9323e-05, 2.3657e-05, 2.5843e-05, 2.2250e-05, 1.9996e-05, 1.2819e-05,
        3.3743e-05, 1.8083e-05, 2.5093e-05, 1.5573e-05, 2.4234e-05, 2.4123e-05,
        2.9271e-05, 1.7435e-05, 1.7058e-05, 2.2975e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.3839e-06, 4.7515e-06, 5.5653e-06, 4.4082e-06, 3.4639e-06, 2.5415e-06,
        5.6109e-06, 4.0169e-06, 3.8263e-06, 2.0795e-06, 4.3721e-06, 3.8013e-06,
        4.4608e-06, 2.6816e-06, 2.9555e-06, 3.6083e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.9323e-05, 3.3839e-06],
        [0.0000e+00, 2.3657e-05, 4.7515e-06],
        [0.0000e+00, 2.5843e-05, 5.5653e-06],
        [0.0000e+00, 2.2250e-05, 4.4082e-06],
        [0.0000e+00, 1.9996e-05, 3.4639e-06],
        [0.0000e+00, 1.2819e-05, 2.5415e-06],
        [0.0000e+00, 3.3743e-05, 5.6109e-06],
        [0.0000e+00, 1.8083e-05, 4.0169e-06],
        [0.0000e+00, 2.5093e-05, 3.8263e-06],
        [0.0000e+00, 1.5573e-05, 2.0795e-06],
        [0.0000e+00, 2.4234e-05, 4.3721e-06],
        [0.0000e+00, 2.4123e-05, 3.8013e-06],
        [0.0000e+00, 2.9271e-05, 4.4608e-06],
        [0.0000e+00, 1.7435e-05, 2.6816e-06],
        [0.0000e+00, 1.7058e-05, 2.9555e-06],
        [0.0000e+00, 2.2975e-05, 3.6083e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.8468e-05, 2.3908e-05, 2.3214e-05, 1.7153e-05, 2.0104e-05, 2.8492e-05,
        3.3328e-05, 2.4667e-05, 2.0319e-05, 1.8381e-05, 2.4824e-05, 1.7205e-05,
        1.8665e-05, 1.7371e-05, 1.3883e-05, 1.5198e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.0781e-06, 3.3681e-06, 4.2368e-06, 3.6316e-06, 3.7112e-06, 3.7562e-06,
        5.1191e-06, 2.2011e-06, 2.3580e-06, 3.0827e-06, 5.3506e-06, 3.6347e-06,
        2.1955e-06, 4.5405e-06, 2.6954e-06, 2.2271e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.8468e-05, 4.0781e-06],
        [0.0000e+00, 2.3908e-05, 3.3681e-06],
        [0.0000e+00, 2.3214e-05, 4.2368e-06],
        [0.0000e+00, 1.7153e-05, 3.6316e-06],
        [0.0000e+00, 2.0104e-05, 3.7112e-06],
        [0.0000e+00, 2.8492e-05, 3.7562e-06],
        [0.0000e+00, 3.3328e-05, 5.1191e-06],
        [0.0000e+00, 2.4667e-05, 2.2011e-06],
        [0.0000e+00, 2.0319e-05, 2.3580e-06],
        [0.0000e+00, 1.8381e-05, 3.0827e-06],
        [0.0000e+00, 2.4824e-05, 5.3506e-06],
        [0.0000e+00, 1.7205e-05, 3.6347e-06],
        [0.0000e+00, 1.8665e-05, 2.1955e-06],
        [0.0000e+00, 1.7371e-05, 4.5405e-06],
        [0.0000e+00, 1.3883e-05, 2.6954e-06],
        [0.0000e+00, 1.5198e-05, 2.2271e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type modal, variation 0 and batchsize 16: 0:02:52.311939
path ['42', 'de', 'bloom', 'NLI', 'modal', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m NLI modal 1 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 296.56it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5320e-05, 1.9171e-05, 2.1876e-05, 2.1163e-05, 2.5577e-05, 1.5166e-05,
        2.3273e-05, 1.6223e-05, 1.5689e-05, 2.0491e-05, 2.1379e-05, 1.7247e-05,
        3.5745e-05, 1.8479e-05, 2.3350e-05, 1.8710e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.5953e-06, 3.9110e-06, 5.2379e-06, 4.5559e-06, 5.3469e-06, 3.8749e-06,
        3.8097e-06, 3.2791e-06, 3.2452e-06, 3.1892e-06, 4.1062e-06, 2.3100e-06,
        6.7273e-06, 3.7801e-06, 4.5663e-06, 4.7124e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5320e-05, 4.5953e-06],
        [0.0000e+00, 1.9171e-05, 3.9110e-06],
        [0.0000e+00, 2.1876e-05, 5.2379e-06],
        [0.0000e+00, 2.1163e-05, 4.5559e-06],
        [0.0000e+00, 2.5577e-05, 5.3469e-06],
        [0.0000e+00, 1.5166e-05, 3.8749e-06],
        [0.0000e+00, 2.3273e-05, 3.8097e-06],
        [0.0000e+00, 1.6223e-05, 3.2791e-06],
        [0.0000e+00, 1.5689e-05, 3.2452e-06],
        [0.0000e+00, 2.0491e-05, 3.1892e-06],
        [0.0000e+00, 2.1379e-05, 4.1062e-06],
        [0.0000e+00, 1.7247e-05, 2.3100e-06],
        [0.0000e+00, 3.5745e-05, 6.7273e-06],
        [0.0000e+00, 1.8479e-05, 3.7801e-06],
        [0.0000e+00, 2.3350e-05, 4.5663e-06],
        [0.0000e+00, 1.8710e-05, 4.7124e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.3131e-05, 2.6340e-05, 2.6755e-05, 1.4032e-05, 3.1511e-05, 3.8266e-05,
        2.5596e-05, 1.4277e-05, 1.2155e-05, 2.3220e-05, 1.7861e-05, 1.5445e-05,
        2.4545e-05, 1.4823e-05, 2.6177e-05, 1.3102e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.6364e-06, 5.9800e-06, 4.6160e-06, 2.9063e-06, 5.0847e-06, 7.8161e-06,
        5.3616e-06, 2.4152e-06, 2.3416e-06, 3.0262e-06, 5.5770e-06, 2.0011e-06,
        3.2073e-06, 2.2508e-06, 4.4944e-06, 2.7471e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.3131e-05, 4.6364e-06],
        [0.0000e+00, 2.6340e-05, 5.9800e-06],
        [0.0000e+00, 2.6755e-05, 4.6160e-06],
        [0.0000e+00, 1.4032e-05, 2.9063e-06],
        [0.0000e+00, 3.1511e-05, 5.0847e-06],
        [0.0000e+00, 3.8266e-05, 7.8161e-06],
        [0.0000e+00, 2.5596e-05, 5.3616e-06],
        [0.0000e+00, 1.4277e-05, 2.4152e-06],
        [0.0000e+00, 1.2155e-05, 2.3416e-06],
        [0.0000e+00, 2.3220e-05, 3.0262e-06],
        [0.0000e+00, 1.7861e-05, 5.5770e-06],
        [0.0000e+00, 1.5445e-05, 2.0011e-06],
        [0.0000e+00, 2.4545e-05, 3.2073e-06],
        [0.0000e+00, 1.4823e-05, 2.2508e-06],
        [0.0000e+00, 2.6177e-05, 4.4944e-06],
        [0.0000e+00, 1.3102e-05, 2.7471e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.1911e-05, 2.4225e-05, 1.9154e-05, 2.1570e-05, 1.8390e-05, 1.8151e-05,
        1.7113e-05, 2.5836e-05, 2.2053e-05, 1.9567e-05, 2.4555e-05, 2.8547e-05,
        2.7842e-05, 1.8780e-05, 1.8998e-05, 1.7516e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.4986e-06, 5.5223e-06, 3.6848e-06, 4.1564e-06, 3.9906e-06, 3.6910e-06,
        4.5861e-06, 6.0670e-06, 4.1283e-06, 4.4888e-06, 6.4967e-06, 3.9799e-06,
        6.5350e-06, 2.5706e-06, 3.7110e-06, 4.2737e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.1911e-05, 5.4986e-06],
        [0.0000e+00, 2.4225e-05, 5.5223e-06],
        [0.0000e+00, 1.9154e-05, 3.6848e-06],
        [0.0000e+00, 2.1570e-05, 4.1564e-06],
        [0.0000e+00, 1.8390e-05, 3.9906e-06],
        [0.0000e+00, 1.8151e-05, 3.6910e-06],
        [0.0000e+00, 1.7113e-05, 4.5861e-06],
        [0.0000e+00, 2.5836e-05, 6.0670e-06],
        [0.0000e+00, 2.2053e-05, 4.1283e-06],
        [0.0000e+00, 1.9567e-05, 4.4888e-06],
        [0.0000e+00, 2.4555e-05, 6.4967e-06],
        [0.0000e+00, 2.8547e-05, 3.9799e-06],
        [0.0000e+00, 2.7842e-05, 6.5350e-06],
        [0.0000e+00, 1.8780e-05, 2.5706e-06],
        [0.0000e+00, 1.8998e-05, 3.7110e-06],
        [0.0000e+00, 1.7516e-05, 4.2737e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type modal, variation 1 and batchsize 16: 0:02:51.333244
path ['42', 'de', 'bloom', 'NLI', 'modal', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m NLI modal 2 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 294.65it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4096e-05, 2.3355e-05, 2.8258e-05, 1.7451e-05, 2.5275e-05, 2.0913e-05,
        1.3186e-05, 1.7078e-05, 3.0949e-05, 2.0438e-05, 2.9298e-05, 1.6703e-05,
        1.9715e-05, 2.1840e-05, 2.1120e-05, 2.1376e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.5624e-06, 5.6948e-06, 6.3869e-06, 1.9332e-06, 6.8482e-06, 6.8912e-06,
        2.3001e-06, 4.6439e-06, 6.5678e-06, 3.0960e-06, 6.7865e-06, 5.0690e-06,
        6.3537e-06, 6.4548e-06, 4.8086e-06, 4.9372e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4096e-05, 5.5624e-06],
        [0.0000e+00, 2.3355e-05, 5.6948e-06],
        [0.0000e+00, 2.8258e-05, 6.3869e-06],
        [0.0000e+00, 1.7451e-05, 1.9332e-06],
        [0.0000e+00, 2.5275e-05, 6.8482e-06],
        [0.0000e+00, 2.0913e-05, 6.8912e-06],
        [0.0000e+00, 1.3186e-05, 2.3001e-06],
        [0.0000e+00, 1.7078e-05, 4.6439e-06],
        [0.0000e+00, 3.0949e-05, 6.5678e-06],
        [0.0000e+00, 2.0438e-05, 3.0960e-06],
        [0.0000e+00, 2.9298e-05, 6.7865e-06],
        [0.0000e+00, 1.6703e-05, 5.0690e-06],
        [0.0000e+00, 1.9715e-05, 6.3537e-06],
        [0.0000e+00, 2.1840e-05, 6.4548e-06],
        [0.0000e+00, 2.1120e-05, 4.8086e-06],
        [0.0000e+00, 2.1376e-05, 4.9372e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.3607e-05, 3.4597e-05, 4.3879e-05, 2.6139e-05, 2.3477e-05, 2.3644e-05,
        2.9931e-05, 1.6123e-05, 3.6665e-05, 2.4200e-05, 2.5283e-05, 2.2754e-05,
        2.4383e-05, 3.4011e-05, 2.0224e-05, 2.1087e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.9875e-06, 8.6497e-06, 6.5982e-06, 6.3816e-06, 5.0432e-06, 7.0847e-06,
        5.0226e-06, 3.4712e-06, 9.4272e-06, 7.8453e-06, 6.3075e-06, 5.6290e-06,
        5.4254e-06, 1.0755e-05, 3.1870e-06, 4.6401e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.3607e-05, 5.9875e-06],
        [0.0000e+00, 3.4597e-05, 8.6497e-06],
        [0.0000e+00, 4.3879e-05, 6.5982e-06],
        [0.0000e+00, 2.6139e-05, 6.3816e-06],
        [0.0000e+00, 2.3477e-05, 5.0432e-06],
        [0.0000e+00, 2.3644e-05, 7.0847e-06],
        [0.0000e+00, 2.9931e-05, 5.0226e-06],
        [0.0000e+00, 1.6123e-05, 3.4712e-06],
        [0.0000e+00, 3.6665e-05, 9.4272e-06],
        [0.0000e+00, 2.4200e-05, 7.8453e-06],
        [0.0000e+00, 2.5283e-05, 6.3075e-06],
        [0.0000e+00, 2.2754e-05, 5.6290e-06],
        [0.0000e+00, 2.4383e-05, 5.4254e-06],
        [0.0000e+00, 3.4011e-05, 1.0755e-05],
        [0.0000e+00, 2.0224e-05, 3.1870e-06],
        [0.0000e+00, 2.1087e-05, 4.6401e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2910e-05, 3.4696e-05, 1.7692e-05, 1.4924e-05, 2.1020e-05, 2.7734e-05,
        2.3146e-05, 2.4149e-05, 1.6659e-05, 2.8682e-05, 2.7541e-05, 3.0264e-05,
        2.9624e-05, 3.4386e-05, 2.1271e-05, 2.2100e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([6.6720e-06, 5.5075e-06, 5.4837e-06, 2.9701e-06, 5.7537e-06, 6.0029e-06,
        6.6826e-06, 5.5510e-06, 2.4337e-06, 5.8885e-06, 7.4714e-06, 4.2977e-06,
        6.0849e-06, 1.0806e-05, 4.6398e-06, 5.6202e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2910e-05, 6.6720e-06],
        [0.0000e+00, 3.4696e-05, 5.5075e-06],
        [0.0000e+00, 1.7692e-05, 5.4837e-06],
        [0.0000e+00, 1.4924e-05, 2.9701e-06],
        [0.0000e+00, 2.1020e-05, 5.7537e-06],
        [0.0000e+00, 2.7734e-05, 6.0029e-06],
        [0.0000e+00, 2.3146e-05, 6.6826e-06],
        [0.0000e+00, 2.4149e-05, 5.5510e-06],
        [0.0000e+00, 1.6659e-05, 2.4337e-06],
        [0.0000e+00, 2.8682e-05, 5.8885e-06],
        [0.0000e+00, 2.7541e-05, 7.4714e-06],
        [0.0000e+00, 3.0264e-05, 4.2977e-06],
        [0.0000e+00, 2.9624e-05, 6.0849e-06],
        [0.0000e+00, 3.4386e-05, 1.0806e-05],
        [0.0000e+00, 2.1271e-05, 4.6398e-06],
        [0.0000e+00, 2.2100e-05, 5.6202e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type modal, variation 2 and batchsize 16: 0:02:51.353883
path ['42', 'de', 'bloom', 'NLI', 'modal', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m NLI rare_synonyms 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 318.51it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.6030e-05, 1.0845e-05, 2.3872e-05, 1.5679e-05, 1.5670e-05, 1.8638e-05,
        1.8330e-05, 2.2576e-05, 2.4384e-05, 1.9433e-05, 2.2825e-05, 1.6836e-05,
        2.1426e-05, 2.3789e-05, 2.0582e-05, 3.1130e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.8188e-06, 2.4127e-06, 4.1965e-06, 3.9401e-06, 4.1389e-06, 3.1734e-06,
        4.0149e-06, 4.9907e-06, 6.1227e-06, 2.6019e-06, 4.1836e-06, 3.1591e-06,
        3.4929e-06, 2.8071e-06, 4.6790e-06, 5.9119e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.6030e-05, 4.8188e-06],
        [0.0000e+00, 1.0845e-05, 2.4127e-06],
        [0.0000e+00, 2.3872e-05, 4.1965e-06],
        [0.0000e+00, 1.5679e-05, 3.9401e-06],
        [0.0000e+00, 1.5670e-05, 4.1389e-06],
        [0.0000e+00, 1.8638e-05, 3.1734e-06],
        [0.0000e+00, 1.8330e-05, 4.0149e-06],
        [0.0000e+00, 2.2576e-05, 4.9907e-06],
        [0.0000e+00, 2.4384e-05, 6.1227e-06],
        [0.0000e+00, 1.9433e-05, 2.6019e-06],
        [0.0000e+00, 2.2825e-05, 4.1836e-06],
        [0.0000e+00, 1.6836e-05, 3.1591e-06],
        [0.0000e+00, 2.1426e-05, 3.4929e-06],
        [0.0000e+00, 2.3789e-05, 2.8071e-06],
        [0.0000e+00, 2.0582e-05, 4.6790e-06],
        [0.0000e+00, 3.1130e-05, 5.9119e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.1630e-05, 2.5623e-05, 1.2642e-05, 2.2419e-05, 1.3647e-05, 1.8457e-05,
        1.6150e-05, 3.0776e-05, 1.8878e-05, 1.6609e-05, 3.2762e-05, 2.3845e-05,
        2.5870e-05, 2.1856e-05, 1.4091e-05, 2.3156e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.4151e-06, 4.5439e-06, 2.8970e-06, 2.5090e-06, 3.1110e-06, 3.7569e-06,
        4.9029e-06, 6.4811e-06, 3.8217e-06, 4.2331e-06, 6.1322e-06, 5.8197e-06,
        4.0810e-06, 6.1693e-06, 2.2646e-06, 5.3099e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.1630e-05, 5.4151e-06],
        [0.0000e+00, 2.5623e-05, 4.5439e-06],
        [0.0000e+00, 1.2642e-05, 2.8970e-06],
        [0.0000e+00, 2.2419e-05, 2.5090e-06],
        [0.0000e+00, 1.3647e-05, 3.1110e-06],
        [0.0000e+00, 1.8457e-05, 3.7569e-06],
        [0.0000e+00, 1.6150e-05, 4.9029e-06],
        [0.0000e+00, 3.0776e-05, 6.4811e-06],
        [0.0000e+00, 1.8878e-05, 3.8217e-06],
        [0.0000e+00, 1.6609e-05, 4.2331e-06],
        [0.0000e+00, 3.2762e-05, 6.1322e-06],
        [0.0000e+00, 2.3845e-05, 5.8197e-06],
        [0.0000e+00, 2.5870e-05, 4.0810e-06],
        [0.0000e+00, 2.1856e-05, 6.1693e-06],
        [0.0000e+00, 1.4091e-05, 2.2646e-06],
        [0.0000e+00, 2.3156e-05, 5.3099e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2744e-05, 1.7898e-05, 1.6131e-05, 2.1954e-05, 1.7491e-05, 1.7410e-05,
        2.1466e-05, 1.9826e-05, 1.3868e-05, 1.6023e-05, 1.7631e-05, 1.3694e-05,
        1.4828e-05, 1.4027e-05, 2.1643e-05, 1.7645e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.4347e-06, 3.6261e-06, 3.2037e-06, 4.8237e-06, 2.4039e-06, 3.5943e-06,
        3.9062e-06, 4.1061e-06, 3.2092e-06, 4.1457e-06, 3.7324e-06, 3.7403e-06,
        2.3433e-06, 2.4786e-06, 4.6604e-06, 4.6178e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2744e-05, 5.4347e-06],
        [0.0000e+00, 1.7898e-05, 3.6261e-06],
        [0.0000e+00, 1.6131e-05, 3.2037e-06],
        [0.0000e+00, 2.1954e-05, 4.8237e-06],
        [0.0000e+00, 1.7491e-05, 2.4039e-06],
        [0.0000e+00, 1.7410e-05, 3.5943e-06],
        [0.0000e+00, 2.1466e-05, 3.9062e-06],
        [0.0000e+00, 1.9826e-05, 4.1061e-06],
        [0.0000e+00, 1.3868e-05, 3.2092e-06],
        [0.0000e+00, 1.6023e-05, 4.1457e-06],
        [0.0000e+00, 1.7631e-05, 3.7324e-06],
        [0.0000e+00, 1.3694e-05, 3.7403e-06],
        [0.0000e+00, 1.4828e-05, 2.3433e-06],
        [0.0000e+00, 1.4027e-05, 2.4786e-06],
        [0.0000e+00, 2.1643e-05, 4.6604e-06],
        [0.0000e+00, 1.7645e-05, 4.6178e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type rare_synonyms, variation 0 and batchsize 16: 0:02:51.510865
path ['42', 'de', 'bloom', 'NLI', 'rare_synonyms', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m NLI rare_synonyms 1 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 316.42it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.8149e-05, 1.4827e-05, 2.0106e-05, 1.1461e-05, 2.3724e-05, 1.6794e-05,
        1.6813e-05, 1.8831e-05, 2.4705e-05, 2.3086e-05, 1.6340e-05, 1.5841e-05,
        2.0178e-05, 2.2641e-05, 3.2304e-05, 2.6333e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.2688e-06, 2.0392e-06, 2.2846e-06, 2.0955e-06, 2.1631e-06, 2.7093e-06,
        3.7780e-06, 3.3229e-06, 5.4033e-06, 5.7487e-06, 2.8575e-06, 3.5589e-06,
        4.2083e-06, 4.6281e-06, 5.3778e-06, 4.0820e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.8149e-05, 3.2688e-06],
        [0.0000e+00, 1.4827e-05, 2.0392e-06],
        [0.0000e+00, 2.0106e-05, 2.2846e-06],
        [0.0000e+00, 1.1461e-05, 2.0955e-06],
        [0.0000e+00, 2.3724e-05, 2.1631e-06],
        [0.0000e+00, 1.6794e-05, 2.7093e-06],
        [0.0000e+00, 1.6813e-05, 3.7780e-06],
        [0.0000e+00, 1.8831e-05, 3.3229e-06],
        [0.0000e+00, 2.4705e-05, 5.4033e-06],
        [0.0000e+00, 2.3086e-05, 5.7487e-06],
        [0.0000e+00, 1.6340e-05, 2.8575e-06],
        [0.0000e+00, 1.5841e-05, 3.5589e-06],
        [0.0000e+00, 2.0178e-05, 4.2083e-06],
        [0.0000e+00, 2.2641e-05, 4.6281e-06],
        [0.0000e+00, 3.2304e-05, 5.3778e-06],
        [0.0000e+00, 2.6333e-05, 4.0820e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.9325e-05, 1.6279e-05, 2.3063e-05, 2.2237e-05, 2.2097e-05, 2.4803e-05,
        1.2103e-05, 2.4533e-05, 3.1122e-05, 1.6606e-05, 2.4045e-05, 1.4230e-05,
        2.2954e-05, 1.9425e-05, 1.4884e-05, 3.2115e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.7050e-06, 3.6597e-06, 3.7170e-06, 3.9620e-06, 4.9131e-06, 3.2537e-06,
        2.3285e-06, 3.9207e-06, 5.8259e-06, 4.3230e-06, 5.1752e-06, 3.5295e-06,
        4.5809e-06, 3.3761e-06, 2.1933e-06, 5.4717e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.9325e-05, 2.7050e-06],
        [0.0000e+00, 1.6279e-05, 3.6597e-06],
        [0.0000e+00, 2.3063e-05, 3.7170e-06],
        [0.0000e+00, 2.2237e-05, 3.9620e-06],
        [0.0000e+00, 2.2097e-05, 4.9131e-06],
        [0.0000e+00, 2.4803e-05, 3.2537e-06],
        [0.0000e+00, 1.2103e-05, 2.3285e-06],
        [0.0000e+00, 2.4533e-05, 3.9207e-06],
        [0.0000e+00, 3.1122e-05, 5.8259e-06],
        [0.0000e+00, 1.6606e-05, 4.3230e-06],
        [0.0000e+00, 2.4045e-05, 5.1752e-06],
        [0.0000e+00, 1.4230e-05, 3.5295e-06],
        [0.0000e+00, 2.2954e-05, 4.5809e-06],
        [0.0000e+00, 1.9425e-05, 3.3761e-06],
        [0.0000e+00, 1.4884e-05, 2.1933e-06],
        [0.0000e+00, 3.2115e-05, 5.4717e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2169e-05, 1.9731e-05, 1.5714e-05, 1.5730e-05, 2.6449e-05, 2.5980e-05,
        1.7806e-05, 1.3780e-05, 1.7754e-05, 2.0436e-05, 2.6799e-05, 1.8119e-05,
        2.1700e-05, 1.8574e-05, 2.2035e-05, 1.4299e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.3824e-06, 2.1921e-06, 3.5290e-06, 1.7892e-06, 2.6569e-06, 3.9488e-06,
        3.0496e-06, 2.7399e-06, 3.8761e-06, 3.6191e-06, 3.5547e-06, 3.3020e-06,
        4.0622e-06, 3.5525e-06, 4.1138e-06, 2.8517e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2169e-05, 3.3824e-06],
        [0.0000e+00, 1.9731e-05, 2.1921e-06],
        [0.0000e+00, 1.5714e-05, 3.5290e-06],
        [0.0000e+00, 1.5730e-05, 1.7892e-06],
        [0.0000e+00, 2.6449e-05, 2.6569e-06],
        [0.0000e+00, 2.5980e-05, 3.9488e-06],
        [0.0000e+00, 1.7806e-05, 3.0496e-06],
        [0.0000e+00, 1.3780e-05, 2.7399e-06],
        [0.0000e+00, 1.7754e-05, 3.8761e-06],
        [0.0000e+00, 2.0436e-05, 3.6191e-06],
        [0.0000e+00, 2.6799e-05, 3.5547e-06],
        [0.0000e+00, 1.8119e-05, 3.3020e-06],
        [0.0000e+00, 2.1700e-05, 4.0622e-06],
        [0.0000e+00, 1.8574e-05, 3.5525e-06],
        [0.0000e+00, 2.2035e-05, 4.1138e-06],
        [0.0000e+00, 1.4299e-05, 2.8517e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type rare_synonyms, variation 1 and batchsize 16: 0:02:51.811024
path ['42', 'de', 'bloom', 'NLI', 'rare_synonyms', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m NLI rare_synonyms 2 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 281.72it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.3327e-05, 2.3150e-05, 1.6735e-05, 1.5824e-05, 2.0899e-05, 3.2782e-05,
        1.7934e-05, 1.4440e-05, 2.7207e-05, 2.0023e-05, 1.4314e-05, 1.7238e-05,
        1.9273e-05, 1.8132e-05, 2.3906e-05, 3.1994e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.8050e-06, 2.2024e-06, 2.9134e-06, 2.1623e-06, 3.8811e-06, 5.7027e-06,
        3.2072e-06, 1.9394e-06, 3.8079e-06, 2.5110e-06, 2.8508e-06, 3.9153e-06,
        3.7433e-06, 4.1120e-06, 4.8628e-06, 6.1621e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.3327e-05, 2.8050e-06],
        [0.0000e+00, 2.3150e-05, 2.2024e-06],
        [0.0000e+00, 1.6735e-05, 2.9134e-06],
        [0.0000e+00, 1.5824e-05, 2.1623e-06],
        [0.0000e+00, 2.0899e-05, 3.8811e-06],
        [0.0000e+00, 3.2782e-05, 5.7027e-06],
        [0.0000e+00, 1.7934e-05, 3.2072e-06],
        [0.0000e+00, 1.4440e-05, 1.9394e-06],
        [0.0000e+00, 2.7207e-05, 3.8079e-06],
        [0.0000e+00, 2.0023e-05, 2.5110e-06],
        [0.0000e+00, 1.4314e-05, 2.8508e-06],
        [0.0000e+00, 1.7238e-05, 3.9153e-06],
        [0.0000e+00, 1.9273e-05, 3.7433e-06],
        [0.0000e+00, 1.8132e-05, 4.1120e-06],
        [0.0000e+00, 2.3906e-05, 4.8628e-06],
        [0.0000e+00, 3.1994e-05, 6.1621e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.1244e-05, 1.8630e-05, 1.7005e-05, 1.8198e-05, 1.4701e-05, 2.4233e-05,
        1.2239e-05, 2.5217e-05, 1.6038e-05, 2.1501e-05, 2.3507e-05, 2.2718e-05,
        2.2325e-05, 2.4724e-05, 1.6236e-05, 1.9677e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.2078e-06, 3.3680e-06, 2.7700e-06, 3.2637e-06, 2.2414e-06, 4.4020e-06,
        2.5370e-06, 2.6939e-06, 3.6568e-06, 4.4915e-06, 3.8775e-06, 4.8242e-06,
        4.3062e-06, 3.9766e-06, 3.7813e-06, 3.5898e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.1244e-05, 2.2078e-06],
        [0.0000e+00, 1.8630e-05, 3.3680e-06],
        [0.0000e+00, 1.7005e-05, 2.7700e-06],
        [0.0000e+00, 1.8198e-05, 3.2637e-06],
        [0.0000e+00, 1.4701e-05, 2.2414e-06],
        [0.0000e+00, 2.4233e-05, 4.4020e-06],
        [0.0000e+00, 1.2239e-05, 2.5370e-06],
        [0.0000e+00, 2.5217e-05, 2.6939e-06],
        [0.0000e+00, 1.6038e-05, 3.6568e-06],
        [0.0000e+00, 2.1501e-05, 4.4915e-06],
        [0.0000e+00, 2.3507e-05, 3.8775e-06],
        [0.0000e+00, 2.2718e-05, 4.8242e-06],
        [0.0000e+00, 2.2325e-05, 4.3062e-06],
        [0.0000e+00, 2.4724e-05, 3.9766e-06],
        [0.0000e+00, 1.6236e-05, 3.7813e-06],
        [0.0000e+00, 1.9677e-05, 3.5898e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.8084e-05, 1.9078e-05, 2.2350e-05, 1.8249e-05, 3.0771e-05, 1.5980e-05,
        1.7114e-05, 2.1681e-05, 2.8746e-05, 2.5078e-05, 1.3975e-05, 2.5612e-05,
        2.1809e-05, 2.3551e-05, 2.3218e-05, 2.1684e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.2798e-06, 2.9142e-06, 5.7100e-06, 3.3970e-06, 5.1836e-06, 3.6637e-06,
        4.5044e-06, 4.2133e-06, 4.6306e-06, 5.6662e-06, 3.4889e-06, 4.0957e-06,
        4.9694e-06, 5.2599e-06, 3.5122e-06, 3.5435e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.8084e-05, 2.2798e-06],
        [0.0000e+00, 1.9078e-05, 2.9142e-06],
        [0.0000e+00, 2.2350e-05, 5.7100e-06],
        [0.0000e+00, 1.8249e-05, 3.3970e-06],
        [0.0000e+00, 3.0771e-05, 5.1836e-06],
        [0.0000e+00, 1.5980e-05, 3.6637e-06],
        [0.0000e+00, 1.7114e-05, 4.5044e-06],
        [0.0000e+00, 2.1681e-05, 4.2133e-06],
        [0.0000e+00, 2.8746e-05, 4.6306e-06],
        [0.0000e+00, 2.5078e-05, 5.6662e-06],
        [0.0000e+00, 1.3975e-05, 3.4889e-06],
        [0.0000e+00, 2.5612e-05, 4.0957e-06],
        [0.0000e+00, 2.1809e-05, 4.9694e-06],
        [0.0000e+00, 2.3551e-05, 5.2599e-06],
        [0.0000e+00, 2.3218e-05, 3.5122e-06],
        [0.0000e+00, 2.1684e-05, 3.5435e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type rare_synonyms, variation 2 and batchsize 16: 0:02:50.325971
path ['42', 'de', 'bloom', 'NLI', 'rare_synonyms', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m SA active 0 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:00<00:00,  8.58it/s]100%|██████████| 3/3 [00:00<00:00, 23.79it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2706e-05, 1.7682e-05, 1.6060e-05, 1.9820e-05, 1.2454e-05, 1.4004e-05,
        1.2929e-05, 1.7120e-05, 3.6641e-05, 2.4527e-05, 2.3471e-05, 2.4000e-05,
        1.9555e-05, 1.8419e-05, 2.3337e-05, 5.6594e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2706e-05],
        [0.0000e+00, 1.7682e-05],
        [0.0000e+00, 1.6060e-05],
        [0.0000e+00, 1.9820e-05],
        [0.0000e+00, 1.2454e-05],
        [0.0000e+00, 1.4004e-05],
        [0.0000e+00, 1.2929e-05],
        [0.0000e+00, 1.7120e-05],
        [0.0000e+00, 3.6641e-05],
        [0.0000e+00, 2.4527e-05],
        [0.0000e+00, 2.3471e-05],
        [0.0000e+00, 2.4000e-05],
        [0.0000e+00, 1.9555e-05],
        [0.0000e+00, 1.8419e-05],
        [0.0000e+00, 2.3337e-05],
        [0.0000e+00, 5.6594e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2313e-05, 2.1659e-05, 1.8426e-05, 5.0004e-05, 2.7439e-05, 1.9815e-05,
        2.2092e-05, 2.5729e-05, 2.2121e-05, 3.1804e-05, 2.7916e-05, 2.6144e-05,
        1.7206e-05, 1.6766e-05, 6.8210e-05, 2.1916e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2313e-05],
        [0.0000e+00, 2.1659e-05],
        [0.0000e+00, 1.8426e-05],
        [0.0000e+00, 5.0004e-05],
        [0.0000e+00, 2.7439e-05],
        [0.0000e+00, 1.9815e-05],
        [0.0000e+00, 2.2092e-05],
        [0.0000e+00, 2.5729e-05],
        [0.0000e+00, 2.2121e-05],
        [0.0000e+00, 3.1804e-05],
        [0.0000e+00, 2.7916e-05],
        [0.0000e+00, 2.6144e-05],
        [0.0000e+00, 1.7206e-05],
        [0.0000e+00, 1.6766e-05],
        [0.0000e+00, 6.8210e-05],
        [0.0000e+00, 2.1916e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.4156e-05, 2.8115e-05, 4.7625e-05, 5.6530e-05, 1.2786e-05, 3.3790e-05,
        2.3765e-05, 2.1024e-05, 2.0985e-05, 1.8200e-05, 1.1639e-05, 2.5059e-05,
        2.1427e-05, 2.2252e-05, 2.3651e-05, 2.6770e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.4156e-05],
        [0.0000e+00, 2.8115e-05],
        [0.0000e+00, 4.7625e-05],
        [0.0000e+00, 5.6530e-05],
        [0.0000e+00, 1.2786e-05],
        [0.0000e+00, 3.3790e-05],
        [0.0000e+00, 2.3765e-05],
        [0.0000e+00, 2.1024e-05],
        [0.0000e+00, 2.0985e-05],
        [0.0000e+00, 1.8200e-05],
        [0.0000e+00, 1.1639e-05],
        [0.0000e+00, 2.5059e-05],
        [0.0000e+00, 2.1427e-05],
        [0.0000e+00, 2.2252e-05],
        [0.0000e+00, 2.3651e-05],
        [0.0000e+00, 2.6770e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([2.2269e-05, 1.4594e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 2.2269e-05],
        [0.0000e+00, 1.4594e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type active, variation 0 and batchsize 16: 0:03:34.387184
path ['42', 'de', 'bloom', 'SA', 'active', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m SA active 1 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 297.14it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5515e-05, 2.4916e-05, 2.2083e-05, 2.4715e-05, 2.0121e-05, 1.7087e-05,
        2.4152e-05, 2.4006e-05, 1.6634e-05, 3.1507e-05, 1.3072e-05, 5.7419e-05,
        1.9113e-05, 1.4944e-05, 1.8748e-05, 2.1388e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5515e-05],
        [0.0000e+00, 2.4916e-05],
        [0.0000e+00, 2.2083e-05],
        [0.0000e+00, 2.4715e-05],
        [0.0000e+00, 2.0121e-05],
        [0.0000e+00, 1.7087e-05],
        [0.0000e+00, 2.4152e-05],
        [0.0000e+00, 2.4006e-05],
        [0.0000e+00, 1.6634e-05],
        [0.0000e+00, 3.1507e-05],
        [0.0000e+00, 1.3072e-05],
        [0.0000e+00, 5.7419e-05],
        [0.0000e+00, 1.9113e-05],
        [0.0000e+00, 1.4944e-05],
        [0.0000e+00, 1.8748e-05],
        [0.0000e+00, 2.1388e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.2423e-05, 2.0939e-05, 1.8371e-05, 2.1109e-05, 1.2725e-05, 2.4855e-05,
        2.2606e-05, 4.6828e-05, 2.1053e-05, 1.8553e-05, 2.4927e-05, 2.7188e-05,
        2.7013e-05, 3.4670e-05, 2.6361e-05, 2.3966e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.2423e-05],
        [0.0000e+00, 2.0939e-05],
        [0.0000e+00, 1.8371e-05],
        [0.0000e+00, 2.1109e-05],
        [0.0000e+00, 1.2725e-05],
        [0.0000e+00, 2.4855e-05],
        [0.0000e+00, 2.2606e-05],
        [0.0000e+00, 4.6828e-05],
        [0.0000e+00, 2.1053e-05],
        [0.0000e+00, 1.8553e-05],
        [0.0000e+00, 2.4927e-05],
        [0.0000e+00, 2.7188e-05],
        [0.0000e+00, 2.7013e-05],
        [0.0000e+00, 3.4670e-05],
        [0.0000e+00, 2.6361e-05],
        [0.0000e+00, 2.3966e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.3126e-05, 1.4299e-05, 2.1964e-05, 1.7895e-05, 2.1913e-05, 6.2740e-05,
        2.1842e-05, 2.0761e-05, 2.0378e-05, 1.3954e-05, 2.5672e-05, 2.4671e-05,
        2.1250e-05, 2.1374e-05, 5.3607e-05, 6.6808e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.3126e-05],
        [0.0000e+00, 1.4299e-05],
        [0.0000e+00, 2.1964e-05],
        [0.0000e+00, 1.7895e-05],
        [0.0000e+00, 2.1913e-05],
        [0.0000e+00, 6.2740e-05],
        [0.0000e+00, 2.1842e-05],
        [0.0000e+00, 2.0761e-05],
        [0.0000e+00, 2.0378e-05],
        [0.0000e+00, 1.3954e-05],
        [0.0000e+00, 2.5672e-05],
        [0.0000e+00, 2.4671e-05],
        [0.0000e+00, 2.1250e-05],
        [0.0000e+00, 2.1374e-05],
        [0.0000e+00, 5.3607e-05],
        [0.0000e+00, 6.6808e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.6359e-05, 2.5382e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.6359e-05],
        [0.0000e+00, 2.5382e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type active, variation 1 and batchsize 16: 0:03:35.156413
path ['42', 'de', 'bloom', 'SA', 'active', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m SA active 2 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 320.09it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.7015e-05, 1.3198e-05, 2.0917e-05, 2.4460e-05, 1.9637e-05, 1.9587e-05,
        2.6428e-05, 2.2013e-05, 5.3600e-05, 2.0943e-05, 2.3259e-05, 2.1336e-05,
        1.4058e-05, 3.1444e-05, 2.6628e-05, 2.7755e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.7015e-05],
        [0.0000e+00, 1.3198e-05],
        [0.0000e+00, 2.0917e-05],
        [0.0000e+00, 2.4460e-05],
        [0.0000e+00, 1.9637e-05],
        [0.0000e+00, 1.9587e-05],
        [0.0000e+00, 2.6428e-05],
        [0.0000e+00, 2.2013e-05],
        [0.0000e+00, 5.3600e-05],
        [0.0000e+00, 2.0943e-05],
        [0.0000e+00, 2.3259e-05],
        [0.0000e+00, 2.1336e-05],
        [0.0000e+00, 1.4058e-05],
        [0.0000e+00, 3.1444e-05],
        [0.0000e+00, 2.6628e-05],
        [0.0000e+00, 2.7755e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4940e-05, 1.2726e-05, 2.0193e-05, 1.4883e-05, 1.8644e-05, 2.4821e-05,
        3.5492e-05, 1.3340e-05, 2.0879e-05, 1.8683e-05, 2.0498e-05, 2.2647e-05,
        2.0241e-05, 1.6987e-05, 1.8587e-05, 1.3451e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4940e-05],
        [0.0000e+00, 1.2726e-05],
        [0.0000e+00, 2.0193e-05],
        [0.0000e+00, 1.4883e-05],
        [0.0000e+00, 1.8644e-05],
        [0.0000e+00, 2.4821e-05],
        [0.0000e+00, 3.5492e-05],
        [0.0000e+00, 1.3340e-05],
        [0.0000e+00, 2.0879e-05],
        [0.0000e+00, 1.8683e-05],
        [0.0000e+00, 2.0498e-05],
        [0.0000e+00, 2.2647e-05],
        [0.0000e+00, 2.0241e-05],
        [0.0000e+00, 1.6987e-05],
        [0.0000e+00, 1.8587e-05],
        [0.0000e+00, 1.3451e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.3319e-05, 6.8673e-05, 1.9459e-05, 2.1931e-05, 2.4567e-05, 2.6769e-05,
        1.5010e-05, 5.7207e-05, 2.5816e-05, 2.7773e-05, 2.4074e-05, 2.5588e-05,
        2.8958e-05, 6.2722e-05, 1.4620e-05, 2.4364e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.3319e-05],
        [0.0000e+00, 6.8673e-05],
        [0.0000e+00, 1.9459e-05],
        [0.0000e+00, 2.1931e-05],
        [0.0000e+00, 2.4567e-05],
        [0.0000e+00, 2.6769e-05],
        [0.0000e+00, 1.5010e-05],
        [0.0000e+00, 5.7207e-05],
        [0.0000e+00, 2.5816e-05],
        [0.0000e+00, 2.7773e-05],
        [0.0000e+00, 2.4074e-05],
        [0.0000e+00, 2.5588e-05],
        [0.0000e+00, 2.8958e-05],
        [0.0000e+00, 6.2722e-05],
        [0.0000e+00, 1.4620e-05],
        [0.0000e+00, 2.4364e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.8681e-05, 1.1689e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.8681e-05],
        [0.0000e+00, 1.1689e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type active, variation 2 and batchsize 16: 0:03:36.166333
path ['42', 'de', 'bloom', 'SA', 'active', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m SA passive 0 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 317.19it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4490e-05, 2.8172e-05, 2.2769e-05, 1.9253e-05, 2.8463e-05, 1.9177e-05,
        1.6993e-05, 2.1481e-05, 2.5673e-05, 2.0340e-05, 1.7215e-05, 1.7442e-05,
        7.8158e-05, 2.6549e-05, 6.5318e-05, 1.9864e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4490e-05],
        [0.0000e+00, 2.8172e-05],
        [0.0000e+00, 2.2769e-05],
        [0.0000e+00, 1.9253e-05],
        [0.0000e+00, 2.8463e-05],
        [0.0000e+00, 1.9177e-05],
        [0.0000e+00, 1.6993e-05],
        [0.0000e+00, 2.1481e-05],
        [0.0000e+00, 2.5673e-05],
        [0.0000e+00, 2.0340e-05],
        [0.0000e+00, 1.7215e-05],
        [0.0000e+00, 1.7442e-05],
        [0.0000e+00, 7.8158e-05],
        [0.0000e+00, 2.6549e-05],
        [0.0000e+00, 6.5318e-05],
        [0.0000e+00, 1.9864e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4546e-05, 2.1863e-05, 3.0560e-05, 4.9956e-05, 5.9684e-05, 2.3987e-05,
        2.9427e-05, 1.2430e-05, 1.9365e-05, 2.3450e-05, 2.7544e-05, 2.5767e-05,
        1.4530e-05, 2.1455e-05, 3.0274e-05, 2.8201e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4546e-05],
        [0.0000e+00, 2.1863e-05],
        [0.0000e+00, 3.0560e-05],
        [0.0000e+00, 4.9956e-05],
        [0.0000e+00, 5.9684e-05],
        [0.0000e+00, 2.3987e-05],
        [0.0000e+00, 2.9427e-05],
        [0.0000e+00, 1.2430e-05],
        [0.0000e+00, 1.9365e-05],
        [0.0000e+00, 2.3450e-05],
        [0.0000e+00, 2.7544e-05],
        [0.0000e+00, 2.5767e-05],
        [0.0000e+00, 1.4530e-05],
        [0.0000e+00, 2.1455e-05],
        [0.0000e+00, 3.0274e-05],
        [0.0000e+00, 2.8201e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4792e-05, 2.2446e-05, 1.3297e-05, 3.2193e-05, 2.1201e-05, 1.9842e-05,
        1.3486e-05, 2.1645e-05, 1.3260e-05, 2.0053e-05, 2.6834e-05, 1.4469e-05,
        1.3541e-05, 3.3673e-05, 5.7407e-05, 2.1380e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4792e-05],
        [0.0000e+00, 2.2446e-05],
        [0.0000e+00, 1.3297e-05],
        [0.0000e+00, 3.2193e-05],
        [0.0000e+00, 2.1201e-05],
        [0.0000e+00, 1.9842e-05],
        [0.0000e+00, 1.3486e-05],
        [0.0000e+00, 2.1645e-05],
        [0.0000e+00, 1.3260e-05],
        [0.0000e+00, 2.0053e-05],
        [0.0000e+00, 2.6834e-05],
        [0.0000e+00, 1.4469e-05],
        [0.0000e+00, 1.3541e-05],
        [0.0000e+00, 3.3673e-05],
        [0.0000e+00, 5.7407e-05],
        [0.0000e+00, 2.1380e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([2.0708e-05, 2.4066e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 2.0708e-05],
        [0.0000e+00, 2.4066e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type passive, variation 0 and batchsize 16: 0:03:05.626560
path ['42', 'de', 'bloom', 'SA', 'passive', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m SA passive 1 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 324.52it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5328e-05, 2.7650e-05, 2.8421e-05, 2.6126e-05, 2.7737e-05, 2.2420e-05,
        4.9424e-05, 3.0178e-05, 2.1858e-05, 2.3999e-05, 3.5474e-05, 3.1212e-05,
        1.3862e-05, 2.2291e-05, 2.6690e-05, 2.3076e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5328e-05],
        [0.0000e+00, 2.7650e-05],
        [0.0000e+00, 2.8421e-05],
        [0.0000e+00, 2.6126e-05],
        [0.0000e+00, 2.7737e-05],
        [0.0000e+00, 2.2420e-05],
        [0.0000e+00, 4.9424e-05],
        [0.0000e+00, 3.0178e-05],
        [0.0000e+00, 2.1858e-05],
        [0.0000e+00, 2.3999e-05],
        [0.0000e+00, 3.5474e-05],
        [0.0000e+00, 3.1212e-05],
        [0.0000e+00, 1.3862e-05],
        [0.0000e+00, 2.2291e-05],
        [0.0000e+00, 2.6690e-05],
        [0.0000e+00, 2.3076e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([8.4440e-05, 1.5709e-05, 1.5439e-05, 1.6528e-05, 2.6394e-05, 2.4717e-05,
        3.6514e-05, 3.3562e-05, 2.2668e-05, 1.7633e-05, 2.5165e-05, 1.2251e-05,
        2.3531e-05, 1.8705e-05, 2.4781e-05, 2.8923e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 8.4440e-05],
        [0.0000e+00, 1.5709e-05],
        [0.0000e+00, 1.5439e-05],
        [0.0000e+00, 1.6528e-05],
        [0.0000e+00, 2.6394e-05],
        [0.0000e+00, 2.4717e-05],
        [0.0000e+00, 3.6514e-05],
        [0.0000e+00, 3.3562e-05],
        [0.0000e+00, 2.2668e-05],
        [0.0000e+00, 1.7633e-05],
        [0.0000e+00, 2.5165e-05],
        [0.0000e+00, 1.2251e-05],
        [0.0000e+00, 2.3531e-05],
        [0.0000e+00, 1.8705e-05],
        [0.0000e+00, 2.4781e-05],
        [0.0000e+00, 2.8923e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5187e-05, 2.8869e-05, 1.9028e-05, 6.8219e-05, 2.5469e-05, 2.8408e-05,
        2.8319e-05, 2.0571e-05, 1.8860e-05, 6.2540e-05, 2.5689e-05, 5.7078e-05,
        1.3179e-05, 1.7875e-05, 2.2924e-05, 2.5800e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5187e-05],
        [0.0000e+00, 2.8869e-05],
        [0.0000e+00, 1.9028e-05],
        [0.0000e+00, 6.8219e-05],
        [0.0000e+00, 2.5469e-05],
        [0.0000e+00, 2.8408e-05],
        [0.0000e+00, 2.8319e-05],
        [0.0000e+00, 2.0571e-05],
        [0.0000e+00, 1.8860e-05],
        [0.0000e+00, 6.2540e-05],
        [0.0000e+00, 2.5689e-05],
        [0.0000e+00, 5.7078e-05],
        [0.0000e+00, 1.3179e-05],
        [0.0000e+00, 1.7875e-05],
        [0.0000e+00, 2.2924e-05],
        [0.0000e+00, 2.5800e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([2.8920e-05, 1.8949e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 2.8920e-05],
        [0.0000e+00, 1.8949e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type passive, variation 1 and batchsize 16: 0:03:05.265213
path ['42', 'de', 'bloom', 'SA', 'passive', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m SA passive 2 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 356.85it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4390e-05, 1.0202e-04, 2.4027e-05, 2.7333e-05, 1.7483e-05, 2.7371e-05,
        2.1568e-05, 3.3536e-05, 1.5236e-05, 2.2638e-05, 3.9731e-05, 2.0272e-05,
        3.5021e-05, 2.7730e-05, 5.8556e-05, 2.0555e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4390e-05],
        [0.0000e+00, 1.0202e-04],
        [0.0000e+00, 2.4027e-05],
        [0.0000e+00, 2.7333e-05],
        [0.0000e+00, 1.7483e-05],
        [0.0000e+00, 2.7371e-05],
        [0.0000e+00, 2.1568e-05],
        [0.0000e+00, 3.3536e-05],
        [0.0000e+00, 1.5236e-05],
        [0.0000e+00, 2.2638e-05],
        [0.0000e+00, 3.9731e-05],
        [0.0000e+00, 2.0272e-05],
        [0.0000e+00, 3.5021e-05],
        [0.0000e+00, 2.7730e-05],
        [0.0000e+00, 5.8556e-05],
        [0.0000e+00, 2.0555e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5407e-05, 2.6056e-05, 2.8979e-05, 2.0338e-05, 1.7252e-05, 2.1124e-05,
        2.0040e-05, 2.5549e-05, 5.5998e-05, 2.0158e-05, 2.4874e-05, 2.1187e-05,
        2.0742e-05, 2.5644e-05, 1.6799e-05, 1.3192e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5407e-05],
        [0.0000e+00, 2.6056e-05],
        [0.0000e+00, 2.8979e-05],
        [0.0000e+00, 2.0338e-05],
        [0.0000e+00, 1.7252e-05],
        [0.0000e+00, 2.1124e-05],
        [0.0000e+00, 2.0040e-05],
        [0.0000e+00, 2.5549e-05],
        [0.0000e+00, 5.5998e-05],
        [0.0000e+00, 2.0158e-05],
        [0.0000e+00, 2.4874e-05],
        [0.0000e+00, 2.1187e-05],
        [0.0000e+00, 2.0742e-05],
        [0.0000e+00, 2.5644e-05],
        [0.0000e+00, 1.6799e-05],
        [0.0000e+00, 1.3192e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.8744e-05, 2.3147e-05, 6.4227e-05, 1.6160e-05, 1.8002e-05, 2.6628e-05,
        1.2029e-05, 1.1828e-05, 3.1172e-05, 2.7042e-05, 5.8399e-05, 2.3540e-05,
        2.1697e-05, 1.2865e-05, 2.4271e-05, 2.0347e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.8744e-05],
        [0.0000e+00, 2.3147e-05],
        [0.0000e+00, 6.4227e-05],
        [0.0000e+00, 1.6160e-05],
        [0.0000e+00, 1.8002e-05],
        [0.0000e+00, 2.6628e-05],
        [0.0000e+00, 1.2029e-05],
        [0.0000e+00, 1.1828e-05],
        [0.0000e+00, 3.1172e-05],
        [0.0000e+00, 2.7042e-05],
        [0.0000e+00, 5.8399e-05],
        [0.0000e+00, 2.3540e-05],
        [0.0000e+00, 2.1697e-05],
        [0.0000e+00, 1.2865e-05],
        [0.0000e+00, 2.4271e-05],
        [0.0000e+00, 2.0347e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.3432e-05, 2.3274e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.3432e-05],
        [0.0000e+00, 2.3274e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type passive, variation 2 and batchsize 16: 0:03:02.937897
path ['42', 'de', 'bloom', 'SA', 'passive', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m SA auxiliary 0 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 348.04it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.2549e-05, 2.0197e-05, 2.8467e-05, 5.2361e-05, 2.3274e-05, 2.7711e-05,
        1.7165e-05, 6.6571e-05, 3.1493e-05, 3.6483e-05, 2.8131e-05, 2.2475e-05,
        2.8550e-05, 2.4449e-05, 1.9258e-05, 2.9149e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.2549e-05],
        [0.0000e+00, 2.0197e-05],
        [0.0000e+00, 2.8467e-05],
        [0.0000e+00, 5.2361e-05],
        [0.0000e+00, 2.3274e-05],
        [0.0000e+00, 2.7711e-05],
        [0.0000e+00, 1.7165e-05],
        [0.0000e+00, 6.6571e-05],
        [0.0000e+00, 3.1493e-05],
        [0.0000e+00, 3.6483e-05],
        [0.0000e+00, 2.8131e-05],
        [0.0000e+00, 2.2475e-05],
        [0.0000e+00, 2.8550e-05],
        [0.0000e+00, 2.4449e-05],
        [0.0000e+00, 1.9258e-05],
        [0.0000e+00, 2.9149e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.8631e-05, 2.4274e-05, 2.6538e-05, 2.3646e-05, 1.1442e-05, 1.5233e-05,
        5.3772e-05, 2.3166e-05, 2.4999e-05, 1.2523e-05, 2.3127e-05, 2.2500e-05,
        2.4389e-05, 2.7273e-05, 1.5568e-05, 3.0466e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.8631e-05],
        [0.0000e+00, 2.4274e-05],
        [0.0000e+00, 2.6538e-05],
        [0.0000e+00, 2.3646e-05],
        [0.0000e+00, 1.1442e-05],
        [0.0000e+00, 1.5233e-05],
        [0.0000e+00, 5.3772e-05],
        [0.0000e+00, 2.3166e-05],
        [0.0000e+00, 2.4999e-05],
        [0.0000e+00, 1.2523e-05],
        [0.0000e+00, 2.3127e-05],
        [0.0000e+00, 2.2500e-05],
        [0.0000e+00, 2.4389e-05],
        [0.0000e+00, 2.7273e-05],
        [0.0000e+00, 1.5568e-05],
        [0.0000e+00, 3.0466e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([8.5998e-05, 2.1799e-05, 1.5499e-05, 2.5117e-05, 2.1905e-05, 2.3232e-05,
        2.7404e-05, 2.7374e-05, 3.3891e-05, 2.7078e-05, 2.1834e-05, 1.6417e-05,
        1.8484e-05, 2.7221e-05, 6.0221e-05, 2.8443e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 8.5998e-05],
        [0.0000e+00, 2.1799e-05],
        [0.0000e+00, 1.5499e-05],
        [0.0000e+00, 2.5117e-05],
        [0.0000e+00, 2.1905e-05],
        [0.0000e+00, 2.3232e-05],
        [0.0000e+00, 2.7404e-05],
        [0.0000e+00, 2.7374e-05],
        [0.0000e+00, 3.3891e-05],
        [0.0000e+00, 2.7078e-05],
        [0.0000e+00, 2.1834e-05],
        [0.0000e+00, 1.6417e-05],
        [0.0000e+00, 1.8484e-05],
        [0.0000e+00, 2.7221e-05],
        [0.0000e+00, 6.0221e-05],
        [0.0000e+00, 2.8443e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.7900e-05, 1.6984e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.7900e-05],
        [0.0000e+00, 1.6984e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type auxiliary, variation 0 and batchsize 16: 0:03:03.503291
path ['42', 'de', 'bloom', 'SA', 'auxiliary', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m SA auxiliary 1 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 368.54it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([6.1910e-05, 2.8508e-05, 2.1855e-05, 1.4318e-05, 2.8169e-05, 2.0651e-05,
        1.5825e-05, 2.9093e-05, 1.9066e-05, 1.7690e-05, 2.4624e-05, 2.8297e-05,
        5.0357e-05, 1.7001e-05, 2.6515e-05, 1.8519e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 6.1910e-05],
        [0.0000e+00, 2.8508e-05],
        [0.0000e+00, 2.1855e-05],
        [0.0000e+00, 1.4318e-05],
        [0.0000e+00, 2.8169e-05],
        [0.0000e+00, 2.0651e-05],
        [0.0000e+00, 1.5825e-05],
        [0.0000e+00, 2.9093e-05],
        [0.0000e+00, 1.9066e-05],
        [0.0000e+00, 1.7690e-05],
        [0.0000e+00, 2.4624e-05],
        [0.0000e+00, 2.8297e-05],
        [0.0000e+00, 5.0357e-05],
        [0.0000e+00, 1.7001e-05],
        [0.0000e+00, 2.6515e-05],
        [0.0000e+00, 1.8519e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.3245e-05, 1.2908e-05, 1.7963e-05, 2.3089e-05, 2.1112e-05, 3.6195e-05,
        2.8772e-05, 2.4287e-05, 1.2493e-05, 3.4080e-05, 8.5022e-05, 2.2311e-05,
        2.2172e-05, 2.7010e-05, 6.4331e-05, 2.1012e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.3245e-05],
        [0.0000e+00, 1.2908e-05],
        [0.0000e+00, 1.7963e-05],
        [0.0000e+00, 2.3089e-05],
        [0.0000e+00, 2.1112e-05],
        [0.0000e+00, 3.6195e-05],
        [0.0000e+00, 2.8772e-05],
        [0.0000e+00, 2.4287e-05],
        [0.0000e+00, 1.2493e-05],
        [0.0000e+00, 3.4080e-05],
        [0.0000e+00, 8.5022e-05],
        [0.0000e+00, 2.2311e-05],
        [0.0000e+00, 2.2172e-05],
        [0.0000e+00, 2.7010e-05],
        [0.0000e+00, 6.4331e-05],
        [0.0000e+00, 2.1012e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.8999e-05, 2.8640e-05, 2.1923e-05, 2.8616e-05, 2.3362e-05, 2.3159e-05,
        2.9210e-05, 2.1302e-05, 2.3665e-05, 2.3608e-05, 2.5039e-05, 1.4424e-05,
        2.1025e-05, 2.6342e-05, 2.5586e-05, 3.3731e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.8999e-05],
        [0.0000e+00, 2.8640e-05],
        [0.0000e+00, 2.1923e-05],
        [0.0000e+00, 2.8616e-05],
        [0.0000e+00, 2.3362e-05],
        [0.0000e+00, 2.3159e-05],
        [0.0000e+00, 2.9210e-05],
        [0.0000e+00, 2.1302e-05],
        [0.0000e+00, 2.3665e-05],
        [0.0000e+00, 2.3608e-05],
        [0.0000e+00, 2.5039e-05],
        [0.0000e+00, 1.4424e-05],
        [0.0000e+00, 2.1025e-05],
        [0.0000e+00, 2.6342e-05],
        [0.0000e+00, 2.5586e-05],
        [0.0000e+00, 3.3731e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([2.7828e-05, 6.3897e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 2.7828e-05],
        [0.0000e+00, 6.3897e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type auxiliary, variation 1 and batchsize 16: 0:03:03.179646
path ['42', 'de', 'bloom', 'SA', 'auxiliary', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m SA auxiliary 2 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 342.88it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2061e-05, 3.0467e-05, 2.8464e-05, 2.3819e-05, 1.8443e-05, 2.6132e-05,
        3.4602e-05, 1.1840e-05, 2.9322e-05, 2.9099e-05, 1.2523e-05, 2.3311e-05,
        9.3951e-05, 6.1932e-05, 2.8614e-05, 2.5313e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2061e-05],
        [0.0000e+00, 3.0467e-05],
        [0.0000e+00, 2.8464e-05],
        [0.0000e+00, 2.3819e-05],
        [0.0000e+00, 1.8443e-05],
        [0.0000e+00, 2.6132e-05],
        [0.0000e+00, 3.4602e-05],
        [0.0000e+00, 1.1840e-05],
        [0.0000e+00, 2.9322e-05],
        [0.0000e+00, 2.9099e-05],
        [0.0000e+00, 1.2523e-05],
        [0.0000e+00, 2.3311e-05],
        [0.0000e+00, 9.3951e-05],
        [0.0000e+00, 6.1932e-05],
        [0.0000e+00, 2.8614e-05],
        [0.0000e+00, 2.5313e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.8378e-05, 2.4453e-05, 2.7952e-05, 2.9595e-05, 6.0032e-05, 3.6628e-05,
        5.6254e-05, 2.9002e-05, 2.7511e-05, 2.6130e-05, 2.3295e-05, 6.6525e-05,
        3.6156e-05, 2.0397e-05, 2.4931e-05, 3.1194e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.8378e-05],
        [0.0000e+00, 2.4453e-05],
        [0.0000e+00, 2.7952e-05],
        [0.0000e+00, 2.9595e-05],
        [0.0000e+00, 6.0032e-05],
        [0.0000e+00, 3.6628e-05],
        [0.0000e+00, 5.6254e-05],
        [0.0000e+00, 2.9002e-05],
        [0.0000e+00, 2.7511e-05],
        [0.0000e+00, 2.6130e-05],
        [0.0000e+00, 2.3295e-05],
        [0.0000e+00, 6.6525e-05],
        [0.0000e+00, 3.6156e-05],
        [0.0000e+00, 2.0397e-05],
        [0.0000e+00, 2.4931e-05],
        [0.0000e+00, 3.1194e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.1046e-05, 2.4615e-05, 1.6563e-05, 3.0840e-05, 1.6047e-05, 1.5263e-05,
        1.7883e-05, 3.1178e-05, 2.2362e-05, 1.2068e-05, 2.3564e-05, 2.3972e-05,
        1.6928e-05, 1.7731e-05, 2.3728e-05, 2.6228e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.1046e-05],
        [0.0000e+00, 2.4615e-05],
        [0.0000e+00, 1.6563e-05],
        [0.0000e+00, 3.0840e-05],
        [0.0000e+00, 1.6047e-05],
        [0.0000e+00, 1.5263e-05],
        [0.0000e+00, 1.7883e-05],
        [0.0000e+00, 3.1178e-05],
        [0.0000e+00, 2.2362e-05],
        [0.0000e+00, 1.2068e-05],
        [0.0000e+00, 2.3564e-05],
        [0.0000e+00, 2.3972e-05],
        [0.0000e+00, 1.6928e-05],
        [0.0000e+00, 1.7731e-05],
        [0.0000e+00, 2.3728e-05],
        [0.0000e+00, 2.6228e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([3.3387e-05, 1.9601e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 3.3387e-05],
        [0.0000e+00, 1.9601e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type auxiliary, variation 2 and batchsize 16: 0:03:03.504069
path ['42', 'de', 'bloom', 'SA', 'auxiliary', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m SA modal 0 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 190.44it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.8413e-05, 1.9983e-05, 2.2230e-05, 2.2037e-05, 4.9212e-05, 2.2262e-05,
        2.4573e-05, 2.8772e-05, 2.8441e-05, 3.3314e-05, 8.1837e-05, 2.0736e-05,
        5.9954e-05, 1.2109e-05, 2.1630e-05, 1.9550e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.8413e-05],
        [0.0000e+00, 1.9983e-05],
        [0.0000e+00, 2.2230e-05],
        [0.0000e+00, 2.2037e-05],
        [0.0000e+00, 4.9212e-05],
        [0.0000e+00, 2.2262e-05],
        [0.0000e+00, 2.4573e-05],
        [0.0000e+00, 2.8772e-05],
        [0.0000e+00, 2.8441e-05],
        [0.0000e+00, 3.3314e-05],
        [0.0000e+00, 8.1837e-05],
        [0.0000e+00, 2.0736e-05],
        [0.0000e+00, 5.9954e-05],
        [0.0000e+00, 1.2109e-05],
        [0.0000e+00, 2.1630e-05],
        [0.0000e+00, 1.9550e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4696e-05, 2.5781e-05, 2.7111e-05, 2.3708e-05, 2.2504e-05, 2.5662e-05,
        2.6645e-05, 1.4059e-05, 2.8171e-05, 2.3443e-05, 2.3429e-05, 1.2739e-05,
        2.1502e-05, 1.9135e-05, 3.5621e-05, 3.0539e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4696e-05],
        [0.0000e+00, 2.5781e-05],
        [0.0000e+00, 2.7111e-05],
        [0.0000e+00, 2.3708e-05],
        [0.0000e+00, 2.2504e-05],
        [0.0000e+00, 2.5662e-05],
        [0.0000e+00, 2.6645e-05],
        [0.0000e+00, 1.4059e-05],
        [0.0000e+00, 2.8171e-05],
        [0.0000e+00, 2.3443e-05],
        [0.0000e+00, 2.3429e-05],
        [0.0000e+00, 1.2739e-05],
        [0.0000e+00, 2.1502e-05],
        [0.0000e+00, 1.9135e-05],
        [0.0000e+00, 3.5621e-05],
        [0.0000e+00, 3.0539e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([6.2945e-05, 3.2322e-05, 1.8992e-05, 1.8554e-05, 2.2050e-05, 2.6543e-05,
        2.2171e-05, 1.2838e-05, 1.7092e-05, 2.7758e-05, 1.4296e-05, 2.4786e-05,
        6.0142e-05, 1.6932e-05, 2.1581e-05, 2.9322e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 6.2945e-05],
        [0.0000e+00, 3.2322e-05],
        [0.0000e+00, 1.8992e-05],
        [0.0000e+00, 1.8554e-05],
        [0.0000e+00, 2.2050e-05],
        [0.0000e+00, 2.6543e-05],
        [0.0000e+00, 2.2171e-05],
        [0.0000e+00, 1.2838e-05],
        [0.0000e+00, 1.7092e-05],
        [0.0000e+00, 2.7758e-05],
        [0.0000e+00, 1.4296e-05],
        [0.0000e+00, 2.4786e-05],
        [0.0000e+00, 6.0142e-05],
        [0.0000e+00, 1.6932e-05],
        [0.0000e+00, 2.1581e-05],
        [0.0000e+00, 2.9322e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([2.2808e-05, 1.5816e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 2.2808e-05],
        [0.0000e+00, 1.5816e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type modal, variation 0 and batchsize 16: 0:03:24.781767
path ['42', 'de', 'bloom', 'SA', 'modal', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m SA modal 1 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 329.02it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.7721e-05, 2.6330e-05, 1.7804e-05, 2.3129e-05, 2.1338e-05, 2.1180e-05,
        2.0780e-05, 7.5108e-05, 6.5508e-05, 3.2421e-05, 2.6109e-05, 2.6670e-05,
        6.1298e-05, 2.5800e-05, 1.1971e-05, 2.1757e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.7721e-05],
        [0.0000e+00, 2.6330e-05],
        [0.0000e+00, 1.7804e-05],
        [0.0000e+00, 2.3129e-05],
        [0.0000e+00, 2.1338e-05],
        [0.0000e+00, 2.1180e-05],
        [0.0000e+00, 2.0780e-05],
        [0.0000e+00, 7.5108e-05],
        [0.0000e+00, 6.5508e-05],
        [0.0000e+00, 3.2421e-05],
        [0.0000e+00, 2.6109e-05],
        [0.0000e+00, 2.6670e-05],
        [0.0000e+00, 6.1298e-05],
        [0.0000e+00, 2.5800e-05],
        [0.0000e+00, 1.1971e-05],
        [0.0000e+00, 2.1757e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.1547e-05, 1.6636e-05, 1.8878e-05, 2.5403e-05, 2.1441e-05, 1.2623e-05,
        1.4604e-05, 1.4937e-05, 1.1700e-05, 1.3648e-05, 2.1315e-05, 2.8582e-05,
        2.3998e-05, 4.8474e-05, 3.0009e-05, 2.2426e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.1547e-05],
        [0.0000e+00, 1.6636e-05],
        [0.0000e+00, 1.8878e-05],
        [0.0000e+00, 2.5403e-05],
        [0.0000e+00, 2.1441e-05],
        [0.0000e+00, 1.2623e-05],
        [0.0000e+00, 1.4604e-05],
        [0.0000e+00, 1.4937e-05],
        [0.0000e+00, 1.1700e-05],
        [0.0000e+00, 1.3648e-05],
        [0.0000e+00, 2.1315e-05],
        [0.0000e+00, 2.8582e-05],
        [0.0000e+00, 2.3998e-05],
        [0.0000e+00, 4.8474e-05],
        [0.0000e+00, 3.0009e-05],
        [0.0000e+00, 2.2426e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.7747e-05, 1.6436e-05, 2.4432e-05, 3.7272e-05, 6.5068e-05, 2.1199e-05,
        2.1343e-05, 1.8963e-05, 2.7938e-05, 2.2559e-05, 2.4767e-05, 2.7802e-05,
        2.5103e-05, 1.9890e-05, 2.0600e-05, 1.6058e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.7747e-05],
        [0.0000e+00, 1.6436e-05],
        [0.0000e+00, 2.4432e-05],
        [0.0000e+00, 3.7272e-05],
        [0.0000e+00, 6.5068e-05],
        [0.0000e+00, 2.1199e-05],
        [0.0000e+00, 2.1343e-05],
        [0.0000e+00, 1.8963e-05],
        [0.0000e+00, 2.7938e-05],
        [0.0000e+00, 2.2559e-05],
        [0.0000e+00, 2.4767e-05],
        [0.0000e+00, 2.7802e-05],
        [0.0000e+00, 2.5103e-05],
        [0.0000e+00, 1.9890e-05],
        [0.0000e+00, 2.0600e-05],
        [0.0000e+00, 1.6058e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([2.3743e-05, 2.9421e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 2.3743e-05],
        [0.0000e+00, 2.9421e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type modal, variation 1 and batchsize 16: 0:03:32.040941
path ['42', 'de', 'bloom', 'SA', 'modal', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m SA modal 2 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 334.75it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.7750e-05, 2.1428e-05, 1.9180e-05, 2.0949e-05, 1.6150e-05, 1.6735e-05,
        1.2355e-05, 8.6103e-05, 2.2437e-05, 2.8009e-05, 6.6927e-05, 1.7368e-05,
        2.1392e-05, 2.6837e-05, 3.0515e-05, 5.1355e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.7750e-05],
        [0.0000e+00, 2.1428e-05],
        [0.0000e+00, 1.9180e-05],
        [0.0000e+00, 2.0949e-05],
        [0.0000e+00, 1.6150e-05],
        [0.0000e+00, 1.6735e-05],
        [0.0000e+00, 1.2355e-05],
        [0.0000e+00, 8.6103e-05],
        [0.0000e+00, 2.2437e-05],
        [0.0000e+00, 2.8009e-05],
        [0.0000e+00, 6.6927e-05],
        [0.0000e+00, 1.7368e-05],
        [0.0000e+00, 2.1392e-05],
        [0.0000e+00, 2.6837e-05],
        [0.0000e+00, 3.0515e-05],
        [0.0000e+00, 5.1355e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.7284e-05, 2.2400e-05, 2.5687e-05, 2.1598e-05, 6.1722e-05, 2.2009e-05,
        2.7931e-05, 3.2728e-05, 1.4825e-05, 2.7649e-05, 1.8747e-05, 1.6258e-05,
        2.4504e-05, 2.4242e-05, 2.8716e-05, 1.7063e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.7284e-05],
        [0.0000e+00, 2.2400e-05],
        [0.0000e+00, 2.5687e-05],
        [0.0000e+00, 2.1598e-05],
        [0.0000e+00, 6.1722e-05],
        [0.0000e+00, 2.2009e-05],
        [0.0000e+00, 2.7931e-05],
        [0.0000e+00, 3.2728e-05],
        [0.0000e+00, 1.4825e-05],
        [0.0000e+00, 2.7649e-05],
        [0.0000e+00, 1.8747e-05],
        [0.0000e+00, 1.6258e-05],
        [0.0000e+00, 2.4504e-05],
        [0.0000e+00, 2.4242e-05],
        [0.0000e+00, 2.8716e-05],
        [0.0000e+00, 1.7063e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.3553e-05, 1.1834e-05, 2.9227e-05, 3.5417e-05, 2.3577e-05, 2.6453e-05,
        2.7113e-05, 2.2152e-05, 1.2657e-05, 2.3270e-05, 2.6419e-05, 2.9015e-05,
        2.5119e-05, 2.2179e-05, 2.7701e-05, 3.4604e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.3553e-05],
        [0.0000e+00, 1.1834e-05],
        [0.0000e+00, 2.9227e-05],
        [0.0000e+00, 3.5417e-05],
        [0.0000e+00, 2.3577e-05],
        [0.0000e+00, 2.6453e-05],
        [0.0000e+00, 2.7113e-05],
        [0.0000e+00, 2.2152e-05],
        [0.0000e+00, 1.2657e-05],
        [0.0000e+00, 2.3270e-05],
        [0.0000e+00, 2.6419e-05],
        [0.0000e+00, 2.9015e-05],
        [0.0000e+00, 2.5119e-05],
        [0.0000e+00, 2.2179e-05],
        [0.0000e+00, 2.7701e-05],
        [0.0000e+00, 3.4604e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.4574e-05, 5.9568e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.4574e-05],
        [0.0000e+00, 5.9568e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type modal, variation 2 and batchsize 16: 0:03:30.566032
path ['42', 'de', 'bloom', 'SA', 'modal', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m SA rare_synonyms 0 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 318.57it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.2288e-05, 2.7350e-05, 1.2515e-05, 2.7630e-05, 3.5106e-05, 2.7847e-05,
        2.5877e-05, 2.5133e-05, 2.8386e-05, 1.5644e-05, 2.0492e-05, 1.7523e-05,
        1.4809e-05, 2.1391e-05, 1.9769e-05, 2.9093e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.2288e-05],
        [0.0000e+00, 2.7350e-05],
        [0.0000e+00, 1.2515e-05],
        [0.0000e+00, 2.7630e-05],
        [0.0000e+00, 3.5106e-05],
        [0.0000e+00, 2.7847e-05],
        [0.0000e+00, 2.5877e-05],
        [0.0000e+00, 2.5133e-05],
        [0.0000e+00, 2.8386e-05],
        [0.0000e+00, 1.5644e-05],
        [0.0000e+00, 2.0492e-05],
        [0.0000e+00, 1.7523e-05],
        [0.0000e+00, 1.4809e-05],
        [0.0000e+00, 2.1391e-05],
        [0.0000e+00, 1.9769e-05],
        [0.0000e+00, 2.9093e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5913e-05, 2.0303e-05, 6.1531e-05, 1.8902e-05, 3.5833e-05, 2.2450e-05,
        2.2603e-05, 1.9287e-05, 2.4881e-05, 2.3554e-05, 1.6673e-05, 5.0079e-05,
        2.2765e-05, 5.6261e-05, 2.2251e-05, 2.4534e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5913e-05],
        [0.0000e+00, 2.0303e-05],
        [0.0000e+00, 6.1531e-05],
        [0.0000e+00, 1.8902e-05],
        [0.0000e+00, 3.5833e-05],
        [0.0000e+00, 2.2450e-05],
        [0.0000e+00, 2.2603e-05],
        [0.0000e+00, 1.9287e-05],
        [0.0000e+00, 2.4881e-05],
        [0.0000e+00, 2.3554e-05],
        [0.0000e+00, 1.6673e-05],
        [0.0000e+00, 5.0079e-05],
        [0.0000e+00, 2.2765e-05],
        [0.0000e+00, 5.6261e-05],
        [0.0000e+00, 2.2251e-05],
        [0.0000e+00, 2.4534e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.3327e-05, 2.3209e-05, 2.7466e-05, 1.2543e-05, 3.0115e-05, 7.1424e-05,
        2.8397e-05, 2.2018e-05, 2.3920e-05, 2.4210e-05, 2.3064e-05, 2.2529e-05,
        1.4037e-05, 1.3190e-05, 3.4451e-05, 6.7911e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.3327e-05],
        [0.0000e+00, 2.3209e-05],
        [0.0000e+00, 2.7466e-05],
        [0.0000e+00, 1.2543e-05],
        [0.0000e+00, 3.0115e-05],
        [0.0000e+00, 7.1424e-05],
        [0.0000e+00, 2.8397e-05],
        [0.0000e+00, 2.2018e-05],
        [0.0000e+00, 2.3920e-05],
        [0.0000e+00, 2.4210e-05],
        [0.0000e+00, 2.3064e-05],
        [0.0000e+00, 2.2529e-05],
        [0.0000e+00, 1.4037e-05],
        [0.0000e+00, 1.3190e-05],
        [0.0000e+00, 3.4451e-05],
        [0.0000e+00, 6.7911e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([2.9649e-05, 1.7011e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 2.9649e-05],
        [0.0000e+00, 1.7011e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type rare_synonyms, variation 0 and batchsize 16: 0:03:04.579542
path ['42', 'de', 'bloom', 'SA', 'rare_synonyms', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m SA rare_synonyms 1 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 368.54it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2389e-05, 2.7957e-05, 2.4228e-05, 2.0500e-05, 2.1779e-05, 2.2634e-05,
        4.8123e-05, 1.8620e-05, 1.1452e-05, 2.2371e-05, 1.6530e-05, 2.8547e-05,
        6.2645e-05, 1.2053e-05, 3.2406e-05, 2.2745e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2389e-05],
        [0.0000e+00, 2.7957e-05],
        [0.0000e+00, 2.4228e-05],
        [0.0000e+00, 2.0500e-05],
        [0.0000e+00, 2.1779e-05],
        [0.0000e+00, 2.2634e-05],
        [0.0000e+00, 4.8123e-05],
        [0.0000e+00, 1.8620e-05],
        [0.0000e+00, 1.1452e-05],
        [0.0000e+00, 2.2371e-05],
        [0.0000e+00, 1.6530e-05],
        [0.0000e+00, 2.8547e-05],
        [0.0000e+00, 6.2645e-05],
        [0.0000e+00, 1.2053e-05],
        [0.0000e+00, 3.2406e-05],
        [0.0000e+00, 2.2745e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.1393e-05, 2.0493e-05, 7.8279e-05, 2.6233e-05, 2.8066e-05, 5.4505e-05,
        6.0182e-05, 2.7096e-05, 1.2989e-05, 3.2829e-05, 2.3498e-05, 2.8235e-05,
        2.4954e-05, 2.7170e-05, 1.4939e-05, 2.8894e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.1393e-05],
        [0.0000e+00, 2.0493e-05],
        [0.0000e+00, 7.8279e-05],
        [0.0000e+00, 2.6233e-05],
        [0.0000e+00, 2.8066e-05],
        [0.0000e+00, 5.4505e-05],
        [0.0000e+00, 6.0182e-05],
        [0.0000e+00, 2.7096e-05],
        [0.0000e+00, 1.2989e-05],
        [0.0000e+00, 3.2829e-05],
        [0.0000e+00, 2.3498e-05],
        [0.0000e+00, 2.8235e-05],
        [0.0000e+00, 2.4954e-05],
        [0.0000e+00, 2.7170e-05],
        [0.0000e+00, 1.4939e-05],
        [0.0000e+00, 2.8894e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2420e-05, 2.1160e-05, 1.3012e-05, 3.3422e-05, 1.4176e-05, 2.1463e-05,
        1.8605e-05, 2.3149e-05, 2.5051e-05, 2.1286e-05, 1.8979e-05, 2.7833e-05,
        1.8622e-05, 2.0421e-05, 2.4848e-05, 2.1716e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2420e-05],
        [0.0000e+00, 2.1160e-05],
        [0.0000e+00, 1.3012e-05],
        [0.0000e+00, 3.3422e-05],
        [0.0000e+00, 1.4176e-05],
        [0.0000e+00, 2.1463e-05],
        [0.0000e+00, 1.8605e-05],
        [0.0000e+00, 2.3149e-05],
        [0.0000e+00, 2.5051e-05],
        [0.0000e+00, 2.1286e-05],
        [0.0000e+00, 1.8979e-05],
        [0.0000e+00, 2.7833e-05],
        [0.0000e+00, 1.8622e-05],
        [0.0000e+00, 2.0421e-05],
        [0.0000e+00, 2.4848e-05],
        [0.0000e+00, 2.1716e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.5757e-05, 1.6373e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.5757e-05],
        [0.0000e+00, 1.6373e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type rare_synonyms, variation 1 and batchsize 16: 0:03:05.733519
path ['42', 'de', 'bloom', 'SA', 'rare_synonyms', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m SA rare_synonyms 2 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 364.85it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5675e-05, 3.5077e-05, 1.3657e-05, 3.1712e-05, 2.3627e-05, 2.8349e-05,
        1.3879e-05, 2.9362e-05, 2.6826e-05, 2.4788e-05, 6.5518e-05, 3.5926e-05,
        1.7167e-05, 2.3741e-05, 2.1387e-05, 1.7371e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5675e-05],
        [0.0000e+00, 3.5077e-05],
        [0.0000e+00, 1.3657e-05],
        [0.0000e+00, 3.1712e-05],
        [0.0000e+00, 2.3627e-05],
        [0.0000e+00, 2.8349e-05],
        [0.0000e+00, 1.3879e-05],
        [0.0000e+00, 2.9362e-05],
        [0.0000e+00, 2.6826e-05],
        [0.0000e+00, 2.4788e-05],
        [0.0000e+00, 6.5518e-05],
        [0.0000e+00, 3.5926e-05],
        [0.0000e+00, 1.7167e-05],
        [0.0000e+00, 2.3741e-05],
        [0.0000e+00, 2.1387e-05],
        [0.0000e+00, 1.7371e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.8806e-05, 2.3069e-05, 2.1328e-05, 7.7430e-05, 2.1745e-05, 2.1731e-05,
        2.2590e-05, 2.7616e-05, 1.4008e-05, 1.9007e-05, 2.4818e-05, 2.3403e-05,
        2.2389e-05, 1.9762e-05, 2.1836e-05, 6.1073e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.8806e-05],
        [0.0000e+00, 2.3069e-05],
        [0.0000e+00, 2.1328e-05],
        [0.0000e+00, 7.7430e-05],
        [0.0000e+00, 2.1745e-05],
        [0.0000e+00, 2.1731e-05],
        [0.0000e+00, 2.2590e-05],
        [0.0000e+00, 2.7616e-05],
        [0.0000e+00, 1.4008e-05],
        [0.0000e+00, 1.9007e-05],
        [0.0000e+00, 2.4818e-05],
        [0.0000e+00, 2.3403e-05],
        [0.0000e+00, 2.2389e-05],
        [0.0000e+00, 1.9762e-05],
        [0.0000e+00, 2.1836e-05],
        [0.0000e+00, 6.1073e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([5.0420e-05, 2.1136e-05, 1.7821e-05, 2.5127e-05, 2.2060e-05, 2.7407e-05,
        2.2483e-05, 1.2991e-05, 1.2930e-05, 5.9119e-05, 2.8530e-05, 2.7384e-05,
        2.3359e-05, 1.5949e-05, 2.0113e-05, 3.3461e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 5.0420e-05],
        [0.0000e+00, 2.1136e-05],
        [0.0000e+00, 1.7821e-05],
        [0.0000e+00, 2.5127e-05],
        [0.0000e+00, 2.2060e-05],
        [0.0000e+00, 2.7407e-05],
        [0.0000e+00, 2.2483e-05],
        [0.0000e+00, 1.2991e-05],
        [0.0000e+00, 1.2930e-05],
        [0.0000e+00, 5.9119e-05],
        [0.0000e+00, 2.8530e-05],
        [0.0000e+00, 2.7384e-05],
        [0.0000e+00, 2.3359e-05],
        [0.0000e+00, 1.5949e-05],
        [0.0000e+00, 2.0113e-05],
        [0.0000e+00, 3.3461e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([2.8131e-05, 1.8620e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 2.8131e-05],
        [0.0000e+00, 1.8620e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type rare_synonyms, variation 2 and batchsize 16: 0:03:03.006557
path ['42', 'de', 'bloom', 'SA', 'rare_synonyms', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
Loading model bigscience/bloomz-560m
Model bigscience/bloomz-560m loaded
Available device is cuda
Model device: cuda:0
----------- 42 de bigscience/bloomz-560m NLI active 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 249.07it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.5025e-05, 4.7392e-05, 2.4046e-05, 5.1849e-05, 2.8388e-05, 4.7323e-05,
        2.6766e-05, 2.4734e-05, 3.8608e-05, 6.7009e-05, 7.0322e-05, 4.0016e-05,
        6.6206e-05, 3.8182e-05, 3.3618e-05, 2.1718e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.2497e-04, 1.4632e-04, 8.0017e-05, 4.1346e-04, 9.5687e-05, 2.8334e-04,
        1.9372e-04, 1.0591e-04, 1.0305e-04, 1.4303e-04, 3.3944e-04, 1.4118e-04,
        1.5913e-04, 1.1451e-04, 1.0209e-04, 6.4951e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.5025e-05, 1.2497e-04],
        [0.0000e+00, 4.7392e-05, 1.4632e-04],
        [0.0000e+00, 2.4046e-05, 8.0017e-05],
        [0.0000e+00, 5.1849e-05, 4.1346e-04],
        [0.0000e+00, 2.8388e-05, 9.5687e-05],
        [0.0000e+00, 4.7323e-05, 2.8334e-04],
        [0.0000e+00, 2.6766e-05, 1.9372e-04],
        [0.0000e+00, 2.4734e-05, 1.0591e-04],
        [0.0000e+00, 3.8608e-05, 1.0305e-04],
        [0.0000e+00, 6.7009e-05, 1.4303e-04],
        [0.0000e+00, 7.0322e-05, 3.3944e-04],
        [0.0000e+00, 4.0016e-05, 1.4118e-04],
        [0.0000e+00, 6.6206e-05, 1.5913e-04],
        [0.0000e+00, 3.8182e-05, 1.1451e-04],
        [0.0000e+00, 3.3618e-05, 1.0209e-04],
        [0.0000e+00, 2.1718e-05, 6.4951e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.6421e-05, 1.4955e-05, 4.5157e-05, 4.4392e-05, 6.9602e-05, 3.1879e-05,
        4.1508e-05, 5.0271e-05, 2.3855e-05, 2.6144e-05, 5.1309e-05, 2.0681e-05,
        6.1782e-05, 2.1482e-05, 3.8165e-05, 3.2649e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.3468e-04, 6.4291e-05, 1.2275e-04, 1.6108e-04, 3.1297e-04, 1.0548e-04,
        1.8417e-04, 1.5432e-04, 2.1359e-04, 4.4238e-05, 1.9754e-04, 9.8900e-05,
        2.5099e-04, 7.6373e-05, 7.4666e-05, 1.6841e-04], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.6421e-05, 1.3468e-04],
        [0.0000e+00, 1.4955e-05, 6.4291e-05],
        [0.0000e+00, 4.5157e-05, 1.2275e-04],
        [0.0000e+00, 4.4392e-05, 1.6108e-04],
        [0.0000e+00, 6.9602e-05, 3.1297e-04],
        [0.0000e+00, 3.1879e-05, 1.0548e-04],
        [0.0000e+00, 4.1508e-05, 1.8417e-04],
        [0.0000e+00, 5.0271e-05, 1.5432e-04],
        [0.0000e+00, 2.3855e-05, 2.1359e-04],
        [0.0000e+00, 2.6144e-05, 4.4238e-05],
        [0.0000e+00, 5.1309e-05, 1.9754e-04],
        [0.0000e+00, 2.0681e-05, 9.8900e-05],
        [0.0000e+00, 6.1782e-05, 2.5099e-04],
        [0.0000e+00, 2.1482e-05, 7.6373e-05],
        [0.0000e+00, 3.8165e-05, 7.4666e-05],
        [0.0000e+00, 3.2649e-05, 1.6841e-04]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2304e-05, 2.7013e-05, 5.1057e-05, 3.4465e-05, 2.0336e-05, 3.6277e-05,
        2.7931e-05, 2.4114e-05, 2.8867e-05, 7.6784e-05, 6.8368e-05, 2.3914e-05,
        2.0080e-05, 3.0272e-05, 3.1405e-05, 2.1279e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.0006e-04, 5.7145e-05, 7.5370e-05, 2.1930e-04, 3.6196e-05, 1.5435e-04,
        7.7608e-05, 8.1218e-05, 9.0445e-05, 2.7706e-04, 2.8666e-04, 9.0616e-05,
        3.8383e-05, 8.9898e-05, 6.8089e-05, 1.1627e-04], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2304e-05, 1.0006e-04],
        [0.0000e+00, 2.7013e-05, 5.7145e-05],
        [0.0000e+00, 5.1057e-05, 7.5370e-05],
        [0.0000e+00, 3.4465e-05, 2.1930e-04],
        [0.0000e+00, 2.0336e-05, 3.6196e-05],
        [0.0000e+00, 3.6277e-05, 1.5435e-04],
        [0.0000e+00, 2.7931e-05, 7.7608e-05],
        [0.0000e+00, 2.4114e-05, 8.1218e-05],
        [0.0000e+00, 2.8867e-05, 9.0445e-05],
        [0.0000e+00, 7.6784e-05, 2.7706e-04],
        [0.0000e+00, 6.8368e-05, 2.8666e-04],
        [0.0000e+00, 2.3914e-05, 9.0616e-05],
        [0.0000e+00, 2.0080e-05, 3.8383e-05],
        [0.0000e+00, 3.0272e-05, 8.9898e-05],
        [0.0000e+00, 3.1405e-05, 6.8089e-05],
        [0.0000e+00, 2.1279e-05, 1.1627e-04]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type active, variation 0 and batchsize 16: 0:02:57.594020
path ['42', 'de', 'bloomz', 'NLI', 'active', 'prompt_id_0']
----------- 42 de bigscience/bloomz-560m NLI active 1 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 318.99it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.9442e-05, 2.4934e-05, 3.1432e-05, 1.5838e-05, 1.6455e-05, 2.9631e-05,
        3.6294e-05, 7.2688e-05, 1.9956e-05, 1.4667e-05, 2.8619e-05, 4.8148e-05,
        4.9597e-05, 3.0903e-05, 1.4529e-05, 7.3504e-06], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.9295e-05, 2.5739e-05, 3.2333e-05, 2.1326e-05, 1.7890e-05, 1.0808e-04,
        2.9774e-05, 5.3970e-05, 2.4908e-05, 5.5715e-05, 6.9741e-05, 2.1039e-05,
        4.2935e-05, 9.1602e-05, 8.7820e-06, 9.8396e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.9442e-05, 3.9295e-05],
        [0.0000e+00, 2.4934e-05, 2.5739e-05],
        [0.0000e+00, 3.1432e-05, 3.2333e-05],
        [0.0000e+00, 1.5838e-05, 2.1326e-05],
        [0.0000e+00, 1.6455e-05, 1.7890e-05],
        [0.0000e+00, 2.9631e-05, 1.0808e-04],
        [0.0000e+00, 3.6294e-05, 2.9774e-05],
        [0.0000e+00, 7.2688e-05, 5.3970e-05],
        [0.0000e+00, 1.9956e-05, 2.4908e-05],
        [0.0000e+00, 1.4667e-05, 5.5715e-05],
        [0.0000e+00, 2.8619e-05, 6.9741e-05],
        [0.0000e+00, 4.8148e-05, 2.1039e-05],
        [0.0000e+00, 4.9597e-05, 4.2935e-05],
        [0.0000e+00, 3.0903e-05, 9.1602e-05],
        [0.0000e+00, 1.4529e-05, 8.7820e-06],
        [0.0000e+00, 7.3504e-06, 9.8396e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.1012e-05, 2.1974e-05, 4.6448e-05, 2.2712e-05, 3.9655e-05, 5.1871e-05,
        3.1494e-05, 2.8985e-05, 1.5118e-05, 2.2849e-05, 3.7928e-05, 3.5308e-05,
        2.5637e-05, 3.7051e-05, 2.4486e-05, 1.6069e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([8.1989e-05, 3.1536e-05, 5.5046e-05, 1.3018e-05, 4.1141e-05, 4.3007e-05,
        5.3915e-05, 6.9189e-05, 2.4469e-05, 2.9405e-05, 4.2536e-05, 4.6433e-05,
        2.1275e-05, 2.9409e-05, 2.3469e-05, 2.6376e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.1012e-05, 8.1989e-05],
        [0.0000e+00, 2.1974e-05, 3.1536e-05],
        [0.0000e+00, 4.6448e-05, 5.5046e-05],
        [0.0000e+00, 2.2712e-05, 1.3018e-05],
        [0.0000e+00, 3.9655e-05, 4.1141e-05],
        [0.0000e+00, 5.1871e-05, 4.3007e-05],
        [0.0000e+00, 3.1494e-05, 5.3915e-05],
        [0.0000e+00, 2.8985e-05, 6.9189e-05],
        [0.0000e+00, 1.5118e-05, 2.4469e-05],
        [0.0000e+00, 2.2849e-05, 2.9405e-05],
        [0.0000e+00, 3.7928e-05, 4.2536e-05],
        [0.0000e+00, 3.5308e-05, 4.6433e-05],
        [0.0000e+00, 2.5637e-05, 2.1275e-05],
        [0.0000e+00, 3.7051e-05, 2.9409e-05],
        [0.0000e+00, 2.4486e-05, 2.3469e-05],
        [0.0000e+00, 1.6069e-05, 2.6376e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.4229e-05, 3.9192e-05, 4.3417e-05, 1.6144e-05, 2.6371e-05, 4.9879e-05,
        4.3541e-05, 2.8316e-05, 3.1026e-05, 2.7391e-05, 1.9579e-05, 5.5494e-05,
        3.1757e-05, 4.0745e-05, 5.1691e-05, 2.8611e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.8506e-05, 7.1259e-05, 4.4077e-05, 4.8167e-05, 3.1268e-05, 3.1801e-05,
        5.8109e-05, 2.7967e-05, 2.7949e-05, 2.8974e-05, 2.7483e-05, 1.0282e-04,
        2.3651e-05, 5.3702e-05, 5.7998e-05, 5.3995e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.4229e-05, 2.8506e-05],
        [0.0000e+00, 3.9192e-05, 7.1259e-05],
        [0.0000e+00, 4.3417e-05, 4.4077e-05],
        [0.0000e+00, 1.6144e-05, 4.8167e-05],
        [0.0000e+00, 2.6371e-05, 3.1268e-05],
        [0.0000e+00, 4.9879e-05, 3.1801e-05],
        [0.0000e+00, 4.3541e-05, 5.8109e-05],
        [0.0000e+00, 2.8316e-05, 2.7967e-05],
        [0.0000e+00, 3.1026e-05, 2.7949e-05],
        [0.0000e+00, 2.7391e-05, 2.8974e-05],
        [0.0000e+00, 1.9579e-05, 2.7483e-05],
        [0.0000e+00, 5.5494e-05, 1.0282e-04],
        [0.0000e+00, 3.1757e-05, 2.3651e-05],
        [0.0000e+00, 4.0745e-05, 5.3702e-05],
        [0.0000e+00, 5.1691e-05, 5.7998e-05],
        [0.0000e+00, 2.8611e-05, 5.3995e-05]], device='cuda:0')
acc:  0.3541666666666667
Time taken to execute the de NLI task with prompt type active, variation 1 and batchsize 16: 0:02:51.324080
path ['42', 'de', 'bloomz', 'NLI', 'active', 'prompt_id_1']
----------- 42 de bigscience/bloomz-560m NLI active 2 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 293.68it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([8.1046e-05, 7.5760e-05, 6.5852e-05, 3.5942e-05, 8.6767e-05, 1.7750e-04,
        6.1409e-05, 8.5796e-05, 3.4098e-05, 1.1429e-04, 8.7067e-05, 8.2021e-05,
        6.7319e-05, 7.4284e-05, 7.2504e-05, 1.4633e-04], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.8245e-05, 9.0865e-06, 1.0341e-05, 4.9005e-06, 1.0709e-05, 2.1010e-05,
        6.7680e-06, 9.7113e-06, 2.1479e-06, 1.2765e-05, 8.4478e-06, 7.0572e-06,
        8.1360e-06, 8.6859e-06, 1.2117e-05, 1.4724e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 8.1046e-05, 1.8245e-05],
        [0.0000e+00, 7.5760e-05, 9.0865e-06],
        [0.0000e+00, 6.5852e-05, 1.0341e-05],
        [0.0000e+00, 3.5942e-05, 4.9005e-06],
        [0.0000e+00, 8.6767e-05, 1.0709e-05],
        [0.0000e+00, 1.7750e-04, 2.1010e-05],
        [0.0000e+00, 6.1409e-05, 6.7680e-06],
        [0.0000e+00, 8.5796e-05, 9.7113e-06],
        [0.0000e+00, 3.4098e-05, 2.1479e-06],
        [0.0000e+00, 1.1429e-04, 1.2765e-05],
        [0.0000e+00, 8.7067e-05, 8.4478e-06],
        [0.0000e+00, 8.2021e-05, 7.0572e-06],
        [0.0000e+00, 6.7319e-05, 8.1360e-06],
        [0.0000e+00, 7.4284e-05, 8.6859e-06],
        [0.0000e+00, 7.2504e-05, 1.2117e-05],
        [0.0000e+00, 1.4633e-04, 1.4724e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([5.9982e-05, 9.9596e-05, 4.1971e-05, 7.1919e-05, 3.1262e-05, 1.2355e-04,
        8.1515e-05, 5.9547e-05, 7.0556e-05, 7.5469e-05, 5.1424e-05, 7.2508e-05,
        4.8347e-05, 6.5257e-05, 4.8315e-05, 3.4677e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.4501e-06, 6.5183e-06, 5.1787e-06, 4.6795e-06, 6.6841e-06, 9.7156e-06,
        7.2648e-06, 6.3247e-06, 1.0854e-05, 1.1674e-05, 1.0522e-05, 7.5698e-06,
        3.6300e-06, 5.4124e-06, 5.9659e-06, 8.7564e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 5.9982e-05, 4.4501e-06],
        [0.0000e+00, 9.9596e-05, 6.5183e-06],
        [0.0000e+00, 4.1971e-05, 5.1787e-06],
        [0.0000e+00, 7.1919e-05, 4.6795e-06],
        [0.0000e+00, 3.1262e-05, 6.6841e-06],
        [0.0000e+00, 1.2355e-04, 9.7156e-06],
        [0.0000e+00, 8.1515e-05, 7.2648e-06],
        [0.0000e+00, 5.9547e-05, 6.3247e-06],
        [0.0000e+00, 7.0556e-05, 1.0854e-05],
        [0.0000e+00, 7.5469e-05, 1.1674e-05],
        [0.0000e+00, 5.1424e-05, 1.0522e-05],
        [0.0000e+00, 7.2508e-05, 7.5698e-06],
        [0.0000e+00, 4.8347e-05, 3.6300e-06],
        [0.0000e+00, 6.5257e-05, 5.4124e-06],
        [0.0000e+00, 4.8315e-05, 5.9659e-06],
        [0.0000e+00, 3.4677e-05, 8.7564e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.9351e-05, 3.0595e-05, 8.5685e-05, 3.8382e-05, 5.3507e-05, 9.7347e-05,
        6.7282e-05, 5.2940e-05, 7.0701e-05, 3.3744e-05, 5.5705e-05, 3.3889e-05,
        5.4890e-05, 6.0313e-05, 1.0722e-04, 9.7466e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([6.2989e-06, 5.1009e-06, 8.5881e-06, 2.8882e-06, 5.8804e-06, 8.8748e-06,
        6.4849e-06, 6.7231e-06, 1.6267e-05, 3.0569e-06, 6.7149e-06, 1.9005e-05,
        5.8851e-06, 1.0273e-05, 7.4662e-06, 1.8480e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.9351e-05, 6.2989e-06],
        [0.0000e+00, 3.0595e-05, 5.1009e-06],
        [0.0000e+00, 8.5685e-05, 8.5881e-06],
        [0.0000e+00, 3.8382e-05, 2.8882e-06],
        [0.0000e+00, 5.3507e-05, 5.8804e-06],
        [0.0000e+00, 9.7347e-05, 8.8748e-06],
        [0.0000e+00, 6.7282e-05, 6.4849e-06],
        [0.0000e+00, 5.2940e-05, 6.7231e-06],
        [0.0000e+00, 7.0701e-05, 1.6267e-05],
        [0.0000e+00, 3.3744e-05, 3.0569e-06],
        [0.0000e+00, 5.5705e-05, 6.7149e-06],
        [0.0000e+00, 3.3889e-05, 1.9005e-05],
        [0.0000e+00, 5.4890e-05, 5.8851e-06],
        [0.0000e+00, 6.0313e-05, 1.0273e-05],
        [0.0000e+00, 1.0722e-04, 7.4662e-06],
        [0.0000e+00, 9.7466e-05, 1.8480e-05]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type active, variation 2 and batchsize 16: 0:02:40.759473
path ['42', 'de', 'bloomz', 'NLI', 'active', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloomz-560m NLI passive 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 192.73it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.2060e-05, 2.4019e-05, 1.8715e-05, 1.0024e-05, 3.5791e-05, 2.7391e-05,
        4.8854e-05, 1.3926e-05, 1.0231e-05, 5.1883e-05, 2.3754e-05, 8.7056e-06,
        9.1680e-06, 4.0422e-05, 4.2421e-05, 2.5793e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.5004e-04, 1.2182e-04, 1.0971e-04, 1.7987e-05, 7.3751e-05, 1.2990e-04,
        7.4503e-05, 3.4210e-05, 9.2768e-05, 7.0035e-05, 8.9039e-05, 5.7564e-05,
        9.3207e-05, 1.6275e-04, 5.7595e-05, 5.2814e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.2060e-05, 1.5004e-04],
        [0.0000e+00, 2.4019e-05, 1.2182e-04],
        [0.0000e+00, 1.8715e-05, 1.0971e-04],
        [0.0000e+00, 1.0024e-05, 1.7987e-05],
        [0.0000e+00, 3.5791e-05, 7.3751e-05],
        [0.0000e+00, 2.7391e-05, 1.2990e-04],
        [0.0000e+00, 4.8854e-05, 7.4503e-05],
        [0.0000e+00, 1.3926e-05, 3.4210e-05],
        [0.0000e+00, 1.0231e-05, 9.2768e-05],
        [0.0000e+00, 5.1883e-05, 7.0035e-05],
        [0.0000e+00, 2.3754e-05, 8.9039e-05],
        [0.0000e+00, 8.7056e-06, 5.7564e-05],
        [0.0000e+00, 9.1680e-06, 9.3207e-05],
        [0.0000e+00, 4.0422e-05, 1.6275e-04],
        [0.0000e+00, 4.2421e-05, 5.7595e-05],
        [0.0000e+00, 2.5793e-05, 5.2814e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.7593e-05, 7.5203e-05, 4.0161e-05, 3.4480e-05, 1.6202e-05, 1.8959e-05,
        4.3759e-05, 3.7970e-05, 4.2021e-05, 7.9015e-05, 3.3651e-05, 5.0601e-05,
        1.8617e-05, 1.7248e-05, 4.8040e-05, 2.1589e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.1404e-04, 1.1261e-04, 1.2028e-04, 5.5562e-05, 5.9477e-05, 8.7801e-05,
        2.5400e-04, 2.7048e-04, 1.8428e-04, 1.0645e-04, 1.8090e-04, 1.5598e-04,
        1.1679e-04, 7.8452e-05, 2.7362e-04, 5.8322e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.7593e-05, 1.1404e-04],
        [0.0000e+00, 7.5203e-05, 1.1261e-04],
        [0.0000e+00, 4.0161e-05, 1.2028e-04],
        [0.0000e+00, 3.4480e-05, 5.5562e-05],
        [0.0000e+00, 1.6202e-05, 5.9477e-05],
        [0.0000e+00, 1.8959e-05, 8.7801e-05],
        [0.0000e+00, 4.3759e-05, 2.5400e-04],
        [0.0000e+00, 3.7970e-05, 2.7048e-04],
        [0.0000e+00, 4.2021e-05, 1.8428e-04],
        [0.0000e+00, 7.9015e-05, 1.0645e-04],
        [0.0000e+00, 3.3651e-05, 1.8090e-04],
        [0.0000e+00, 5.0601e-05, 1.5598e-04],
        [0.0000e+00, 1.8617e-05, 1.1679e-04],
        [0.0000e+00, 1.7248e-05, 7.8452e-05],
        [0.0000e+00, 4.8040e-05, 2.7362e-04],
        [0.0000e+00, 2.1589e-05, 5.8322e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.6288e-05, 4.2609e-05, 3.6609e-05, 2.3487e-05, 5.4481e-05, 2.4091e-05,
        3.6464e-05, 5.8138e-05, 1.9349e-05, 4.0076e-05, 2.5034e-05, 2.4315e-05,
        3.1845e-05, 3.7116e-05, 3.8896e-05, 2.9899e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([8.4129e-05, 1.3138e-04, 9.0877e-05, 3.4529e-05, 1.3308e-04, 4.4252e-05,
        9.7935e-05, 1.4284e-04, 5.7289e-05, 4.9877e-05, 9.8106e-05, 1.0656e-04,
        1.6735e-04, 1.3318e-04, 1.3403e-04, 8.3154e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.6288e-05, 8.4129e-05],
        [0.0000e+00, 4.2609e-05, 1.3138e-04],
        [0.0000e+00, 3.6609e-05, 9.0877e-05],
        [0.0000e+00, 2.3487e-05, 3.4529e-05],
        [0.0000e+00, 5.4481e-05, 1.3308e-04],
        [0.0000e+00, 2.4091e-05, 4.4252e-05],
        [0.0000e+00, 3.6464e-05, 9.7935e-05],
        [0.0000e+00, 5.8138e-05, 1.4284e-04],
        [0.0000e+00, 1.9349e-05, 5.7289e-05],
        [0.0000e+00, 4.0076e-05, 4.9877e-05],
        [0.0000e+00, 2.5034e-05, 9.8106e-05],
        [0.0000e+00, 2.4315e-05, 1.0656e-04],
        [0.0000e+00, 3.1845e-05, 1.6735e-04],
        [0.0000e+00, 3.7116e-05, 1.3318e-04],
        [0.0000e+00, 3.8896e-05, 1.3403e-04],
        [0.0000e+00, 2.9899e-05, 8.3154e-05]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type passive, variation 0 and batchsize 16: 0:02:58.904931
path ['42', 'de', 'bloomz', 'NLI', 'passive', 'prompt_id_0']
----------- 42 de bigscience/bloomz-560m NLI passive 1 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 350.32it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4670e-05, 1.3931e-05, 4.5092e-05, 2.8057e-05, 4.5420e-05, 1.7759e-05,
        1.6449e-05, 2.6194e-05, 2.0559e-05, 3.2686e-05, 4.5167e-05, 2.3273e-05,
        3.6426e-05, 2.2289e-05, 8.5675e-06, 3.6304e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.7862e-05, 2.5587e-05, 1.0134e-04, 4.7305e-05, 5.5838e-05, 7.2161e-05,
        3.2565e-05, 3.3212e-05, 4.9804e-05, 7.6967e-05, 1.4573e-04, 7.7662e-05,
        1.1386e-04, 8.8292e-05, 2.8261e-05, 5.6276e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4670e-05, 5.7862e-05],
        [0.0000e+00, 1.3931e-05, 2.5587e-05],
        [0.0000e+00, 4.5092e-05, 1.0134e-04],
        [0.0000e+00, 2.8057e-05, 4.7305e-05],
        [0.0000e+00, 4.5420e-05, 5.5838e-05],
        [0.0000e+00, 1.7759e-05, 7.2161e-05],
        [0.0000e+00, 1.6449e-05, 3.2565e-05],
        [0.0000e+00, 2.6194e-05, 3.3212e-05],
        [0.0000e+00, 2.0559e-05, 4.9804e-05],
        [0.0000e+00, 3.2686e-05, 7.6967e-05],
        [0.0000e+00, 4.5167e-05, 1.4573e-04],
        [0.0000e+00, 2.3273e-05, 7.7662e-05],
        [0.0000e+00, 3.6426e-05, 1.1386e-04],
        [0.0000e+00, 2.2289e-05, 8.8292e-05],
        [0.0000e+00, 8.5675e-06, 2.8261e-05],
        [0.0000e+00, 3.6304e-05, 5.6276e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.5175e-05, 2.4544e-05, 2.2214e-05, 2.0124e-05, 4.4511e-05, 1.8523e-05,
        1.0299e-05, 3.0459e-05, 2.1329e-05, 1.6381e-05, 4.7557e-05, 2.9839e-05,
        3.2243e-05, 2.7638e-05, 4.2983e-05, 2.4375e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.8367e-04, 5.0166e-05, 4.5374e-05, 3.4646e-05, 1.1451e-04, 1.3598e-05,
        1.1418e-05, 9.6232e-05, 5.1288e-05, 2.8724e-05, 5.4329e-05, 7.2473e-05,
        1.2604e-04, 1.0383e-04, 8.7389e-05, 8.6187e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.5175e-05, 1.8367e-04],
        [0.0000e+00, 2.4544e-05, 5.0166e-05],
        [0.0000e+00, 2.2214e-05, 4.5374e-05],
        [0.0000e+00, 2.0124e-05, 3.4646e-05],
        [0.0000e+00, 4.4511e-05, 1.1451e-04],
        [0.0000e+00, 1.8523e-05, 1.3598e-05],
        [0.0000e+00, 1.0299e-05, 1.1418e-05],
        [0.0000e+00, 3.0459e-05, 9.6232e-05],
        [0.0000e+00, 2.1329e-05, 5.1288e-05],
        [0.0000e+00, 1.6381e-05, 2.8724e-05],
        [0.0000e+00, 4.7557e-05, 5.4329e-05],
        [0.0000e+00, 2.9839e-05, 7.2473e-05],
        [0.0000e+00, 3.2243e-05, 1.2604e-04],
        [0.0000e+00, 2.7638e-05, 1.0383e-04],
        [0.0000e+00, 4.2983e-05, 8.7389e-05],
        [0.0000e+00, 2.4375e-05, 8.6187e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.7462e-05, 5.7325e-05, 3.3290e-05, 1.5023e-05, 8.2850e-05, 3.1551e-05,
        1.9655e-05, 2.2712e-05, 5.7897e-05, 3.1029e-05, 4.2118e-05, 2.0867e-05,
        2.6092e-05, 2.0645e-05, 1.1063e-05, 3.1186e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.8234e-05, 1.0525e-04, 7.9786e-05, 1.9990e-05, 1.0025e-04, 8.1262e-05,
        4.3087e-05, 1.8771e-05, 2.5125e-04, 5.4922e-05, 7.0101e-05, 6.0345e-05,
        1.7000e-04, 4.2842e-05, 6.6130e-05, 7.7863e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.7462e-05, 3.8234e-05],
        [0.0000e+00, 5.7325e-05, 1.0525e-04],
        [0.0000e+00, 3.3290e-05, 7.9786e-05],
        [0.0000e+00, 1.5023e-05, 1.9990e-05],
        [0.0000e+00, 8.2850e-05, 1.0025e-04],
        [0.0000e+00, 3.1551e-05, 8.1262e-05],
        [0.0000e+00, 1.9655e-05, 4.3087e-05],
        [0.0000e+00, 2.2712e-05, 1.8771e-05],
        [0.0000e+00, 5.7897e-05, 2.5125e-04],
        [0.0000e+00, 3.1029e-05, 5.4922e-05],
        [0.0000e+00, 4.2118e-05, 7.0101e-05],
        [0.0000e+00, 2.0867e-05, 6.0345e-05],
        [0.0000e+00, 2.6092e-05, 1.7000e-04],
        [0.0000e+00, 2.0645e-05, 4.2842e-05],
        [0.0000e+00, 1.1063e-05, 6.6130e-05],
        [0.0000e+00, 3.1186e-05, 7.7863e-05]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type passive, variation 1 and batchsize 16: 0:02:57.829409
path ['42', 'de', 'bloomz', 'NLI', 'passive', 'prompt_id_1']
----------- 42 de bigscience/bloomz-560m NLI passive 2 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 341.17it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5220e-05, 1.1626e-05, 2.8317e-05, 1.2478e-05, 2.3880e-05, 2.2338e-05,
        1.0219e-05, 2.8360e-05, 3.7905e-05, 3.1629e-05, 7.3293e-06, 2.1379e-05,
        5.4270e-05, 2.9717e-05, 2.8040e-05, 4.6612e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([8.6467e-05, 4.4184e-05, 1.7838e-04, 7.3452e-05, 1.0758e-04, 6.8434e-05,
        2.3588e-05, 8.4980e-05, 1.1529e-04, 1.8530e-04, 1.2777e-05, 8.2892e-05,
        1.2173e-04, 4.2711e-05, 3.0065e-05, 6.4424e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5220e-05, 8.6467e-05],
        [0.0000e+00, 1.1626e-05, 4.4184e-05],
        [0.0000e+00, 2.8317e-05, 1.7838e-04],
        [0.0000e+00, 1.2478e-05, 7.3452e-05],
        [0.0000e+00, 2.3880e-05, 1.0758e-04],
        [0.0000e+00, 2.2338e-05, 6.8434e-05],
        [0.0000e+00, 1.0219e-05, 2.3588e-05],
        [0.0000e+00, 2.8360e-05, 8.4980e-05],
        [0.0000e+00, 3.7905e-05, 1.1529e-04],
        [0.0000e+00, 3.1629e-05, 1.8530e-04],
        [0.0000e+00, 7.3293e-06, 1.2777e-05],
        [0.0000e+00, 2.1379e-05, 8.2892e-05],
        [0.0000e+00, 5.4270e-05, 1.2173e-04],
        [0.0000e+00, 2.9717e-05, 4.2711e-05],
        [0.0000e+00, 2.8040e-05, 3.0065e-05],
        [0.0000e+00, 4.6612e-05, 6.4424e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.7632e-05, 4.4164e-05, 1.1793e-05, 2.4785e-05, 6.5260e-06, 5.2649e-05,
        4.2122e-05, 4.4778e-05, 4.1147e-05, 4.2651e-05, 3.3022e-05, 3.3466e-05,
        3.4667e-05, 1.6237e-05, 2.3911e-05, 4.5314e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([6.4188e-05, 1.5238e-04, 2.3743e-05, 1.1511e-04, 6.6933e-05, 7.3572e-05,
        1.9135e-04, 6.6658e-05, 2.7393e-04, 1.6228e-04, 1.4004e-04, 3.9891e-04,
        1.6186e-04, 1.1124e-04, 7.9256e-05, 3.1830e-04], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.7632e-05, 6.4188e-05],
        [0.0000e+00, 4.4164e-05, 1.5238e-04],
        [0.0000e+00, 1.1793e-05, 2.3743e-05],
        [0.0000e+00, 2.4785e-05, 1.1511e-04],
        [0.0000e+00, 6.5260e-06, 6.6933e-05],
        [0.0000e+00, 5.2649e-05, 7.3572e-05],
        [0.0000e+00, 4.2122e-05, 1.9135e-04],
        [0.0000e+00, 4.4778e-05, 6.6658e-05],
        [0.0000e+00, 4.1147e-05, 2.7393e-04],
        [0.0000e+00, 4.2651e-05, 1.6228e-04],
        [0.0000e+00, 3.3022e-05, 1.4004e-04],
        [0.0000e+00, 3.3466e-05, 3.9891e-04],
        [0.0000e+00, 3.4667e-05, 1.6186e-04],
        [0.0000e+00, 1.6237e-05, 1.1124e-04],
        [0.0000e+00, 2.3911e-05, 7.9256e-05],
        [0.0000e+00, 4.5314e-05, 3.1830e-04]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([7.8051e-06, 3.9161e-05, 4.3435e-06, 2.0648e-05, 5.8993e-05, 2.2138e-05,
        4.3480e-05, 1.6063e-05, 1.6412e-05, 2.9806e-05, 3.7093e-05, 3.6728e-05,
        8.2471e-05, 1.6008e-05, 2.2139e-05, 1.2268e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([7.1236e-05, 1.1945e-04, 3.1748e-05, 4.3301e-05, 1.6614e-04, 4.9605e-05,
        1.1812e-04, 1.2980e-04, 3.2609e-05, 7.6737e-05, 1.4760e-04, 1.0986e-04,
        1.2713e-04, 9.8073e-05, 9.5731e-05, 5.4985e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 7.8051e-06, 7.1236e-05],
        [0.0000e+00, 3.9161e-05, 1.1945e-04],
        [0.0000e+00, 4.3435e-06, 3.1748e-05],
        [0.0000e+00, 2.0648e-05, 4.3301e-05],
        [0.0000e+00, 5.8993e-05, 1.6614e-04],
        [0.0000e+00, 2.2138e-05, 4.9605e-05],
        [0.0000e+00, 4.3480e-05, 1.1812e-04],
        [0.0000e+00, 1.6063e-05, 1.2980e-04],
        [0.0000e+00, 1.6412e-05, 3.2609e-05],
        [0.0000e+00, 2.9806e-05, 7.6737e-05],
        [0.0000e+00, 3.7093e-05, 1.4760e-04],
        [0.0000e+00, 3.6728e-05, 1.0986e-04],
        [0.0000e+00, 8.2471e-05, 1.2713e-04],
        [0.0000e+00, 1.6008e-05, 9.8073e-05],
        [0.0000e+00, 2.2139e-05, 9.5731e-05],
        [0.0000e+00, 1.2268e-05, 5.4985e-05]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type passive, variation 2 and batchsize 16: 0:02:40.912477
path ['42', 'de', 'bloomz', 'NLI', 'passive', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloomz-560m NLI auxiliary 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 324.71it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.3444e-05, 4.1471e-05, 5.6337e-05, 4.8972e-05, 6.5889e-05, 2.0393e-05,
        2.5347e-05, 4.4804e-05, 3.1508e-05, 4.9035e-05, 2.8004e-05, 6.1413e-05,
        2.3861e-05, 3.7293e-05, 4.0623e-05, 1.4204e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([6.1874e-05, 5.2312e-05, 6.8682e-05, 2.2298e-04, 2.7105e-04, 2.9192e-05,
        3.5181e-05, 1.8669e-04, 1.6272e-04, 9.5180e-05, 2.2275e-04, 1.1467e-04,
        8.0125e-05, 1.3732e-04, 8.5043e-05, 5.6575e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.3444e-05, 6.1874e-05],
        [0.0000e+00, 4.1471e-05, 5.2312e-05],
        [0.0000e+00, 5.6337e-05, 6.8682e-05],
        [0.0000e+00, 4.8972e-05, 2.2298e-04],
        [0.0000e+00, 6.5889e-05, 2.7105e-04],
        [0.0000e+00, 2.0393e-05, 2.9192e-05],
        [0.0000e+00, 2.5347e-05, 3.5181e-05],
        [0.0000e+00, 4.4804e-05, 1.8669e-04],
        [0.0000e+00, 3.1508e-05, 1.6272e-04],
        [0.0000e+00, 4.9035e-05, 9.5180e-05],
        [0.0000e+00, 2.8004e-05, 2.2275e-04],
        [0.0000e+00, 6.1413e-05, 1.1467e-04],
        [0.0000e+00, 2.3861e-05, 8.0125e-05],
        [0.0000e+00, 3.7293e-05, 1.3732e-04],
        [0.0000e+00, 4.0623e-05, 8.5043e-05],
        [0.0000e+00, 1.4204e-05, 5.6575e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([7.6151e-05, 4.9280e-05, 2.5546e-05, 2.6879e-05, 6.7671e-05, 2.2063e-05,
        3.1351e-05, 6.0323e-05, 3.0080e-05, 2.4416e-05, 4.5050e-05, 5.3660e-05,
        3.3402e-05, 2.1023e-05, 7.4643e-05, 2.6208e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.4629e-04, 1.4410e-04, 1.2028e-04, 1.9618e-04, 3.6864e-04, 8.7856e-05,
        8.6630e-05, 1.6263e-04, 8.2023e-05, 9.8799e-05, 1.4072e-04, 1.0094e-04,
        8.9445e-05, 9.6617e-05, 1.5001e-04, 5.5896e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 7.6151e-05, 2.4629e-04],
        [0.0000e+00, 4.9280e-05, 1.4410e-04],
        [0.0000e+00, 2.5546e-05, 1.2028e-04],
        [0.0000e+00, 2.6879e-05, 1.9618e-04],
        [0.0000e+00, 6.7671e-05, 3.6864e-04],
        [0.0000e+00, 2.2063e-05, 8.7856e-05],
        [0.0000e+00, 3.1351e-05, 8.6630e-05],
        [0.0000e+00, 6.0323e-05, 1.6263e-04],
        [0.0000e+00, 3.0080e-05, 8.2023e-05],
        [0.0000e+00, 2.4416e-05, 9.8799e-05],
        [0.0000e+00, 4.5050e-05, 1.4072e-04],
        [0.0000e+00, 5.3660e-05, 1.0094e-04],
        [0.0000e+00, 3.3402e-05, 8.9445e-05],
        [0.0000e+00, 2.1023e-05, 9.6617e-05],
        [0.0000e+00, 7.4643e-05, 1.5001e-04],
        [0.0000e+00, 2.6208e-05, 5.5896e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([7.3967e-05, 1.8200e-05, 3.0448e-05, 2.8403e-05, 4.5779e-05, 2.9318e-05,
        4.2528e-05, 3.9422e-05, 2.4580e-05, 2.3165e-05, 4.7697e-05, 6.4196e-05,
        7.8384e-05, 7.3989e-05, 2.5645e-05, 3.8834e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.2542e-04, 1.0461e-04, 8.0039e-05, 3.6831e-05, 1.3998e-04, 9.0649e-05,
        1.3200e-04, 7.1515e-05, 7.0668e-05, 6.0289e-05, 2.0320e-04, 1.9070e-04,
        2.6712e-04, 1.1242e-04, 1.1862e-04, 7.5554e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 7.3967e-05, 3.2542e-04],
        [0.0000e+00, 1.8200e-05, 1.0461e-04],
        [0.0000e+00, 3.0448e-05, 8.0039e-05],
        [0.0000e+00, 2.8403e-05, 3.6831e-05],
        [0.0000e+00, 4.5779e-05, 1.3998e-04],
        [0.0000e+00, 2.9318e-05, 9.0649e-05],
        [0.0000e+00, 4.2528e-05, 1.3200e-04],
        [0.0000e+00, 3.9422e-05, 7.1515e-05],
        [0.0000e+00, 2.4580e-05, 7.0668e-05],
        [0.0000e+00, 2.3165e-05, 6.0289e-05],
        [0.0000e+00, 4.7697e-05, 2.0320e-04],
        [0.0000e+00, 6.4196e-05, 1.9070e-04],
        [0.0000e+00, 7.8384e-05, 2.6712e-04],
        [0.0000e+00, 7.3989e-05, 1.1242e-04],
        [0.0000e+00, 2.5645e-05, 1.1862e-04],
        [0.0000e+00, 3.8834e-05, 7.5554e-05]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type auxiliary, variation 0 and batchsize 16: 0:02:49.422967
path ['42', 'de', 'bloomz', 'NLI', 'auxiliary', 'prompt_id_0']
----------- 42 de bigscience/bloomz-560m NLI auxiliary 1 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 338.47it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([6.4428e-05, 2.8645e-05, 8.4812e-05, 6.9120e-05, 4.2373e-05, 2.1798e-05,
        6.6143e-05, 7.9996e-05, 3.4898e-05, 2.4558e-05, 2.8819e-05, 6.8650e-05,
        2.6474e-05, 4.6944e-05, 2.5872e-05, 2.2142e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([7.7130e-05, 5.8442e-05, 1.2025e-04, 1.7332e-04, 1.5410e-04, 8.2956e-05,
        1.0281e-04, 2.8374e-04, 5.3935e-05, 6.9914e-05, 1.7749e-04, 1.1647e-04,
        1.4828e-04, 1.5326e-04, 9.0619e-05, 8.1211e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 6.4428e-05, 7.7130e-05],
        [0.0000e+00, 2.8645e-05, 5.8442e-05],
        [0.0000e+00, 8.4812e-05, 1.2025e-04],
        [0.0000e+00, 6.9120e-05, 1.7332e-04],
        [0.0000e+00, 4.2373e-05, 1.5410e-04],
        [0.0000e+00, 2.1798e-05, 8.2956e-05],
        [0.0000e+00, 6.6143e-05, 1.0281e-04],
        [0.0000e+00, 7.9996e-05, 2.8374e-04],
        [0.0000e+00, 3.4898e-05, 5.3935e-05],
        [0.0000e+00, 2.4558e-05, 6.9914e-05],
        [0.0000e+00, 2.8819e-05, 1.7749e-04],
        [0.0000e+00, 6.8650e-05, 1.1647e-04],
        [0.0000e+00, 2.6474e-05, 1.4828e-04],
        [0.0000e+00, 4.6944e-05, 1.5326e-04],
        [0.0000e+00, 2.5872e-05, 9.0619e-05],
        [0.0000e+00, 2.2142e-05, 8.1211e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.7674e-05, 2.7757e-05, 5.4703e-05, 3.9685e-05, 6.7003e-05, 7.6260e-05,
        3.5194e-05, 1.4061e-05, 5.2870e-05, 1.4371e-05, 3.3849e-05, 7.2132e-05,
        2.4103e-05, 3.6383e-05, 2.9292e-05, 4.8382e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.3416e-05, 7.3476e-05, 1.2911e-04, 5.3872e-05, 1.4331e-04, 2.5415e-04,
        8.2730e-05, 4.7992e-05, 1.9873e-04, 7.4110e-05, 5.0024e-05, 1.8941e-04,
        8.2066e-05, 6.8044e-05, 2.7264e-05, 8.4901e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.7674e-05, 4.3416e-05],
        [0.0000e+00, 2.7757e-05, 7.3476e-05],
        [0.0000e+00, 5.4703e-05, 1.2911e-04],
        [0.0000e+00, 3.9685e-05, 5.3872e-05],
        [0.0000e+00, 6.7003e-05, 1.4331e-04],
        [0.0000e+00, 7.6260e-05, 2.5415e-04],
        [0.0000e+00, 3.5194e-05, 8.2730e-05],
        [0.0000e+00, 1.4061e-05, 4.7992e-05],
        [0.0000e+00, 5.2870e-05, 1.9873e-04],
        [0.0000e+00, 1.4371e-05, 7.4110e-05],
        [0.0000e+00, 3.3849e-05, 5.0024e-05],
        [0.0000e+00, 7.2132e-05, 1.8941e-04],
        [0.0000e+00, 2.4103e-05, 8.2066e-05],
        [0.0000e+00, 3.6383e-05, 6.8044e-05],
        [0.0000e+00, 2.9292e-05, 2.7264e-05],
        [0.0000e+00, 4.8382e-05, 8.4901e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.1274e-05, 3.0594e-05, 4.2140e-05, 5.1883e-05, 7.5927e-05, 2.4004e-05,
        3.0796e-05, 4.1351e-05, 2.2488e-05, 3.5359e-05, 6.3392e-05, 3.7042e-05,
        2.3736e-05, 4.1085e-05, 2.1992e-05, 8.6593e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([7.2289e-05, 7.9266e-05, 1.3370e-04, 1.4063e-04, 2.3330e-04, 5.2155e-05,
        1.3646e-04, 1.0538e-04, 8.2420e-05, 6.8690e-05, 3.3796e-04, 6.3431e-05,
        3.7272e-05, 1.1459e-04, 2.1925e-05, 1.4798e-04], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.1274e-05, 7.2289e-05],
        [0.0000e+00, 3.0594e-05, 7.9266e-05],
        [0.0000e+00, 4.2140e-05, 1.3370e-04],
        [0.0000e+00, 5.1883e-05, 1.4063e-04],
        [0.0000e+00, 7.5927e-05, 2.3330e-04],
        [0.0000e+00, 2.4004e-05, 5.2155e-05],
        [0.0000e+00, 3.0796e-05, 1.3646e-04],
        [0.0000e+00, 4.1351e-05, 1.0538e-04],
        [0.0000e+00, 2.2488e-05, 8.2420e-05],
        [0.0000e+00, 3.5359e-05, 6.8690e-05],
        [0.0000e+00, 6.3392e-05, 3.3796e-04],
        [0.0000e+00, 3.7042e-05, 6.3431e-05],
        [0.0000e+00, 2.3736e-05, 3.7272e-05],
        [0.0000e+00, 4.1085e-05, 1.1459e-04],
        [0.0000e+00, 2.1992e-05, 2.1925e-05],
        [0.0000e+00, 8.6593e-05, 1.4798e-04]], device='cuda:0')
acc:  0.3125
Time taken to execute the de NLI task with prompt type auxiliary, variation 1 and batchsize 16: 0:02:57.350709
path ['42', 'de', 'bloomz', 'NLI', 'auxiliary', 'prompt_id_1']
----------- 42 de bigscience/bloomz-560m NLI auxiliary 2 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 297.26it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([6.4161e-05, 6.9680e-05, 3.8151e-05, 2.3963e-05, 2.0314e-05, 6.0094e-05,
        1.9662e-05, 2.2004e-05, 3.8017e-05, 4.4858e-05, 2.6589e-05, 2.3858e-05,
        6.6575e-05, 3.0145e-05, 4.2344e-05, 3.1317e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.8813e-04, 1.4768e-04, 1.3739e-04, 7.3682e-05, 9.5839e-05, 2.2875e-04,
        3.7077e-05, 8.5783e-05, 1.1582e-04, 2.1174e-04, 1.3607e-04, 1.5741e-04,
        1.2483e-04, 8.5480e-05, 1.5555e-04, 6.5432e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 6.4161e-05, 1.8813e-04],
        [0.0000e+00, 6.9680e-05, 1.4768e-04],
        [0.0000e+00, 3.8151e-05, 1.3739e-04],
        [0.0000e+00, 2.3963e-05, 7.3682e-05],
        [0.0000e+00, 2.0314e-05, 9.5839e-05],
        [0.0000e+00, 6.0094e-05, 2.2875e-04],
        [0.0000e+00, 1.9662e-05, 3.7077e-05],
        [0.0000e+00, 2.2004e-05, 8.5783e-05],
        [0.0000e+00, 3.8017e-05, 1.1582e-04],
        [0.0000e+00, 4.4858e-05, 2.1174e-04],
        [0.0000e+00, 2.6589e-05, 1.3607e-04],
        [0.0000e+00, 2.3858e-05, 1.5741e-04],
        [0.0000e+00, 6.6575e-05, 1.2483e-04],
        [0.0000e+00, 3.0145e-05, 8.5480e-05],
        [0.0000e+00, 4.2344e-05, 1.5555e-04],
        [0.0000e+00, 3.1317e-05, 6.5432e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.3282e-05, 2.0184e-05, 3.3785e-05, 5.6107e-05, 1.3288e-05, 1.9704e-05,
        4.2119e-05, 7.4891e-05, 2.3341e-05, 3.4089e-05, 2.5466e-05, 4.7775e-05,
        2.0457e-05, 2.8007e-05, 6.4773e-05, 4.2616e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([6.8866e-05, 6.2007e-05, 5.9137e-05, 1.2074e-04, 4.4764e-05, 2.3245e-05,
        8.9484e-05, 1.3094e-04, 5.7886e-05, 7.7775e-05, 2.7888e-05, 1.3043e-04,
        8.0154e-05, 8.1282e-05, 3.3061e-04, 1.7809e-04], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.3282e-05, 6.8866e-05],
        [0.0000e+00, 2.0184e-05, 6.2007e-05],
        [0.0000e+00, 3.3785e-05, 5.9137e-05],
        [0.0000e+00, 5.6107e-05, 1.2074e-04],
        [0.0000e+00, 1.3288e-05, 4.4764e-05],
        [0.0000e+00, 1.9704e-05, 2.3245e-05],
        [0.0000e+00, 4.2119e-05, 8.9484e-05],
        [0.0000e+00, 7.4891e-05, 1.3094e-04],
        [0.0000e+00, 2.3341e-05, 5.7886e-05],
        [0.0000e+00, 3.4089e-05, 7.7775e-05],
        [0.0000e+00, 2.5466e-05, 2.7888e-05],
        [0.0000e+00, 4.7775e-05, 1.3043e-04],
        [0.0000e+00, 2.0457e-05, 8.0154e-05],
        [0.0000e+00, 2.8007e-05, 8.1282e-05],
        [0.0000e+00, 6.4773e-05, 3.3061e-04],
        [0.0000e+00, 4.2616e-05, 1.7809e-04]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([6.8189e-05, 5.6879e-05, 3.0689e-05, 5.3413e-05, 3.1743e-05, 3.2799e-05,
        2.5046e-05, 2.3198e-05, 3.2614e-05, 2.2425e-05, 6.5597e-05, 6.6613e-05,
        2.2482e-05, 3.6346e-05, 2.0875e-05, 2.8198e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.7942e-04, 1.6688e-04, 6.0191e-05, 7.3997e-05, 6.1545e-05, 1.0968e-04,
        4.7052e-05, 7.5927e-05, 7.0087e-05, 1.4269e-04, 1.9281e-04, 2.4611e-04,
        9.2556e-05, 1.2265e-04, 5.6767e-05, 4.2477e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 6.8189e-05, 2.7942e-04],
        [0.0000e+00, 5.6879e-05, 1.6688e-04],
        [0.0000e+00, 3.0689e-05, 6.0191e-05],
        [0.0000e+00, 5.3413e-05, 7.3997e-05],
        [0.0000e+00, 3.1743e-05, 6.1545e-05],
        [0.0000e+00, 3.2799e-05, 1.0968e-04],
        [0.0000e+00, 2.5046e-05, 4.7052e-05],
        [0.0000e+00, 2.3198e-05, 7.5927e-05],
        [0.0000e+00, 3.2614e-05, 7.0087e-05],
        [0.0000e+00, 2.2425e-05, 1.4269e-04],
        [0.0000e+00, 6.5597e-05, 1.9281e-04],
        [0.0000e+00, 6.6613e-05, 2.4611e-04],
        [0.0000e+00, 2.2482e-05, 9.2556e-05],
        [0.0000e+00, 3.6346e-05, 1.2265e-04],
        [0.0000e+00, 2.0875e-05, 5.6767e-05],
        [0.0000e+00, 2.8198e-05, 4.2477e-05]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type auxiliary, variation 2 and batchsize 16: 0:02:58.380121
path ['42', 'de', 'bloomz', 'NLI', 'auxiliary', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloomz-560m NLI modal 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 296.50it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.5834e-05, 2.2236e-05, 1.2927e-05, 2.5514e-05, 1.7382e-05, 3.1149e-05,
        1.4905e-05, 4.7422e-06, 1.4326e-05, 3.1682e-05, 1.4155e-05, 3.8410e-05,
        1.9306e-05, 7.4053e-06, 1.5410e-05, 1.5987e-06], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.3895e-04, 7.0136e-05, 4.9374e-05, 1.2486e-04, 1.4862e-04, 1.6167e-04,
        3.6905e-05, 1.5166e-05, 8.3452e-05, 2.1790e-04, 8.0443e-05, 1.6944e-04,
        7.9596e-05, 1.5939e-05, 3.5820e-05, 2.5946e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.5834e-05, 1.3895e-04],
        [0.0000e+00, 2.2236e-05, 7.0136e-05],
        [0.0000e+00, 1.2927e-05, 4.9374e-05],
        [0.0000e+00, 2.5514e-05, 1.2486e-04],
        [0.0000e+00, 1.7382e-05, 1.4862e-04],
        [0.0000e+00, 3.1149e-05, 1.6167e-04],
        [0.0000e+00, 1.4905e-05, 3.6905e-05],
        [0.0000e+00, 4.7422e-06, 1.5166e-05],
        [0.0000e+00, 1.4326e-05, 8.3452e-05],
        [0.0000e+00, 3.1682e-05, 2.1790e-04],
        [0.0000e+00, 1.4155e-05, 8.0443e-05],
        [0.0000e+00, 3.8410e-05, 1.6944e-04],
        [0.0000e+00, 1.9306e-05, 7.9596e-05],
        [0.0000e+00, 7.4053e-06, 1.5939e-05],
        [0.0000e+00, 1.5410e-05, 3.5820e-05],
        [0.0000e+00, 1.5987e-06, 2.5946e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.3043e-05, 1.1742e-05, 3.2510e-05, 2.1267e-05, 3.5405e-05, 2.4393e-05,
        1.9105e-05, 1.1728e-05, 2.6833e-05, 1.3126e-05, 2.0003e-05, 3.3742e-05,
        3.9128e-05, 5.3462e-06, 4.3109e-05, 2.0719e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([8.5266e-05, 2.0978e-05, 1.0734e-04, 6.1397e-05, 1.4569e-04, 1.2096e-04,
        8.5994e-05, 5.4790e-05, 9.9845e-05, 8.1209e-05, 1.1457e-04, 1.5472e-04,
        1.8217e-04, 1.6274e-05, 1.0544e-04, 9.3293e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.3043e-05, 8.5266e-05],
        [0.0000e+00, 1.1742e-05, 2.0978e-05],
        [0.0000e+00, 3.2510e-05, 1.0734e-04],
        [0.0000e+00, 2.1267e-05, 6.1397e-05],
        [0.0000e+00, 3.5405e-05, 1.4569e-04],
        [0.0000e+00, 2.4393e-05, 1.2096e-04],
        [0.0000e+00, 1.9105e-05, 8.5994e-05],
        [0.0000e+00, 1.1728e-05, 5.4790e-05],
        [0.0000e+00, 2.6833e-05, 9.9845e-05],
        [0.0000e+00, 1.3126e-05, 8.1209e-05],
        [0.0000e+00, 2.0003e-05, 1.1457e-04],
        [0.0000e+00, 3.3742e-05, 1.5472e-04],
        [0.0000e+00, 3.9128e-05, 1.8217e-04],
        [0.0000e+00, 5.3462e-06, 1.6274e-05],
        [0.0000e+00, 4.3109e-05, 1.0544e-04],
        [0.0000e+00, 2.0719e-05, 9.3293e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.6226e-05, 2.1099e-05, 3.7816e-05, 1.0373e-05, 5.4545e-06, 2.4226e-05,
        2.0680e-05, 1.8752e-05, 2.7211e-05, 2.0581e-05, 2.5938e-05, 2.7907e-05,
        3.4781e-05, 2.5729e-05, 1.0704e-05, 3.4690e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.8653e-05, 9.6203e-05, 2.0204e-04, 5.4303e-05, 1.1672e-05, 2.8292e-04,
        7.5807e-05, 9.6661e-05, 1.1058e-04, 9.8039e-05, 9.9221e-05, 9.2151e-05,
        8.2155e-05, 1.8806e-04, 1.9642e-05, 1.6341e-04], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.6226e-05, 3.8653e-05],
        [0.0000e+00, 2.1099e-05, 9.6203e-05],
        [0.0000e+00, 3.7816e-05, 2.0204e-04],
        [0.0000e+00, 1.0373e-05, 5.4303e-05],
        [0.0000e+00, 5.4545e-06, 1.1672e-05],
        [0.0000e+00, 2.4226e-05, 2.8292e-04],
        [0.0000e+00, 2.0680e-05, 7.5807e-05],
        [0.0000e+00, 1.8752e-05, 9.6661e-05],
        [0.0000e+00, 2.7211e-05, 1.1058e-04],
        [0.0000e+00, 2.0581e-05, 9.8039e-05],
        [0.0000e+00, 2.5938e-05, 9.9221e-05],
        [0.0000e+00, 2.7907e-05, 9.2151e-05],
        [0.0000e+00, 3.4781e-05, 8.2155e-05],
        [0.0000e+00, 2.5729e-05, 1.8806e-04],
        [0.0000e+00, 1.0704e-05, 1.9642e-05],
        [0.0000e+00, 3.4690e-05, 1.6341e-04]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type modal, variation 0 and batchsize 16: 0:02:57.888980
path ['42', 'de', 'bloomz', 'NLI', 'modal', 'prompt_id_0']
----------- 42 de bigscience/bloomz-560m NLI modal 1 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 174.55it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.9067e-06, 2.4050e-05, 1.8533e-05, 1.7778e-05, 3.1190e-05, 1.4500e-05,
        1.1914e-05, 2.0273e-05, 1.9543e-05, 3.2994e-05, 2.0902e-05, 1.2966e-05,
        4.5389e-05, 3.6046e-05, 5.0198e-06, 1.4690e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.4889e-05, 2.7077e-04, 1.1559e-04, 5.1040e-05, 1.0765e-04, 8.2035e-05,
        7.6726e-05, 1.1245e-04, 6.1698e-05, 1.9277e-04, 1.1480e-04, 6.0395e-05,
        2.0776e-04, 9.7141e-05, 1.6239e-05, 1.4468e-04], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.9067e-06, 1.4889e-05],
        [0.0000e+00, 2.4050e-05, 2.7077e-04],
        [0.0000e+00, 1.8533e-05, 1.1559e-04],
        [0.0000e+00, 1.7778e-05, 5.1040e-05],
        [0.0000e+00, 3.1190e-05, 1.0765e-04],
        [0.0000e+00, 1.4500e-05, 8.2035e-05],
        [0.0000e+00, 1.1914e-05, 7.6726e-05],
        [0.0000e+00, 2.0273e-05, 1.1245e-04],
        [0.0000e+00, 1.9543e-05, 6.1698e-05],
        [0.0000e+00, 3.2994e-05, 1.9277e-04],
        [0.0000e+00, 2.0902e-05, 1.1480e-04],
        [0.0000e+00, 1.2966e-05, 6.0395e-05],
        [0.0000e+00, 4.5389e-05, 2.0776e-04],
        [0.0000e+00, 3.6046e-05, 9.7141e-05],
        [0.0000e+00, 5.0198e-06, 1.6239e-05],
        [0.0000e+00, 1.4690e-05, 1.4468e-04]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.3002e-05, 2.7923e-05, 1.3844e-05, 1.2399e-05, 3.5591e-05, 2.8274e-05,
        1.7524e-05, 3.1957e-05, 4.0105e-05, 1.9902e-05, 1.2907e-05, 1.9133e-05,
        1.7033e-05, 2.2527e-05, 2.1415e-05, 3.5842e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.5708e-05, 1.4060e-04, 3.1864e-05, 8.7964e-05, 1.7210e-04, 1.3385e-04,
        1.0545e-04, 1.0010e-04, 2.0606e-04, 9.2189e-05, 2.7939e-05, 9.2088e-05,
        1.6155e-04, 1.9316e-04, 8.0529e-05, 1.7152e-04], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.3002e-05, 4.5708e-05],
        [0.0000e+00, 2.7923e-05, 1.4060e-04],
        [0.0000e+00, 1.3844e-05, 3.1864e-05],
        [0.0000e+00, 1.2399e-05, 8.7964e-05],
        [0.0000e+00, 3.5591e-05, 1.7210e-04],
        [0.0000e+00, 2.8274e-05, 1.3385e-04],
        [0.0000e+00, 1.7524e-05, 1.0545e-04],
        [0.0000e+00, 3.1957e-05, 1.0010e-04],
        [0.0000e+00, 4.0105e-05, 2.0606e-04],
        [0.0000e+00, 1.9902e-05, 9.2189e-05],
        [0.0000e+00, 1.2907e-05, 2.7939e-05],
        [0.0000e+00, 1.9133e-05, 9.2088e-05],
        [0.0000e+00, 1.7033e-05, 1.6155e-04],
        [0.0000e+00, 2.2527e-05, 1.9316e-04],
        [0.0000e+00, 2.1415e-05, 8.0529e-05],
        [0.0000e+00, 3.5842e-05, 1.7152e-04]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.0246e-06, 2.5042e-05, 1.2384e-05, 2.7404e-05, 1.9783e-05, 4.0858e-05,
        3.3468e-05, 1.2817e-05, 2.2507e-05, 4.8030e-06, 6.2399e-06, 1.1067e-05,
        3.4648e-05, 3.8074e-05, 3.7902e-05, 1.1148e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.7684e-06, 1.3527e-04, 2.8777e-05, 1.1199e-04, 8.1016e-05, 1.1708e-04,
        1.0288e-04, 9.0878e-05, 1.0993e-04, 1.2854e-05, 1.3909e-05, 5.2602e-05,
        2.5757e-04, 2.1174e-04, 1.8759e-04, 2.0502e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.0246e-06, 1.7684e-06],
        [0.0000e+00, 2.5042e-05, 1.3527e-04],
        [0.0000e+00, 1.2384e-05, 2.8777e-05],
        [0.0000e+00, 2.7404e-05, 1.1199e-04],
        [0.0000e+00, 1.9783e-05, 8.1016e-05],
        [0.0000e+00, 4.0858e-05, 1.1708e-04],
        [0.0000e+00, 3.3468e-05, 1.0288e-04],
        [0.0000e+00, 1.2817e-05, 9.0878e-05],
        [0.0000e+00, 2.2507e-05, 1.0993e-04],
        [0.0000e+00, 4.8030e-06, 1.2854e-05],
        [0.0000e+00, 6.2399e-06, 1.3909e-05],
        [0.0000e+00, 1.1067e-05, 5.2602e-05],
        [0.0000e+00, 3.4648e-05, 2.5757e-04],
        [0.0000e+00, 3.8074e-05, 2.1174e-04],
        [0.0000e+00, 3.7902e-05, 1.8759e-04],
        [0.0000e+00, 1.1148e-05, 2.0502e-05]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type modal, variation 1 and batchsize 16: 0:02:41.485495
path ['42', 'de', 'bloomz', 'NLI', 'modal', 'prompt_id_1']
----------- 42 de bigscience/bloomz-560m NLI modal 2 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 334.39it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([6.3127e-06, 1.2810e-05, 2.5036e-05, 1.9043e-05, 3.6975e-05, 1.7378e-05,
        1.4318e-05, 2.7988e-05, 1.2869e-05, 3.0974e-05, 1.6469e-05, 4.2428e-05,
        1.3402e-05, 1.9474e-05, 3.5128e-05, 2.1862e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.1585e-05, 5.6823e-05, 1.1614e-04, 7.9879e-05, 1.4466e-04, 9.0283e-05,
        4.8349e-05, 9.6867e-05, 2.4421e-05, 1.0481e-04, 1.2059e-04, 1.7052e-04,
        2.5386e-05, 8.9514e-05, 1.3284e-04, 5.5320e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 6.3127e-06, 2.1585e-05],
        [0.0000e+00, 1.2810e-05, 5.6823e-05],
        [0.0000e+00, 2.5036e-05, 1.1614e-04],
        [0.0000e+00, 1.9043e-05, 7.9879e-05],
        [0.0000e+00, 3.6975e-05, 1.4466e-04],
        [0.0000e+00, 1.7378e-05, 9.0283e-05],
        [0.0000e+00, 1.4318e-05, 4.8349e-05],
        [0.0000e+00, 2.7988e-05, 9.6867e-05],
        [0.0000e+00, 1.2869e-05, 2.4421e-05],
        [0.0000e+00, 3.0974e-05, 1.0481e-04],
        [0.0000e+00, 1.6469e-05, 1.2059e-04],
        [0.0000e+00, 4.2428e-05, 1.7052e-04],
        [0.0000e+00, 1.3402e-05, 2.5386e-05],
        [0.0000e+00, 1.9474e-05, 8.9514e-05],
        [0.0000e+00, 3.5128e-05, 1.3284e-04],
        [0.0000e+00, 2.1862e-05, 5.5320e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.0333e-05, 2.5480e-05, 1.2161e-05, 2.2363e-05, 3.1324e-05, 2.9079e-05,
        1.9562e-05, 1.3473e-05, 3.5325e-05, 2.8798e-05, 1.6249e-05, 4.1209e-06,
        1.3830e-05, 4.1272e-05, 1.8729e-05, 3.2112e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.5514e-04, 1.6015e-04, 7.2022e-05, 1.0611e-04, 9.3258e-05, 8.5804e-05,
        6.7550e-05, 8.1482e-05, 1.9810e-04, 9.6279e-05, 1.1119e-04, 1.2576e-05,
        7.9238e-05, 9.5795e-05, 7.0121e-05, 1.4672e-04], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.0333e-05, 1.5514e-04],
        [0.0000e+00, 2.5480e-05, 1.6015e-04],
        [0.0000e+00, 1.2161e-05, 7.2022e-05],
        [0.0000e+00, 2.2363e-05, 1.0611e-04],
        [0.0000e+00, 3.1324e-05, 9.3258e-05],
        [0.0000e+00, 2.9079e-05, 8.5804e-05],
        [0.0000e+00, 1.9562e-05, 6.7550e-05],
        [0.0000e+00, 1.3473e-05, 8.1482e-05],
        [0.0000e+00, 3.5325e-05, 1.9810e-04],
        [0.0000e+00, 2.8798e-05, 9.6279e-05],
        [0.0000e+00, 1.6249e-05, 1.1119e-04],
        [0.0000e+00, 4.1209e-06, 1.2576e-05],
        [0.0000e+00, 1.3830e-05, 7.9238e-05],
        [0.0000e+00, 4.1272e-05, 9.5795e-05],
        [0.0000e+00, 1.8729e-05, 7.0121e-05],
        [0.0000e+00, 3.2112e-05, 1.4672e-04]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.1835e-05, 3.5856e-05, 1.5638e-05, 1.1074e-05, 3.3219e-05, 1.5930e-05,
        2.6353e-05, 2.0616e-05, 5.7206e-06, 1.0246e-05, 4.0505e-05, 9.9588e-06,
        1.6964e-06, 2.6869e-05, 3.3019e-05, 3.4518e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([6.3206e-05, 1.5363e-04, 7.5874e-05, 2.4076e-05, 1.4254e-04, 3.9458e-05,
        1.0890e-04, 5.9088e-05, 1.3062e-05, 2.2111e-05, 1.8303e-04, 1.8227e-05,
        2.7261e-06, 2.5349e-04, 8.8745e-05, 6.9953e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.1835e-05, 6.3206e-05],
        [0.0000e+00, 3.5856e-05, 1.5363e-04],
        [0.0000e+00, 1.5638e-05, 7.5874e-05],
        [0.0000e+00, 1.1074e-05, 2.4076e-05],
        [0.0000e+00, 3.3219e-05, 1.4254e-04],
        [0.0000e+00, 1.5930e-05, 3.9458e-05],
        [0.0000e+00, 2.6353e-05, 1.0890e-04],
        [0.0000e+00, 2.0616e-05, 5.9088e-05],
        [0.0000e+00, 5.7206e-06, 1.3062e-05],
        [0.0000e+00, 1.0246e-05, 2.2111e-05],
        [0.0000e+00, 4.0505e-05, 1.8303e-04],
        [0.0000e+00, 9.9588e-06, 1.8227e-05],
        [0.0000e+00, 1.6964e-06, 2.7261e-06],
        [0.0000e+00, 2.6869e-05, 2.5349e-04],
        [0.0000e+00, 3.3019e-05, 8.8745e-05],
        [0.0000e+00, 3.4518e-05, 6.9953e-05]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type modal, variation 2 and batchsize 16: 0:02:40.838542
path ['42', 'de', 'bloomz', 'NLI', 'modal', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloomz-560m NLI rare_synonyms 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 301.08it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([8.2440e-06, 1.5849e-06, 1.3243e-05, 1.7840e-05, 1.6296e-05, 3.2034e-05,
        2.0534e-05, 3.9195e-05, 3.1829e-05, 9.8283e-06, 5.4756e-06, 1.2031e-05,
        2.4031e-05, 1.1400e-05, 2.4952e-05, 1.5760e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([7.0379e-05, 3.5623e-06, 7.1705e-05, 9.9054e-05, 1.6333e-04, 1.0620e-04,
        1.2377e-04, 2.1269e-04, 8.8740e-05, 1.8056e-05, 2.3503e-05, 5.1716e-05,
        1.4273e-04, 6.5930e-05, 1.1641e-04, 5.4845e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 8.2440e-06, 7.0379e-05],
        [0.0000e+00, 1.5849e-06, 3.5623e-06],
        [0.0000e+00, 1.3243e-05, 7.1705e-05],
        [0.0000e+00, 1.7840e-05, 9.9054e-05],
        [0.0000e+00, 1.6296e-05, 1.6333e-04],
        [0.0000e+00, 3.2034e-05, 1.0620e-04],
        [0.0000e+00, 2.0534e-05, 1.2377e-04],
        [0.0000e+00, 3.9195e-05, 2.1269e-04],
        [0.0000e+00, 3.1829e-05, 8.8740e-05],
        [0.0000e+00, 9.8283e-06, 1.8056e-05],
        [0.0000e+00, 5.4756e-06, 2.3503e-05],
        [0.0000e+00, 1.2031e-05, 5.1716e-05],
        [0.0000e+00, 2.4031e-05, 1.4273e-04],
        [0.0000e+00, 1.1400e-05, 6.5930e-05],
        [0.0000e+00, 2.4952e-05, 1.1641e-04],
        [0.0000e+00, 1.5760e-05, 5.4845e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.9920e-05, 2.8274e-05, 5.2407e-06, 2.0246e-05, 4.3722e-05, 2.2522e-05,
        3.2203e-05, 2.5745e-05, 7.6198e-06, 3.8071e-05, 1.7327e-05, 2.3983e-05,
        2.4958e-05, 1.8799e-05, 3.2738e-05, 2.1619e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([7.8338e-05, 2.3676e-04, 1.8561e-05, 1.3177e-04, 1.2272e-04, 3.1105e-04,
        1.7795e-04, 9.8699e-05, 2.0500e-05, 2.1479e-04, 9.1090e-05, 1.2560e-04,
        1.1005e-04, 8.2507e-05, 1.5595e-04, 8.4502e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.9920e-05, 7.8338e-05],
        [0.0000e+00, 2.8274e-05, 2.3676e-04],
        [0.0000e+00, 5.2407e-06, 1.8561e-05],
        [0.0000e+00, 2.0246e-05, 1.3177e-04],
        [0.0000e+00, 4.3722e-05, 1.2272e-04],
        [0.0000e+00, 2.2522e-05, 3.1105e-04],
        [0.0000e+00, 3.2203e-05, 1.7795e-04],
        [0.0000e+00, 2.5745e-05, 9.8699e-05],
        [0.0000e+00, 7.6198e-06, 2.0500e-05],
        [0.0000e+00, 3.8071e-05, 2.1479e-04],
        [0.0000e+00, 1.7327e-05, 9.1090e-05],
        [0.0000e+00, 2.3983e-05, 1.2560e-04],
        [0.0000e+00, 2.4958e-05, 1.1005e-04],
        [0.0000e+00, 1.8799e-05, 8.2507e-05],
        [0.0000e+00, 3.2738e-05, 1.5595e-04],
        [0.0000e+00, 2.1619e-05, 8.4502e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.5094e-05, 1.8715e-05, 1.7797e-05, 1.2731e-05, 1.3507e-05, 2.3501e-05,
        1.4163e-05, 3.4576e-05, 2.3719e-05, 1.2086e-05, 5.9762e-06, 1.0141e-05,
        1.6098e-05, 3.7797e-05, 1.2911e-05, 2.0807e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.2012e-04, 1.1207e-04, 8.6731e-05, 8.8331e-05, 4.7341e-05, 1.9511e-04,
        3.7570e-05, 1.6703e-04, 1.1634e-04, 8.9732e-05, 1.4819e-05, 2.1939e-05,
        1.5276e-04, 1.9165e-04, 8.8307e-05, 7.7677e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.5094e-05, 2.2012e-04],
        [0.0000e+00, 1.8715e-05, 1.1207e-04],
        [0.0000e+00, 1.7797e-05, 8.6731e-05],
        [0.0000e+00, 1.2731e-05, 8.8331e-05],
        [0.0000e+00, 1.3507e-05, 4.7341e-05],
        [0.0000e+00, 2.3501e-05, 1.9511e-04],
        [0.0000e+00, 1.4163e-05, 3.7570e-05],
        [0.0000e+00, 3.4576e-05, 1.6703e-04],
        [0.0000e+00, 2.3719e-05, 1.1634e-04],
        [0.0000e+00, 1.2086e-05, 8.9732e-05],
        [0.0000e+00, 5.9762e-06, 1.4819e-05],
        [0.0000e+00, 1.0141e-05, 2.1939e-05],
        [0.0000e+00, 1.6098e-05, 1.5276e-04],
        [0.0000e+00, 3.7797e-05, 1.9165e-04],
        [0.0000e+00, 1.2911e-05, 8.8307e-05],
        [0.0000e+00, 2.0807e-05, 7.7677e-05]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type rare_synonyms, variation 0 and batchsize 16: 0:02:40.789562
path ['42', 'de', 'bloomz', 'NLI', 'rare_synonyms', 'prompt_id_0']
----------- 42 de bigscience/bloomz-560m NLI rare_synonyms 1 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 313.32it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([9.8629e-06, 2.4909e-05, 3.7598e-05, 1.8522e-05, 3.0024e-05, 1.9248e-05,
        1.7098e-05, 2.8876e-05, 4.2275e-05, 1.8487e-05, 2.4291e-05, 1.9453e-06,
        1.7028e-05, 1.0275e-05, 3.3869e-05, 1.2271e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([6.3926e-05, 1.1561e-04, 1.8322e-04, 6.8901e-05, 1.1304e-04, 9.2954e-05,
        5.1534e-05, 2.3182e-04, 1.1789e-04, 8.0143e-05, 1.3129e-04, 3.6046e-06,
        1.0756e-04, 1.9067e-05, 9.2428e-05, 8.3696e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 9.8629e-06, 6.3926e-05],
        [0.0000e+00, 2.4909e-05, 1.1561e-04],
        [0.0000e+00, 3.7598e-05, 1.8322e-04],
        [0.0000e+00, 1.8522e-05, 6.8901e-05],
        [0.0000e+00, 3.0024e-05, 1.1304e-04],
        [0.0000e+00, 1.9248e-05, 9.2954e-05],
        [0.0000e+00, 1.7098e-05, 5.1534e-05],
        [0.0000e+00, 2.8876e-05, 2.3182e-04],
        [0.0000e+00, 4.2275e-05, 1.1789e-04],
        [0.0000e+00, 1.8487e-05, 8.0143e-05],
        [0.0000e+00, 2.4291e-05, 1.3129e-04],
        [0.0000e+00, 1.9453e-06, 3.6046e-06],
        [0.0000e+00, 1.7028e-05, 1.0756e-04],
        [0.0000e+00, 1.0275e-05, 1.9067e-05],
        [0.0000e+00, 3.3869e-05, 9.2428e-05],
        [0.0000e+00, 1.2271e-05, 8.3696e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.4045e-05, 1.3208e-05, 2.5499e-05, 2.7804e-05, 3.2882e-05, 2.3628e-05,
        2.6837e-05, 1.1643e-05, 3.3072e-05, 1.7906e-05, 3.3313e-05, 1.1875e-05,
        5.4131e-06, 2.3606e-05, 1.2292e-05, 1.5937e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.1581e-04, 2.9842e-05, 1.1015e-04, 1.4886e-04, 1.7845e-04, 1.3158e-04,
        9.8966e-05, 1.9280e-05, 1.6166e-04, 1.0123e-04, 1.6305e-04, 7.9847e-05,
        1.8693e-05, 9.6804e-05, 5.2400e-05, 1.5358e-04], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.4045e-05, 2.1581e-04],
        [0.0000e+00, 1.3208e-05, 2.9842e-05],
        [0.0000e+00, 2.5499e-05, 1.1015e-04],
        [0.0000e+00, 2.7804e-05, 1.4886e-04],
        [0.0000e+00, 3.2882e-05, 1.7845e-04],
        [0.0000e+00, 2.3628e-05, 1.3158e-04],
        [0.0000e+00, 2.6837e-05, 9.8966e-05],
        [0.0000e+00, 1.1643e-05, 1.9280e-05],
        [0.0000e+00, 3.3072e-05, 1.6166e-04],
        [0.0000e+00, 1.7906e-05, 1.0123e-04],
        [0.0000e+00, 3.3313e-05, 1.6305e-04],
        [0.0000e+00, 1.1875e-05, 7.9847e-05],
        [0.0000e+00, 5.4131e-06, 1.8693e-05],
        [0.0000e+00, 2.3606e-05, 9.6804e-05],
        [0.0000e+00, 1.2292e-05, 5.2400e-05],
        [0.0000e+00, 1.5937e-05, 1.5358e-04]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.9954e-05, 3.5925e-05, 1.6173e-05, 1.8290e-05, 1.6733e-05, 2.3921e-05,
        1.9701e-05, 2.1314e-05, 2.2450e-05, 6.7001e-06, 4.4576e-06, 1.1931e-05,
        8.1635e-06, 1.7660e-05, 1.2081e-05, 1.1849e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.1046e-04, 1.9092e-04, 1.5098e-04, 9.3510e-05, 5.3649e-05, 2.0843e-04,
        6.1817e-05, 2.8790e-04, 1.0028e-04, 1.7426e-05, 1.2331e-05, 6.6364e-05,
        2.1031e-05, 1.1610e-04, 7.2863e-05, 5.7923e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.9954e-05, 1.1046e-04],
        [0.0000e+00, 3.5925e-05, 1.9092e-04],
        [0.0000e+00, 1.6173e-05, 1.5098e-04],
        [0.0000e+00, 1.8290e-05, 9.3510e-05],
        [0.0000e+00, 1.6733e-05, 5.3649e-05],
        [0.0000e+00, 2.3921e-05, 2.0843e-04],
        [0.0000e+00, 1.9701e-05, 6.1817e-05],
        [0.0000e+00, 2.1314e-05, 2.8790e-04],
        [0.0000e+00, 2.2450e-05, 1.0028e-04],
        [0.0000e+00, 6.7001e-06, 1.7426e-05],
        [0.0000e+00, 4.4576e-06, 1.2331e-05],
        [0.0000e+00, 1.1931e-05, 6.6364e-05],
        [0.0000e+00, 8.1635e-06, 2.1031e-05],
        [0.0000e+00, 1.7660e-05, 1.1610e-04],
        [0.0000e+00, 1.2081e-05, 7.2863e-05],
        [0.0000e+00, 1.1849e-05, 5.7923e-05]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type rare_synonyms, variation 1 and batchsize 16: 0:02:40.628053
path ['42', 'de', 'bloomz', 'NLI', 'rare_synonyms', 'prompt_id_1']
----------- 42 de bigscience/bloomz-560m NLI rare_synonyms 2 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 344.98it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.5655e-06, 3.7101e-05, 3.7872e-06, 2.9531e-05, 1.2730e-05, 1.1192e-05,
        1.6087e-05, 1.8871e-05, 1.4688e-06, 5.2081e-06, 1.7036e-05, 3.3827e-06,
        1.4001e-05, 2.2807e-05, 3.1715e-05, 3.4544e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([9.6221e-06, 2.0134e-04, 7.2808e-06, 1.4219e-04, 3.2830e-05, 7.0617e-05,
        9.8439e-05, 8.5143e-05, 2.6110e-06, 1.0889e-05, 8.3851e-05, 8.8585e-06,
        1.2032e-04, 1.2491e-04, 1.6394e-04, 1.7725e-04], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.5655e-06, 9.6221e-06],
        [0.0000e+00, 3.7101e-05, 2.0134e-04],
        [0.0000e+00, 3.7872e-06, 7.2808e-06],
        [0.0000e+00, 2.9531e-05, 1.4219e-04],
        [0.0000e+00, 1.2730e-05, 3.2830e-05],
        [0.0000e+00, 1.1192e-05, 7.0617e-05],
        [0.0000e+00, 1.6087e-05, 9.8439e-05],
        [0.0000e+00, 1.8871e-05, 8.5143e-05],
        [0.0000e+00, 1.4688e-06, 2.6110e-06],
        [0.0000e+00, 5.2081e-06, 1.0889e-05],
        [0.0000e+00, 1.7036e-05, 8.3851e-05],
        [0.0000e+00, 3.3827e-06, 8.8585e-06],
        [0.0000e+00, 1.4001e-05, 1.2032e-04],
        [0.0000e+00, 2.2807e-05, 1.2491e-04],
        [0.0000e+00, 3.1715e-05, 1.6394e-04],
        [0.0000e+00, 3.4544e-05, 1.7725e-04]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.7375e-05, 2.1873e-05, 1.5845e-05, 8.5174e-06, 1.8465e-05, 9.9238e-06,
        3.2859e-05, 3.0387e-05, 1.0841e-05, 2.3083e-05, 3.4566e-05, 2.4012e-05,
        1.5610e-05, 1.7393e-05, 2.7638e-05, 1.7194e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.0484e-04, 1.2641e-04, 4.1268e-05, 5.7663e-05, 5.2613e-05, 1.7463e-05,
        8.8758e-05, 1.6384e-04, 8.1220e-05, 9.4983e-05, 2.2489e-04, 9.1191e-05,
        6.3490e-05, 9.8261e-05, 1.5958e-04, 8.6566e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.7375e-05, 1.0484e-04],
        [0.0000e+00, 2.1873e-05, 1.2641e-04],
        [0.0000e+00, 1.5845e-05, 4.1268e-05],
        [0.0000e+00, 8.5174e-06, 5.7663e-05],
        [0.0000e+00, 1.8465e-05, 5.2613e-05],
        [0.0000e+00, 9.9238e-06, 1.7463e-05],
        [0.0000e+00, 3.2859e-05, 8.8758e-05],
        [0.0000e+00, 3.0387e-05, 1.6384e-04],
        [0.0000e+00, 1.0841e-05, 8.1220e-05],
        [0.0000e+00, 2.3083e-05, 9.4983e-05],
        [0.0000e+00, 3.4566e-05, 2.2489e-04],
        [0.0000e+00, 2.4012e-05, 9.1191e-05],
        [0.0000e+00, 1.5610e-05, 6.3490e-05],
        [0.0000e+00, 1.7393e-05, 9.8261e-05],
        [0.0000e+00, 2.7638e-05, 1.5958e-04],
        [0.0000e+00, 1.7194e-05, 8.6566e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.0416e-05, 2.9169e-05, 2.7857e-05, 2.0767e-05, 8.6590e-06, 2.3662e-05,
        1.7785e-05, 1.4896e-05, 2.3532e-05, 2.0468e-05, 1.6513e-05, 1.0095e-05,
        1.0755e-05, 1.0566e-05, 2.0771e-05, 1.0898e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.9642e-05, 1.1345e-04, 2.4139e-04, 1.7124e-04, 1.3672e-05, 1.1423e-04,
        7.7638e-05, 1.2556e-04, 1.0814e-04, 2.6021e-04, 1.1490e-04, 4.8786e-05,
        5.8908e-05, 5.2323e-05, 6.1637e-05, 6.8022e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.0416e-05, 1.9642e-05],
        [0.0000e+00, 2.9169e-05, 1.1345e-04],
        [0.0000e+00, 2.7857e-05, 2.4139e-04],
        [0.0000e+00, 2.0767e-05, 1.7124e-04],
        [0.0000e+00, 8.6590e-06, 1.3672e-05],
        [0.0000e+00, 2.3662e-05, 1.1423e-04],
        [0.0000e+00, 1.7785e-05, 7.7638e-05],
        [0.0000e+00, 1.4896e-05, 1.2556e-04],
        [0.0000e+00, 2.3532e-05, 1.0814e-04],
        [0.0000e+00, 2.0468e-05, 2.6021e-04],
        [0.0000e+00, 1.6513e-05, 1.1490e-04],
        [0.0000e+00, 1.0095e-05, 4.8786e-05],
        [0.0000e+00, 1.0755e-05, 5.8908e-05],
        [0.0000e+00, 1.0566e-05, 5.2323e-05],
        [0.0000e+00, 2.0771e-05, 6.1637e-05],
        [0.0000e+00, 1.0898e-05, 6.8022e-05]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type rare_synonyms, variation 2 and batchsize 16: 0:02:41.013192
path ['42', 'de', 'bloomz', 'NLI', 'rare_synonyms', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloomz-560m SA active 0 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 194.13it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.2936e-06, 3.4817e-08, 9.7821e-08, 1.3161e-07, 4.2934e-08, 1.5744e-08,
        3.0888e-08, 4.6373e-08, 8.7743e-08, 2.7509e-07, 4.2579e-08, 2.5475e-07,
        1.7287e-07, 1.5952e-08, 3.9683e-08, 4.6729e-07], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.2936e-06],
        [0.0000e+00, 3.4817e-08],
        [0.0000e+00, 9.7821e-08],
        [0.0000e+00, 1.3161e-07],
        [0.0000e+00, 4.2934e-08],
        [0.0000e+00, 1.5744e-08],
        [0.0000e+00, 3.0888e-08],
        [0.0000e+00, 4.6373e-08],
        [0.0000e+00, 8.7743e-08],
        [0.0000e+00, 2.7509e-07],
        [0.0000e+00, 4.2579e-08],
        [0.0000e+00, 2.5475e-07],
        [0.0000e+00, 1.7287e-07],
        [0.0000e+00, 1.5952e-08],
        [0.0000e+00, 3.9683e-08],
        [0.0000e+00, 4.6729e-07]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.0484e-07, 1.1517e-06, 7.6441e-08, 8.0857e-08, 5.1342e-08, 9.4978e-08,
        4.1830e-07, 1.4283e-07, 3.1963e-08, 2.7242e-08, 5.4218e-08, 7.5700e-08,
        4.1878e-08, 2.3956e-07, 6.9449e-08, 2.6437e-08], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.0484e-07],
        [0.0000e+00, 1.1517e-06],
        [0.0000e+00, 7.6441e-08],
        [0.0000e+00, 8.0857e-08],
        [0.0000e+00, 5.1342e-08],
        [0.0000e+00, 9.4978e-08],
        [0.0000e+00, 4.1830e-07],
        [0.0000e+00, 1.4283e-07],
        [0.0000e+00, 3.1963e-08],
        [0.0000e+00, 2.7242e-08],
        [0.0000e+00, 5.4218e-08],
        [0.0000e+00, 7.5700e-08],
        [0.0000e+00, 4.1878e-08],
        [0.0000e+00, 2.3956e-07],
        [0.0000e+00, 6.9449e-08],
        [0.0000e+00, 2.6437e-08]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([7.3412e-07, 1.2183e-07, 3.8372e-07, 8.4405e-08, 6.2533e-08, 2.1486e-08,
        9.5107e-08, 2.7609e-07, 1.8188e-07, 2.3758e-09, 6.7236e-08, 4.3072e-07,
        1.1827e-07, 4.5436e-08, 1.3819e-07, 5.6764e-08], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 7.3412e-07],
        [0.0000e+00, 1.2183e-07],
        [0.0000e+00, 3.8372e-07],
        [0.0000e+00, 8.4405e-08],
        [0.0000e+00, 6.2533e-08],
        [0.0000e+00, 2.1486e-08],
        [0.0000e+00, 9.5107e-08],
        [0.0000e+00, 2.7609e-07],
        [0.0000e+00, 1.8188e-07],
        [0.0000e+00, 2.3758e-09],
        [0.0000e+00, 6.7236e-08],
        [0.0000e+00, 4.3072e-07],
        [0.0000e+00, 1.1827e-07],
        [0.0000e+00, 4.5436e-08],
        [0.0000e+00, 1.3819e-07],
        [0.0000e+00, 5.6764e-08]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([5.8795e-08, 7.5791e-07], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 5.8795e-08],
        [0.0000e+00, 7.5791e-07]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type active, variation 0 and batchsize 16: 0:03:05.892254
path ['42', 'de', 'bloomz', 'SA', 'active', 'prompt_id_0']
----------- 42 de bigscience/bloomz-560m SA active 1 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 196.31it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([6.2009e-06, 2.2262e-06, 9.6759e-07, 2.4980e-06, 7.6210e-07, 7.9104e-06,
        1.7425e-06, 9.0209e-07, 1.6480e-06, 1.5896e-06, 1.4053e-06, 2.5431e-06,
        9.1214e-07, 1.6438e-06, 4.3887e-06, 4.1745e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 6.2009e-06],
        [0.0000e+00, 2.2262e-06],
        [0.0000e+00, 9.6759e-07],
        [0.0000e+00, 2.4980e-06],
        [0.0000e+00, 7.6210e-07],
        [0.0000e+00, 7.9104e-06],
        [0.0000e+00, 1.7425e-06],
        [0.0000e+00, 9.0209e-07],
        [0.0000e+00, 1.6480e-06],
        [0.0000e+00, 1.5896e-06],
        [0.0000e+00, 1.4053e-06],
        [0.0000e+00, 2.5431e-06],
        [0.0000e+00, 9.1214e-07],
        [0.0000e+00, 1.6438e-06],
        [0.0000e+00, 4.3887e-06],
        [0.0000e+00, 4.1745e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.6472e-06, 2.1203e-06, 2.9225e-06, 3.6156e-06, 1.0405e-06, 1.8073e-06,
        3.5134e-06, 7.8922e-07, 4.9912e-06, 5.6964e-08, 4.4151e-07, 8.1898e-07,
        6.8283e-06, 1.7097e-06, 2.7021e-06, 2.1601e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.6472e-06],
        [0.0000e+00, 2.1203e-06],
        [0.0000e+00, 2.9225e-06],
        [0.0000e+00, 3.6156e-06],
        [0.0000e+00, 1.0405e-06],
        [0.0000e+00, 1.8073e-06],
        [0.0000e+00, 3.5134e-06],
        [0.0000e+00, 7.8922e-07],
        [0.0000e+00, 4.9912e-06],
        [0.0000e+00, 5.6964e-08],
        [0.0000e+00, 4.4151e-07],
        [0.0000e+00, 8.1898e-07],
        [0.0000e+00, 6.8283e-06],
        [0.0000e+00, 1.7097e-06],
        [0.0000e+00, 2.7021e-06],
        [0.0000e+00, 2.1601e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.7249e-06, 2.1735e-06, 1.6007e-06, 2.4760e-06, 2.2232e-05, 9.8656e-07,
        1.4656e-06, 1.3426e-05, 3.2128e-06, 1.3945e-06, 7.2344e-06, 2.3693e-06,
        1.3293e-06, 2.0788e-06, 1.9265e-06, 1.4675e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.7249e-06],
        [0.0000e+00, 2.1735e-06],
        [0.0000e+00, 1.6007e-06],
        [0.0000e+00, 2.4760e-06],
        [0.0000e+00, 2.2232e-05],
        [0.0000e+00, 9.8656e-07],
        [0.0000e+00, 1.4656e-06],
        [0.0000e+00, 1.3426e-05],
        [0.0000e+00, 3.2128e-06],
        [0.0000e+00, 1.3945e-06],
        [0.0000e+00, 7.2344e-06],
        [0.0000e+00, 2.3693e-06],
        [0.0000e+00, 1.3293e-06],
        [0.0000e+00, 2.0788e-06],
        [0.0000e+00, 1.9265e-06],
        [0.0000e+00, 1.4675e-06]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.5074e-06, 3.8074e-06], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.5074e-06],
        [0.0000e+00, 3.8074e-06]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type active, variation 1 and batchsize 16: 0:03:31.844919
path ['42', 'de', 'bloomz', 'SA', 'active', 'prompt_id_1']
----------- 42 de bigscience/bloomz-560m SA active 2 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 297.13it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([6.4276e-06, 4.1471e-06, 2.2133e-06, 7.1416e-07, 4.2150e-06, 1.0060e-06,
        1.8848e-06, 1.4331e-06, 2.0750e-06, 2.7804e-06, 2.0291e-06, 1.9707e-05,
        3.7849e-06, 1.2103e-06, 2.0937e-06, 1.7894e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 6.4276e-06],
        [0.0000e+00, 4.1471e-06],
        [0.0000e+00, 2.2133e-06],
        [0.0000e+00, 7.1416e-07],
        [0.0000e+00, 4.2150e-06],
        [0.0000e+00, 1.0060e-06],
        [0.0000e+00, 1.8848e-06],
        [0.0000e+00, 1.4331e-06],
        [0.0000e+00, 2.0750e-06],
        [0.0000e+00, 2.7804e-06],
        [0.0000e+00, 2.0291e-06],
        [0.0000e+00, 1.9707e-05],
        [0.0000e+00, 3.7849e-06],
        [0.0000e+00, 1.2103e-06],
        [0.0000e+00, 2.0937e-06],
        [0.0000e+00, 1.7894e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.0232e-06, 1.6338e-06, 1.0216e-06, 3.3311e-06, 2.7020e-06, 2.5141e-06,
        1.4868e-06, 1.1066e-06, 1.4106e-06, 3.0600e-06, 8.0176e-08, 3.1981e-06,
        1.7198e-06, 5.7232e-06, 1.2904e-05, 6.3743e-07], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.0232e-06],
        [0.0000e+00, 1.6338e-06],
        [0.0000e+00, 1.0216e-06],
        [0.0000e+00, 3.3311e-06],
        [0.0000e+00, 2.7020e-06],
        [0.0000e+00, 2.5141e-06],
        [0.0000e+00, 1.4868e-06],
        [0.0000e+00, 1.1066e-06],
        [0.0000e+00, 1.4106e-06],
        [0.0000e+00, 3.0600e-06],
        [0.0000e+00, 8.0176e-08],
        [0.0000e+00, 3.1981e-06],
        [0.0000e+00, 1.7198e-06],
        [0.0000e+00, 5.7232e-06],
        [0.0000e+00, 1.2904e-05],
        [0.0000e+00, 6.3743e-07]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.1105e-05, 4.3002e-06, 3.5252e-06, 2.7196e-06, 2.0656e-06, 1.0200e-05,
        1.2515e-06, 1.2666e-06, 2.2025e-05, 2.7740e-06, 3.8301e-06, 4.5590e-06,
        5.6500e-06, 1.0219e-05, 7.0102e-06, 3.4531e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.1105e-05],
        [0.0000e+00, 4.3002e-06],
        [0.0000e+00, 3.5252e-06],
        [0.0000e+00, 2.7196e-06],
        [0.0000e+00, 2.0656e-06],
        [0.0000e+00, 1.0200e-05],
        [0.0000e+00, 1.2515e-06],
        [0.0000e+00, 1.2666e-06],
        [0.0000e+00, 2.2025e-05],
        [0.0000e+00, 2.7740e-06],
        [0.0000e+00, 3.8301e-06],
        [0.0000e+00, 4.5590e-06],
        [0.0000e+00, 5.6500e-06],
        [0.0000e+00, 1.0219e-05],
        [0.0000e+00, 7.0102e-06],
        [0.0000e+00, 3.4531e-06]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([2.7048e-06, 1.7868e-06], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 2.7048e-06],
        [0.0000e+00, 1.7868e-06]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type active, variation 2 and batchsize 16: 0:03:33.815594
path ['42', 'de', 'bloomz', 'SA', 'active', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloomz-560m SA passive 0 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 336.91it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.1082e-06, 4.6622e-06, 4.8089e-07, 4.8953e-07, 6.8904e-07, 8.4388e-07,
        3.4057e-07, 5.0825e-07, 1.4211e-06, 2.3797e-06, 2.4829e-06, 8.3629e-07,
        1.0830e-06, 7.1660e-07, 7.2951e-07, 4.4274e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.1082e-06],
        [0.0000e+00, 4.6622e-06],
        [0.0000e+00, 4.8089e-07],
        [0.0000e+00, 4.8953e-07],
        [0.0000e+00, 6.8904e-07],
        [0.0000e+00, 8.4388e-07],
        [0.0000e+00, 3.4057e-07],
        [0.0000e+00, 5.0825e-07],
        [0.0000e+00, 1.4211e-06],
        [0.0000e+00, 2.3797e-06],
        [0.0000e+00, 2.4829e-06],
        [0.0000e+00, 8.3629e-07],
        [0.0000e+00, 1.0830e-06],
        [0.0000e+00, 7.1660e-07],
        [0.0000e+00, 7.2951e-07],
        [0.0000e+00, 4.4274e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.3885e-07, 6.8292e-07, 7.4255e-07, 2.2603e-07, 4.4546e-07, 4.0399e-07,
        2.0754e-07, 8.8485e-07, 7.3470e-06, 2.7052e-07, 4.6846e-06, 1.0272e-07,
        9.1919e-07, 1.4708e-06, 1.4125e-06, 6.7884e-07], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.3885e-07],
        [0.0000e+00, 6.8292e-07],
        [0.0000e+00, 7.4255e-07],
        [0.0000e+00, 2.2603e-07],
        [0.0000e+00, 4.4546e-07],
        [0.0000e+00, 4.0399e-07],
        [0.0000e+00, 2.0754e-07],
        [0.0000e+00, 8.8485e-07],
        [0.0000e+00, 7.3470e-06],
        [0.0000e+00, 2.7052e-07],
        [0.0000e+00, 4.6846e-06],
        [0.0000e+00, 1.0272e-07],
        [0.0000e+00, 9.1919e-07],
        [0.0000e+00, 1.4708e-06],
        [0.0000e+00, 1.4125e-06],
        [0.0000e+00, 6.7884e-07]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.6532e-06, 4.9292e-07, 1.6163e-06, 7.0832e-07, 5.1518e-07, 6.1979e-07,
        7.6591e-07, 3.1207e-07, 1.6009e-06, 1.3345e-07, 1.3668e-06, 2.7421e-06,
        4.4628e-07, 3.2543e-06, 6.5694e-07, 4.0666e-07], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.6532e-06],
        [0.0000e+00, 4.9292e-07],
        [0.0000e+00, 1.6163e-06],
        [0.0000e+00, 7.0832e-07],
        [0.0000e+00, 5.1518e-07],
        [0.0000e+00, 6.1979e-07],
        [0.0000e+00, 7.6591e-07],
        [0.0000e+00, 3.1207e-07],
        [0.0000e+00, 1.6009e-06],
        [0.0000e+00, 1.3345e-07],
        [0.0000e+00, 1.3668e-06],
        [0.0000e+00, 2.7421e-06],
        [0.0000e+00, 4.4628e-07],
        [0.0000e+00, 3.2543e-06],
        [0.0000e+00, 6.5694e-07],
        [0.0000e+00, 4.0666e-07]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([6.4509e-07, 1.1852e-08], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 6.4509e-07],
        [0.0000e+00, 1.1852e-08]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type passive, variation 0 and batchsize 16: 0:03:32.960343
path ['42', 'de', 'bloomz', 'SA', 'passive', 'prompt_id_0']
----------- 42 de bigscience/bloomz-560m SA passive 1 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 318.68it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.8327e-06, 2.5677e-06, 1.4927e-06, 2.3900e-06, 1.3005e-06, 1.9079e-06,
        2.3151e-06, 2.3427e-06, 8.9510e-07, 1.6460e-06, 8.6127e-07, 1.3446e-06,
        1.6688e-06, 1.1486e-05, 2.6185e-06, 3.3240e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.8327e-06],
        [0.0000e+00, 2.5677e-06],
        [0.0000e+00, 1.4927e-06],
        [0.0000e+00, 2.3900e-06],
        [0.0000e+00, 1.3005e-06],
        [0.0000e+00, 1.9079e-06],
        [0.0000e+00, 2.3151e-06],
        [0.0000e+00, 2.3427e-06],
        [0.0000e+00, 8.9510e-07],
        [0.0000e+00, 1.6460e-06],
        [0.0000e+00, 8.6127e-07],
        [0.0000e+00, 1.3446e-06],
        [0.0000e+00, 1.6688e-06],
        [0.0000e+00, 1.1486e-05],
        [0.0000e+00, 2.6185e-06],
        [0.0000e+00, 3.3240e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([9.0302e-07, 6.8860e-06, 6.5169e-07, 1.4431e-06, 2.4132e-06, 1.0723e-06,
        5.9381e-06, 3.7623e-08, 9.9632e-07, 1.3110e-06, 4.9231e-06, 1.2532e-06,
        1.7038e-06, 2.2247e-06, 1.2018e-06, 4.8395e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 9.0302e-07],
        [0.0000e+00, 6.8860e-06],
        [0.0000e+00, 6.5169e-07],
        [0.0000e+00, 1.4431e-06],
        [0.0000e+00, 2.4132e-06],
        [0.0000e+00, 1.0723e-06],
        [0.0000e+00, 5.9381e-06],
        [0.0000e+00, 3.7623e-08],
        [0.0000e+00, 9.9632e-07],
        [0.0000e+00, 1.3110e-06],
        [0.0000e+00, 4.9231e-06],
        [0.0000e+00, 1.2532e-06],
        [0.0000e+00, 1.7038e-06],
        [0.0000e+00, 2.2247e-06],
        [0.0000e+00, 1.2018e-06],
        [0.0000e+00, 4.8395e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5324e-06, 2.6952e-07, 4.3755e-06, 2.5193e-06, 5.3924e-07, 1.0762e-06,
        2.5466e-06, 6.9300e-07, 1.4504e-06, 1.7893e-06, 1.8235e-06, 2.6685e-06,
        4.9448e-06, 6.0139e-06, 1.2080e-05, 1.9875e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5324e-06],
        [0.0000e+00, 2.6952e-07],
        [0.0000e+00, 4.3755e-06],
        [0.0000e+00, 2.5193e-06],
        [0.0000e+00, 5.3924e-07],
        [0.0000e+00, 1.0762e-06],
        [0.0000e+00, 2.5466e-06],
        [0.0000e+00, 6.9300e-07],
        [0.0000e+00, 1.4504e-06],
        [0.0000e+00, 1.7893e-06],
        [0.0000e+00, 1.8235e-06],
        [0.0000e+00, 2.6685e-06],
        [0.0000e+00, 4.9448e-06],
        [0.0000e+00, 6.0139e-06],
        [0.0000e+00, 1.2080e-05],
        [0.0000e+00, 1.9875e-06]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([4.1106e-06, 3.1117e-06], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 4.1106e-06],
        [0.0000e+00, 3.1117e-06]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type passive, variation 1 and batchsize 16: 0:03:03.382476
path ['42', 'de', 'bloomz', 'SA', 'passive', 'prompt_id_1']
----------- 42 de bigscience/bloomz-560m SA passive 2 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 319.23it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([7.2984e-06, 1.0428e-06, 7.6458e-06, 2.3509e-06, 8.4779e-07, 2.4621e-06,
        2.4657e-08, 3.8967e-06, 1.4586e-06, 1.1595e-06, 4.6223e-06, 6.1289e-06,
        7.2926e-07, 1.6347e-06, 9.7562e-07, 4.5544e-07], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 7.2984e-06],
        [0.0000e+00, 1.0428e-06],
        [0.0000e+00, 7.6458e-06],
        [0.0000e+00, 2.3509e-06],
        [0.0000e+00, 8.4779e-07],
        [0.0000e+00, 2.4621e-06],
        [0.0000e+00, 2.4657e-08],
        [0.0000e+00, 3.8967e-06],
        [0.0000e+00, 1.4586e-06],
        [0.0000e+00, 1.1595e-06],
        [0.0000e+00, 4.6223e-06],
        [0.0000e+00, 6.1289e-06],
        [0.0000e+00, 7.2926e-07],
        [0.0000e+00, 1.6347e-06],
        [0.0000e+00, 9.7562e-07],
        [0.0000e+00, 4.5544e-07]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.7899e-07, 1.3734e-06, 5.4390e-07, 1.5948e-06, 1.6644e-05, 7.5587e-07,
        8.4857e-07, 7.6416e-07, 1.0044e-06, 1.6626e-06, 7.7040e-07, 3.4128e-07,
        3.1566e-06, 1.7524e-06, 2.2388e-05, 1.8138e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.7899e-07],
        [0.0000e+00, 1.3734e-06],
        [0.0000e+00, 5.4390e-07],
        [0.0000e+00, 1.5948e-06],
        [0.0000e+00, 1.6644e-05],
        [0.0000e+00, 7.5587e-07],
        [0.0000e+00, 8.4857e-07],
        [0.0000e+00, 7.6416e-07],
        [0.0000e+00, 1.0044e-06],
        [0.0000e+00, 1.6626e-06],
        [0.0000e+00, 7.7040e-07],
        [0.0000e+00, 3.4128e-07],
        [0.0000e+00, 3.1566e-06],
        [0.0000e+00, 1.7524e-06],
        [0.0000e+00, 2.2388e-05],
        [0.0000e+00, 1.8138e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.9012e-06, 7.9379e-07, 4.6095e-06, 2.4927e-06, 4.2766e-07, 9.4824e-07,
        2.2389e-06, 2.6810e-06, 7.1103e-07, 2.2600e-06, 1.4686e-06, 5.8626e-07,
        1.0951e-06, 1.1245e-06, 7.3601e-07, 6.7007e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.9012e-06],
        [0.0000e+00, 7.9379e-07],
        [0.0000e+00, 4.6095e-06],
        [0.0000e+00, 2.4927e-06],
        [0.0000e+00, 4.2766e-07],
        [0.0000e+00, 9.4824e-07],
        [0.0000e+00, 2.2389e-06],
        [0.0000e+00, 2.6810e-06],
        [0.0000e+00, 7.1103e-07],
        [0.0000e+00, 2.2600e-06],
        [0.0000e+00, 1.4686e-06],
        [0.0000e+00, 5.8626e-07],
        [0.0000e+00, 1.0951e-06],
        [0.0000e+00, 1.1245e-06],
        [0.0000e+00, 7.3601e-07],
        [0.0000e+00, 6.7007e-06]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.4897e-06, 1.6730e-06], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.4897e-06],
        [0.0000e+00, 1.6730e-06]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type passive, variation 2 and batchsize 16: 0:03:32.155214
path ['42', 'de', 'bloomz', 'SA', 'passive', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloomz-560m SA auxiliary 0 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 322.09it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2482e-06, 2.2152e-06, 3.5230e-07, 2.0138e-06, 1.1354e-06, 1.1689e-06,
        1.8473e-06, 1.5741e-06, 6.1045e-06, 1.2708e-06, 1.5606e-06, 4.2452e-07,
        2.8515e-08, 9.4673e-07, 1.4128e-06, 6.3898e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2482e-06],
        [0.0000e+00, 2.2152e-06],
        [0.0000e+00, 3.5230e-07],
        [0.0000e+00, 2.0138e-06],
        [0.0000e+00, 1.1354e-06],
        [0.0000e+00, 1.1689e-06],
        [0.0000e+00, 1.8473e-06],
        [0.0000e+00, 1.5741e-06],
        [0.0000e+00, 6.1045e-06],
        [0.0000e+00, 1.2708e-06],
        [0.0000e+00, 1.5606e-06],
        [0.0000e+00, 4.2452e-07],
        [0.0000e+00, 2.8515e-08],
        [0.0000e+00, 9.4673e-07],
        [0.0000e+00, 1.4128e-06],
        [0.0000e+00, 6.3898e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.7275e-06, 1.9850e-06, 2.4666e-06, 2.8135e-06, 9.7944e-07, 1.5483e-06,
        9.6650e-07, 1.2244e-06, 2.5863e-06, 5.0369e-06, 6.7838e-07, 5.7430e-07,
        1.5444e-06, 2.5425e-06, 2.3867e-06, 4.6920e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.7275e-06],
        [0.0000e+00, 1.9850e-06],
        [0.0000e+00, 2.4666e-06],
        [0.0000e+00, 2.8135e-06],
        [0.0000e+00, 9.7944e-07],
        [0.0000e+00, 1.5483e-06],
        [0.0000e+00, 9.6650e-07],
        [0.0000e+00, 1.2244e-06],
        [0.0000e+00, 2.5863e-06],
        [0.0000e+00, 5.0369e-06],
        [0.0000e+00, 6.7838e-07],
        [0.0000e+00, 5.7430e-07],
        [0.0000e+00, 1.5444e-06],
        [0.0000e+00, 2.5425e-06],
        [0.0000e+00, 2.3867e-06],
        [0.0000e+00, 4.6920e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.1458e-06, 3.4574e-06, 1.3947e-06, 1.8346e-06, 1.0890e-06, 4.9171e-06,
        3.3333e-06, 1.2190e-06, 2.2790e-06, 1.1492e-05, 1.5786e-06, 1.2569e-05,
        1.8245e-06, 2.0425e-06, 6.6141e-06, 1.8123e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.1458e-06],
        [0.0000e+00, 3.4574e-06],
        [0.0000e+00, 1.3947e-06],
        [0.0000e+00, 1.8346e-06],
        [0.0000e+00, 1.0890e-06],
        [0.0000e+00, 4.9171e-06],
        [0.0000e+00, 3.3333e-06],
        [0.0000e+00, 1.2190e-06],
        [0.0000e+00, 2.2790e-06],
        [0.0000e+00, 1.1492e-05],
        [0.0000e+00, 1.5786e-06],
        [0.0000e+00, 1.2569e-05],
        [0.0000e+00, 1.8245e-06],
        [0.0000e+00, 2.0425e-06],
        [0.0000e+00, 6.6141e-06],
        [0.0000e+00, 1.8123e-06]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([3.5117e-07, 2.6168e-06], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 3.5117e-07],
        [0.0000e+00, 2.6168e-06]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type auxiliary, variation 0 and batchsize 16: 0:03:32.449488
path ['42', 'de', 'bloomz', 'SA', 'auxiliary', 'prompt_id_0']
----------- 42 de bigscience/bloomz-560m SA auxiliary 1 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 332.88it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([7.2745e-06, 1.2336e-06, 2.8268e-06, 3.0636e-06, 3.3608e-06, 9.9168e-06,
        2.1826e-06, 3.6845e-06, 4.1032e-06, 6.2839e-06, 2.2580e-06, 1.8947e-06,
        7.2249e-06, 1.2308e-06, 3.3198e-06, 1.9904e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 7.2745e-06],
        [0.0000e+00, 1.2336e-06],
        [0.0000e+00, 2.8268e-06],
        [0.0000e+00, 3.0636e-06],
        [0.0000e+00, 3.3608e-06],
        [0.0000e+00, 9.9168e-06],
        [0.0000e+00, 2.1826e-06],
        [0.0000e+00, 3.6845e-06],
        [0.0000e+00, 4.1032e-06],
        [0.0000e+00, 6.2839e-06],
        [0.0000e+00, 2.2580e-06],
        [0.0000e+00, 1.8947e-06],
        [0.0000e+00, 7.2249e-06],
        [0.0000e+00, 1.2308e-06],
        [0.0000e+00, 3.3198e-06],
        [0.0000e+00, 1.9904e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.8365e-06, 3.1823e-06, 2.2421e-06, 3.0039e-06, 1.8538e-06, 1.2201e-06,
        3.5291e-06, 5.0328e-06, 2.0584e-06, 1.6810e-06, 5.0278e-06, 1.6195e-05,
        2.5496e-06, 7.8422e-07, 2.3794e-06, 6.2583e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.8365e-06],
        [0.0000e+00, 3.1823e-06],
        [0.0000e+00, 2.2421e-06],
        [0.0000e+00, 3.0039e-06],
        [0.0000e+00, 1.8538e-06],
        [0.0000e+00, 1.2201e-06],
        [0.0000e+00, 3.5291e-06],
        [0.0000e+00, 5.0328e-06],
        [0.0000e+00, 2.0584e-06],
        [0.0000e+00, 1.6810e-06],
        [0.0000e+00, 5.0278e-06],
        [0.0000e+00, 1.6195e-05],
        [0.0000e+00, 2.5496e-06],
        [0.0000e+00, 7.8422e-07],
        [0.0000e+00, 2.3794e-06],
        [0.0000e+00, 6.2583e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([7.6666e-07, 1.3990e-06, 1.9765e-06, 1.2140e-06, 1.7487e-06, 2.1627e-05,
        3.3422e-06, 7.8900e-06, 2.0246e-06, 2.8742e-06, 3.5939e-06, 2.2371e-06,
        7.2888e-08, 1.8550e-06, 8.1352e-06, 3.0739e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 7.6666e-07],
        [0.0000e+00, 1.3990e-06],
        [0.0000e+00, 1.9765e-06],
        [0.0000e+00, 1.2140e-06],
        [0.0000e+00, 1.7487e-06],
        [0.0000e+00, 2.1627e-05],
        [0.0000e+00, 3.3422e-06],
        [0.0000e+00, 7.8900e-06],
        [0.0000e+00, 2.0246e-06],
        [0.0000e+00, 2.8742e-06],
        [0.0000e+00, 3.5939e-06],
        [0.0000e+00, 2.2371e-06],
        [0.0000e+00, 7.2888e-08],
        [0.0000e+00, 1.8550e-06],
        [0.0000e+00, 8.1352e-06],
        [0.0000e+00, 3.0739e-06]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.1374e-06, 6.3997e-07], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.1374e-06],
        [0.0000e+00, 6.3997e-07]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type auxiliary, variation 1 and batchsize 16: 0:03:33.268958
path ['42', 'de', 'bloomz', 'SA', 'auxiliary', 'prompt_id_1']
----------- 42 de bigscience/bloomz-560m SA auxiliary 2 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 187.72it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([6.9186e-06, 4.8777e-07, 5.5245e-06, 1.3874e-06, 1.1073e-06, 7.7443e-07,
        1.8760e-06, 1.1414e-06, 2.4899e-07, 4.1907e-06, 9.2001e-07, 1.6091e-06,
        1.5780e-06, 1.2640e-06, 1.9078e-06, 2.5276e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 6.9186e-06],
        [0.0000e+00, 4.8777e-07],
        [0.0000e+00, 5.5245e-06],
        [0.0000e+00, 1.3874e-06],
        [0.0000e+00, 1.1073e-06],
        [0.0000e+00, 7.7443e-07],
        [0.0000e+00, 1.8760e-06],
        [0.0000e+00, 1.1414e-06],
        [0.0000e+00, 2.4899e-07],
        [0.0000e+00, 4.1907e-06],
        [0.0000e+00, 9.2001e-07],
        [0.0000e+00, 1.6091e-06],
        [0.0000e+00, 1.5780e-06],
        [0.0000e+00, 1.2640e-06],
        [0.0000e+00, 1.9078e-06],
        [0.0000e+00, 2.5276e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.6640e-06, 1.3954e-06, 9.9519e-07, 4.8471e-06, 1.3561e-05, 3.1894e-06,
        8.1363e-07, 2.7336e-08, 1.5133e-06, 1.7177e-06, 6.6197e-06, 2.1276e-06,
        5.7364e-06, 2.9127e-06, 1.1379e-06, 1.9777e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.6640e-06],
        [0.0000e+00, 1.3954e-06],
        [0.0000e+00, 9.9519e-07],
        [0.0000e+00, 4.8471e-06],
        [0.0000e+00, 1.3561e-05],
        [0.0000e+00, 3.1894e-06],
        [0.0000e+00, 8.1363e-07],
        [0.0000e+00, 2.7336e-08],
        [0.0000e+00, 1.5133e-06],
        [0.0000e+00, 1.7177e-06],
        [0.0000e+00, 6.6197e-06],
        [0.0000e+00, 2.1276e-06],
        [0.0000e+00, 5.7364e-06],
        [0.0000e+00, 2.9127e-06],
        [0.0000e+00, 1.1379e-06],
        [0.0000e+00, 1.9777e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.6330e-06, 1.2762e-05, 1.4287e-06, 5.8068e-07, 2.4435e-06, 2.0519e-06,
        1.8597e-06, 4.8748e-07, 2.2638e-06, 3.2459e-07, 8.3126e-07, 1.9226e-06,
        1.1243e-06, 1.2974e-06, 7.9035e-07, 1.3879e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.6330e-06],
        [0.0000e+00, 1.2762e-05],
        [0.0000e+00, 1.4287e-06],
        [0.0000e+00, 5.8068e-07],
        [0.0000e+00, 2.4435e-06],
        [0.0000e+00, 2.0519e-06],
        [0.0000e+00, 1.8597e-06],
        [0.0000e+00, 4.8748e-07],
        [0.0000e+00, 2.2638e-06],
        [0.0000e+00, 3.2459e-07],
        [0.0000e+00, 8.3126e-07],
        [0.0000e+00, 1.9226e-06],
        [0.0000e+00, 1.1243e-06],
        [0.0000e+00, 1.2974e-06],
        [0.0000e+00, 7.9035e-07],
        [0.0000e+00, 1.3879e-06]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.1281e-06, 1.2219e-06], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.1281e-06],
        [0.0000e+00, 1.2219e-06]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type auxiliary, variation 2 and batchsize 16: 0:03:04.842164
path ['42', 'de', 'bloomz', 'SA', 'auxiliary', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloomz-560m SA modal 0 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 323.78it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.9739e-05, 1.9660e-06, 1.4932e-06, 9.1770e-06, 2.7250e-06, 7.0170e-06,
        2.1785e-06, 3.9872e-06, 2.5224e-06, 1.8599e-06, 2.3453e-06, 4.9221e-06,
        1.0835e-06, 4.7689e-06, 1.5385e-06, 2.6631e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.9739e-05],
        [0.0000e+00, 1.9660e-06],
        [0.0000e+00, 1.4932e-06],
        [0.0000e+00, 9.1770e-06],
        [0.0000e+00, 2.7250e-06],
        [0.0000e+00, 7.0170e-06],
        [0.0000e+00, 2.1785e-06],
        [0.0000e+00, 3.9872e-06],
        [0.0000e+00, 2.5224e-06],
        [0.0000e+00, 1.8599e-06],
        [0.0000e+00, 2.3453e-06],
        [0.0000e+00, 4.9221e-06],
        [0.0000e+00, 1.0835e-06],
        [0.0000e+00, 4.7689e-06],
        [0.0000e+00, 1.5385e-06],
        [0.0000e+00, 2.6631e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.7566e-06, 5.3261e-06, 1.1681e-07, 9.4608e-06, 7.7937e-06, 3.8384e-06,
        1.3870e-06, 3.0177e-05, 2.2250e-06, 4.1030e-06, 3.4765e-06, 3.5308e-06,
        3.2344e-06, 3.7022e-06, 7.8510e-06, 2.9815e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.7566e-06],
        [0.0000e+00, 5.3261e-06],
        [0.0000e+00, 1.1681e-07],
        [0.0000e+00, 9.4608e-06],
        [0.0000e+00, 7.7937e-06],
        [0.0000e+00, 3.8384e-06],
        [0.0000e+00, 1.3870e-06],
        [0.0000e+00, 3.0177e-05],
        [0.0000e+00, 2.2250e-06],
        [0.0000e+00, 4.1030e-06],
        [0.0000e+00, 3.4765e-06],
        [0.0000e+00, 3.5308e-06],
        [0.0000e+00, 3.2344e-06],
        [0.0000e+00, 3.7022e-06],
        [0.0000e+00, 7.8510e-06],
        [0.0000e+00, 2.9815e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([6.1653e-06, 2.7105e-06, 2.1905e-06, 2.4630e-06, 4.9759e-06, 3.4940e-06,
        3.7480e-06, 1.2620e-06, 4.3295e-06, 4.0130e-06, 2.7340e-06, 1.2356e-06,
        8.3282e-06, 2.5594e-06, 1.5310e-06, 1.7637e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 6.1653e-06],
        [0.0000e+00, 2.7105e-06],
        [0.0000e+00, 2.1905e-06],
        [0.0000e+00, 2.4630e-06],
        [0.0000e+00, 4.9759e-06],
        [0.0000e+00, 3.4940e-06],
        [0.0000e+00, 3.7480e-06],
        [0.0000e+00, 1.2620e-06],
        [0.0000e+00, 4.3295e-06],
        [0.0000e+00, 4.0130e-06],
        [0.0000e+00, 2.7340e-06],
        [0.0000e+00, 1.2356e-06],
        [0.0000e+00, 8.3282e-06],
        [0.0000e+00, 2.5594e-06],
        [0.0000e+00, 1.5310e-06],
        [0.0000e+00, 1.7637e-06]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.3323e-05, 2.7714e-06], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.3323e-05],
        [0.0000e+00, 2.7714e-06]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type modal, variation 0 and batchsize 16: 0:03:05.749218
path ['42', 'de', 'bloomz', 'SA', 'modal', 'prompt_id_0']
----------- 42 de bigscience/bloomz-560m SA modal 1 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 327.30it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([5.1255e-06, 1.5521e-06, 8.2470e-07, 1.7223e-06, 3.2010e-06, 8.0145e-07,
        2.3491e-06, 1.7025e-06, 5.7559e-07, 5.1976e-06, 2.0384e-06, 7.2857e-07,
        5.7913e-06, 1.2427e-06, 1.2964e-06, 1.8424e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 5.1255e-06],
        [0.0000e+00, 1.5521e-06],
        [0.0000e+00, 8.2470e-07],
        [0.0000e+00, 1.7223e-06],
        [0.0000e+00, 3.2010e-06],
        [0.0000e+00, 8.0145e-07],
        [0.0000e+00, 2.3491e-06],
        [0.0000e+00, 1.7025e-06],
        [0.0000e+00, 5.7559e-07],
        [0.0000e+00, 5.1976e-06],
        [0.0000e+00, 2.0384e-06],
        [0.0000e+00, 7.2857e-07],
        [0.0000e+00, 5.7913e-06],
        [0.0000e+00, 1.2427e-06],
        [0.0000e+00, 1.2964e-06],
        [0.0000e+00, 1.8424e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([5.8733e-06, 1.5825e-05, 2.1399e-06, 1.3310e-06, 8.8521e-07, 5.2116e-06,
        2.2767e-06, 1.1141e-06, 6.0825e-08, 7.4472e-07, 1.6329e-06, 2.5285e-06,
        1.0385e-06, 3.1333e-06, 1.4023e-06, 2.1227e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 5.8733e-06],
        [0.0000e+00, 1.5825e-05],
        [0.0000e+00, 2.1399e-06],
        [0.0000e+00, 1.3310e-06],
        [0.0000e+00, 8.8521e-07],
        [0.0000e+00, 5.2116e-06],
        [0.0000e+00, 2.2767e-06],
        [0.0000e+00, 1.1141e-06],
        [0.0000e+00, 6.0825e-08],
        [0.0000e+00, 7.4472e-07],
        [0.0000e+00, 1.6329e-06],
        [0.0000e+00, 2.5285e-06],
        [0.0000e+00, 1.0385e-06],
        [0.0000e+00, 3.1333e-06],
        [0.0000e+00, 1.4023e-06],
        [0.0000e+00, 2.1227e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.1973e-06, 3.5099e-06, 9.1813e-07, 9.2791e-07, 1.6144e-06, 6.3828e-06,
        2.5132e-06, 1.7251e-06, 1.4278e-06, 4.0320e-07, 1.6350e-06, 1.8315e-06,
        1.7314e-05, 2.3948e-06, 2.2260e-06, 7.9444e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.1973e-06],
        [0.0000e+00, 3.5099e-06],
        [0.0000e+00, 9.1813e-07],
        [0.0000e+00, 9.2791e-07],
        [0.0000e+00, 1.6144e-06],
        [0.0000e+00, 6.3828e-06],
        [0.0000e+00, 2.5132e-06],
        [0.0000e+00, 1.7251e-06],
        [0.0000e+00, 1.4278e-06],
        [0.0000e+00, 4.0320e-07],
        [0.0000e+00, 1.6350e-06],
        [0.0000e+00, 1.8315e-06],
        [0.0000e+00, 1.7314e-05],
        [0.0000e+00, 2.3948e-06],
        [0.0000e+00, 2.2260e-06],
        [0.0000e+00, 7.9444e-06]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.3197e-06, 1.9025e-06], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.3197e-06],
        [0.0000e+00, 1.9025e-06]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type modal, variation 1 and batchsize 16: 0:03:03.675584
path ['42', 'de', 'bloomz', 'SA', 'modal', 'prompt_id_1']
----------- 42 de bigscience/bloomz-560m SA modal 2 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 334.53it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.7017e-06, 2.9983e-06, 2.6557e-06, 2.7916e-06, 1.7879e-06, 4.5251e-08,
        1.5455e-05, 6.3129e-07, 1.1498e-06, 1.2592e-06, 4.6405e-07, 1.1383e-06,
        1.8077e-06, 8.5823e-07, 1.3639e-06, 4.4713e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.7017e-06],
        [0.0000e+00, 2.9983e-06],
        [0.0000e+00, 2.6557e-06],
        [0.0000e+00, 2.7916e-06],
        [0.0000e+00, 1.7879e-06],
        [0.0000e+00, 4.5251e-08],
        [0.0000e+00, 1.5455e-05],
        [0.0000e+00, 6.3129e-07],
        [0.0000e+00, 1.1498e-06],
        [0.0000e+00, 1.2592e-06],
        [0.0000e+00, 4.6405e-07],
        [0.0000e+00, 1.1383e-06],
        [0.0000e+00, 1.8077e-06],
        [0.0000e+00, 8.5823e-07],
        [0.0000e+00, 1.3639e-06],
        [0.0000e+00, 4.4713e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.1473e-06, 5.2437e-06, 2.3006e-06, 6.3244e-06, 1.6107e-06, 5.1614e-07,
        1.3875e-06, 5.5971e-07, 4.9919e-06, 1.8399e-06, 2.6754e-06, 1.1622e-06,
        2.0527e-06, 9.0271e-07, 5.2913e-06, 7.4712e-07], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.1473e-06],
        [0.0000e+00, 5.2437e-06],
        [0.0000e+00, 2.3006e-06],
        [0.0000e+00, 6.3244e-06],
        [0.0000e+00, 1.6107e-06],
        [0.0000e+00, 5.1614e-07],
        [0.0000e+00, 1.3875e-06],
        [0.0000e+00, 5.5971e-07],
        [0.0000e+00, 4.9919e-06],
        [0.0000e+00, 1.8399e-06],
        [0.0000e+00, 2.6754e-06],
        [0.0000e+00, 1.1622e-06],
        [0.0000e+00, 2.0527e-06],
        [0.0000e+00, 9.0271e-07],
        [0.0000e+00, 5.2913e-06],
        [0.0000e+00, 7.4712e-07]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.6458e-06, 2.8933e-07, 5.0086e-06, 7.9224e-07, 1.1417e-06, 1.9101e-06,
        7.1786e-07, 1.6184e-06, 1.6606e-06, 2.0296e-06, 7.3024e-07, 1.5928e-06,
        1.3461e-06, 1.9603e-06, 1.3810e-06, 1.1491e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.6458e-06],
        [0.0000e+00, 2.8933e-07],
        [0.0000e+00, 5.0086e-06],
        [0.0000e+00, 7.9224e-07],
        [0.0000e+00, 1.1417e-06],
        [0.0000e+00, 1.9101e-06],
        [0.0000e+00, 7.1786e-07],
        [0.0000e+00, 1.6184e-06],
        [0.0000e+00, 1.6606e-06],
        [0.0000e+00, 2.0296e-06],
        [0.0000e+00, 7.3024e-07],
        [0.0000e+00, 1.5928e-06],
        [0.0000e+00, 1.3461e-06],
        [0.0000e+00, 1.9603e-06],
        [0.0000e+00, 1.3810e-06],
        [0.0000e+00, 1.1491e-06]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.3791e-05, 7.4197e-07], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.3791e-05],
        [0.0000e+00, 7.4197e-07]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type modal, variation 2 and batchsize 16: 0:03:04.846213
path ['42', 'de', 'bloomz', 'SA', 'modal', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloomz-560m SA rare_synonyms 0 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 345.82it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.1260e-06, 4.1420e-06, 6.7034e-06, 7.0417e-08, 1.6801e-06, 4.7630e-06,
        1.1638e-06, 1.4950e-06, 2.4413e-06, 9.9276e-07, 2.7511e-06, 3.3089e-06,
        2.6219e-06, 2.7590e-06, 1.9167e-06, 6.4609e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.1260e-06],
        [0.0000e+00, 4.1420e-06],
        [0.0000e+00, 6.7034e-06],
        [0.0000e+00, 7.0417e-08],
        [0.0000e+00, 1.6801e-06],
        [0.0000e+00, 4.7630e-06],
        [0.0000e+00, 1.1638e-06],
        [0.0000e+00, 1.4950e-06],
        [0.0000e+00, 2.4413e-06],
        [0.0000e+00, 9.9276e-07],
        [0.0000e+00, 2.7511e-06],
        [0.0000e+00, 3.3089e-06],
        [0.0000e+00, 2.6219e-06],
        [0.0000e+00, 2.7590e-06],
        [0.0000e+00, 1.9167e-06],
        [0.0000e+00, 6.4609e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([8.0536e-06, 1.5005e-06, 9.3694e-07, 1.0779e-05, 3.4049e-06, 6.0172e-06,
        3.1121e-06, 1.6919e-06, 2.9670e-06, 9.4091e-07, 1.6346e-06, 2.5175e-06,
        3.1343e-06, 9.4718e-07, 1.6534e-06, 2.9916e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 8.0536e-06],
        [0.0000e+00, 1.5005e-06],
        [0.0000e+00, 9.3694e-07],
        [0.0000e+00, 1.0779e-05],
        [0.0000e+00, 3.4049e-06],
        [0.0000e+00, 6.0172e-06],
        [0.0000e+00, 3.1121e-06],
        [0.0000e+00, 1.6919e-06],
        [0.0000e+00, 2.9670e-06],
        [0.0000e+00, 9.4091e-07],
        [0.0000e+00, 1.6346e-06],
        [0.0000e+00, 2.5175e-06],
        [0.0000e+00, 3.1343e-06],
        [0.0000e+00, 9.4718e-07],
        [0.0000e+00, 1.6534e-06],
        [0.0000e+00, 2.9916e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.2633e-06, 2.0146e-06, 2.0278e-06, 2.8419e-06, 3.5881e-06, 1.6846e-06,
        2.8294e-05, 1.3774e-06, 1.9073e-06, 2.7450e-06, 1.1892e-06, 6.5041e-07,
        6.5500e-06, 6.2608e-06, 2.1720e-06, 2.6661e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.2633e-06],
        [0.0000e+00, 2.0146e-06],
        [0.0000e+00, 2.0278e-06],
        [0.0000e+00, 2.8419e-06],
        [0.0000e+00, 3.5881e-06],
        [0.0000e+00, 1.6846e-06],
        [0.0000e+00, 2.8294e-05],
        [0.0000e+00, 1.3774e-06],
        [0.0000e+00, 1.9073e-06],
        [0.0000e+00, 2.7450e-06],
        [0.0000e+00, 1.1892e-06],
        [0.0000e+00, 6.5041e-07],
        [0.0000e+00, 6.5500e-06],
        [0.0000e+00, 6.2608e-06],
        [0.0000e+00, 2.1720e-06],
        [0.0000e+00, 2.6661e-06]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.6952e-05, 2.3168e-06], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.6952e-05],
        [0.0000e+00, 2.3168e-06]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type rare_synonyms, variation 0 and batchsize 16: 0:03:04.443236
path ['42', 'de', 'bloomz', 'SA', 'rare_synonyms', 'prompt_id_0']
----------- 42 de bigscience/bloomz-560m SA rare_synonyms 1 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 320.61it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2528e-06, 1.7533e-06, 2.1462e-06, 1.2958e-05, 1.5810e-06, 9.9550e-07,
        1.3232e-06, 3.2034e-06, 1.9001e-06, 1.7410e-05, 8.3519e-07, 1.8601e-06,
        1.1794e-06, 2.8005e-06, 1.7542e-06, 6.6267e-07], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2528e-06],
        [0.0000e+00, 1.7533e-06],
        [0.0000e+00, 2.1462e-06],
        [0.0000e+00, 1.2958e-05],
        [0.0000e+00, 1.5810e-06],
        [0.0000e+00, 9.9550e-07],
        [0.0000e+00, 1.3232e-06],
        [0.0000e+00, 3.2034e-06],
        [0.0000e+00, 1.9001e-06],
        [0.0000e+00, 1.7410e-05],
        [0.0000e+00, 8.3519e-07],
        [0.0000e+00, 1.8601e-06],
        [0.0000e+00, 1.1794e-06],
        [0.0000e+00, 2.8005e-06],
        [0.0000e+00, 1.7542e-06],
        [0.0000e+00, 6.6267e-07]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([9.9323e-07, 2.5051e-06, 1.2013e-06, 3.2084e-06, 2.0020e-06, 1.4552e-06,
        5.9239e-06, 4.1571e-06, 1.2532e-06, 1.3487e-06, 4.4995e-06, 1.8844e-06,
        1.4874e-06, 7.5807e-06, 1.1728e-06, 1.5766e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 9.9323e-07],
        [0.0000e+00, 2.5051e-06],
        [0.0000e+00, 1.2013e-06],
        [0.0000e+00, 3.2084e-06],
        [0.0000e+00, 2.0020e-06],
        [0.0000e+00, 1.4552e-06],
        [0.0000e+00, 5.9239e-06],
        [0.0000e+00, 4.1571e-06],
        [0.0000e+00, 1.2532e-06],
        [0.0000e+00, 1.3487e-06],
        [0.0000e+00, 4.4995e-06],
        [0.0000e+00, 1.8844e-06],
        [0.0000e+00, 1.4874e-06],
        [0.0000e+00, 7.5807e-06],
        [0.0000e+00, 1.1728e-06],
        [0.0000e+00, 1.5766e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.0020e-06, 7.5530e-07, 7.7309e-07, 1.6375e-06, 4.7062e-08, 1.4507e-06,
        7.0492e-07, 8.7398e-07, 5.5329e-07, 1.1099e-06, 3.3679e-07, 4.5951e-06,
        1.4104e-06, 5.7766e-07, 7.4253e-07, 5.5359e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.0020e-06],
        [0.0000e+00, 7.5530e-07],
        [0.0000e+00, 7.7309e-07],
        [0.0000e+00, 1.6375e-06],
        [0.0000e+00, 4.7062e-08],
        [0.0000e+00, 1.4507e-06],
        [0.0000e+00, 7.0492e-07],
        [0.0000e+00, 8.7398e-07],
        [0.0000e+00, 5.5329e-07],
        [0.0000e+00, 1.1099e-06],
        [0.0000e+00, 3.3679e-07],
        [0.0000e+00, 4.5951e-06],
        [0.0000e+00, 1.4104e-06],
        [0.0000e+00, 5.7766e-07],
        [0.0000e+00, 7.4253e-07],
        [0.0000e+00, 5.5359e-06]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([9.6739e-07, 3.6075e-06], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 9.6739e-07],
        [0.0000e+00, 3.6075e-06]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type rare_synonyms, variation 1 and batchsize 16: 0:03:04.786029
path ['42', 'de', 'bloomz', 'SA', 'rare_synonyms', 'prompt_id_1']
----------- 42 de bigscience/bloomz-560m SA rare_synonyms 2 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 350.23it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([5.2631e-07, 2.5305e-06, 2.0761e-06, 1.4914e-06, 8.8066e-07, 7.6795e-06,
        3.4793e-06, 1.9568e-06, 3.4727e-06, 2.3684e-06, 2.5700e-06, 1.5376e-06,
        2.0742e-06, 2.8746e-06, 1.3212e-06, 2.1151e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 5.2631e-07],
        [0.0000e+00, 2.5305e-06],
        [0.0000e+00, 2.0761e-06],
        [0.0000e+00, 1.4914e-06],
        [0.0000e+00, 8.8066e-07],
        [0.0000e+00, 7.6795e-06],
        [0.0000e+00, 3.4793e-06],
        [0.0000e+00, 1.9568e-06],
        [0.0000e+00, 3.4727e-06],
        [0.0000e+00, 2.3684e-06],
        [0.0000e+00, 2.5700e-06],
        [0.0000e+00, 1.5376e-06],
        [0.0000e+00, 2.0742e-06],
        [0.0000e+00, 2.8746e-06],
        [0.0000e+00, 1.3212e-06],
        [0.0000e+00, 2.1151e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([5.6993e-06, 2.2459e-06, 5.4919e-06, 1.3720e-06, 1.6663e-06, 2.1324e-06,
        9.6224e-06, 1.0578e-06, 5.8900e-06, 2.3137e-06, 2.2684e-06, 1.0259e-06,
        1.0086e-06, 2.9095e-06, 2.3395e-06, 1.0759e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 5.6993e-06],
        [0.0000e+00, 2.2459e-06],
        [0.0000e+00, 5.4919e-06],
        [0.0000e+00, 1.3720e-06],
        [0.0000e+00, 1.6663e-06],
        [0.0000e+00, 2.1324e-06],
        [0.0000e+00, 9.6224e-06],
        [0.0000e+00, 1.0578e-06],
        [0.0000e+00, 5.8900e-06],
        [0.0000e+00, 2.3137e-06],
        [0.0000e+00, 2.2684e-06],
        [0.0000e+00, 1.0259e-06],
        [0.0000e+00, 1.0086e-06],
        [0.0000e+00, 2.9095e-06],
        [0.0000e+00, 2.3395e-06],
        [0.0000e+00, 1.0759e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.3332e-06, 1.6144e-06, 1.5760e-06, 2.5354e-06, 1.5949e-05, 2.3077e-05,
        3.8018e-06, 1.1444e-06, 6.6218e-06, 7.3592e-07, 5.4226e-06, 1.1778e-06,
        1.5053e-06, 2.8179e-06, 5.1452e-08, 7.9855e-07], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.3332e-06],
        [0.0000e+00, 1.6144e-06],
        [0.0000e+00, 1.5760e-06],
        [0.0000e+00, 2.5354e-06],
        [0.0000e+00, 1.5949e-05],
        [0.0000e+00, 2.3077e-05],
        [0.0000e+00, 3.8018e-06],
        [0.0000e+00, 1.1444e-06],
        [0.0000e+00, 6.6218e-06],
        [0.0000e+00, 7.3592e-07],
        [0.0000e+00, 5.4226e-06],
        [0.0000e+00, 1.1778e-06],
        [0.0000e+00, 1.5053e-06],
        [0.0000e+00, 2.8179e-06],
        [0.0000e+00, 5.1452e-08],
        [0.0000e+00, 7.9855e-07]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.6748e-06, 8.2239e-07], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.6748e-06],
        [0.0000e+00, 8.2239e-07]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type rare_synonyms, variation 2 and batchsize 16: 0:03:04.772820
path ['42', 'de', 'bloomz', 'SA', 'rare_synonyms', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
Loading model google/flan-t5-base
Model google/flan-t5-base loaded
Available device is cuda
Model device: cuda:0
----------- 42 de google/flan-t5-base NLI active 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 321.30it/s]
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [2662, 1], 'attention_mask': [1, 1]}
id: [2662, 1] -> [2662]
Traceback (most recent call last):
  File "/home/lcur1101/ATCS_group3/src/main.py", line 169, in <module>
    pipeline(seeds, languages, models, tasks, prompt_types,
  File "/home/lcur1101/ATCS_group3/src/main.py", line 125, in pipeline
    logits_dict_for_prompt = get_prompt_acc(
  File "/home/lcur1101/ATCS_group3/src/main.py", line 56, in get_prompt_acc
    answers_probs_batch, pred_answer_batch = LM(
  File "/home/lcur1101/ATCS_group3/src/models/model.py", line 163, in __call__
    answers_probs[:, idx] = probs
RuntimeError: expand(torch.cuda.FloatTensor{[16, 1]}, size=[16]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)
srun: error: r29n3: task 0: Exited with exit code 1
