Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
****Start Time: 2023-05-21_17-00-21
Loading model bigscience/bloom-560m
Model bigscience/bloom-560m loaded
Available device is cuda
Model device: cuda:0
----------- 42 de bigscience/bloom-560m NLI active 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 306.05it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5035e-05, 1.6302e-05, 2.1933e-05, 2.5255e-05, 1.9995e-05, 2.0725e-05,
        1.8029e-05, 2.4960e-05, 3.3741e-05, 2.7468e-05, 1.6279e-05, 2.1870e-05,
        1.9436e-05, 1.9096e-05, 2.8200e-05, 2.3363e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.4414e-06, 2.4943e-06, 4.6118e-06, 5.7195e-06, 4.8003e-06, 5.2662e-06,
        3.4016e-06, 3.6942e-06, 7.1140e-06, 6.7853e-06, 3.5808e-06, 4.8733e-06,
        3.0139e-06, 4.1305e-06, 7.4395e-06, 5.7250e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5035e-05, 5.4414e-06],
        [0.0000e+00, 1.6302e-05, 2.4943e-06],
        [0.0000e+00, 2.1933e-05, 4.6118e-06],
        [0.0000e+00, 2.5255e-05, 5.7195e-06],
        [0.0000e+00, 1.9995e-05, 4.8003e-06],
        [0.0000e+00, 2.0725e-05, 5.2662e-06],
        [0.0000e+00, 1.8029e-05, 3.4016e-06],
        [0.0000e+00, 2.4960e-05, 3.6942e-06],
        [0.0000e+00, 3.3741e-05, 7.1140e-06],
        [0.0000e+00, 2.7468e-05, 6.7853e-06],
        [0.0000e+00, 1.6279e-05, 3.5808e-06],
        [0.0000e+00, 2.1870e-05, 4.8733e-06],
        [0.0000e+00, 1.9436e-05, 3.0139e-06],
        [0.0000e+00, 1.9096e-05, 4.1305e-06],
        [0.0000e+00, 2.8200e-05, 7.4395e-06],
        [0.0000e+00, 2.3363e-05, 5.7250e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.6986e-05, 3.2012e-05, 1.6651e-05, 1.7773e-05, 2.2970e-05, 2.2394e-05,
        4.0148e-05, 1.8532e-05, 2.8501e-05, 3.6412e-05, 2.1246e-05, 2.3074e-05,
        3.3091e-05, 1.8534e-05, 1.4379e-05, 2.3671e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.5394e-06, 8.7920e-06, 2.7231e-06, 4.3872e-06, 5.1636e-06, 5.7128e-06,
        9.9495e-06, 2.9200e-06, 5.6040e-06, 9.0789e-06, 3.8879e-06, 4.9318e-06,
        7.6640e-06, 4.5070e-06, 4.2165e-06, 7.2273e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.6986e-05, 5.5394e-06],
        [0.0000e+00, 3.2012e-05, 8.7920e-06],
        [0.0000e+00, 1.6651e-05, 2.7231e-06],
        [0.0000e+00, 1.7773e-05, 4.3872e-06],
        [0.0000e+00, 2.2970e-05, 5.1636e-06],
        [0.0000e+00, 2.2394e-05, 5.7128e-06],
        [0.0000e+00, 4.0148e-05, 9.9495e-06],
        [0.0000e+00, 1.8532e-05, 2.9200e-06],
        [0.0000e+00, 2.8501e-05, 5.6040e-06],
        [0.0000e+00, 3.6412e-05, 9.0789e-06],
        [0.0000e+00, 2.1246e-05, 3.8879e-06],
        [0.0000e+00, 2.3074e-05, 4.9318e-06],
        [0.0000e+00, 3.3091e-05, 7.6640e-06],
        [0.0000e+00, 1.8534e-05, 4.5070e-06],
        [0.0000e+00, 1.4379e-05, 4.2165e-06],
        [0.0000e+00, 2.3671e-05, 7.2273e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4036e-05, 3.8124e-05, 1.6946e-05, 1.8165e-05, 3.2785e-05, 2.0719e-05,
        2.0535e-05, 2.2671e-05, 1.4900e-05, 2.3056e-05, 1.7496e-05, 3.5868e-05,
        2.4720e-05, 2.9321e-05, 3.9868e-05, 2.3504e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([6.2761e-06, 9.0571e-06, 2.4438e-06, 4.3456e-06, 7.3088e-06, 4.8603e-06,
        3.3395e-06, 6.4862e-06, 3.7631e-06, 7.0516e-06, 5.3048e-06, 8.7923e-06,
        5.7165e-06, 6.8789e-06, 1.0048e-05, 4.5193e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4036e-05, 6.2761e-06],
        [0.0000e+00, 3.8124e-05, 9.0571e-06],
        [0.0000e+00, 1.6946e-05, 2.4438e-06],
        [0.0000e+00, 1.8165e-05, 4.3456e-06],
        [0.0000e+00, 3.2785e-05, 7.3088e-06],
        [0.0000e+00, 2.0719e-05, 4.8603e-06],
        [0.0000e+00, 2.0535e-05, 3.3395e-06],
        [0.0000e+00, 2.2671e-05, 6.4862e-06],
        [0.0000e+00, 1.4900e-05, 3.7631e-06],
        [0.0000e+00, 2.3056e-05, 7.0516e-06],
        [0.0000e+00, 1.7496e-05, 5.3048e-06],
        [0.0000e+00, 3.5868e-05, 8.7923e-06],
        [0.0000e+00, 2.4720e-05, 5.7165e-06],
        [0.0000e+00, 2.9321e-05, 6.8789e-06],
        [0.0000e+00, 3.9868e-05, 1.0048e-05],
        [0.0000e+00, 2.3504e-05, 4.5193e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type active, variation 0 and batchsize 16: 0:02:58.135882
path ['42', 'de', 'bloom', 'NLI', 'active', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m NLI active 1 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 283.01it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.2959e-05, 7.1957e-05, 2.0612e-05, 1.4123e-05, 2.2766e-05, 1.9103e-05,
        2.1583e-05, 2.9819e-05, 1.8368e-05, 2.0382e-05, 2.9887e-05, 3.5132e-05,
        4.0942e-05, 2.4149e-05, 2.8259e-05, 2.4130e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.6807e-06, 1.3738e-05, 4.5342e-06, 5.6543e-06, 5.9083e-06, 4.1461e-06,
        7.1584e-06, 7.5704e-06, 5.7117e-06, 3.9215e-06, 7.8160e-06, 5.6585e-06,
        1.4457e-05, 5.8964e-06, 7.0748e-06, 7.9902e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.2959e-05, 4.6807e-06],
        [0.0000e+00, 7.1957e-05, 1.3738e-05],
        [0.0000e+00, 2.0612e-05, 4.5342e-06],
        [0.0000e+00, 1.4123e-05, 5.6543e-06],
        [0.0000e+00, 2.2766e-05, 5.9083e-06],
        [0.0000e+00, 1.9103e-05, 4.1461e-06],
        [0.0000e+00, 2.1583e-05, 7.1584e-06],
        [0.0000e+00, 2.9819e-05, 7.5704e-06],
        [0.0000e+00, 1.8368e-05, 5.7117e-06],
        [0.0000e+00, 2.0382e-05, 3.9215e-06],
        [0.0000e+00, 2.9887e-05, 7.8160e-06],
        [0.0000e+00, 3.5132e-05, 5.6585e-06],
        [0.0000e+00, 4.0942e-05, 1.4457e-05],
        [0.0000e+00, 2.4149e-05, 5.8964e-06],
        [0.0000e+00, 2.8259e-05, 7.0748e-06],
        [0.0000e+00, 2.4130e-05, 7.9902e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4165e-05, 2.3712e-05, 2.6646e-05, 2.6728e-05, 3.3235e-05, 4.0422e-05,
        2.6527e-05, 1.4859e-05, 2.5506e-05, 2.4045e-05, 3.3186e-05, 1.7808e-05,
        2.5685e-05, 1.8348e-05, 4.6883e-05, 3.7384e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.3173e-06, 7.5890e-06, 4.2063e-06, 4.3806e-06, 9.4568e-06, 5.0374e-06,
        5.8722e-06, 4.8236e-06, 7.7000e-06, 4.7432e-06, 9.4838e-06, 2.7849e-06,
        4.7412e-06, 1.0520e-05, 6.3067e-06, 1.2004e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4165e-05, 4.3173e-06],
        [0.0000e+00, 2.3712e-05, 7.5890e-06],
        [0.0000e+00, 2.6646e-05, 4.2063e-06],
        [0.0000e+00, 2.6728e-05, 4.3806e-06],
        [0.0000e+00, 3.3235e-05, 9.4568e-06],
        [0.0000e+00, 4.0422e-05, 5.0374e-06],
        [0.0000e+00, 2.6527e-05, 5.8722e-06],
        [0.0000e+00, 1.4859e-05, 4.8236e-06],
        [0.0000e+00, 2.5506e-05, 7.7000e-06],
        [0.0000e+00, 2.4045e-05, 4.7432e-06],
        [0.0000e+00, 3.3186e-05, 9.4838e-06],
        [0.0000e+00, 1.7808e-05, 2.7849e-06],
        [0.0000e+00, 2.5685e-05, 4.7412e-06],
        [0.0000e+00, 1.8348e-05, 1.0520e-05],
        [0.0000e+00, 4.6883e-05, 6.3067e-06],
        [0.0000e+00, 3.7384e-05, 1.2004e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.3892e-05, 1.7489e-05, 2.7776e-05, 2.9084e-05, 2.8706e-05, 2.0784e-05,
        3.9492e-05, 1.6302e-05, 3.8473e-05, 3.7289e-05, 1.9754e-05, 2.6519e-05,
        2.9698e-05, 4.0426e-05, 2.6628e-05, 1.7842e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([7.8343e-06, 4.3032e-06, 6.2222e-06, 8.0024e-06, 6.8355e-06, 6.0404e-06,
        9.5469e-06, 4.4795e-06, 8.7000e-06, 9.5607e-06, 3.6211e-06, 7.1116e-06,
        7.2672e-06, 1.3315e-05, 5.2093e-06, 3.6375e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.3892e-05, 7.8343e-06],
        [0.0000e+00, 1.7489e-05, 4.3032e-06],
        [0.0000e+00, 2.7776e-05, 6.2222e-06],
        [0.0000e+00, 2.9084e-05, 8.0024e-06],
        [0.0000e+00, 2.8706e-05, 6.8355e-06],
        [0.0000e+00, 2.0784e-05, 6.0404e-06],
        [0.0000e+00, 3.9492e-05, 9.5469e-06],
        [0.0000e+00, 1.6302e-05, 4.4795e-06],
        [0.0000e+00, 3.8473e-05, 8.7000e-06],
        [0.0000e+00, 3.7289e-05, 9.5607e-06],
        [0.0000e+00, 1.9754e-05, 3.6211e-06],
        [0.0000e+00, 2.6519e-05, 7.1116e-06],
        [0.0000e+00, 2.9698e-05, 7.2672e-06],
        [0.0000e+00, 4.0426e-05, 1.3315e-05],
        [0.0000e+00, 2.6628e-05, 5.2093e-06],
        [0.0000e+00, 1.7842e-05, 3.6375e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type active, variation 1 and batchsize 16: 0:03:09.239309
path ['42', 'de', 'bloom', 'NLI', 'active', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m NLI active 2 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 310.22it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([7.5130e-05, 1.0602e-05, 5.2881e-05, 4.5075e-05, 2.4324e-05, 2.2459e-05,
        3.8533e-05, 5.1217e-05, 1.6158e-05, 1.8847e-05, 2.6572e-05, 3.5974e-05,
        1.4035e-04, 4.1429e-05, 2.2107e-05, 2.6432e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.0144e-05, 3.6733e-06, 1.5396e-05, 8.9047e-06, 8.3899e-06, 6.6175e-06,
        1.0249e-05, 8.8177e-06, 4.5952e-06, 6.6466e-06, 1.2022e-05, 8.7928e-06,
        2.9610e-05, 1.2712e-05, 1.3196e-05, 5.4048e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 7.5130e-05, 2.0144e-05],
        [0.0000e+00, 1.0602e-05, 3.6733e-06],
        [0.0000e+00, 5.2881e-05, 1.5396e-05],
        [0.0000e+00, 4.5075e-05, 8.9047e-06],
        [0.0000e+00, 2.4324e-05, 8.3899e-06],
        [0.0000e+00, 2.2459e-05, 6.6175e-06],
        [0.0000e+00, 3.8533e-05, 1.0249e-05],
        [0.0000e+00, 5.1217e-05, 8.8177e-06],
        [0.0000e+00, 1.6158e-05, 4.5952e-06],
        [0.0000e+00, 1.8847e-05, 6.6466e-06],
        [0.0000e+00, 2.6572e-05, 1.2022e-05],
        [0.0000e+00, 3.5974e-05, 8.7928e-06],
        [0.0000e+00, 1.4035e-04, 2.9610e-05],
        [0.0000e+00, 4.1429e-05, 1.2712e-05],
        [0.0000e+00, 2.2107e-05, 1.3196e-05],
        [0.0000e+00, 2.6432e-05, 5.4048e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.3268e-05, 4.3177e-05, 4.7207e-05, 6.1064e-05, 2.2695e-05, 1.8799e-05,
        4.8858e-05, 1.4561e-05, 3.1206e-05, 3.2987e-05, 5.4519e-05, 3.1411e-05,
        9.2791e-05, 2.6031e-05, 1.3757e-05, 5.9915e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.0794e-05, 1.0438e-05, 1.4806e-05, 1.2651e-05, 9.3169e-06, 9.0285e-06,
        1.4895e-05, 1.1952e-05, 1.0309e-05, 6.2155e-06, 6.9833e-06, 9.8488e-06,
        1.3298e-05, 6.7082e-06, 4.7156e-06, 1.3463e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.3268e-05, 1.0794e-05],
        [0.0000e+00, 4.3177e-05, 1.0438e-05],
        [0.0000e+00, 4.7207e-05, 1.4806e-05],
        [0.0000e+00, 6.1064e-05, 1.2651e-05],
        [0.0000e+00, 2.2695e-05, 9.3169e-06],
        [0.0000e+00, 1.8799e-05, 9.0285e-06],
        [0.0000e+00, 4.8858e-05, 1.4895e-05],
        [0.0000e+00, 1.4561e-05, 1.1952e-05],
        [0.0000e+00, 3.1206e-05, 1.0309e-05],
        [0.0000e+00, 3.2987e-05, 6.2155e-06],
        [0.0000e+00, 5.4519e-05, 6.9833e-06],
        [0.0000e+00, 3.1411e-05, 9.8488e-06],
        [0.0000e+00, 9.2791e-05, 1.3298e-05],
        [0.0000e+00, 2.6031e-05, 6.7082e-06],
        [0.0000e+00, 1.3757e-05, 4.7156e-06],
        [0.0000e+00, 5.9915e-05, 1.3463e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.6030e-05, 2.2930e-05, 3.3533e-05, 1.2641e-05, 8.0866e-05, 1.6865e-05,
        2.0723e-05, 3.8202e-05, 5.1390e-05, 7.1028e-05, 1.5779e-05, 2.6186e-05,
        1.5692e-05, 5.2966e-05, 1.3479e-05, 7.8539e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.2963e-05, 9.8311e-06, 1.0785e-05, 5.0805e-06, 1.0812e-05, 5.6001e-06,
        6.4381e-06, 8.2092e-06, 1.0701e-05, 9.2076e-06, 5.2855e-06, 1.2005e-05,
        6.4221e-06, 1.1603e-05, 8.8336e-06, 1.3409e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.6030e-05, 1.2963e-05],
        [0.0000e+00, 2.2930e-05, 9.8311e-06],
        [0.0000e+00, 3.3533e-05, 1.0785e-05],
        [0.0000e+00, 1.2641e-05, 5.0805e-06],
        [0.0000e+00, 8.0866e-05, 1.0812e-05],
        [0.0000e+00, 1.6865e-05, 5.6001e-06],
        [0.0000e+00, 2.0723e-05, 6.4381e-06],
        [0.0000e+00, 3.8202e-05, 8.2092e-06],
        [0.0000e+00, 5.1390e-05, 1.0701e-05],
        [0.0000e+00, 7.1028e-05, 9.2076e-06],
        [0.0000e+00, 1.5779e-05, 5.2855e-06],
        [0.0000e+00, 2.6186e-05, 1.2005e-05],
        [0.0000e+00, 1.5692e-05, 6.4221e-06],
        [0.0000e+00, 5.2966e-05, 1.1603e-05],
        [0.0000e+00, 1.3479e-05, 8.8336e-06],
        [0.0000e+00, 7.8539e-05, 1.3409e-05]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type active, variation 2 and batchsize 16: 0:03:09.032154
path ['42', 'de', 'bloom', 'NLI', 'active', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m NLI passive 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 274.92it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.6234e-05, 5.7518e-05, 8.3081e-05, 2.4300e-05, 2.9459e-05, 3.0592e-05,
        5.9224e-05, 7.0163e-05, 2.9135e-05, 2.8977e-05, 6.5492e-05, 2.7062e-05,
        3.8009e-05, 3.8771e-05, 1.6142e-05, 3.3482e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.4175e-05, 2.3953e-05, 1.7853e-05, 9.0578e-06, 7.7309e-06, 1.0183e-05,
        1.5911e-05, 2.2586e-05, 1.1409e-05, 1.1536e-05, 1.4964e-05, 7.8576e-06,
        1.0692e-05, 7.7410e-06, 5.9273e-06, 5.6271e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.6234e-05, 1.4175e-05],
        [0.0000e+00, 5.7518e-05, 2.3953e-05],
        [0.0000e+00, 8.3081e-05, 1.7853e-05],
        [0.0000e+00, 2.4300e-05, 9.0578e-06],
        [0.0000e+00, 2.9459e-05, 7.7309e-06],
        [0.0000e+00, 3.0592e-05, 1.0183e-05],
        [0.0000e+00, 5.9224e-05, 1.5911e-05],
        [0.0000e+00, 7.0163e-05, 2.2586e-05],
        [0.0000e+00, 2.9135e-05, 1.1409e-05],
        [0.0000e+00, 2.8977e-05, 1.1536e-05],
        [0.0000e+00, 6.5492e-05, 1.4964e-05],
        [0.0000e+00, 2.7062e-05, 7.8576e-06],
        [0.0000e+00, 3.8009e-05, 1.0692e-05],
        [0.0000e+00, 3.8771e-05, 7.7410e-06],
        [0.0000e+00, 1.6142e-05, 5.9273e-06],
        [0.0000e+00, 3.3482e-05, 5.6271e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.1298e-05, 3.9365e-05, 3.2553e-05, 2.3103e-05, 3.1700e-05, 3.8402e-05,
        3.1075e-05, 2.5634e-05, 5.1775e-05, 2.0329e-05, 2.0480e-05, 3.0333e-05,
        4.1261e-05, 2.2855e-05, 7.0701e-05, 7.7855e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.6313e-06, 1.1829e-05, 1.1776e-05, 8.6667e-06, 1.0367e-05, 9.8995e-06,
        1.3491e-05, 1.6957e-05, 2.1250e-05, 6.2067e-06, 6.8247e-06, 8.4405e-06,
        1.6242e-05, 6.5669e-06, 1.3219e-05, 1.9916e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.1298e-05, 5.6313e-06],
        [0.0000e+00, 3.9365e-05, 1.1829e-05],
        [0.0000e+00, 3.2553e-05, 1.1776e-05],
        [0.0000e+00, 2.3103e-05, 8.6667e-06],
        [0.0000e+00, 3.1700e-05, 1.0367e-05],
        [0.0000e+00, 3.8402e-05, 9.8995e-06],
        [0.0000e+00, 3.1075e-05, 1.3491e-05],
        [0.0000e+00, 2.5634e-05, 1.6957e-05],
        [0.0000e+00, 5.1775e-05, 2.1250e-05],
        [0.0000e+00, 2.0329e-05, 6.2067e-06],
        [0.0000e+00, 2.0480e-05, 6.8247e-06],
        [0.0000e+00, 3.0333e-05, 8.4405e-06],
        [0.0000e+00, 4.1261e-05, 1.6242e-05],
        [0.0000e+00, 2.2855e-05, 6.5669e-06],
        [0.0000e+00, 7.0701e-05, 1.3219e-05],
        [0.0000e+00, 7.7855e-05, 1.9916e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.5237e-05, 3.3076e-05, 3.5099e-05, 2.0659e-05, 5.7489e-05, 1.1958e-05,
        3.7476e-05, 3.4773e-05, 3.8056e-05, 2.1172e-05, 5.1546e-05, 3.6481e-05,
        2.9027e-05, 4.3281e-05, 2.9081e-05, 2.5699e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([9.5539e-06, 1.4776e-05, 1.1788e-05, 7.2105e-06, 2.0305e-05, 1.7575e-06,
        1.7266e-05, 9.5343e-06, 1.0037e-05, 5.9768e-06, 1.9842e-05, 1.2487e-05,
        1.0455e-05, 1.4547e-05, 5.3888e-06, 5.2593e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.5237e-05, 9.5539e-06],
        [0.0000e+00, 3.3076e-05, 1.4776e-05],
        [0.0000e+00, 3.5099e-05, 1.1788e-05],
        [0.0000e+00, 2.0659e-05, 7.2105e-06],
        [0.0000e+00, 5.7489e-05, 2.0305e-05],
        [0.0000e+00, 1.1958e-05, 1.7575e-06],
        [0.0000e+00, 3.7476e-05, 1.7266e-05],
        [0.0000e+00, 3.4773e-05, 9.5343e-06],
        [0.0000e+00, 3.8056e-05, 1.0037e-05],
        [0.0000e+00, 2.1172e-05, 5.9768e-06],
        [0.0000e+00, 5.1546e-05, 1.9842e-05],
        [0.0000e+00, 3.6481e-05, 1.2487e-05],
        [0.0000e+00, 2.9027e-05, 1.0455e-05],
        [0.0000e+00, 4.3281e-05, 1.4547e-05],
        [0.0000e+00, 2.9081e-05, 5.3888e-06],
        [0.0000e+00, 2.5699e-05, 5.2593e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type passive, variation 0 and batchsize 16: 0:03:07.665550
path ['42', 'de', 'bloom', 'NLI', 'passive', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m NLI passive 1 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 265.74it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4870e-05, 3.0050e-05, 2.6465e-05, 3.4119e-05, 2.2676e-05, 1.6807e-05,
        2.4687e-05, 1.9306e-05, 1.7883e-05, 2.4671e-05, 2.2474e-05, 1.9717e-05,
        2.5940e-05, 2.7256e-05, 2.2586e-05, 3.0410e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.3090e-06, 7.5118e-06, 4.4307e-06, 7.5256e-06, 4.4989e-06, 4.4633e-06,
        5.5549e-06, 3.4304e-06, 5.0235e-06, 7.2708e-06, 3.9042e-06, 3.2046e-06,
        6.5393e-06, 5.7426e-06, 6.0015e-06, 6.3148e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4870e-05, 5.3090e-06],
        [0.0000e+00, 3.0050e-05, 7.5118e-06],
        [0.0000e+00, 2.6465e-05, 4.4307e-06],
        [0.0000e+00, 3.4119e-05, 7.5256e-06],
        [0.0000e+00, 2.2676e-05, 4.4989e-06],
        [0.0000e+00, 1.6807e-05, 4.4633e-06],
        [0.0000e+00, 2.4687e-05, 5.5549e-06],
        [0.0000e+00, 1.9306e-05, 3.4304e-06],
        [0.0000e+00, 1.7883e-05, 5.0235e-06],
        [0.0000e+00, 2.4671e-05, 7.2708e-06],
        [0.0000e+00, 2.2474e-05, 3.9042e-06],
        [0.0000e+00, 1.9717e-05, 3.2046e-06],
        [0.0000e+00, 2.5940e-05, 6.5393e-06],
        [0.0000e+00, 2.7256e-05, 5.7426e-06],
        [0.0000e+00, 2.2586e-05, 6.0015e-06],
        [0.0000e+00, 3.0410e-05, 6.3148e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.0117e-05, 2.2493e-05, 2.1435e-05, 3.1230e-05, 1.9396e-05, 1.7846e-05,
        2.7551e-05, 1.8057e-05, 2.6796e-05, 2.4478e-05, 3.5125e-05, 2.2725e-05,
        2.1716e-05, 1.9865e-05, 1.6196e-05, 1.7789e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([7.5843e-06, 5.8982e-06, 3.3880e-06, 7.9495e-06, 4.8126e-06, 2.4604e-06,
        5.1728e-06, 3.4751e-06, 4.3747e-06, 5.7722e-06, 7.0293e-06, 4.1703e-06,
        4.2588e-06, 5.4738e-06, 4.9662e-06, 4.0521e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.0117e-05, 7.5843e-06],
        [0.0000e+00, 2.2493e-05, 5.8982e-06],
        [0.0000e+00, 2.1435e-05, 3.3880e-06],
        [0.0000e+00, 3.1230e-05, 7.9495e-06],
        [0.0000e+00, 1.9396e-05, 4.8126e-06],
        [0.0000e+00, 1.7846e-05, 2.4604e-06],
        [0.0000e+00, 2.7551e-05, 5.1728e-06],
        [0.0000e+00, 1.8057e-05, 3.4751e-06],
        [0.0000e+00, 2.6796e-05, 4.3747e-06],
        [0.0000e+00, 2.4478e-05, 5.7722e-06],
        [0.0000e+00, 3.5125e-05, 7.0293e-06],
        [0.0000e+00, 2.2725e-05, 4.1703e-06],
        [0.0000e+00, 2.1716e-05, 4.2588e-06],
        [0.0000e+00, 1.9865e-05, 5.4738e-06],
        [0.0000e+00, 1.6196e-05, 4.9662e-06],
        [0.0000e+00, 1.7789e-05, 4.0521e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.9162e-05, 1.1847e-05, 2.6429e-05, 2.6894e-05, 1.1688e-05, 1.6270e-05,
        1.9260e-05, 2.4460e-05, 2.5505e-05, 2.8824e-05, 1.2507e-05, 1.7304e-05,
        3.3473e-05, 1.7875e-05, 2.1962e-05, 2.4420e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.2520e-06, 2.2968e-06, 6.3479e-06, 6.9128e-06, 4.1769e-06, 2.1619e-06,
        3.2378e-06, 6.7321e-06, 6.1554e-06, 7.1042e-06, 2.3965e-06, 4.4745e-06,
        9.9926e-06, 4.2895e-06, 5.7004e-06, 5.2911e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.9162e-05, 3.2520e-06],
        [0.0000e+00, 1.1847e-05, 2.2968e-06],
        [0.0000e+00, 2.6429e-05, 6.3479e-06],
        [0.0000e+00, 2.6894e-05, 6.9128e-06],
        [0.0000e+00, 1.1688e-05, 4.1769e-06],
        [0.0000e+00, 1.6270e-05, 2.1619e-06],
        [0.0000e+00, 1.9260e-05, 3.2378e-06],
        [0.0000e+00, 2.4460e-05, 6.7321e-06],
        [0.0000e+00, 2.5505e-05, 6.1554e-06],
        [0.0000e+00, 2.8824e-05, 7.1042e-06],
        [0.0000e+00, 1.2507e-05, 2.3965e-06],
        [0.0000e+00, 1.7304e-05, 4.4745e-06],
        [0.0000e+00, 3.3473e-05, 9.9926e-06],
        [0.0000e+00, 1.7875e-05, 4.2895e-06],
        [0.0000e+00, 2.1962e-05, 5.7004e-06],
        [0.0000e+00, 2.4420e-05, 5.2911e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type passive, variation 1 and batchsize 16: 0:03:10.463176
path ['42', 'de', 'bloom', 'NLI', 'passive', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m NLI passive 2 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 302.23it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.6045e-05, 3.4734e-05, 5.0245e-05, 6.0573e-05, 3.0512e-05, 2.8137e-05,
        5.7406e-05, 8.3904e-05, 6.6932e-05, 3.2998e-05, 2.1149e-05, 2.5847e-05,
        4.5626e-05, 3.0434e-05, 4.4061e-05, 3.7133e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([6.6772e-06, 1.0568e-05, 1.7841e-05, 1.6486e-05, 4.9303e-06, 7.7462e-06,
        1.8801e-05, 1.6998e-05, 1.3518e-05, 8.3355e-06, 3.9579e-06, 1.2485e-05,
        1.7318e-05, 7.4722e-06, 6.7277e-06, 8.8281e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.6045e-05, 6.6772e-06],
        [0.0000e+00, 3.4734e-05, 1.0568e-05],
        [0.0000e+00, 5.0245e-05, 1.7841e-05],
        [0.0000e+00, 6.0573e-05, 1.6486e-05],
        [0.0000e+00, 3.0512e-05, 4.9303e-06],
        [0.0000e+00, 2.8137e-05, 7.7462e-06],
        [0.0000e+00, 5.7406e-05, 1.8801e-05],
        [0.0000e+00, 8.3904e-05, 1.6998e-05],
        [0.0000e+00, 6.6932e-05, 1.3518e-05],
        [0.0000e+00, 3.2998e-05, 8.3355e-06],
        [0.0000e+00, 2.1149e-05, 3.9579e-06],
        [0.0000e+00, 2.5847e-05, 1.2485e-05],
        [0.0000e+00, 4.5626e-05, 1.7318e-05],
        [0.0000e+00, 3.0434e-05, 7.4722e-06],
        [0.0000e+00, 4.4061e-05, 6.7277e-06],
        [0.0000e+00, 3.7133e-05, 8.8281e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.8142e-05, 3.9759e-05, 3.0313e-05, 4.1328e-05, 1.8973e-05, 4.7954e-05,
        3.6298e-05, 2.0848e-05, 5.9827e-05, 3.4600e-05, 6.3396e-05, 3.3743e-05,
        3.1580e-05, 4.2785e-05, 3.3983e-05, 2.3932e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.3403e-05, 8.2515e-06, 6.5439e-06, 1.1021e-05, 6.3338e-06, 1.2464e-05,
        9.4282e-06, 4.3123e-06, 1.9763e-05, 5.2352e-06, 1.7580e-05, 9.8351e-06,
        7.1624e-06, 1.0647e-05, 8.9990e-06, 5.9802e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.8142e-05, 1.3403e-05],
        [0.0000e+00, 3.9759e-05, 8.2515e-06],
        [0.0000e+00, 3.0313e-05, 6.5439e-06],
        [0.0000e+00, 4.1328e-05, 1.1021e-05],
        [0.0000e+00, 1.8973e-05, 6.3338e-06],
        [0.0000e+00, 4.7954e-05, 1.2464e-05],
        [0.0000e+00, 3.6298e-05, 9.4282e-06],
        [0.0000e+00, 2.0848e-05, 4.3123e-06],
        [0.0000e+00, 5.9827e-05, 1.9763e-05],
        [0.0000e+00, 3.4600e-05, 5.2352e-06],
        [0.0000e+00, 6.3396e-05, 1.7580e-05],
        [0.0000e+00, 3.3743e-05, 9.8351e-06],
        [0.0000e+00, 3.1580e-05, 7.1624e-06],
        [0.0000e+00, 4.2785e-05, 1.0647e-05],
        [0.0000e+00, 3.3983e-05, 8.9990e-06],
        [0.0000e+00, 2.3932e-05, 5.9802e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.1672e-05, 2.6556e-05, 2.4149e-05, 6.5155e-05, 3.6310e-05, 7.0586e-05,
        3.3969e-05, 4.5068e-05, 1.8149e-05, 2.4889e-05, 3.4226e-05, 3.0658e-05,
        1.8490e-05, 3.1632e-05, 1.3158e-05, 3.0484e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([8.7211e-06, 6.7366e-06, 5.7403e-06, 1.1794e-05, 5.1851e-06, 1.1270e-05,
        9.2606e-06, 1.6338e-05, 4.9072e-06, 4.9281e-06, 8.8143e-06, 9.4233e-06,
        3.7424e-06, 6.4215e-06, 1.5862e-06, 9.3507e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.1672e-05, 8.7211e-06],
        [0.0000e+00, 2.6556e-05, 6.7366e-06],
        [0.0000e+00, 2.4149e-05, 5.7403e-06],
        [0.0000e+00, 6.5155e-05, 1.1794e-05],
        [0.0000e+00, 3.6310e-05, 5.1851e-06],
        [0.0000e+00, 7.0586e-05, 1.1270e-05],
        [0.0000e+00, 3.3969e-05, 9.2606e-06],
        [0.0000e+00, 4.5068e-05, 1.6338e-05],
        [0.0000e+00, 1.8149e-05, 4.9072e-06],
        [0.0000e+00, 2.4889e-05, 4.9281e-06],
        [0.0000e+00, 3.4226e-05, 8.8143e-06],
        [0.0000e+00, 3.0658e-05, 9.4233e-06],
        [0.0000e+00, 1.8490e-05, 3.7424e-06],
        [0.0000e+00, 3.1632e-05, 6.4215e-06],
        [0.0000e+00, 1.3158e-05, 1.5862e-06],
        [0.0000e+00, 3.0484e-05, 9.3507e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type passive, variation 2 and batchsize 16: 0:03:09.434452
path ['42', 'de', 'bloom', 'NLI', 'passive', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m NLI auxiliary 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 307.41it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.3747e-05, 1.5352e-05, 2.5769e-05, 3.7333e-05, 2.6210e-05, 2.6403e-05,
        2.9526e-05, 2.2826e-05, 2.5036e-05, 2.1055e-05, 2.6450e-05, 2.2760e-05,
        1.9972e-05, 3.2641e-05, 2.2988e-05, 2.8801e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.0013e-05, 2.0874e-06, 5.9116e-06, 7.1286e-06, 4.0835e-06, 3.0269e-06,
        4.9725e-06, 3.1956e-06, 5.3274e-06, 2.5021e-06, 5.0506e-06, 5.2008e-06,
        3.9458e-06, 5.2024e-06, 5.9240e-06, 4.5621e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.3747e-05, 1.0013e-05],
        [0.0000e+00, 1.5352e-05, 2.0874e-06],
        [0.0000e+00, 2.5769e-05, 5.9116e-06],
        [0.0000e+00, 3.7333e-05, 7.1286e-06],
        [0.0000e+00, 2.6210e-05, 4.0835e-06],
        [0.0000e+00, 2.6403e-05, 3.0269e-06],
        [0.0000e+00, 2.9526e-05, 4.9725e-06],
        [0.0000e+00, 2.2826e-05, 3.1956e-06],
        [0.0000e+00, 2.5036e-05, 5.3274e-06],
        [0.0000e+00, 2.1055e-05, 2.5021e-06],
        [0.0000e+00, 2.6450e-05, 5.0506e-06],
        [0.0000e+00, 2.2760e-05, 5.2008e-06],
        [0.0000e+00, 1.9972e-05, 3.9458e-06],
        [0.0000e+00, 3.2641e-05, 5.2024e-06],
        [0.0000e+00, 2.2988e-05, 5.9240e-06],
        [0.0000e+00, 2.8801e-05, 4.5621e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.7759e-05, 4.6189e-05, 2.0927e-05, 1.7312e-05, 2.0911e-05, 2.6289e-05,
        2.2441e-05, 2.7104e-05, 3.4957e-05, 3.7628e-05, 1.4243e-05, 2.3771e-05,
        1.7545e-05, 2.1570e-05, 2.1877e-05, 1.8148e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([7.7576e-06, 8.7465e-06, 4.7246e-06, 3.7181e-06, 2.4087e-06, 5.7907e-06,
        4.2240e-06, 4.7025e-06, 8.4496e-06, 6.6593e-06, 3.9590e-06, 5.5207e-06,
        2.2112e-06, 3.5365e-06, 4.2930e-06, 3.6939e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.7759e-05, 7.7576e-06],
        [0.0000e+00, 4.6189e-05, 8.7465e-06],
        [0.0000e+00, 2.0927e-05, 4.7246e-06],
        [0.0000e+00, 1.7312e-05, 3.7181e-06],
        [0.0000e+00, 2.0911e-05, 2.4087e-06],
        [0.0000e+00, 2.6289e-05, 5.7907e-06],
        [0.0000e+00, 2.2441e-05, 4.2240e-06],
        [0.0000e+00, 2.7104e-05, 4.7025e-06],
        [0.0000e+00, 3.4957e-05, 8.4496e-06],
        [0.0000e+00, 3.7628e-05, 6.6593e-06],
        [0.0000e+00, 1.4243e-05, 3.9590e-06],
        [0.0000e+00, 2.3771e-05, 5.5207e-06],
        [0.0000e+00, 1.7545e-05, 2.2112e-06],
        [0.0000e+00, 2.1570e-05, 3.5365e-06],
        [0.0000e+00, 2.1877e-05, 4.2930e-06],
        [0.0000e+00, 1.8148e-05, 3.6939e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.6013e-05, 1.9291e-05, 3.4383e-05, 3.1324e-05, 3.2892e-05, 2.4746e-05,
        2.6472e-05, 2.9501e-05, 2.8635e-05, 2.0756e-05, 3.8350e-05, 2.0662e-05,
        2.4556e-05, 4.2981e-05, 1.8695e-05, 4.0557e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.5061e-06, 2.1756e-06, 6.6278e-06, 5.1802e-06, 6.8641e-06, 4.4471e-06,
        2.8424e-06, 6.3366e-06, 5.0548e-06, 4.0732e-06, 6.7461e-06, 4.6166e-06,
        6.5845e-06, 8.5529e-06, 3.2801e-06, 7.9761e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.6013e-05, 5.5061e-06],
        [0.0000e+00, 1.9291e-05, 2.1756e-06],
        [0.0000e+00, 3.4383e-05, 6.6278e-06],
        [0.0000e+00, 3.1324e-05, 5.1802e-06],
        [0.0000e+00, 3.2892e-05, 6.8641e-06],
        [0.0000e+00, 2.4746e-05, 4.4471e-06],
        [0.0000e+00, 2.6472e-05, 2.8424e-06],
        [0.0000e+00, 2.9501e-05, 6.3366e-06],
        [0.0000e+00, 2.8635e-05, 5.0548e-06],
        [0.0000e+00, 2.0756e-05, 4.0732e-06],
        [0.0000e+00, 3.8350e-05, 6.7461e-06],
        [0.0000e+00, 2.0662e-05, 4.6166e-06],
        [0.0000e+00, 2.4556e-05, 6.5845e-06],
        [0.0000e+00, 4.2981e-05, 8.5529e-06],
        [0.0000e+00, 1.8695e-05, 3.2801e-06],
        [0.0000e+00, 4.0557e-05, 7.9761e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type auxiliary, variation 0 and batchsize 16: 0:03:09.017290
path ['42', 'de', 'bloom', 'NLI', 'auxiliary', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m NLI auxiliary 1 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 276.44it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.6399e-05, 3.5627e-05, 2.8193e-05, 2.0385e-05, 3.6909e-05, 1.7541e-05,
        1.6624e-05, 2.3636e-05, 3.5892e-05, 1.5193e-05, 2.7713e-05, 2.1063e-05,
        4.0375e-05, 2.1428e-05, 2.4869e-05, 3.2379e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.9905e-06, 6.0798e-06, 5.8822e-06, 3.8083e-06, 7.8984e-06, 3.6069e-06,
        3.6537e-06, 4.4352e-06, 5.8269e-06, 1.9575e-06, 5.0468e-06, 2.4478e-06,
        6.8999e-06, 3.1323e-06, 5.7520e-06, 5.2013e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.6399e-05, 3.9905e-06],
        [0.0000e+00, 3.5627e-05, 6.0798e-06],
        [0.0000e+00, 2.8193e-05, 5.8822e-06],
        [0.0000e+00, 2.0385e-05, 3.8083e-06],
        [0.0000e+00, 3.6909e-05, 7.8984e-06],
        [0.0000e+00, 1.7541e-05, 3.6069e-06],
        [0.0000e+00, 1.6624e-05, 3.6537e-06],
        [0.0000e+00, 2.3636e-05, 4.4352e-06],
        [0.0000e+00, 3.5892e-05, 5.8269e-06],
        [0.0000e+00, 1.5193e-05, 1.9575e-06],
        [0.0000e+00, 2.7713e-05, 5.0468e-06],
        [0.0000e+00, 2.1063e-05, 2.4478e-06],
        [0.0000e+00, 4.0375e-05, 6.8999e-06],
        [0.0000e+00, 2.1428e-05, 3.1323e-06],
        [0.0000e+00, 2.4869e-05, 5.7520e-06],
        [0.0000e+00, 3.2379e-05, 5.2013e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.7299e-05, 2.2539e-05, 2.6077e-05, 1.8773e-05, 4.3476e-05, 2.1507e-05,
        1.9604e-05, 2.3439e-05, 2.6215e-05, 1.8719e-05, 1.9491e-05, 2.9215e-05,
        2.3846e-05, 1.8044e-05, 2.2319e-05, 4.0072e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.9860e-06, 5.0143e-06, 5.1054e-06, 4.3215e-06, 8.6517e-06, 3.4661e-06,
        2.0125e-06, 5.7472e-06, 3.9869e-06, 3.1767e-06, 3.5504e-06, 4.6100e-06,
        5.1326e-06, 2.1927e-06, 3.8682e-06, 7.7337e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.7299e-05, 2.9860e-06],
        [0.0000e+00, 2.2539e-05, 5.0143e-06],
        [0.0000e+00, 2.6077e-05, 5.1054e-06],
        [0.0000e+00, 1.8773e-05, 4.3215e-06],
        [0.0000e+00, 4.3476e-05, 8.6517e-06],
        [0.0000e+00, 2.1507e-05, 3.4661e-06],
        [0.0000e+00, 1.9604e-05, 2.0125e-06],
        [0.0000e+00, 2.3439e-05, 5.7472e-06],
        [0.0000e+00, 2.6215e-05, 3.9869e-06],
        [0.0000e+00, 1.8719e-05, 3.1767e-06],
        [0.0000e+00, 1.9491e-05, 3.5504e-06],
        [0.0000e+00, 2.9215e-05, 4.6100e-06],
        [0.0000e+00, 2.3846e-05, 5.1326e-06],
        [0.0000e+00, 1.8044e-05, 2.1927e-06],
        [0.0000e+00, 2.2319e-05, 3.8682e-06],
        [0.0000e+00, 4.0072e-05, 7.7337e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.4261e-05, 3.1092e-05, 2.8290e-05, 2.7781e-05, 2.6934e-05, 3.3398e-05,
        1.8935e-05, 4.3263e-05, 2.5077e-05, 2.5226e-05, 3.3013e-05, 2.1470e-05,
        4.5631e-05, 3.5562e-05, 2.2187e-05, 1.9490e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.7664e-06, 5.1270e-06, 5.2359e-06, 4.3880e-06, 2.6877e-06, 6.7298e-06,
        3.7423e-06, 8.1138e-06, 6.6391e-06, 5.5823e-06, 6.1881e-06, 4.5521e-06,
        7.1074e-06, 8.1916e-06, 3.5909e-06, 2.2757e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.4261e-05, 3.7664e-06],
        [0.0000e+00, 3.1092e-05, 5.1270e-06],
        [0.0000e+00, 2.8290e-05, 5.2359e-06],
        [0.0000e+00, 2.7781e-05, 4.3880e-06],
        [0.0000e+00, 2.6934e-05, 2.6877e-06],
        [0.0000e+00, 3.3398e-05, 6.7298e-06],
        [0.0000e+00, 1.8935e-05, 3.7423e-06],
        [0.0000e+00, 4.3263e-05, 8.1138e-06],
        [0.0000e+00, 2.5077e-05, 6.6391e-06],
        [0.0000e+00, 2.5226e-05, 5.5823e-06],
        [0.0000e+00, 3.3013e-05, 6.1881e-06],
        [0.0000e+00, 2.1470e-05, 4.5521e-06],
        [0.0000e+00, 4.5631e-05, 7.1074e-06],
        [0.0000e+00, 3.5562e-05, 8.1916e-06],
        [0.0000e+00, 2.2187e-05, 3.5909e-06],
        [0.0000e+00, 1.9490e-05, 2.2757e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type auxiliary, variation 1 and batchsize 16: 0:03:09.718002
path ['42', 'de', 'bloom', 'NLI', 'auxiliary', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m NLI auxiliary 2 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 286.56it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.7556e-05, 2.4528e-05, 2.0454e-05, 3.6658e-05, 1.1876e-05, 1.6832e-05,
        2.3218e-05, 2.4928e-05, 2.8484e-05, 3.1292e-05, 2.3176e-05, 2.3197e-05,
        1.5532e-05, 1.7961e-05, 1.7088e-05, 1.6894e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.3035e-06, 4.1552e-06, 3.4563e-06, 8.9637e-06, 3.6831e-06, 3.4068e-06,
        2.4177e-06, 4.6176e-06, 5.1293e-06, 8.4649e-06, 3.8300e-06, 5.7290e-06,
        2.1331e-06, 3.9685e-06, 2.2057e-06, 2.2461e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.7556e-05, 4.3035e-06],
        [0.0000e+00, 2.4528e-05, 4.1552e-06],
        [0.0000e+00, 2.0454e-05, 3.4563e-06],
        [0.0000e+00, 3.6658e-05, 8.9637e-06],
        [0.0000e+00, 1.1876e-05, 3.6831e-06],
        [0.0000e+00, 1.6832e-05, 3.4068e-06],
        [0.0000e+00, 2.3218e-05, 2.4177e-06],
        [0.0000e+00, 2.4928e-05, 4.6176e-06],
        [0.0000e+00, 2.8484e-05, 5.1293e-06],
        [0.0000e+00, 3.1292e-05, 8.4649e-06],
        [0.0000e+00, 2.3176e-05, 3.8300e-06],
        [0.0000e+00, 2.3197e-05, 5.7290e-06],
        [0.0000e+00, 1.5532e-05, 2.1331e-06],
        [0.0000e+00, 1.7961e-05, 3.9685e-06],
        [0.0000e+00, 1.7088e-05, 2.2057e-06],
        [0.0000e+00, 1.6894e-05, 2.2461e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2173e-05, 3.8518e-05, 2.4568e-05, 2.8928e-05, 3.5201e-05, 1.6922e-05,
        2.0455e-05, 2.5140e-05, 3.1471e-05, 4.0396e-05, 1.8203e-05, 2.8982e-05,
        2.5507e-05, 3.1567e-05, 1.9934e-05, 1.7060e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.6418e-06, 9.0421e-06, 4.3915e-06, 6.7207e-06, 8.2747e-06, 2.2016e-06,
        5.3640e-06, 5.8720e-06, 6.7532e-06, 7.1578e-06, 4.2387e-06, 5.1195e-06,
        5.4019e-06, 7.2988e-06, 4.0311e-06, 4.3113e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2173e-05, 5.6418e-06],
        [0.0000e+00, 3.8518e-05, 9.0421e-06],
        [0.0000e+00, 2.4568e-05, 4.3915e-06],
        [0.0000e+00, 2.8928e-05, 6.7207e-06],
        [0.0000e+00, 3.5201e-05, 8.2747e-06],
        [0.0000e+00, 1.6922e-05, 2.2016e-06],
        [0.0000e+00, 2.0455e-05, 5.3640e-06],
        [0.0000e+00, 2.5140e-05, 5.8720e-06],
        [0.0000e+00, 3.1471e-05, 6.7532e-06],
        [0.0000e+00, 4.0396e-05, 7.1578e-06],
        [0.0000e+00, 1.8203e-05, 4.2387e-06],
        [0.0000e+00, 2.8982e-05, 5.1195e-06],
        [0.0000e+00, 2.5507e-05, 5.4019e-06],
        [0.0000e+00, 3.1567e-05, 7.2988e-06],
        [0.0000e+00, 1.9934e-05, 4.0311e-06],
        [0.0000e+00, 1.7060e-05, 4.3113e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.9306e-05, 2.3159e-05, 1.8559e-05, 1.5167e-05, 1.9590e-05, 2.5191e-05,
        3.2567e-05, 3.9576e-05, 2.2870e-05, 2.3353e-05, 1.6446e-05, 1.5962e-05,
        1.9018e-05, 2.0261e-05, 3.0649e-05, 1.6396e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.5486e-06, 3.0176e-06, 2.8885e-06, 3.8198e-06, 5.2324e-06, 5.0946e-06,
        6.2198e-06, 8.6103e-06, 6.5215e-06, 5.4402e-06, 3.6089e-06, 1.8132e-06,
        4.9525e-06, 4.2337e-06, 6.1182e-06, 3.1000e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.9306e-05, 3.5486e-06],
        [0.0000e+00, 2.3159e-05, 3.0176e-06],
        [0.0000e+00, 1.8559e-05, 2.8885e-06],
        [0.0000e+00, 1.5167e-05, 3.8198e-06],
        [0.0000e+00, 1.9590e-05, 5.2324e-06],
        [0.0000e+00, 2.5191e-05, 5.0946e-06],
        [0.0000e+00, 3.2567e-05, 6.2198e-06],
        [0.0000e+00, 3.9576e-05, 8.6103e-06],
        [0.0000e+00, 2.2870e-05, 6.5215e-06],
        [0.0000e+00, 2.3353e-05, 5.4402e-06],
        [0.0000e+00, 1.6446e-05, 3.6089e-06],
        [0.0000e+00, 1.5962e-05, 1.8132e-06],
        [0.0000e+00, 1.9018e-05, 4.9525e-06],
        [0.0000e+00, 2.0261e-05, 4.2337e-06],
        [0.0000e+00, 3.0649e-05, 6.1182e-06],
        [0.0000e+00, 1.6396e-05, 3.1000e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type auxiliary, variation 2 and batchsize 16: 0:02:51.632391
path ['42', 'de', 'bloom', 'NLI', 'auxiliary', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m NLI modal 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 282.31it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.1982e-05, 1.6388e-05, 1.5486e-05, 2.4162e-05, 2.6811e-05, 2.1660e-05,
        1.4121e-05, 1.9657e-05, 2.2302e-05, 3.2715e-05, 2.2610e-05, 2.2279e-05,
        1.8952e-05, 1.9342e-05, 1.4928e-05, 2.5761e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.1809e-06, 3.6975e-06, 1.8837e-06, 4.7254e-06, 2.7164e-06, 3.6965e-06,
        3.4712e-06, 2.8815e-06, 5.0344e-06, 5.9167e-06, 5.5590e-06, 4.1028e-06,
        3.2665e-06, 3.3601e-06, 2.9005e-06, 3.9081e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.1982e-05, 2.1809e-06],
        [0.0000e+00, 1.6388e-05, 3.6975e-06],
        [0.0000e+00, 1.5486e-05, 1.8837e-06],
        [0.0000e+00, 2.4162e-05, 4.7254e-06],
        [0.0000e+00, 2.6811e-05, 2.7164e-06],
        [0.0000e+00, 2.1660e-05, 3.6965e-06],
        [0.0000e+00, 1.4121e-05, 3.4712e-06],
        [0.0000e+00, 1.9657e-05, 2.8815e-06],
        [0.0000e+00, 2.2302e-05, 5.0344e-06],
        [0.0000e+00, 3.2715e-05, 5.9167e-06],
        [0.0000e+00, 2.2610e-05, 5.5590e-06],
        [0.0000e+00, 2.2279e-05, 4.1028e-06],
        [0.0000e+00, 1.8952e-05, 3.2665e-06],
        [0.0000e+00, 1.9342e-05, 3.3601e-06],
        [0.0000e+00, 1.4928e-05, 2.9005e-06],
        [0.0000e+00, 2.5761e-05, 3.9081e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.9323e-05, 2.3657e-05, 2.5843e-05, 2.2250e-05, 1.9996e-05, 1.2819e-05,
        3.3743e-05, 1.8083e-05, 2.5093e-05, 1.5573e-05, 2.4234e-05, 2.4123e-05,
        2.9271e-05, 1.7435e-05, 1.7058e-05, 2.2975e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.3839e-06, 4.7515e-06, 5.5653e-06, 4.4082e-06, 3.4639e-06, 2.5415e-06,
        5.6109e-06, 4.0169e-06, 3.8263e-06, 2.0795e-06, 4.3721e-06, 3.8013e-06,
        4.4608e-06, 2.6816e-06, 2.9555e-06, 3.6083e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.9323e-05, 3.3839e-06],
        [0.0000e+00, 2.3657e-05, 4.7515e-06],
        [0.0000e+00, 2.5843e-05, 5.5653e-06],
        [0.0000e+00, 2.2250e-05, 4.4082e-06],
        [0.0000e+00, 1.9996e-05, 3.4639e-06],
        [0.0000e+00, 1.2819e-05, 2.5415e-06],
        [0.0000e+00, 3.3743e-05, 5.6109e-06],
        [0.0000e+00, 1.8083e-05, 4.0169e-06],
        [0.0000e+00, 2.5093e-05, 3.8263e-06],
        [0.0000e+00, 1.5573e-05, 2.0795e-06],
        [0.0000e+00, 2.4234e-05, 4.3721e-06],
        [0.0000e+00, 2.4123e-05, 3.8013e-06],
        [0.0000e+00, 2.9271e-05, 4.4608e-06],
        [0.0000e+00, 1.7435e-05, 2.6816e-06],
        [0.0000e+00, 1.7058e-05, 2.9555e-06],
        [0.0000e+00, 2.2975e-05, 3.6083e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.8468e-05, 2.3908e-05, 2.3214e-05, 1.7153e-05, 2.0104e-05, 2.8492e-05,
        3.3328e-05, 2.4667e-05, 2.0319e-05, 1.8381e-05, 2.4824e-05, 1.7205e-05,
        1.8665e-05, 1.7371e-05, 1.3883e-05, 1.5198e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.0781e-06, 3.3681e-06, 4.2368e-06, 3.6316e-06, 3.7112e-06, 3.7562e-06,
        5.1191e-06, 2.2011e-06, 2.3580e-06, 3.0827e-06, 5.3506e-06, 3.6347e-06,
        2.1955e-06, 4.5405e-06, 2.6954e-06, 2.2271e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.8468e-05, 4.0781e-06],
        [0.0000e+00, 2.3908e-05, 3.3681e-06],
        [0.0000e+00, 2.3214e-05, 4.2368e-06],
        [0.0000e+00, 1.7153e-05, 3.6316e-06],
        [0.0000e+00, 2.0104e-05, 3.7112e-06],
        [0.0000e+00, 2.8492e-05, 3.7562e-06],
        [0.0000e+00, 3.3328e-05, 5.1191e-06],
        [0.0000e+00, 2.4667e-05, 2.2011e-06],
        [0.0000e+00, 2.0319e-05, 2.3580e-06],
        [0.0000e+00, 1.8381e-05, 3.0827e-06],
        [0.0000e+00, 2.4824e-05, 5.3506e-06],
        [0.0000e+00, 1.7205e-05, 3.6347e-06],
        [0.0000e+00, 1.8665e-05, 2.1955e-06],
        [0.0000e+00, 1.7371e-05, 4.5405e-06],
        [0.0000e+00, 1.3883e-05, 2.6954e-06],
        [0.0000e+00, 1.5198e-05, 2.2271e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type modal, variation 0 and batchsize 16: 0:02:52.311939
path ['42', 'de', 'bloom', 'NLI', 'modal', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m NLI modal 1 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 296.56it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5320e-05, 1.9171e-05, 2.1876e-05, 2.1163e-05, 2.5577e-05, 1.5166e-05,
        2.3273e-05, 1.6223e-05, 1.5689e-05, 2.0491e-05, 2.1379e-05, 1.7247e-05,
        3.5745e-05, 1.8479e-05, 2.3350e-05, 1.8710e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.5953e-06, 3.9110e-06, 5.2379e-06, 4.5559e-06, 5.3469e-06, 3.8749e-06,
        3.8097e-06, 3.2791e-06, 3.2452e-06, 3.1892e-06, 4.1062e-06, 2.3100e-06,
        6.7273e-06, 3.7801e-06, 4.5663e-06, 4.7124e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5320e-05, 4.5953e-06],
        [0.0000e+00, 1.9171e-05, 3.9110e-06],
        [0.0000e+00, 2.1876e-05, 5.2379e-06],
        [0.0000e+00, 2.1163e-05, 4.5559e-06],
        [0.0000e+00, 2.5577e-05, 5.3469e-06],
        [0.0000e+00, 1.5166e-05, 3.8749e-06],
        [0.0000e+00, 2.3273e-05, 3.8097e-06],
        [0.0000e+00, 1.6223e-05, 3.2791e-06],
        [0.0000e+00, 1.5689e-05, 3.2452e-06],
        [0.0000e+00, 2.0491e-05, 3.1892e-06],
        [0.0000e+00, 2.1379e-05, 4.1062e-06],
        [0.0000e+00, 1.7247e-05, 2.3100e-06],
        [0.0000e+00, 3.5745e-05, 6.7273e-06],
        [0.0000e+00, 1.8479e-05, 3.7801e-06],
        [0.0000e+00, 2.3350e-05, 4.5663e-06],
        [0.0000e+00, 1.8710e-05, 4.7124e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.3131e-05, 2.6340e-05, 2.6755e-05, 1.4032e-05, 3.1511e-05, 3.8266e-05,
        2.5596e-05, 1.4277e-05, 1.2155e-05, 2.3220e-05, 1.7861e-05, 1.5445e-05,
        2.4545e-05, 1.4823e-05, 2.6177e-05, 1.3102e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.6364e-06, 5.9800e-06, 4.6160e-06, 2.9063e-06, 5.0847e-06, 7.8161e-06,
        5.3616e-06, 2.4152e-06, 2.3416e-06, 3.0262e-06, 5.5770e-06, 2.0011e-06,
        3.2073e-06, 2.2508e-06, 4.4944e-06, 2.7471e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.3131e-05, 4.6364e-06],
        [0.0000e+00, 2.6340e-05, 5.9800e-06],
        [0.0000e+00, 2.6755e-05, 4.6160e-06],
        [0.0000e+00, 1.4032e-05, 2.9063e-06],
        [0.0000e+00, 3.1511e-05, 5.0847e-06],
        [0.0000e+00, 3.8266e-05, 7.8161e-06],
        [0.0000e+00, 2.5596e-05, 5.3616e-06],
        [0.0000e+00, 1.4277e-05, 2.4152e-06],
        [0.0000e+00, 1.2155e-05, 2.3416e-06],
        [0.0000e+00, 2.3220e-05, 3.0262e-06],
        [0.0000e+00, 1.7861e-05, 5.5770e-06],
        [0.0000e+00, 1.5445e-05, 2.0011e-06],
        [0.0000e+00, 2.4545e-05, 3.2073e-06],
        [0.0000e+00, 1.4823e-05, 2.2508e-06],
        [0.0000e+00, 2.6177e-05, 4.4944e-06],
        [0.0000e+00, 1.3102e-05, 2.7471e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.1911e-05, 2.4225e-05, 1.9154e-05, 2.1570e-05, 1.8390e-05, 1.8151e-05,
        1.7113e-05, 2.5836e-05, 2.2053e-05, 1.9567e-05, 2.4555e-05, 2.8547e-05,
        2.7842e-05, 1.8780e-05, 1.8998e-05, 1.7516e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.4986e-06, 5.5223e-06, 3.6848e-06, 4.1564e-06, 3.9906e-06, 3.6910e-06,
        4.5861e-06, 6.0670e-06, 4.1283e-06, 4.4888e-06, 6.4967e-06, 3.9799e-06,
        6.5350e-06, 2.5706e-06, 3.7110e-06, 4.2737e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.1911e-05, 5.4986e-06],
        [0.0000e+00, 2.4225e-05, 5.5223e-06],
        [0.0000e+00, 1.9154e-05, 3.6848e-06],
        [0.0000e+00, 2.1570e-05, 4.1564e-06],
        [0.0000e+00, 1.8390e-05, 3.9906e-06],
        [0.0000e+00, 1.8151e-05, 3.6910e-06],
        [0.0000e+00, 1.7113e-05, 4.5861e-06],
        [0.0000e+00, 2.5836e-05, 6.0670e-06],
        [0.0000e+00, 2.2053e-05, 4.1283e-06],
        [0.0000e+00, 1.9567e-05, 4.4888e-06],
        [0.0000e+00, 2.4555e-05, 6.4967e-06],
        [0.0000e+00, 2.8547e-05, 3.9799e-06],
        [0.0000e+00, 2.7842e-05, 6.5350e-06],
        [0.0000e+00, 1.8780e-05, 2.5706e-06],
        [0.0000e+00, 1.8998e-05, 3.7110e-06],
        [0.0000e+00, 1.7516e-05, 4.2737e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type modal, variation 1 and batchsize 16: 0:02:51.333244
path ['42', 'de', 'bloom', 'NLI', 'modal', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m NLI modal 2 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 294.65it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4096e-05, 2.3355e-05, 2.8258e-05, 1.7451e-05, 2.5275e-05, 2.0913e-05,
        1.3186e-05, 1.7078e-05, 3.0949e-05, 2.0438e-05, 2.9298e-05, 1.6703e-05,
        1.9715e-05, 2.1840e-05, 2.1120e-05, 2.1376e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.5624e-06, 5.6948e-06, 6.3869e-06, 1.9332e-06, 6.8482e-06, 6.8912e-06,
        2.3001e-06, 4.6439e-06, 6.5678e-06, 3.0960e-06, 6.7865e-06, 5.0690e-06,
        6.3537e-06, 6.4548e-06, 4.8086e-06, 4.9372e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4096e-05, 5.5624e-06],
        [0.0000e+00, 2.3355e-05, 5.6948e-06],
        [0.0000e+00, 2.8258e-05, 6.3869e-06],
        [0.0000e+00, 1.7451e-05, 1.9332e-06],
        [0.0000e+00, 2.5275e-05, 6.8482e-06],
        [0.0000e+00, 2.0913e-05, 6.8912e-06],
        [0.0000e+00, 1.3186e-05, 2.3001e-06],
        [0.0000e+00, 1.7078e-05, 4.6439e-06],
        [0.0000e+00, 3.0949e-05, 6.5678e-06],
        [0.0000e+00, 2.0438e-05, 3.0960e-06],
        [0.0000e+00, 2.9298e-05, 6.7865e-06],
        [0.0000e+00, 1.6703e-05, 5.0690e-06],
        [0.0000e+00, 1.9715e-05, 6.3537e-06],
        [0.0000e+00, 2.1840e-05, 6.4548e-06],
        [0.0000e+00, 2.1120e-05, 4.8086e-06],
        [0.0000e+00, 2.1376e-05, 4.9372e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.3607e-05, 3.4597e-05, 4.3879e-05, 2.6139e-05, 2.3477e-05, 2.3644e-05,
        2.9931e-05, 1.6123e-05, 3.6665e-05, 2.4200e-05, 2.5283e-05, 2.2754e-05,
        2.4383e-05, 3.4011e-05, 2.0224e-05, 2.1087e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.9875e-06, 8.6497e-06, 6.5982e-06, 6.3816e-06, 5.0432e-06, 7.0847e-06,
        5.0226e-06, 3.4712e-06, 9.4272e-06, 7.8453e-06, 6.3075e-06, 5.6290e-06,
        5.4254e-06, 1.0755e-05, 3.1870e-06, 4.6401e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.3607e-05, 5.9875e-06],
        [0.0000e+00, 3.4597e-05, 8.6497e-06],
        [0.0000e+00, 4.3879e-05, 6.5982e-06],
        [0.0000e+00, 2.6139e-05, 6.3816e-06],
        [0.0000e+00, 2.3477e-05, 5.0432e-06],
        [0.0000e+00, 2.3644e-05, 7.0847e-06],
        [0.0000e+00, 2.9931e-05, 5.0226e-06],
        [0.0000e+00, 1.6123e-05, 3.4712e-06],
        [0.0000e+00, 3.6665e-05, 9.4272e-06],
        [0.0000e+00, 2.4200e-05, 7.8453e-06],
        [0.0000e+00, 2.5283e-05, 6.3075e-06],
        [0.0000e+00, 2.2754e-05, 5.6290e-06],
        [0.0000e+00, 2.4383e-05, 5.4254e-06],
        [0.0000e+00, 3.4011e-05, 1.0755e-05],
        [0.0000e+00, 2.0224e-05, 3.1870e-06],
        [0.0000e+00, 2.1087e-05, 4.6401e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2910e-05, 3.4696e-05, 1.7692e-05, 1.4924e-05, 2.1020e-05, 2.7734e-05,
        2.3146e-05, 2.4149e-05, 1.6659e-05, 2.8682e-05, 2.7541e-05, 3.0264e-05,
        2.9624e-05, 3.4386e-05, 2.1271e-05, 2.2100e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([6.6720e-06, 5.5075e-06, 5.4837e-06, 2.9701e-06, 5.7537e-06, 6.0029e-06,
        6.6826e-06, 5.5510e-06, 2.4337e-06, 5.8885e-06, 7.4714e-06, 4.2977e-06,
        6.0849e-06, 1.0806e-05, 4.6398e-06, 5.6202e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2910e-05, 6.6720e-06],
        [0.0000e+00, 3.4696e-05, 5.5075e-06],
        [0.0000e+00, 1.7692e-05, 5.4837e-06],
        [0.0000e+00, 1.4924e-05, 2.9701e-06],
        [0.0000e+00, 2.1020e-05, 5.7537e-06],
        [0.0000e+00, 2.7734e-05, 6.0029e-06],
        [0.0000e+00, 2.3146e-05, 6.6826e-06],
        [0.0000e+00, 2.4149e-05, 5.5510e-06],
        [0.0000e+00, 1.6659e-05, 2.4337e-06],
        [0.0000e+00, 2.8682e-05, 5.8885e-06],
        [0.0000e+00, 2.7541e-05, 7.4714e-06],
        [0.0000e+00, 3.0264e-05, 4.2977e-06],
        [0.0000e+00, 2.9624e-05, 6.0849e-06],
        [0.0000e+00, 3.4386e-05, 1.0806e-05],
        [0.0000e+00, 2.1271e-05, 4.6398e-06],
        [0.0000e+00, 2.2100e-05, 5.6202e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type modal, variation 2 and batchsize 16: 0:02:51.353883
path ['42', 'de', 'bloom', 'NLI', 'modal', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m NLI rare_synonyms 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 318.51it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.6030e-05, 1.0845e-05, 2.3872e-05, 1.5679e-05, 1.5670e-05, 1.8638e-05,
        1.8330e-05, 2.2576e-05, 2.4384e-05, 1.9433e-05, 2.2825e-05, 1.6836e-05,
        2.1426e-05, 2.3789e-05, 2.0582e-05, 3.1130e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.8188e-06, 2.4127e-06, 4.1965e-06, 3.9401e-06, 4.1389e-06, 3.1734e-06,
        4.0149e-06, 4.9907e-06, 6.1227e-06, 2.6019e-06, 4.1836e-06, 3.1591e-06,
        3.4929e-06, 2.8071e-06, 4.6790e-06, 5.9119e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.6030e-05, 4.8188e-06],
        [0.0000e+00, 1.0845e-05, 2.4127e-06],
        [0.0000e+00, 2.3872e-05, 4.1965e-06],
        [0.0000e+00, 1.5679e-05, 3.9401e-06],
        [0.0000e+00, 1.5670e-05, 4.1389e-06],
        [0.0000e+00, 1.8638e-05, 3.1734e-06],
        [0.0000e+00, 1.8330e-05, 4.0149e-06],
        [0.0000e+00, 2.2576e-05, 4.9907e-06],
        [0.0000e+00, 2.4384e-05, 6.1227e-06],
        [0.0000e+00, 1.9433e-05, 2.6019e-06],
        [0.0000e+00, 2.2825e-05, 4.1836e-06],
        [0.0000e+00, 1.6836e-05, 3.1591e-06],
        [0.0000e+00, 2.1426e-05, 3.4929e-06],
        [0.0000e+00, 2.3789e-05, 2.8071e-06],
        [0.0000e+00, 2.0582e-05, 4.6790e-06],
        [0.0000e+00, 3.1130e-05, 5.9119e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.1630e-05, 2.5623e-05, 1.2642e-05, 2.2419e-05, 1.3647e-05, 1.8457e-05,
        1.6150e-05, 3.0776e-05, 1.8878e-05, 1.6609e-05, 3.2762e-05, 2.3845e-05,
        2.5870e-05, 2.1856e-05, 1.4091e-05, 2.3156e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.4151e-06, 4.5439e-06, 2.8970e-06, 2.5090e-06, 3.1110e-06, 3.7569e-06,
        4.9029e-06, 6.4811e-06, 3.8217e-06, 4.2331e-06, 6.1322e-06, 5.8197e-06,
        4.0810e-06, 6.1693e-06, 2.2646e-06, 5.3099e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.1630e-05, 5.4151e-06],
        [0.0000e+00, 2.5623e-05, 4.5439e-06],
        [0.0000e+00, 1.2642e-05, 2.8970e-06],
        [0.0000e+00, 2.2419e-05, 2.5090e-06],
        [0.0000e+00, 1.3647e-05, 3.1110e-06],
        [0.0000e+00, 1.8457e-05, 3.7569e-06],
        [0.0000e+00, 1.6150e-05, 4.9029e-06],
        [0.0000e+00, 3.0776e-05, 6.4811e-06],
        [0.0000e+00, 1.8878e-05, 3.8217e-06],
        [0.0000e+00, 1.6609e-05, 4.2331e-06],
        [0.0000e+00, 3.2762e-05, 6.1322e-06],
        [0.0000e+00, 2.3845e-05, 5.8197e-06],
        [0.0000e+00, 2.5870e-05, 4.0810e-06],
        [0.0000e+00, 2.1856e-05, 6.1693e-06],
        [0.0000e+00, 1.4091e-05, 2.2646e-06],
        [0.0000e+00, 2.3156e-05, 5.3099e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2744e-05, 1.7898e-05, 1.6131e-05, 2.1954e-05, 1.7491e-05, 1.7410e-05,
        2.1466e-05, 1.9826e-05, 1.3868e-05, 1.6023e-05, 1.7631e-05, 1.3694e-05,
        1.4828e-05, 1.4027e-05, 2.1643e-05, 1.7645e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([5.4347e-06, 3.6261e-06, 3.2037e-06, 4.8237e-06, 2.4039e-06, 3.5943e-06,
        3.9062e-06, 4.1061e-06, 3.2092e-06, 4.1457e-06, 3.7324e-06, 3.7403e-06,
        2.3433e-06, 2.4786e-06, 4.6604e-06, 4.6178e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2744e-05, 5.4347e-06],
        [0.0000e+00, 1.7898e-05, 3.6261e-06],
        [0.0000e+00, 1.6131e-05, 3.2037e-06],
        [0.0000e+00, 2.1954e-05, 4.8237e-06],
        [0.0000e+00, 1.7491e-05, 2.4039e-06],
        [0.0000e+00, 1.7410e-05, 3.5943e-06],
        [0.0000e+00, 2.1466e-05, 3.9062e-06],
        [0.0000e+00, 1.9826e-05, 4.1061e-06],
        [0.0000e+00, 1.3868e-05, 3.2092e-06],
        [0.0000e+00, 1.6023e-05, 4.1457e-06],
        [0.0000e+00, 1.7631e-05, 3.7324e-06],
        [0.0000e+00, 1.3694e-05, 3.7403e-06],
        [0.0000e+00, 1.4828e-05, 2.3433e-06],
        [0.0000e+00, 1.4027e-05, 2.4786e-06],
        [0.0000e+00, 2.1643e-05, 4.6604e-06],
        [0.0000e+00, 1.7645e-05, 4.6178e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type rare_synonyms, variation 0 and batchsize 16: 0:02:51.510865
path ['42', 'de', 'bloom', 'NLI', 'rare_synonyms', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m NLI rare_synonyms 1 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 316.42it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.8149e-05, 1.4827e-05, 2.0106e-05, 1.1461e-05, 2.3724e-05, 1.6794e-05,
        1.6813e-05, 1.8831e-05, 2.4705e-05, 2.3086e-05, 1.6340e-05, 1.5841e-05,
        2.0178e-05, 2.2641e-05, 3.2304e-05, 2.6333e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.2688e-06, 2.0392e-06, 2.2846e-06, 2.0955e-06, 2.1631e-06, 2.7093e-06,
        3.7780e-06, 3.3229e-06, 5.4033e-06, 5.7487e-06, 2.8575e-06, 3.5589e-06,
        4.2083e-06, 4.6281e-06, 5.3778e-06, 4.0820e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.8149e-05, 3.2688e-06],
        [0.0000e+00, 1.4827e-05, 2.0392e-06],
        [0.0000e+00, 2.0106e-05, 2.2846e-06],
        [0.0000e+00, 1.1461e-05, 2.0955e-06],
        [0.0000e+00, 2.3724e-05, 2.1631e-06],
        [0.0000e+00, 1.6794e-05, 2.7093e-06],
        [0.0000e+00, 1.6813e-05, 3.7780e-06],
        [0.0000e+00, 1.8831e-05, 3.3229e-06],
        [0.0000e+00, 2.4705e-05, 5.4033e-06],
        [0.0000e+00, 2.3086e-05, 5.7487e-06],
        [0.0000e+00, 1.6340e-05, 2.8575e-06],
        [0.0000e+00, 1.5841e-05, 3.5589e-06],
        [0.0000e+00, 2.0178e-05, 4.2083e-06],
        [0.0000e+00, 2.2641e-05, 4.6281e-06],
        [0.0000e+00, 3.2304e-05, 5.3778e-06],
        [0.0000e+00, 2.6333e-05, 4.0820e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.9325e-05, 1.6279e-05, 2.3063e-05, 2.2237e-05, 2.2097e-05, 2.4803e-05,
        1.2103e-05, 2.4533e-05, 3.1122e-05, 1.6606e-05, 2.4045e-05, 1.4230e-05,
        2.2954e-05, 1.9425e-05, 1.4884e-05, 3.2115e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.7050e-06, 3.6597e-06, 3.7170e-06, 3.9620e-06, 4.9131e-06, 3.2537e-06,
        2.3285e-06, 3.9207e-06, 5.8259e-06, 4.3230e-06, 5.1752e-06, 3.5295e-06,
        4.5809e-06, 3.3761e-06, 2.1933e-06, 5.4717e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.9325e-05, 2.7050e-06],
        [0.0000e+00, 1.6279e-05, 3.6597e-06],
        [0.0000e+00, 2.3063e-05, 3.7170e-06],
        [0.0000e+00, 2.2237e-05, 3.9620e-06],
        [0.0000e+00, 2.2097e-05, 4.9131e-06],
        [0.0000e+00, 2.4803e-05, 3.2537e-06],
        [0.0000e+00, 1.2103e-05, 2.3285e-06],
        [0.0000e+00, 2.4533e-05, 3.9207e-06],
        [0.0000e+00, 3.1122e-05, 5.8259e-06],
        [0.0000e+00, 1.6606e-05, 4.3230e-06],
        [0.0000e+00, 2.4045e-05, 5.1752e-06],
        [0.0000e+00, 1.4230e-05, 3.5295e-06],
        [0.0000e+00, 2.2954e-05, 4.5809e-06],
        [0.0000e+00, 1.9425e-05, 3.3761e-06],
        [0.0000e+00, 1.4884e-05, 2.1933e-06],
        [0.0000e+00, 3.2115e-05, 5.4717e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2169e-05, 1.9731e-05, 1.5714e-05, 1.5730e-05, 2.6449e-05, 2.5980e-05,
        1.7806e-05, 1.3780e-05, 1.7754e-05, 2.0436e-05, 2.6799e-05, 1.8119e-05,
        2.1700e-05, 1.8574e-05, 2.2035e-05, 1.4299e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.3824e-06, 2.1921e-06, 3.5290e-06, 1.7892e-06, 2.6569e-06, 3.9488e-06,
        3.0496e-06, 2.7399e-06, 3.8761e-06, 3.6191e-06, 3.5547e-06, 3.3020e-06,
        4.0622e-06, 3.5525e-06, 4.1138e-06, 2.8517e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2169e-05, 3.3824e-06],
        [0.0000e+00, 1.9731e-05, 2.1921e-06],
        [0.0000e+00, 1.5714e-05, 3.5290e-06],
        [0.0000e+00, 1.5730e-05, 1.7892e-06],
        [0.0000e+00, 2.6449e-05, 2.6569e-06],
        [0.0000e+00, 2.5980e-05, 3.9488e-06],
        [0.0000e+00, 1.7806e-05, 3.0496e-06],
        [0.0000e+00, 1.3780e-05, 2.7399e-06],
        [0.0000e+00, 1.7754e-05, 3.8761e-06],
        [0.0000e+00, 2.0436e-05, 3.6191e-06],
        [0.0000e+00, 2.6799e-05, 3.5547e-06],
        [0.0000e+00, 1.8119e-05, 3.3020e-06],
        [0.0000e+00, 2.1700e-05, 4.0622e-06],
        [0.0000e+00, 1.8574e-05, 3.5525e-06],
        [0.0000e+00, 2.2035e-05, 4.1138e-06],
        [0.0000e+00, 1.4299e-05, 2.8517e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type rare_synonyms, variation 1 and batchsize 16: 0:02:51.811024
path ['42', 'de', 'bloom', 'NLI', 'rare_synonyms', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m NLI rare_synonyms 2 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 281.72it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.3327e-05, 2.3150e-05, 1.6735e-05, 1.5824e-05, 2.0899e-05, 3.2782e-05,
        1.7934e-05, 1.4440e-05, 2.7207e-05, 2.0023e-05, 1.4314e-05, 1.7238e-05,
        1.9273e-05, 1.8132e-05, 2.3906e-05, 3.1994e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.8050e-06, 2.2024e-06, 2.9134e-06, 2.1623e-06, 3.8811e-06, 5.7027e-06,
        3.2072e-06, 1.9394e-06, 3.8079e-06, 2.5110e-06, 2.8508e-06, 3.9153e-06,
        3.7433e-06, 4.1120e-06, 4.8628e-06, 6.1621e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.3327e-05, 2.8050e-06],
        [0.0000e+00, 2.3150e-05, 2.2024e-06],
        [0.0000e+00, 1.6735e-05, 2.9134e-06],
        [0.0000e+00, 1.5824e-05, 2.1623e-06],
        [0.0000e+00, 2.0899e-05, 3.8811e-06],
        [0.0000e+00, 3.2782e-05, 5.7027e-06],
        [0.0000e+00, 1.7934e-05, 3.2072e-06],
        [0.0000e+00, 1.4440e-05, 1.9394e-06],
        [0.0000e+00, 2.7207e-05, 3.8079e-06],
        [0.0000e+00, 2.0023e-05, 2.5110e-06],
        [0.0000e+00, 1.4314e-05, 2.8508e-06],
        [0.0000e+00, 1.7238e-05, 3.9153e-06],
        [0.0000e+00, 1.9273e-05, 3.7433e-06],
        [0.0000e+00, 1.8132e-05, 4.1120e-06],
        [0.0000e+00, 2.3906e-05, 4.8628e-06],
        [0.0000e+00, 3.1994e-05, 6.1621e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.1244e-05, 1.8630e-05, 1.7005e-05, 1.8198e-05, 1.4701e-05, 2.4233e-05,
        1.2239e-05, 2.5217e-05, 1.6038e-05, 2.1501e-05, 2.3507e-05, 2.2718e-05,
        2.2325e-05, 2.4724e-05, 1.6236e-05, 1.9677e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.2078e-06, 3.3680e-06, 2.7700e-06, 3.2637e-06, 2.2414e-06, 4.4020e-06,
        2.5370e-06, 2.6939e-06, 3.6568e-06, 4.4915e-06, 3.8775e-06, 4.8242e-06,
        4.3062e-06, 3.9766e-06, 3.7813e-06, 3.5898e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.1244e-05, 2.2078e-06],
        [0.0000e+00, 1.8630e-05, 3.3680e-06],
        [0.0000e+00, 1.7005e-05, 2.7700e-06],
        [0.0000e+00, 1.8198e-05, 3.2637e-06],
        [0.0000e+00, 1.4701e-05, 2.2414e-06],
        [0.0000e+00, 2.4233e-05, 4.4020e-06],
        [0.0000e+00, 1.2239e-05, 2.5370e-06],
        [0.0000e+00, 2.5217e-05, 2.6939e-06],
        [0.0000e+00, 1.6038e-05, 3.6568e-06],
        [0.0000e+00, 2.1501e-05, 4.4915e-06],
        [0.0000e+00, 2.3507e-05, 3.8775e-06],
        [0.0000e+00, 2.2718e-05, 4.8242e-06],
        [0.0000e+00, 2.2325e-05, 4.3062e-06],
        [0.0000e+00, 2.4724e-05, 3.9766e-06],
        [0.0000e+00, 1.6236e-05, 3.7813e-06],
        [0.0000e+00, 1.9677e-05, 3.5898e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.8084e-05, 1.9078e-05, 2.2350e-05, 1.8249e-05, 3.0771e-05, 1.5980e-05,
        1.7114e-05, 2.1681e-05, 2.8746e-05, 2.5078e-05, 1.3975e-05, 2.5612e-05,
        2.1809e-05, 2.3551e-05, 2.3218e-05, 2.1684e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.2798e-06, 2.9142e-06, 5.7100e-06, 3.3970e-06, 5.1836e-06, 3.6637e-06,
        4.5044e-06, 4.2133e-06, 4.6306e-06, 5.6662e-06, 3.4889e-06, 4.0957e-06,
        4.9694e-06, 5.2599e-06, 3.5122e-06, 3.5435e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.8084e-05, 2.2798e-06],
        [0.0000e+00, 1.9078e-05, 2.9142e-06],
        [0.0000e+00, 2.2350e-05, 5.7100e-06],
        [0.0000e+00, 1.8249e-05, 3.3970e-06],
        [0.0000e+00, 3.0771e-05, 5.1836e-06],
        [0.0000e+00, 1.5980e-05, 3.6637e-06],
        [0.0000e+00, 1.7114e-05, 4.5044e-06],
        [0.0000e+00, 2.1681e-05, 4.2133e-06],
        [0.0000e+00, 2.8746e-05, 4.6306e-06],
        [0.0000e+00, 2.5078e-05, 5.6662e-06],
        [0.0000e+00, 1.3975e-05, 3.4889e-06],
        [0.0000e+00, 2.5612e-05, 4.0957e-06],
        [0.0000e+00, 2.1809e-05, 4.9694e-06],
        [0.0000e+00, 2.3551e-05, 5.2599e-06],
        [0.0000e+00, 2.3218e-05, 3.5122e-06],
        [0.0000e+00, 2.1684e-05, 3.5435e-06]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type rare_synonyms, variation 2 and batchsize 16: 0:02:50.325971
path ['42', 'de', 'bloom', 'NLI', 'rare_synonyms', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m SA active 0 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:00<00:00,  8.58it/s]100%|██████████| 3/3 [00:00<00:00, 23.79it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2706e-05, 1.7682e-05, 1.6060e-05, 1.9820e-05, 1.2454e-05, 1.4004e-05,
        1.2929e-05, 1.7120e-05, 3.6641e-05, 2.4527e-05, 2.3471e-05, 2.4000e-05,
        1.9555e-05, 1.8419e-05, 2.3337e-05, 5.6594e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2706e-05],
        [0.0000e+00, 1.7682e-05],
        [0.0000e+00, 1.6060e-05],
        [0.0000e+00, 1.9820e-05],
        [0.0000e+00, 1.2454e-05],
        [0.0000e+00, 1.4004e-05],
        [0.0000e+00, 1.2929e-05],
        [0.0000e+00, 1.7120e-05],
        [0.0000e+00, 3.6641e-05],
        [0.0000e+00, 2.4527e-05],
        [0.0000e+00, 2.3471e-05],
        [0.0000e+00, 2.4000e-05],
        [0.0000e+00, 1.9555e-05],
        [0.0000e+00, 1.8419e-05],
        [0.0000e+00, 2.3337e-05],
        [0.0000e+00, 5.6594e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2313e-05, 2.1659e-05, 1.8426e-05, 5.0004e-05, 2.7439e-05, 1.9815e-05,
        2.2092e-05, 2.5729e-05, 2.2121e-05, 3.1804e-05, 2.7916e-05, 2.6144e-05,
        1.7206e-05, 1.6766e-05, 6.8210e-05, 2.1916e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2313e-05],
        [0.0000e+00, 2.1659e-05],
        [0.0000e+00, 1.8426e-05],
        [0.0000e+00, 5.0004e-05],
        [0.0000e+00, 2.7439e-05],
        [0.0000e+00, 1.9815e-05],
        [0.0000e+00, 2.2092e-05],
        [0.0000e+00, 2.5729e-05],
        [0.0000e+00, 2.2121e-05],
        [0.0000e+00, 3.1804e-05],
        [0.0000e+00, 2.7916e-05],
        [0.0000e+00, 2.6144e-05],
        [0.0000e+00, 1.7206e-05],
        [0.0000e+00, 1.6766e-05],
        [0.0000e+00, 6.8210e-05],
        [0.0000e+00, 2.1916e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.4156e-05, 2.8115e-05, 4.7625e-05, 5.6530e-05, 1.2786e-05, 3.3790e-05,
        2.3765e-05, 2.1024e-05, 2.0985e-05, 1.8200e-05, 1.1639e-05, 2.5059e-05,
        2.1427e-05, 2.2252e-05, 2.3651e-05, 2.6770e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.4156e-05],
        [0.0000e+00, 2.8115e-05],
        [0.0000e+00, 4.7625e-05],
        [0.0000e+00, 5.6530e-05],
        [0.0000e+00, 1.2786e-05],
        [0.0000e+00, 3.3790e-05],
        [0.0000e+00, 2.3765e-05],
        [0.0000e+00, 2.1024e-05],
        [0.0000e+00, 2.0985e-05],
        [0.0000e+00, 1.8200e-05],
        [0.0000e+00, 1.1639e-05],
        [0.0000e+00, 2.5059e-05],
        [0.0000e+00, 2.1427e-05],
        [0.0000e+00, 2.2252e-05],
        [0.0000e+00, 2.3651e-05],
        [0.0000e+00, 2.6770e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([2.2269e-05, 1.4594e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 2.2269e-05],
        [0.0000e+00, 1.4594e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type active, variation 0 and batchsize 16: 0:03:34.387184
path ['42', 'de', 'bloom', 'SA', 'active', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m SA active 1 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 297.14it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5515e-05, 2.4916e-05, 2.2083e-05, 2.4715e-05, 2.0121e-05, 1.7087e-05,
        2.4152e-05, 2.4006e-05, 1.6634e-05, 3.1507e-05, 1.3072e-05, 5.7419e-05,
        1.9113e-05, 1.4944e-05, 1.8748e-05, 2.1388e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5515e-05],
        [0.0000e+00, 2.4916e-05],
        [0.0000e+00, 2.2083e-05],
        [0.0000e+00, 2.4715e-05],
        [0.0000e+00, 2.0121e-05],
        [0.0000e+00, 1.7087e-05],
        [0.0000e+00, 2.4152e-05],
        [0.0000e+00, 2.4006e-05],
        [0.0000e+00, 1.6634e-05],
        [0.0000e+00, 3.1507e-05],
        [0.0000e+00, 1.3072e-05],
        [0.0000e+00, 5.7419e-05],
        [0.0000e+00, 1.9113e-05],
        [0.0000e+00, 1.4944e-05],
        [0.0000e+00, 1.8748e-05],
        [0.0000e+00, 2.1388e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.2423e-05, 2.0939e-05, 1.8371e-05, 2.1109e-05, 1.2725e-05, 2.4855e-05,
        2.2606e-05, 4.6828e-05, 2.1053e-05, 1.8553e-05, 2.4927e-05, 2.7188e-05,
        2.7013e-05, 3.4670e-05, 2.6361e-05, 2.3966e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.2423e-05],
        [0.0000e+00, 2.0939e-05],
        [0.0000e+00, 1.8371e-05],
        [0.0000e+00, 2.1109e-05],
        [0.0000e+00, 1.2725e-05],
        [0.0000e+00, 2.4855e-05],
        [0.0000e+00, 2.2606e-05],
        [0.0000e+00, 4.6828e-05],
        [0.0000e+00, 2.1053e-05],
        [0.0000e+00, 1.8553e-05],
        [0.0000e+00, 2.4927e-05],
        [0.0000e+00, 2.7188e-05],
        [0.0000e+00, 2.7013e-05],
        [0.0000e+00, 3.4670e-05],
        [0.0000e+00, 2.6361e-05],
        [0.0000e+00, 2.3966e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.3126e-05, 1.4299e-05, 2.1964e-05, 1.7895e-05, 2.1913e-05, 6.2740e-05,
        2.1842e-05, 2.0761e-05, 2.0378e-05, 1.3954e-05, 2.5672e-05, 2.4671e-05,
        2.1250e-05, 2.1374e-05, 5.3607e-05, 6.6808e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.3126e-05],
        [0.0000e+00, 1.4299e-05],
        [0.0000e+00, 2.1964e-05],
        [0.0000e+00, 1.7895e-05],
        [0.0000e+00, 2.1913e-05],
        [0.0000e+00, 6.2740e-05],
        [0.0000e+00, 2.1842e-05],
        [0.0000e+00, 2.0761e-05],
        [0.0000e+00, 2.0378e-05],
        [0.0000e+00, 1.3954e-05],
        [0.0000e+00, 2.5672e-05],
        [0.0000e+00, 2.4671e-05],
        [0.0000e+00, 2.1250e-05],
        [0.0000e+00, 2.1374e-05],
        [0.0000e+00, 5.3607e-05],
        [0.0000e+00, 6.6808e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.6359e-05, 2.5382e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.6359e-05],
        [0.0000e+00, 2.5382e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type active, variation 1 and batchsize 16: 0:03:35.156413
path ['42', 'de', 'bloom', 'SA', 'active', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m SA active 2 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 320.09it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.7015e-05, 1.3198e-05, 2.0917e-05, 2.4460e-05, 1.9637e-05, 1.9587e-05,
        2.6428e-05, 2.2013e-05, 5.3600e-05, 2.0943e-05, 2.3259e-05, 2.1336e-05,
        1.4058e-05, 3.1444e-05, 2.6628e-05, 2.7755e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.7015e-05],
        [0.0000e+00, 1.3198e-05],
        [0.0000e+00, 2.0917e-05],
        [0.0000e+00, 2.4460e-05],
        [0.0000e+00, 1.9637e-05],
        [0.0000e+00, 1.9587e-05],
        [0.0000e+00, 2.6428e-05],
        [0.0000e+00, 2.2013e-05],
        [0.0000e+00, 5.3600e-05],
        [0.0000e+00, 2.0943e-05],
        [0.0000e+00, 2.3259e-05],
        [0.0000e+00, 2.1336e-05],
        [0.0000e+00, 1.4058e-05],
        [0.0000e+00, 3.1444e-05],
        [0.0000e+00, 2.6628e-05],
        [0.0000e+00, 2.7755e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4940e-05, 1.2726e-05, 2.0193e-05, 1.4883e-05, 1.8644e-05, 2.4821e-05,
        3.5492e-05, 1.3340e-05, 2.0879e-05, 1.8683e-05, 2.0498e-05, 2.2647e-05,
        2.0241e-05, 1.6987e-05, 1.8587e-05, 1.3451e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4940e-05],
        [0.0000e+00, 1.2726e-05],
        [0.0000e+00, 2.0193e-05],
        [0.0000e+00, 1.4883e-05],
        [0.0000e+00, 1.8644e-05],
        [0.0000e+00, 2.4821e-05],
        [0.0000e+00, 3.5492e-05],
        [0.0000e+00, 1.3340e-05],
        [0.0000e+00, 2.0879e-05],
        [0.0000e+00, 1.8683e-05],
        [0.0000e+00, 2.0498e-05],
        [0.0000e+00, 2.2647e-05],
        [0.0000e+00, 2.0241e-05],
        [0.0000e+00, 1.6987e-05],
        [0.0000e+00, 1.8587e-05],
        [0.0000e+00, 1.3451e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.3319e-05, 6.8673e-05, 1.9459e-05, 2.1931e-05, 2.4567e-05, 2.6769e-05,
        1.5010e-05, 5.7207e-05, 2.5816e-05, 2.7773e-05, 2.4074e-05, 2.5588e-05,
        2.8958e-05, 6.2722e-05, 1.4620e-05, 2.4364e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.3319e-05],
        [0.0000e+00, 6.8673e-05],
        [0.0000e+00, 1.9459e-05],
        [0.0000e+00, 2.1931e-05],
        [0.0000e+00, 2.4567e-05],
        [0.0000e+00, 2.6769e-05],
        [0.0000e+00, 1.5010e-05],
        [0.0000e+00, 5.7207e-05],
        [0.0000e+00, 2.5816e-05],
        [0.0000e+00, 2.7773e-05],
        [0.0000e+00, 2.4074e-05],
        [0.0000e+00, 2.5588e-05],
        [0.0000e+00, 2.8958e-05],
        [0.0000e+00, 6.2722e-05],
        [0.0000e+00, 1.4620e-05],
        [0.0000e+00, 2.4364e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.8681e-05, 1.1689e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.8681e-05],
        [0.0000e+00, 1.1689e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type active, variation 2 and batchsize 16: 0:03:36.166333
path ['42', 'de', 'bloom', 'SA', 'active', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m SA passive 0 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 317.19it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4490e-05, 2.8172e-05, 2.2769e-05, 1.9253e-05, 2.8463e-05, 1.9177e-05,
        1.6993e-05, 2.1481e-05, 2.5673e-05, 2.0340e-05, 1.7215e-05, 1.7442e-05,
        7.8158e-05, 2.6549e-05, 6.5318e-05, 1.9864e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4490e-05],
        [0.0000e+00, 2.8172e-05],
        [0.0000e+00, 2.2769e-05],
        [0.0000e+00, 1.9253e-05],
        [0.0000e+00, 2.8463e-05],
        [0.0000e+00, 1.9177e-05],
        [0.0000e+00, 1.6993e-05],
        [0.0000e+00, 2.1481e-05],
        [0.0000e+00, 2.5673e-05],
        [0.0000e+00, 2.0340e-05],
        [0.0000e+00, 1.7215e-05],
        [0.0000e+00, 1.7442e-05],
        [0.0000e+00, 7.8158e-05],
        [0.0000e+00, 2.6549e-05],
        [0.0000e+00, 6.5318e-05],
        [0.0000e+00, 1.9864e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4546e-05, 2.1863e-05, 3.0560e-05, 4.9956e-05, 5.9684e-05, 2.3987e-05,
        2.9427e-05, 1.2430e-05, 1.9365e-05, 2.3450e-05, 2.7544e-05, 2.5767e-05,
        1.4530e-05, 2.1455e-05, 3.0274e-05, 2.8201e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4546e-05],
        [0.0000e+00, 2.1863e-05],
        [0.0000e+00, 3.0560e-05],
        [0.0000e+00, 4.9956e-05],
        [0.0000e+00, 5.9684e-05],
        [0.0000e+00, 2.3987e-05],
        [0.0000e+00, 2.9427e-05],
        [0.0000e+00, 1.2430e-05],
        [0.0000e+00, 1.9365e-05],
        [0.0000e+00, 2.3450e-05],
        [0.0000e+00, 2.7544e-05],
        [0.0000e+00, 2.5767e-05],
        [0.0000e+00, 1.4530e-05],
        [0.0000e+00, 2.1455e-05],
        [0.0000e+00, 3.0274e-05],
        [0.0000e+00, 2.8201e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4792e-05, 2.2446e-05, 1.3297e-05, 3.2193e-05, 2.1201e-05, 1.9842e-05,
        1.3486e-05, 2.1645e-05, 1.3260e-05, 2.0053e-05, 2.6834e-05, 1.4469e-05,
        1.3541e-05, 3.3673e-05, 5.7407e-05, 2.1380e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4792e-05],
        [0.0000e+00, 2.2446e-05],
        [0.0000e+00, 1.3297e-05],
        [0.0000e+00, 3.2193e-05],
        [0.0000e+00, 2.1201e-05],
        [0.0000e+00, 1.9842e-05],
        [0.0000e+00, 1.3486e-05],
        [0.0000e+00, 2.1645e-05],
        [0.0000e+00, 1.3260e-05],
        [0.0000e+00, 2.0053e-05],
        [0.0000e+00, 2.6834e-05],
        [0.0000e+00, 1.4469e-05],
        [0.0000e+00, 1.3541e-05],
        [0.0000e+00, 3.3673e-05],
        [0.0000e+00, 5.7407e-05],
        [0.0000e+00, 2.1380e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([2.0708e-05, 2.4066e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 2.0708e-05],
        [0.0000e+00, 2.4066e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type passive, variation 0 and batchsize 16: 0:03:05.626560
path ['42', 'de', 'bloom', 'SA', 'passive', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m SA passive 1 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 324.52it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5328e-05, 2.7650e-05, 2.8421e-05, 2.6126e-05, 2.7737e-05, 2.2420e-05,
        4.9424e-05, 3.0178e-05, 2.1858e-05, 2.3999e-05, 3.5474e-05, 3.1212e-05,
        1.3862e-05, 2.2291e-05, 2.6690e-05, 2.3076e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5328e-05],
        [0.0000e+00, 2.7650e-05],
        [0.0000e+00, 2.8421e-05],
        [0.0000e+00, 2.6126e-05],
        [0.0000e+00, 2.7737e-05],
        [0.0000e+00, 2.2420e-05],
        [0.0000e+00, 4.9424e-05],
        [0.0000e+00, 3.0178e-05],
        [0.0000e+00, 2.1858e-05],
        [0.0000e+00, 2.3999e-05],
        [0.0000e+00, 3.5474e-05],
        [0.0000e+00, 3.1212e-05],
        [0.0000e+00, 1.3862e-05],
        [0.0000e+00, 2.2291e-05],
        [0.0000e+00, 2.6690e-05],
        [0.0000e+00, 2.3076e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([8.4440e-05, 1.5709e-05, 1.5439e-05, 1.6528e-05, 2.6394e-05, 2.4717e-05,
        3.6514e-05, 3.3562e-05, 2.2668e-05, 1.7633e-05, 2.5165e-05, 1.2251e-05,
        2.3531e-05, 1.8705e-05, 2.4781e-05, 2.8923e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 8.4440e-05],
        [0.0000e+00, 1.5709e-05],
        [0.0000e+00, 1.5439e-05],
        [0.0000e+00, 1.6528e-05],
        [0.0000e+00, 2.6394e-05],
        [0.0000e+00, 2.4717e-05],
        [0.0000e+00, 3.6514e-05],
        [0.0000e+00, 3.3562e-05],
        [0.0000e+00, 2.2668e-05],
        [0.0000e+00, 1.7633e-05],
        [0.0000e+00, 2.5165e-05],
        [0.0000e+00, 1.2251e-05],
        [0.0000e+00, 2.3531e-05],
        [0.0000e+00, 1.8705e-05],
        [0.0000e+00, 2.4781e-05],
        [0.0000e+00, 2.8923e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5187e-05, 2.8869e-05, 1.9028e-05, 6.8219e-05, 2.5469e-05, 2.8408e-05,
        2.8319e-05, 2.0571e-05, 1.8860e-05, 6.2540e-05, 2.5689e-05, 5.7078e-05,
        1.3179e-05, 1.7875e-05, 2.2924e-05, 2.5800e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5187e-05],
        [0.0000e+00, 2.8869e-05],
        [0.0000e+00, 1.9028e-05],
        [0.0000e+00, 6.8219e-05],
        [0.0000e+00, 2.5469e-05],
        [0.0000e+00, 2.8408e-05],
        [0.0000e+00, 2.8319e-05],
        [0.0000e+00, 2.0571e-05],
        [0.0000e+00, 1.8860e-05],
        [0.0000e+00, 6.2540e-05],
        [0.0000e+00, 2.5689e-05],
        [0.0000e+00, 5.7078e-05],
        [0.0000e+00, 1.3179e-05],
        [0.0000e+00, 1.7875e-05],
        [0.0000e+00, 2.2924e-05],
        [0.0000e+00, 2.5800e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([2.8920e-05, 1.8949e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 2.8920e-05],
        [0.0000e+00, 1.8949e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type passive, variation 1 and batchsize 16: 0:03:05.265213
path ['42', 'de', 'bloom', 'SA', 'passive', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m SA passive 2 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 356.85it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4390e-05, 1.0202e-04, 2.4027e-05, 2.7333e-05, 1.7483e-05, 2.7371e-05,
        2.1568e-05, 3.3536e-05, 1.5236e-05, 2.2638e-05, 3.9731e-05, 2.0272e-05,
        3.5021e-05, 2.7730e-05, 5.8556e-05, 2.0555e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4390e-05],
        [0.0000e+00, 1.0202e-04],
        [0.0000e+00, 2.4027e-05],
        [0.0000e+00, 2.7333e-05],
        [0.0000e+00, 1.7483e-05],
        [0.0000e+00, 2.7371e-05],
        [0.0000e+00, 2.1568e-05],
        [0.0000e+00, 3.3536e-05],
        [0.0000e+00, 1.5236e-05],
        [0.0000e+00, 2.2638e-05],
        [0.0000e+00, 3.9731e-05],
        [0.0000e+00, 2.0272e-05],
        [0.0000e+00, 3.5021e-05],
        [0.0000e+00, 2.7730e-05],
        [0.0000e+00, 5.8556e-05],
        [0.0000e+00, 2.0555e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5407e-05, 2.6056e-05, 2.8979e-05, 2.0338e-05, 1.7252e-05, 2.1124e-05,
        2.0040e-05, 2.5549e-05, 5.5998e-05, 2.0158e-05, 2.4874e-05, 2.1187e-05,
        2.0742e-05, 2.5644e-05, 1.6799e-05, 1.3192e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5407e-05],
        [0.0000e+00, 2.6056e-05],
        [0.0000e+00, 2.8979e-05],
        [0.0000e+00, 2.0338e-05],
        [0.0000e+00, 1.7252e-05],
        [0.0000e+00, 2.1124e-05],
        [0.0000e+00, 2.0040e-05],
        [0.0000e+00, 2.5549e-05],
        [0.0000e+00, 5.5998e-05],
        [0.0000e+00, 2.0158e-05],
        [0.0000e+00, 2.4874e-05],
        [0.0000e+00, 2.1187e-05],
        [0.0000e+00, 2.0742e-05],
        [0.0000e+00, 2.5644e-05],
        [0.0000e+00, 1.6799e-05],
        [0.0000e+00, 1.3192e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.8744e-05, 2.3147e-05, 6.4227e-05, 1.6160e-05, 1.8002e-05, 2.6628e-05,
        1.2029e-05, 1.1828e-05, 3.1172e-05, 2.7042e-05, 5.8399e-05, 2.3540e-05,
        2.1697e-05, 1.2865e-05, 2.4271e-05, 2.0347e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.8744e-05],
        [0.0000e+00, 2.3147e-05],
        [0.0000e+00, 6.4227e-05],
        [0.0000e+00, 1.6160e-05],
        [0.0000e+00, 1.8002e-05],
        [0.0000e+00, 2.6628e-05],
        [0.0000e+00, 1.2029e-05],
        [0.0000e+00, 1.1828e-05],
        [0.0000e+00, 3.1172e-05],
        [0.0000e+00, 2.7042e-05],
        [0.0000e+00, 5.8399e-05],
        [0.0000e+00, 2.3540e-05],
        [0.0000e+00, 2.1697e-05],
        [0.0000e+00, 1.2865e-05],
        [0.0000e+00, 2.4271e-05],
        [0.0000e+00, 2.0347e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.3432e-05, 2.3274e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.3432e-05],
        [0.0000e+00, 2.3274e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type passive, variation 2 and batchsize 16: 0:03:02.937897
path ['42', 'de', 'bloom', 'SA', 'passive', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m SA auxiliary 0 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 348.04it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.2549e-05, 2.0197e-05, 2.8467e-05, 5.2361e-05, 2.3274e-05, 2.7711e-05,
        1.7165e-05, 6.6571e-05, 3.1493e-05, 3.6483e-05, 2.8131e-05, 2.2475e-05,
        2.8550e-05, 2.4449e-05, 1.9258e-05, 2.9149e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.2549e-05],
        [0.0000e+00, 2.0197e-05],
        [0.0000e+00, 2.8467e-05],
        [0.0000e+00, 5.2361e-05],
        [0.0000e+00, 2.3274e-05],
        [0.0000e+00, 2.7711e-05],
        [0.0000e+00, 1.7165e-05],
        [0.0000e+00, 6.6571e-05],
        [0.0000e+00, 3.1493e-05],
        [0.0000e+00, 3.6483e-05],
        [0.0000e+00, 2.8131e-05],
        [0.0000e+00, 2.2475e-05],
        [0.0000e+00, 2.8550e-05],
        [0.0000e+00, 2.4449e-05],
        [0.0000e+00, 1.9258e-05],
        [0.0000e+00, 2.9149e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.8631e-05, 2.4274e-05, 2.6538e-05, 2.3646e-05, 1.1442e-05, 1.5233e-05,
        5.3772e-05, 2.3166e-05, 2.4999e-05, 1.2523e-05, 2.3127e-05, 2.2500e-05,
        2.4389e-05, 2.7273e-05, 1.5568e-05, 3.0466e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.8631e-05],
        [0.0000e+00, 2.4274e-05],
        [0.0000e+00, 2.6538e-05],
        [0.0000e+00, 2.3646e-05],
        [0.0000e+00, 1.1442e-05],
        [0.0000e+00, 1.5233e-05],
        [0.0000e+00, 5.3772e-05],
        [0.0000e+00, 2.3166e-05],
        [0.0000e+00, 2.4999e-05],
        [0.0000e+00, 1.2523e-05],
        [0.0000e+00, 2.3127e-05],
        [0.0000e+00, 2.2500e-05],
        [0.0000e+00, 2.4389e-05],
        [0.0000e+00, 2.7273e-05],
        [0.0000e+00, 1.5568e-05],
        [0.0000e+00, 3.0466e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([8.5998e-05, 2.1799e-05, 1.5499e-05, 2.5117e-05, 2.1905e-05, 2.3232e-05,
        2.7404e-05, 2.7374e-05, 3.3891e-05, 2.7078e-05, 2.1834e-05, 1.6417e-05,
        1.8484e-05, 2.7221e-05, 6.0221e-05, 2.8443e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 8.5998e-05],
        [0.0000e+00, 2.1799e-05],
        [0.0000e+00, 1.5499e-05],
        [0.0000e+00, 2.5117e-05],
        [0.0000e+00, 2.1905e-05],
        [0.0000e+00, 2.3232e-05],
        [0.0000e+00, 2.7404e-05],
        [0.0000e+00, 2.7374e-05],
        [0.0000e+00, 3.3891e-05],
        [0.0000e+00, 2.7078e-05],
        [0.0000e+00, 2.1834e-05],
        [0.0000e+00, 1.6417e-05],
        [0.0000e+00, 1.8484e-05],
        [0.0000e+00, 2.7221e-05],
        [0.0000e+00, 6.0221e-05],
        [0.0000e+00, 2.8443e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.7900e-05, 1.6984e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.7900e-05],
        [0.0000e+00, 1.6984e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type auxiliary, variation 0 and batchsize 16: 0:03:03.503291
path ['42', 'de', 'bloom', 'SA', 'auxiliary', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m SA auxiliary 1 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 368.54it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([6.1910e-05, 2.8508e-05, 2.1855e-05, 1.4318e-05, 2.8169e-05, 2.0651e-05,
        1.5825e-05, 2.9093e-05, 1.9066e-05, 1.7690e-05, 2.4624e-05, 2.8297e-05,
        5.0357e-05, 1.7001e-05, 2.6515e-05, 1.8519e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 6.1910e-05],
        [0.0000e+00, 2.8508e-05],
        [0.0000e+00, 2.1855e-05],
        [0.0000e+00, 1.4318e-05],
        [0.0000e+00, 2.8169e-05],
        [0.0000e+00, 2.0651e-05],
        [0.0000e+00, 1.5825e-05],
        [0.0000e+00, 2.9093e-05],
        [0.0000e+00, 1.9066e-05],
        [0.0000e+00, 1.7690e-05],
        [0.0000e+00, 2.4624e-05],
        [0.0000e+00, 2.8297e-05],
        [0.0000e+00, 5.0357e-05],
        [0.0000e+00, 1.7001e-05],
        [0.0000e+00, 2.6515e-05],
        [0.0000e+00, 1.8519e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.3245e-05, 1.2908e-05, 1.7963e-05, 2.3089e-05, 2.1112e-05, 3.6195e-05,
        2.8772e-05, 2.4287e-05, 1.2493e-05, 3.4080e-05, 8.5022e-05, 2.2311e-05,
        2.2172e-05, 2.7010e-05, 6.4331e-05, 2.1012e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.3245e-05],
        [0.0000e+00, 1.2908e-05],
        [0.0000e+00, 1.7963e-05],
        [0.0000e+00, 2.3089e-05],
        [0.0000e+00, 2.1112e-05],
        [0.0000e+00, 3.6195e-05],
        [0.0000e+00, 2.8772e-05],
        [0.0000e+00, 2.4287e-05],
        [0.0000e+00, 1.2493e-05],
        [0.0000e+00, 3.4080e-05],
        [0.0000e+00, 8.5022e-05],
        [0.0000e+00, 2.2311e-05],
        [0.0000e+00, 2.2172e-05],
        [0.0000e+00, 2.7010e-05],
        [0.0000e+00, 6.4331e-05],
        [0.0000e+00, 2.1012e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.8999e-05, 2.8640e-05, 2.1923e-05, 2.8616e-05, 2.3362e-05, 2.3159e-05,
        2.9210e-05, 2.1302e-05, 2.3665e-05, 2.3608e-05, 2.5039e-05, 1.4424e-05,
        2.1025e-05, 2.6342e-05, 2.5586e-05, 3.3731e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.8999e-05],
        [0.0000e+00, 2.8640e-05],
        [0.0000e+00, 2.1923e-05],
        [0.0000e+00, 2.8616e-05],
        [0.0000e+00, 2.3362e-05],
        [0.0000e+00, 2.3159e-05],
        [0.0000e+00, 2.9210e-05],
        [0.0000e+00, 2.1302e-05],
        [0.0000e+00, 2.3665e-05],
        [0.0000e+00, 2.3608e-05],
        [0.0000e+00, 2.5039e-05],
        [0.0000e+00, 1.4424e-05],
        [0.0000e+00, 2.1025e-05],
        [0.0000e+00, 2.6342e-05],
        [0.0000e+00, 2.5586e-05],
        [0.0000e+00, 3.3731e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([2.7828e-05, 6.3897e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 2.7828e-05],
        [0.0000e+00, 6.3897e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type auxiliary, variation 1 and batchsize 16: 0:03:03.179646
path ['42', 'de', 'bloom', 'SA', 'auxiliary', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m SA auxiliary 2 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 342.88it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2061e-05, 3.0467e-05, 2.8464e-05, 2.3819e-05, 1.8443e-05, 2.6132e-05,
        3.4602e-05, 1.1840e-05, 2.9322e-05, 2.9099e-05, 1.2523e-05, 2.3311e-05,
        9.3951e-05, 6.1932e-05, 2.8614e-05, 2.5313e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2061e-05],
        [0.0000e+00, 3.0467e-05],
        [0.0000e+00, 2.8464e-05],
        [0.0000e+00, 2.3819e-05],
        [0.0000e+00, 1.8443e-05],
        [0.0000e+00, 2.6132e-05],
        [0.0000e+00, 3.4602e-05],
        [0.0000e+00, 1.1840e-05],
        [0.0000e+00, 2.9322e-05],
        [0.0000e+00, 2.9099e-05],
        [0.0000e+00, 1.2523e-05],
        [0.0000e+00, 2.3311e-05],
        [0.0000e+00, 9.3951e-05],
        [0.0000e+00, 6.1932e-05],
        [0.0000e+00, 2.8614e-05],
        [0.0000e+00, 2.5313e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.8378e-05, 2.4453e-05, 2.7952e-05, 2.9595e-05, 6.0032e-05, 3.6628e-05,
        5.6254e-05, 2.9002e-05, 2.7511e-05, 2.6130e-05, 2.3295e-05, 6.6525e-05,
        3.6156e-05, 2.0397e-05, 2.4931e-05, 3.1194e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.8378e-05],
        [0.0000e+00, 2.4453e-05],
        [0.0000e+00, 2.7952e-05],
        [0.0000e+00, 2.9595e-05],
        [0.0000e+00, 6.0032e-05],
        [0.0000e+00, 3.6628e-05],
        [0.0000e+00, 5.6254e-05],
        [0.0000e+00, 2.9002e-05],
        [0.0000e+00, 2.7511e-05],
        [0.0000e+00, 2.6130e-05],
        [0.0000e+00, 2.3295e-05],
        [0.0000e+00, 6.6525e-05],
        [0.0000e+00, 3.6156e-05],
        [0.0000e+00, 2.0397e-05],
        [0.0000e+00, 2.4931e-05],
        [0.0000e+00, 3.1194e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.1046e-05, 2.4615e-05, 1.6563e-05, 3.0840e-05, 1.6047e-05, 1.5263e-05,
        1.7883e-05, 3.1178e-05, 2.2362e-05, 1.2068e-05, 2.3564e-05, 2.3972e-05,
        1.6928e-05, 1.7731e-05, 2.3728e-05, 2.6228e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.1046e-05],
        [0.0000e+00, 2.4615e-05],
        [0.0000e+00, 1.6563e-05],
        [0.0000e+00, 3.0840e-05],
        [0.0000e+00, 1.6047e-05],
        [0.0000e+00, 1.5263e-05],
        [0.0000e+00, 1.7883e-05],
        [0.0000e+00, 3.1178e-05],
        [0.0000e+00, 2.2362e-05],
        [0.0000e+00, 1.2068e-05],
        [0.0000e+00, 2.3564e-05],
        [0.0000e+00, 2.3972e-05],
        [0.0000e+00, 1.6928e-05],
        [0.0000e+00, 1.7731e-05],
        [0.0000e+00, 2.3728e-05],
        [0.0000e+00, 2.6228e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([3.3387e-05, 1.9601e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 3.3387e-05],
        [0.0000e+00, 1.9601e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type auxiliary, variation 2 and batchsize 16: 0:03:03.504069
path ['42', 'de', 'bloom', 'SA', 'auxiliary', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m SA modal 0 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 190.44it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.8413e-05, 1.9983e-05, 2.2230e-05, 2.2037e-05, 4.9212e-05, 2.2262e-05,
        2.4573e-05, 2.8772e-05, 2.8441e-05, 3.3314e-05, 8.1837e-05, 2.0736e-05,
        5.9954e-05, 1.2109e-05, 2.1630e-05, 1.9550e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.8413e-05],
        [0.0000e+00, 1.9983e-05],
        [0.0000e+00, 2.2230e-05],
        [0.0000e+00, 2.2037e-05],
        [0.0000e+00, 4.9212e-05],
        [0.0000e+00, 2.2262e-05],
        [0.0000e+00, 2.4573e-05],
        [0.0000e+00, 2.8772e-05],
        [0.0000e+00, 2.8441e-05],
        [0.0000e+00, 3.3314e-05],
        [0.0000e+00, 8.1837e-05],
        [0.0000e+00, 2.0736e-05],
        [0.0000e+00, 5.9954e-05],
        [0.0000e+00, 1.2109e-05],
        [0.0000e+00, 2.1630e-05],
        [0.0000e+00, 1.9550e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.4696e-05, 2.5781e-05, 2.7111e-05, 2.3708e-05, 2.2504e-05, 2.5662e-05,
        2.6645e-05, 1.4059e-05, 2.8171e-05, 2.3443e-05, 2.3429e-05, 1.2739e-05,
        2.1502e-05, 1.9135e-05, 3.5621e-05, 3.0539e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.4696e-05],
        [0.0000e+00, 2.5781e-05],
        [0.0000e+00, 2.7111e-05],
        [0.0000e+00, 2.3708e-05],
        [0.0000e+00, 2.2504e-05],
        [0.0000e+00, 2.5662e-05],
        [0.0000e+00, 2.6645e-05],
        [0.0000e+00, 1.4059e-05],
        [0.0000e+00, 2.8171e-05],
        [0.0000e+00, 2.3443e-05],
        [0.0000e+00, 2.3429e-05],
        [0.0000e+00, 1.2739e-05],
        [0.0000e+00, 2.1502e-05],
        [0.0000e+00, 1.9135e-05],
        [0.0000e+00, 3.5621e-05],
        [0.0000e+00, 3.0539e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([6.2945e-05, 3.2322e-05, 1.8992e-05, 1.8554e-05, 2.2050e-05, 2.6543e-05,
        2.2171e-05, 1.2838e-05, 1.7092e-05, 2.7758e-05, 1.4296e-05, 2.4786e-05,
        6.0142e-05, 1.6932e-05, 2.1581e-05, 2.9322e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 6.2945e-05],
        [0.0000e+00, 3.2322e-05],
        [0.0000e+00, 1.8992e-05],
        [0.0000e+00, 1.8554e-05],
        [0.0000e+00, 2.2050e-05],
        [0.0000e+00, 2.6543e-05],
        [0.0000e+00, 2.2171e-05],
        [0.0000e+00, 1.2838e-05],
        [0.0000e+00, 1.7092e-05],
        [0.0000e+00, 2.7758e-05],
        [0.0000e+00, 1.4296e-05],
        [0.0000e+00, 2.4786e-05],
        [0.0000e+00, 6.0142e-05],
        [0.0000e+00, 1.6932e-05],
        [0.0000e+00, 2.1581e-05],
        [0.0000e+00, 2.9322e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([2.2808e-05, 1.5816e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 2.2808e-05],
        [0.0000e+00, 1.5816e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type modal, variation 0 and batchsize 16: 0:03:24.781767
path ['42', 'de', 'bloom', 'SA', 'modal', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m SA modal 1 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 329.02it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.7721e-05, 2.6330e-05, 1.7804e-05, 2.3129e-05, 2.1338e-05, 2.1180e-05,
        2.0780e-05, 7.5108e-05, 6.5508e-05, 3.2421e-05, 2.6109e-05, 2.6670e-05,
        6.1298e-05, 2.5800e-05, 1.1971e-05, 2.1757e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.7721e-05],
        [0.0000e+00, 2.6330e-05],
        [0.0000e+00, 1.7804e-05],
        [0.0000e+00, 2.3129e-05],
        [0.0000e+00, 2.1338e-05],
        [0.0000e+00, 2.1180e-05],
        [0.0000e+00, 2.0780e-05],
        [0.0000e+00, 7.5108e-05],
        [0.0000e+00, 6.5508e-05],
        [0.0000e+00, 3.2421e-05],
        [0.0000e+00, 2.6109e-05],
        [0.0000e+00, 2.6670e-05],
        [0.0000e+00, 6.1298e-05],
        [0.0000e+00, 2.5800e-05],
        [0.0000e+00, 1.1971e-05],
        [0.0000e+00, 2.1757e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.1547e-05, 1.6636e-05, 1.8878e-05, 2.5403e-05, 2.1441e-05, 1.2623e-05,
        1.4604e-05, 1.4937e-05, 1.1700e-05, 1.3648e-05, 2.1315e-05, 2.8582e-05,
        2.3998e-05, 4.8474e-05, 3.0009e-05, 2.2426e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.1547e-05],
        [0.0000e+00, 1.6636e-05],
        [0.0000e+00, 1.8878e-05],
        [0.0000e+00, 2.5403e-05],
        [0.0000e+00, 2.1441e-05],
        [0.0000e+00, 1.2623e-05],
        [0.0000e+00, 1.4604e-05],
        [0.0000e+00, 1.4937e-05],
        [0.0000e+00, 1.1700e-05],
        [0.0000e+00, 1.3648e-05],
        [0.0000e+00, 2.1315e-05],
        [0.0000e+00, 2.8582e-05],
        [0.0000e+00, 2.3998e-05],
        [0.0000e+00, 4.8474e-05],
        [0.0000e+00, 3.0009e-05],
        [0.0000e+00, 2.2426e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.7747e-05, 1.6436e-05, 2.4432e-05, 3.7272e-05, 6.5068e-05, 2.1199e-05,
        2.1343e-05, 1.8963e-05, 2.7938e-05, 2.2559e-05, 2.4767e-05, 2.7802e-05,
        2.5103e-05, 1.9890e-05, 2.0600e-05, 1.6058e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.7747e-05],
        [0.0000e+00, 1.6436e-05],
        [0.0000e+00, 2.4432e-05],
        [0.0000e+00, 3.7272e-05],
        [0.0000e+00, 6.5068e-05],
        [0.0000e+00, 2.1199e-05],
        [0.0000e+00, 2.1343e-05],
        [0.0000e+00, 1.8963e-05],
        [0.0000e+00, 2.7938e-05],
        [0.0000e+00, 2.2559e-05],
        [0.0000e+00, 2.4767e-05],
        [0.0000e+00, 2.7802e-05],
        [0.0000e+00, 2.5103e-05],
        [0.0000e+00, 1.9890e-05],
        [0.0000e+00, 2.0600e-05],
        [0.0000e+00, 1.6058e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([2.3743e-05, 2.9421e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 2.3743e-05],
        [0.0000e+00, 2.9421e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type modal, variation 1 and batchsize 16: 0:03:32.040941
path ['42', 'de', 'bloom', 'SA', 'modal', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m SA modal 2 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 334.75it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.7750e-05, 2.1428e-05, 1.9180e-05, 2.0949e-05, 1.6150e-05, 1.6735e-05,
        1.2355e-05, 8.6103e-05, 2.2437e-05, 2.8009e-05, 6.6927e-05, 1.7368e-05,
        2.1392e-05, 2.6837e-05, 3.0515e-05, 5.1355e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.7750e-05],
        [0.0000e+00, 2.1428e-05],
        [0.0000e+00, 1.9180e-05],
        [0.0000e+00, 2.0949e-05],
        [0.0000e+00, 1.6150e-05],
        [0.0000e+00, 1.6735e-05],
        [0.0000e+00, 1.2355e-05],
        [0.0000e+00, 8.6103e-05],
        [0.0000e+00, 2.2437e-05],
        [0.0000e+00, 2.8009e-05],
        [0.0000e+00, 6.6927e-05],
        [0.0000e+00, 1.7368e-05],
        [0.0000e+00, 2.1392e-05],
        [0.0000e+00, 2.6837e-05],
        [0.0000e+00, 3.0515e-05],
        [0.0000e+00, 5.1355e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.7284e-05, 2.2400e-05, 2.5687e-05, 2.1598e-05, 6.1722e-05, 2.2009e-05,
        2.7931e-05, 3.2728e-05, 1.4825e-05, 2.7649e-05, 1.8747e-05, 1.6258e-05,
        2.4504e-05, 2.4242e-05, 2.8716e-05, 1.7063e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.7284e-05],
        [0.0000e+00, 2.2400e-05],
        [0.0000e+00, 2.5687e-05],
        [0.0000e+00, 2.1598e-05],
        [0.0000e+00, 6.1722e-05],
        [0.0000e+00, 2.2009e-05],
        [0.0000e+00, 2.7931e-05],
        [0.0000e+00, 3.2728e-05],
        [0.0000e+00, 1.4825e-05],
        [0.0000e+00, 2.7649e-05],
        [0.0000e+00, 1.8747e-05],
        [0.0000e+00, 1.6258e-05],
        [0.0000e+00, 2.4504e-05],
        [0.0000e+00, 2.4242e-05],
        [0.0000e+00, 2.8716e-05],
        [0.0000e+00, 1.7063e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.3553e-05, 1.1834e-05, 2.9227e-05, 3.5417e-05, 2.3577e-05, 2.6453e-05,
        2.7113e-05, 2.2152e-05, 1.2657e-05, 2.3270e-05, 2.6419e-05, 2.9015e-05,
        2.5119e-05, 2.2179e-05, 2.7701e-05, 3.4604e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.3553e-05],
        [0.0000e+00, 1.1834e-05],
        [0.0000e+00, 2.9227e-05],
        [0.0000e+00, 3.5417e-05],
        [0.0000e+00, 2.3577e-05],
        [0.0000e+00, 2.6453e-05],
        [0.0000e+00, 2.7113e-05],
        [0.0000e+00, 2.2152e-05],
        [0.0000e+00, 1.2657e-05],
        [0.0000e+00, 2.3270e-05],
        [0.0000e+00, 2.6419e-05],
        [0.0000e+00, 2.9015e-05],
        [0.0000e+00, 2.5119e-05],
        [0.0000e+00, 2.2179e-05],
        [0.0000e+00, 2.7701e-05],
        [0.0000e+00, 3.4604e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.4574e-05, 5.9568e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.4574e-05],
        [0.0000e+00, 5.9568e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type modal, variation 2 and batchsize 16: 0:03:30.566032
path ['42', 'de', 'bloom', 'SA', 'modal', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloom-560m SA rare_synonyms 0 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 318.57it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.2288e-05, 2.7350e-05, 1.2515e-05, 2.7630e-05, 3.5106e-05, 2.7847e-05,
        2.5877e-05, 2.5133e-05, 2.8386e-05, 1.5644e-05, 2.0492e-05, 1.7523e-05,
        1.4809e-05, 2.1391e-05, 1.9769e-05, 2.9093e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.2288e-05],
        [0.0000e+00, 2.7350e-05],
        [0.0000e+00, 1.2515e-05],
        [0.0000e+00, 2.7630e-05],
        [0.0000e+00, 3.5106e-05],
        [0.0000e+00, 2.7847e-05],
        [0.0000e+00, 2.5877e-05],
        [0.0000e+00, 2.5133e-05],
        [0.0000e+00, 2.8386e-05],
        [0.0000e+00, 1.5644e-05],
        [0.0000e+00, 2.0492e-05],
        [0.0000e+00, 1.7523e-05],
        [0.0000e+00, 1.4809e-05],
        [0.0000e+00, 2.1391e-05],
        [0.0000e+00, 1.9769e-05],
        [0.0000e+00, 2.9093e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5913e-05, 2.0303e-05, 6.1531e-05, 1.8902e-05, 3.5833e-05, 2.2450e-05,
        2.2603e-05, 1.9287e-05, 2.4881e-05, 2.3554e-05, 1.6673e-05, 5.0079e-05,
        2.2765e-05, 5.6261e-05, 2.2251e-05, 2.4534e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5913e-05],
        [0.0000e+00, 2.0303e-05],
        [0.0000e+00, 6.1531e-05],
        [0.0000e+00, 1.8902e-05],
        [0.0000e+00, 3.5833e-05],
        [0.0000e+00, 2.2450e-05],
        [0.0000e+00, 2.2603e-05],
        [0.0000e+00, 1.9287e-05],
        [0.0000e+00, 2.4881e-05],
        [0.0000e+00, 2.3554e-05],
        [0.0000e+00, 1.6673e-05],
        [0.0000e+00, 5.0079e-05],
        [0.0000e+00, 2.2765e-05],
        [0.0000e+00, 5.6261e-05],
        [0.0000e+00, 2.2251e-05],
        [0.0000e+00, 2.4534e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.3327e-05, 2.3209e-05, 2.7466e-05, 1.2543e-05, 3.0115e-05, 7.1424e-05,
        2.8397e-05, 2.2018e-05, 2.3920e-05, 2.4210e-05, 2.3064e-05, 2.2529e-05,
        1.4037e-05, 1.3190e-05, 3.4451e-05, 6.7911e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.3327e-05],
        [0.0000e+00, 2.3209e-05],
        [0.0000e+00, 2.7466e-05],
        [0.0000e+00, 1.2543e-05],
        [0.0000e+00, 3.0115e-05],
        [0.0000e+00, 7.1424e-05],
        [0.0000e+00, 2.8397e-05],
        [0.0000e+00, 2.2018e-05],
        [0.0000e+00, 2.3920e-05],
        [0.0000e+00, 2.4210e-05],
        [0.0000e+00, 2.3064e-05],
        [0.0000e+00, 2.2529e-05],
        [0.0000e+00, 1.4037e-05],
        [0.0000e+00, 1.3190e-05],
        [0.0000e+00, 3.4451e-05],
        [0.0000e+00, 6.7911e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([2.9649e-05, 1.7011e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 2.9649e-05],
        [0.0000e+00, 1.7011e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type rare_synonyms, variation 0 and batchsize 16: 0:03:04.579542
path ['42', 'de', 'bloom', 'SA', 'rare_synonyms', 'prompt_id_0']
----------- 42 de bigscience/bloom-560m SA rare_synonyms 1 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 368.54it/s]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2389e-05, 2.7957e-05, 2.4228e-05, 2.0500e-05, 2.1779e-05, 2.2634e-05,
        4.8123e-05, 1.8620e-05, 1.1452e-05, 2.2371e-05, 1.6530e-05, 2.8547e-05,
        6.2645e-05, 1.2053e-05, 3.2406e-05, 2.2745e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2389e-05],
        [0.0000e+00, 2.7957e-05],
        [0.0000e+00, 2.4228e-05],
        [0.0000e+00, 2.0500e-05],
        [0.0000e+00, 2.1779e-05],
        [0.0000e+00, 2.2634e-05],
        [0.0000e+00, 4.8123e-05],
        [0.0000e+00, 1.8620e-05],
        [0.0000e+00, 1.1452e-05],
        [0.0000e+00, 2.2371e-05],
        [0.0000e+00, 1.6530e-05],
        [0.0000e+00, 2.8547e-05],
        [0.0000e+00, 6.2645e-05],
        [0.0000e+00, 1.2053e-05],
        [0.0000e+00, 3.2406e-05],
        [0.0000e+00, 2.2745e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.1393e-05, 2.0493e-05, 7.8279e-05, 2.6233e-05, 2.8066e-05, 5.4505e-05,
        6.0182e-05, 2.7096e-05, 1.2989e-05, 3.2829e-05, 2.3498e-05, 2.8235e-05,
        2.4954e-05, 2.7170e-05, 1.4939e-05, 2.8894e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.1393e-05],
        [0.0000e+00, 2.0493e-05],
        [0.0000e+00, 7.8279e-05],
        [0.0000e+00, 2.6233e-05],
        [0.0000e+00, 2.8066e-05],
        [0.0000e+00, 5.4505e-05],
        [0.0000e+00, 6.0182e-05],
        [0.0000e+00, 2.7096e-05],
        [0.0000e+00, 1.2989e-05],
        [0.0000e+00, 3.2829e-05],
        [0.0000e+00, 2.3498e-05],
        [0.0000e+00, 2.8235e-05],
        [0.0000e+00, 2.4954e-05],
        [0.0000e+00, 2.7170e-05],
        [0.0000e+00, 1.4939e-05],
        [0.0000e+00, 2.8894e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2420e-05, 2.1160e-05, 1.3012e-05, 3.3422e-05, 1.4176e-05, 2.1463e-05,
        1.8605e-05, 2.3149e-05, 2.5051e-05, 2.1286e-05, 1.8979e-05, 2.7833e-05,
        1.8622e-05, 2.0421e-05, 2.4848e-05, 2.1716e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2420e-05],
        [0.0000e+00, 2.1160e-05],
        [0.0000e+00, 1.3012e-05],
        [0.0000e+00, 3.3422e-05],
        [0.0000e+00, 1.4176e-05],
        [0.0000e+00, 2.1463e-05],
        [0.0000e+00, 1.8605e-05],
        [0.0000e+00, 2.3149e-05],
        [0.0000e+00, 2.5051e-05],
        [0.0000e+00, 2.1286e-05],
        [0.0000e+00, 1.8979e-05],
        [0.0000e+00, 2.7833e-05],
        [0.0000e+00, 1.8622e-05],
        [0.0000e+00, 2.0421e-05],
        [0.0000e+00, 2.4848e-05],
        [0.0000e+00, 2.1716e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([1.5757e-05, 1.6373e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 1.5757e-05],
        [0.0000e+00, 1.6373e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type rare_synonyms, variation 1 and batchsize 16: 0:03:05.733519
path ['42', 'de', 'bloom', 'SA', 'rare_synonyms', 'prompt_id_1']
----------- 42 de bigscience/bloom-560m SA rare_synonyms 2 50 16 --------------
Loading MARC dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 364.85it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
MARC dataset loaded
Average length of review_body for rows with 1 star: 199.5979
Average length of review_body for rows with 5 star: 177.19965
len of lowest cat:  38908
len of pos_reviews, neg_reviews:  38908 38908
len dataset  77816
len dataset  50
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.5675e-05, 3.5077e-05, 1.3657e-05, 3.1712e-05, 2.3627e-05, 2.8349e-05,
        1.3879e-05, 2.9362e-05, 2.6826e-05, 2.4788e-05, 6.5518e-05, 3.5926e-05,
        1.7167e-05, 2.3741e-05, 2.1387e-05, 1.7371e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.5675e-05],
        [0.0000e+00, 3.5077e-05],
        [0.0000e+00, 1.3657e-05],
        [0.0000e+00, 3.1712e-05],
        [0.0000e+00, 2.3627e-05],
        [0.0000e+00, 2.8349e-05],
        [0.0000e+00, 1.3879e-05],
        [0.0000e+00, 2.9362e-05],
        [0.0000e+00, 2.6826e-05],
        [0.0000e+00, 2.4788e-05],
        [0.0000e+00, 6.5518e-05],
        [0.0000e+00, 3.5926e-05],
        [0.0000e+00, 1.7167e-05],
        [0.0000e+00, 2.3741e-05],
        [0.0000e+00, 2.1387e-05],
        [0.0000e+00, 1.7371e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.8806e-05, 2.3069e-05, 2.1328e-05, 7.7430e-05, 2.1745e-05, 2.1731e-05,
        2.2590e-05, 2.7616e-05, 1.4008e-05, 1.9007e-05, 2.4818e-05, 2.3403e-05,
        2.2389e-05, 1.9762e-05, 2.1836e-05, 6.1073e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.8806e-05],
        [0.0000e+00, 2.3069e-05],
        [0.0000e+00, 2.1328e-05],
        [0.0000e+00, 7.7430e-05],
        [0.0000e+00, 2.1745e-05],
        [0.0000e+00, 2.1731e-05],
        [0.0000e+00, 2.2590e-05],
        [0.0000e+00, 2.7616e-05],
        [0.0000e+00, 1.4008e-05],
        [0.0000e+00, 1.9007e-05],
        [0.0000e+00, 2.4818e-05],
        [0.0000e+00, 2.3403e-05],
        [0.0000e+00, 2.2389e-05],
        [0.0000e+00, 1.9762e-05],
        [0.0000e+00, 2.1836e-05],
        [0.0000e+00, 6.1073e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([5.0420e-05, 2.1136e-05, 1.7821e-05, 2.5127e-05, 2.2060e-05, 2.7407e-05,
        2.2483e-05, 1.2991e-05, 1.2930e-05, 5.9119e-05, 2.8530e-05, 2.7384e-05,
        2.3359e-05, 1.5949e-05, 2.0113e-05, 3.3461e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 5.0420e-05],
        [0.0000e+00, 2.1136e-05],
        [0.0000e+00, 1.7821e-05],
        [0.0000e+00, 2.5127e-05],
        [0.0000e+00, 2.2060e-05],
        [0.0000e+00, 2.7407e-05],
        [0.0000e+00, 2.2483e-05],
        [0.0000e+00, 1.2991e-05],
        [0.0000e+00, 1.2930e-05],
        [0.0000e+00, 5.9119e-05],
        [0.0000e+00, 2.8530e-05],
        [0.0000e+00, 2.7384e-05],
        [0.0000e+00, 2.3359e-05],
        [0.0000e+00, 1.5949e-05],
        [0.0000e+00, 2.0113e-05],
        [0.0000e+00, 3.3461e-05]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([2])
id: [951, 265] -> tensor([2.8131e-05, 1.8620e-05], device='cuda:0'), torch.Size([2])
answers_probs: tensor([[0.0000e+00, 2.8131e-05],
        [0.0000e+00, 1.8620e-05]], device='cuda:0')
acc:  0.5
Time taken to execute the de SA task with prompt type rare_synonyms, variation 2 and batchsize 16: 0:03:03.006557
path ['42', 'de', 'bloom', 'SA', 'rare_synonyms', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
Loading model bigscience/bloomz-560m
Model bigscience/bloomz-560m loaded
Available device is cuda
Model device: cuda:0
----------- 42 de bigscience/bloomz-560m NLI active 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 249.07it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.5025e-05, 4.7392e-05, 2.4046e-05, 5.1849e-05, 2.8388e-05, 4.7323e-05,
        2.6766e-05, 2.4734e-05, 3.8608e-05, 6.7009e-05, 7.0322e-05, 4.0016e-05,
        6.6206e-05, 3.8182e-05, 3.3618e-05, 2.1718e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.2497e-04, 1.4632e-04, 8.0017e-05, 4.1346e-04, 9.5687e-05, 2.8334e-04,
        1.9372e-04, 1.0591e-04, 1.0305e-04, 1.4303e-04, 3.3944e-04, 1.4118e-04,
        1.5913e-04, 1.1451e-04, 1.0209e-04, 6.4951e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.5025e-05, 1.2497e-04],
        [0.0000e+00, 4.7392e-05, 1.4632e-04],
        [0.0000e+00, 2.4046e-05, 8.0017e-05],
        [0.0000e+00, 5.1849e-05, 4.1346e-04],
        [0.0000e+00, 2.8388e-05, 9.5687e-05],
        [0.0000e+00, 4.7323e-05, 2.8334e-04],
        [0.0000e+00, 2.6766e-05, 1.9372e-04],
        [0.0000e+00, 2.4734e-05, 1.0591e-04],
        [0.0000e+00, 3.8608e-05, 1.0305e-04],
        [0.0000e+00, 6.7009e-05, 1.4303e-04],
        [0.0000e+00, 7.0322e-05, 3.3944e-04],
        [0.0000e+00, 4.0016e-05, 1.4118e-04],
        [0.0000e+00, 6.6206e-05, 1.5913e-04],
        [0.0000e+00, 3.8182e-05, 1.1451e-04],
        [0.0000e+00, 3.3618e-05, 1.0209e-04],
        [0.0000e+00, 2.1718e-05, 6.4951e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([3.6421e-05, 1.4955e-05, 4.5157e-05, 4.4392e-05, 6.9602e-05, 3.1879e-05,
        4.1508e-05, 5.0271e-05, 2.3855e-05, 2.6144e-05, 5.1309e-05, 2.0681e-05,
        6.1782e-05, 2.1482e-05, 3.8165e-05, 3.2649e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.3468e-04, 6.4291e-05, 1.2275e-04, 1.6108e-04, 3.1297e-04, 1.0548e-04,
        1.8417e-04, 1.5432e-04, 2.1359e-04, 4.4238e-05, 1.9754e-04, 9.8900e-05,
        2.5099e-04, 7.6373e-05, 7.4666e-05, 1.6841e-04], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 3.6421e-05, 1.3468e-04],
        [0.0000e+00, 1.4955e-05, 6.4291e-05],
        [0.0000e+00, 4.5157e-05, 1.2275e-04],
        [0.0000e+00, 4.4392e-05, 1.6108e-04],
        [0.0000e+00, 6.9602e-05, 3.1297e-04],
        [0.0000e+00, 3.1879e-05, 1.0548e-04],
        [0.0000e+00, 4.1508e-05, 1.8417e-04],
        [0.0000e+00, 5.0271e-05, 1.5432e-04],
        [0.0000e+00, 2.3855e-05, 2.1359e-04],
        [0.0000e+00, 2.6144e-05, 4.4238e-05],
        [0.0000e+00, 5.1309e-05, 1.9754e-04],
        [0.0000e+00, 2.0681e-05, 9.8900e-05],
        [0.0000e+00, 6.1782e-05, 2.5099e-04],
        [0.0000e+00, 2.1482e-05, 7.6373e-05],
        [0.0000e+00, 3.8165e-05, 7.4666e-05],
        [0.0000e+00, 3.2649e-05, 1.6841e-04]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([2.2304e-05, 2.7013e-05, 5.1057e-05, 3.4465e-05, 2.0336e-05, 3.6277e-05,
        2.7931e-05, 2.4114e-05, 2.8867e-05, 7.6784e-05, 6.8368e-05, 2.3914e-05,
        2.0080e-05, 3.0272e-05, 3.1405e-05, 2.1279e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.0006e-04, 5.7145e-05, 7.5370e-05, 2.1930e-04, 3.6196e-05, 1.5435e-04,
        7.7608e-05, 8.1218e-05, 9.0445e-05, 2.7706e-04, 2.8666e-04, 9.0616e-05,
        3.8383e-05, 8.9898e-05, 6.8089e-05, 1.1627e-04], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 2.2304e-05, 1.0006e-04],
        [0.0000e+00, 2.7013e-05, 5.7145e-05],
        [0.0000e+00, 5.1057e-05, 7.5370e-05],
        [0.0000e+00, 3.4465e-05, 2.1930e-04],
        [0.0000e+00, 2.0336e-05, 3.6196e-05],
        [0.0000e+00, 3.6277e-05, 1.5435e-04],
        [0.0000e+00, 2.7931e-05, 7.7608e-05],
        [0.0000e+00, 2.4114e-05, 8.1218e-05],
        [0.0000e+00, 2.8867e-05, 9.0445e-05],
        [0.0000e+00, 7.6784e-05, 2.7706e-04],
        [0.0000e+00, 6.8368e-05, 2.8666e-04],
        [0.0000e+00, 2.3914e-05, 9.0616e-05],
        [0.0000e+00, 2.0080e-05, 3.8383e-05],
        [0.0000e+00, 3.0272e-05, 8.9898e-05],
        [0.0000e+00, 3.1405e-05, 6.8089e-05],
        [0.0000e+00, 2.1279e-05, 1.1627e-04]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type active, variation 0 and batchsize 16: 0:02:57.594020
path ['42', 'de', 'bloomz', 'NLI', 'active', 'prompt_id_0']
----------- 42 de bigscience/bloomz-560m NLI active 1 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 318.99it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.9442e-05, 2.4934e-05, 3.1432e-05, 1.5838e-05, 1.6455e-05, 2.9631e-05,
        3.6294e-05, 7.2688e-05, 1.9956e-05, 1.4667e-05, 2.8619e-05, 4.8148e-05,
        4.9597e-05, 3.0903e-05, 1.4529e-05, 7.3504e-06], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([3.9295e-05, 2.5739e-05, 3.2333e-05, 2.1326e-05, 1.7890e-05, 1.0808e-04,
        2.9774e-05, 5.3970e-05, 2.4908e-05, 5.5715e-05, 6.9741e-05, 2.1039e-05,
        4.2935e-05, 9.1602e-05, 8.7820e-06, 9.8396e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.9442e-05, 3.9295e-05],
        [0.0000e+00, 2.4934e-05, 2.5739e-05],
        [0.0000e+00, 3.1432e-05, 3.2333e-05],
        [0.0000e+00, 1.5838e-05, 2.1326e-05],
        [0.0000e+00, 1.6455e-05, 1.7890e-05],
        [0.0000e+00, 2.9631e-05, 1.0808e-04],
        [0.0000e+00, 3.6294e-05, 2.9774e-05],
        [0.0000e+00, 7.2688e-05, 5.3970e-05],
        [0.0000e+00, 1.9956e-05, 2.4908e-05],
        [0.0000e+00, 1.4667e-05, 5.5715e-05],
        [0.0000e+00, 2.8619e-05, 6.9741e-05],
        [0.0000e+00, 4.8148e-05, 2.1039e-05],
        [0.0000e+00, 4.9597e-05, 4.2935e-05],
        [0.0000e+00, 3.0903e-05, 9.1602e-05],
        [0.0000e+00, 1.4529e-05, 8.7820e-06],
        [0.0000e+00, 7.3504e-06, 9.8396e-06]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.1012e-05, 2.1974e-05, 4.6448e-05, 2.2712e-05, 3.9655e-05, 5.1871e-05,
        3.1494e-05, 2.8985e-05, 1.5118e-05, 2.2849e-05, 3.7928e-05, 3.5308e-05,
        2.5637e-05, 3.7051e-05, 2.4486e-05, 1.6069e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([8.1989e-05, 3.1536e-05, 5.5046e-05, 1.3018e-05, 4.1141e-05, 4.3007e-05,
        5.3915e-05, 6.9189e-05, 2.4469e-05, 2.9405e-05, 4.2536e-05, 4.6433e-05,
        2.1275e-05, 2.9409e-05, 2.3469e-05, 2.6376e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.1012e-05, 8.1989e-05],
        [0.0000e+00, 2.1974e-05, 3.1536e-05],
        [0.0000e+00, 4.6448e-05, 5.5046e-05],
        [0.0000e+00, 2.2712e-05, 1.3018e-05],
        [0.0000e+00, 3.9655e-05, 4.1141e-05],
        [0.0000e+00, 5.1871e-05, 4.3007e-05],
        [0.0000e+00, 3.1494e-05, 5.3915e-05],
        [0.0000e+00, 2.8985e-05, 6.9189e-05],
        [0.0000e+00, 1.5118e-05, 2.4469e-05],
        [0.0000e+00, 2.2849e-05, 2.9405e-05],
        [0.0000e+00, 3.7928e-05, 4.2536e-05],
        [0.0000e+00, 3.5308e-05, 4.6433e-05],
        [0.0000e+00, 2.5637e-05, 2.1275e-05],
        [0.0000e+00, 3.7051e-05, 2.9409e-05],
        [0.0000e+00, 2.4486e-05, 2.3469e-05],
        [0.0000e+00, 1.6069e-05, 2.6376e-05]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([1.4229e-05, 3.9192e-05, 4.3417e-05, 1.6144e-05, 2.6371e-05, 4.9879e-05,
        4.3541e-05, 2.8316e-05, 3.1026e-05, 2.7391e-05, 1.9579e-05, 5.5494e-05,
        3.1757e-05, 4.0745e-05, 5.1691e-05, 2.8611e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([2.8506e-05, 7.1259e-05, 4.4077e-05, 4.8167e-05, 3.1268e-05, 3.1801e-05,
        5.8109e-05, 2.7967e-05, 2.7949e-05, 2.8974e-05, 2.7483e-05, 1.0282e-04,
        2.3651e-05, 5.3702e-05, 5.7998e-05, 5.3995e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 1.4229e-05, 2.8506e-05],
        [0.0000e+00, 3.9192e-05, 7.1259e-05],
        [0.0000e+00, 4.3417e-05, 4.4077e-05],
        [0.0000e+00, 1.6144e-05, 4.8167e-05],
        [0.0000e+00, 2.6371e-05, 3.1268e-05],
        [0.0000e+00, 4.9879e-05, 3.1801e-05],
        [0.0000e+00, 4.3541e-05, 5.8109e-05],
        [0.0000e+00, 2.8316e-05, 2.7967e-05],
        [0.0000e+00, 3.1026e-05, 2.7949e-05],
        [0.0000e+00, 2.7391e-05, 2.8974e-05],
        [0.0000e+00, 1.9579e-05, 2.7483e-05],
        [0.0000e+00, 5.5494e-05, 1.0282e-04],
        [0.0000e+00, 3.1757e-05, 2.3651e-05],
        [0.0000e+00, 4.0745e-05, 5.3702e-05],
        [0.0000e+00, 5.1691e-05, 5.7998e-05],
        [0.0000e+00, 2.8611e-05, 5.3995e-05]], device='cuda:0')
acc:  0.3541666666666667
Time taken to execute the de NLI task with prompt type active, variation 1 and batchsize 16: 0:02:51.324080
path ['42', 'de', 'bloomz', 'NLI', 'active', 'prompt_id_1']
----------- 42 de bigscience/bloomz-560m NLI active 2 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 293.68it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/de/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  16 16 16
len dataset  48
Batch: 0 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([8.1046e-05, 7.5760e-05, 6.5852e-05, 3.5942e-05, 8.6767e-05, 1.7750e-04,
        6.1409e-05, 8.5796e-05, 3.4098e-05, 1.1429e-04, 8.7067e-05, 8.2021e-05,
        6.7319e-05, 7.4284e-05, 7.2504e-05, 1.4633e-04], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([1.8245e-05, 9.0865e-06, 1.0341e-05, 4.9005e-06, 1.0709e-05, 2.1010e-05,
        6.7680e-06, 9.7113e-06, 2.1479e-06, 1.2765e-05, 8.4478e-06, 7.0572e-06,
        8.1360e-06, 8.6859e-06, 1.2117e-05, 1.4724e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 8.1046e-05, 1.8245e-05],
        [0.0000e+00, 7.5760e-05, 9.0865e-06],
        [0.0000e+00, 6.5852e-05, 1.0341e-05],
        [0.0000e+00, 3.5942e-05, 4.9005e-06],
        [0.0000e+00, 8.6767e-05, 1.0709e-05],
        [0.0000e+00, 1.7750e-04, 2.1010e-05],
        [0.0000e+00, 6.1409e-05, 6.7680e-06],
        [0.0000e+00, 8.5796e-05, 9.7113e-06],
        [0.0000e+00, 3.4098e-05, 2.1479e-06],
        [0.0000e+00, 1.1429e-04, 1.2765e-05],
        [0.0000e+00, 8.7067e-05, 8.4478e-06],
        [0.0000e+00, 8.2021e-05, 7.0572e-06],
        [0.0000e+00, 6.7319e-05, 8.1360e-06],
        [0.0000e+00, 7.4284e-05, 8.6859e-06],
        [0.0000e+00, 7.2504e-05, 1.2117e-05],
        [0.0000e+00, 1.4633e-04, 1.4724e-05]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([5.9982e-05, 9.9596e-05, 4.1971e-05, 7.1919e-05, 3.1262e-05, 1.2355e-04,
        8.1515e-05, 5.9547e-05, 7.0556e-05, 7.5469e-05, 5.1424e-05, 7.2508e-05,
        4.8347e-05, 6.5257e-05, 4.8315e-05, 3.4677e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([4.4501e-06, 6.5183e-06, 5.1787e-06, 4.6795e-06, 6.6841e-06, 9.7156e-06,
        7.2648e-06, 6.3247e-06, 1.0854e-05, 1.1674e-05, 1.0522e-05, 7.5698e-06,
        3.6300e-06, 5.4124e-06, 5.9659e-06, 8.7564e-06], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 5.9982e-05, 4.4501e-06],
        [0.0000e+00, 9.9596e-05, 6.5183e-06],
        [0.0000e+00, 4.1971e-05, 5.1787e-06],
        [0.0000e+00, 7.1919e-05, 4.6795e-06],
        [0.0000e+00, 3.1262e-05, 6.6841e-06],
        [0.0000e+00, 1.2355e-04, 9.7156e-06],
        [0.0000e+00, 8.1515e-05, 7.2648e-06],
        [0.0000e+00, 5.9547e-05, 6.3247e-06],
        [0.0000e+00, 7.0556e-05, 1.0854e-05],
        [0.0000e+00, 7.5469e-05, 1.1674e-05],
        [0.0000e+00, 5.1424e-05, 1.0522e-05],
        [0.0000e+00, 7.2508e-05, 7.5698e-06],
        [0.0000e+00, 4.8347e-05, 3.6300e-06],
        [0.0000e+00, 6.5257e-05, 5.4124e-06],
        [0.0000e+00, 4.8315e-05, 5.9659e-06],
        [0.0000e+00, 3.4677e-05, 8.7564e-06]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 50
answer  {'input_ids': [1650], 'attention_mask': [1]}
answer  {'input_ids': [951, 265], 'attention_mask': [1, 1]}
probs_ shape torch.Size([16])
id: [951, 265] -> tensor([4.9351e-05, 3.0595e-05, 8.5685e-05, 3.8382e-05, 5.3507e-05, 9.7347e-05,
        6.7282e-05, 5.2940e-05, 7.0701e-05, 3.3744e-05, 5.5705e-05, 3.3889e-05,
        5.4890e-05, 6.0313e-05, 1.0722e-04, 9.7466e-05], device='cuda:0'), torch.Size([16])
answer  {'input_ids': [89, 25898, 18508], 'attention_mask': [1, 1, 1]}
probs_ shape torch.Size([16])
id: [89, 25898, 18508] -> tensor([6.2989e-06, 5.1009e-06, 8.5881e-06, 2.8882e-06, 5.8804e-06, 8.8748e-06,
        6.4849e-06, 6.7231e-06, 1.6267e-05, 3.0569e-06, 6.7149e-06, 1.9005e-05,
        5.8851e-06, 1.0273e-05, 7.4662e-06, 1.8480e-05], device='cuda:0'), torch.Size([16])
answers_probs: tensor([[0.0000e+00, 4.9351e-05, 6.2989e-06],
        [0.0000e+00, 3.0595e-05, 5.1009e-06],
        [0.0000e+00, 8.5685e-05, 8.5881e-06],
        [0.0000e+00, 3.8382e-05, 2.8882e-06],
        [0.0000e+00, 5.3507e-05, 5.8804e-06],
        [0.0000e+00, 9.7347e-05, 8.8748e-06],
        [0.0000e+00, 6.7282e-05, 6.4849e-06],
        [0.0000e+00, 5.2940e-05, 6.7231e-06],
        [0.0000e+00, 7.0701e-05, 1.6267e-05],
        [0.0000e+00, 3.3744e-05, 3.0569e-06],
        [0.0000e+00, 5.5705e-05, 6.7149e-06],
        [0.0000e+00, 3.3889e-05, 1.9005e-05],
        [0.0000e+00, 5.4890e-05, 5.8851e-06],
        [0.0000e+00, 6.0313e-05, 1.0273e-05],
        [0.0000e+00, 1.0722e-04, 7.4662e-06],
        [0.0000e+00, 9.7466e-05, 1.8480e-05]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the de NLI task with prompt type active, variation 2 and batchsize 16: 0:02:40.759473
path ['42', 'de', 'bloomz', 'NLI', 'active', 'prompt_id_2']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_de_v3.pickle' as a pickle file.
----------- 42 de bigscience/bloomz-560m NLI passive 0 50 16 --------------
Loading NLI dataset for de
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 192.73it/s]
