----------- llama NLI --------------
pad token added
Loading model huggyllama/llama-7b
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.85s/it]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
Model huggyllama/llama-7b loaded
Moving model to cuda
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:00<00:00,  6.09it/s]100%|██████████| 3/3 [00:00<00:00, 17.42it/s]
NLI dataset loaded
len dataset  200
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [1, 4874], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 4874] -> [4874]
answer  {'input_ids': [1, 694], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 694] -> [694]
answer  {'input_ids': [1, 5505], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 5505] -> [5505]
Logits saved to saved_logits/huggyllama/llama-7b__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'no', 'yes', 'yes', 'no', 'maybe', 'no', 'maybe', 'maybe', 'maybe', 'yes', 'maybe', 'no', 'maybe', 'maybe', 'no')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [1, 4874], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 4874] -> [4874]
answer  {'input_ids': [1, 694], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 694] -> [694]
answer  {'input_ids': [1, 5505], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 5505] -> [5505]
Logits saved to saved_logits/huggyllama/llama-7b__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'no', 'maybe', 'maybe', 'no', 'maybe', 'yes', 'no', 'maybe', 'maybe', 'no', 'yes', 'no', 'no', 'no', 'yes')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [1, 4874], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 4874] -> [4874]
answer  {'input_ids': [1, 694], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 694] -> [694]
answer  {'input_ids': [1, 5505], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 5505] -> [5505]
Logits saved to saved_logits/huggyllama/llama-7b__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'maybe', 'maybe', 'yes', 'no', 'yes', 'no')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [1, 4874], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 4874] -> [4874]
answer  {'input_ids': [1, 694], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 694] -> [694]
answer  {'input_ids': [1, 5505], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 5505] -> [5505]
Logits saved to saved_logits/huggyllama/llama-7b__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('maybe', 'maybe', 'yes', 'yes', 'yes', 'maybe', 'maybe', 'yes', 'maybe', 'no', 'no', 'no', 'no', 'maybe', 'maybe', 'maybe')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [1, 4874], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 4874] -> [4874]
answer  {'input_ids': [1, 694], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 694] -> [694]
answer  {'input_ids': [1, 5505], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 5505] -> [5505]
Logits saved to saved_logits/huggyllama/llama-7b__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('yes', 'maybe', 'yes', 'maybe', 'maybe', 'yes', 'no', 'yes', 'maybe', 'maybe', 'maybe', 'no', 'maybe', 'maybe', 'maybe', 'no')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [1, 4874], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 4874] -> [4874]
answer  {'input_ids': [1, 694], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 694] -> [694]
answer  {'input_ids': [1, 5505], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 5505] -> [5505]
Logits saved to saved_logits/huggyllama/llama-7b__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'no', 'yes', 'yes', 'yes', 'no', 'maybe', 'maybe', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'maybe')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [1, 4874], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 4874] -> [4874]
answer  {'input_ids': [1, 694], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 694] -> [694]
answer  {'input_ids': [1, 5505], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 5505] -> [5505]
Logits saved to saved_logits/huggyllama/llama-7b__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('maybe', 'maybe', 'yes', 'no', 'maybe', 'maybe', 'maybe', 'maybe', 'maybe', 'yes', 'no', 'yes', 'maybe', 'yes', 'maybe', 'no')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [1, 4874], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 4874] -> [4874]
answer  {'input_ids': [1, 694], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 694] -> [694]
answer  {'input_ids': [1, 5505], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 5505] -> [5505]
Logits saved to saved_logits/huggyllama/llama-7b__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'maybe', 'yes', 'no', 'no')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [1, 4874], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 4874] -> [4874]
answer  {'input_ids': [1, 694], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 694] -> [694]
answer  {'input_ids': [1, 5505], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 5505] -> [5505]
Logits saved to saved_logits/huggyllama/llama-7b__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('maybe', 'no', 'yes', 'maybe', 'no', 'yes', 'maybe', 'no', 'no', 'no', 'maybe', 'yes', 'yes', 'yes', 'no', 'yes')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [1, 4874], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 4874] -> [4874]
answer  {'input_ids': [1, 694], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 694] -> [694]
answer  {'input_ids': [1, 5505], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 5505] -> [5505]
Logits saved to saved_logits/huggyllama/llama-7b__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'maybe', 'maybe', 'maybe', 'no', 'no', 'maybe', 'no', 'no', 'maybe', 'maybe', 'maybe', 'no', 'maybe', 'no', 'no')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [1, 4874], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 4874] -> [4874]
answer  {'input_ids': [1, 694], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 694] -> [694]
answer  {'input_ids': [1, 5505], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 5505] -> [5505]
Logits saved to saved_logits/huggyllama/llama-7b__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'maybe', 'maybe', 'yes', 'yes', 'maybe', 'maybe')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [1, 4874], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 4874] -> [4874]
answer  {'input_ids': [1, 694], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 694] -> [694]
answer  {'input_ids': [1, 5505], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 5505] -> [5505]
Logits saved to saved_logits/huggyllama/llama-7b__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('maybe', 'maybe', 'maybe', 'no', 'no', 'no', 'maybe', 'no', 'maybe', 'yes', 'yes', 'maybe', 'yes', 'yes', 'no', 'yes')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [1, 4874], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 4874] -> [4874]
answer  {'input_ids': [1, 694], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 694] -> [694]
answer  {'input_ids': [1, 5505], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}
id: [1, 5505] -> [5505]
Logits saved to saved_logits/huggyllama/llama-7b__NLI__8.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('yes', 'maybe', 'maybe', 'no', 'yes', 'no', 'no', 'maybe')
acc:  0.285
