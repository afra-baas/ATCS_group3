Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/fr/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
****Start Time: 2023-05-23_21-22-57
Using MARC dataset for fr
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:00<00:00,  9.49it/s]100%|██████████| 3/3 [00:00<00:00, 26.44it/s]
loading model Duraction: 0:00:01.247528
Average length of review_body for rows with 1 star: 155.920675
Average length of review_body for rows with 5 star: 144.119575
len of lowest cat:  39333
len of pos_reviews, neg_reviews:  39333 39333
len dataset  78666
len dataset  200
create dataloader Duraction: 0:03:07.849460
Loading model bigscience/bloom-560m
Model bigscience/bloom-560m loaded
Available device is cuda
Model device: cuda:0
answer  {'input_ids': [92000], 'attention_mask': [1]}
id:[92000]
answer  {'input_ids': [25490], 'attention_mask': [1]}
id:[25490]
load model Duraction: 0:00:10.429266
----------- 42 fr bigscience/bloom-560m SA active 0 200 64 --------------
Batch: 0 , batch size: 64, sample_size: 200
filling in prompts labelsDuraction: 0:00:00.000155
mapping labels Duraction: 0:00:00.000008
Traceback (most recent call last):
  File "/home/lcur1101/ATCS_group3/src/main.py", line 199, in <module>
    pipeline(seed, lang, models, tasks, prompt_types,
  File "/home/lcur1101/ATCS_group3/src/main.py", line 152, in pipeline
    logits_dict_for_prompt = get_prompt_acc(
  File "/home/lcur1101/ATCS_group3/src/main.py", line 64, in get_prompt_acc
    answers_probs_batch, pred_answer_batch = LM(prompts)
  File "/home/lcur1101/ATCS_group3/src/models/model.py", line 94, in __call__
    outputs = self.model(**inputs, labels=inputs["input_ids"])
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/transformers/models/bloom/modeling_bloom.py", line 938, in forward
    loss = loss_fct(
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.82 GiB (GPU 0; 23.65 GiB total capacity; 17.17 GiB already allocated; 5.50 GiB free; 17.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
srun: error: r28n2: task 0: Exited with exit code 1
