Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
****Start Time: 2023-06-01_19-21-39
Using MARC dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 284.53it/s]
loading model Duration: 0:00:01.313492
Average length of review_body for rows with 1 star: 170.985525
Average length of review_body for rows with 5 star: 151.0092
len of lowest cat:  38553
len of pos_reviews, neg_reviews:  38553 38553
len dataset  77106
len dataset  200
create dataloader Duration: 0:03:06.927643
Loading model bigscience/bloom-7b1
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.43s/it]
Model bigscience/bloom-7b1 loaded
Available device is cuda
Model device: cuda:0
possible_answers: ['A', 'B']
answer  {'input_ids': [36], 'attention_mask': [1]}
id:[36]
answer  {'input_ids': [37], 'attention_mask': [1]}
id:[37]
summ of probs approach
load model Duration: 0:04:45.658995
prompt_type active has 10 prompts in it
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([87, 2])
answers_probs just softmax dim 0: tensor([[0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115]], device='cuda:0')
tensor([[0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA active 0 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0005, 0.0007],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0004],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0007],
        [0.0004, 0.0007],
        [0.0008, 0.0013],
        [0.0004, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0643, 0.0606],
        [0.0668, 0.0583],
        [0.0577, 0.0675],
        [0.0578, 0.0674],
        [0.0656, 0.0595],
        [0.0602, 0.0647],
        [0.0600, 0.0649],
        [0.0635, 0.0614],
        [0.0626, 0.0623],
        [0.0633, 0.0616],
        [0.0591, 0.0660],
        [0.0631, 0.0617],
        [0.0647, 0.0602],
        [0.0619, 0.0630],
        [0.0624, 0.0624],
        [0.0668, 0.0583]], device='cuda:0')
 Batch: 0 of active classification Duration: 0:00:00.541202
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0003, 0.0003],
        [0.0004, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0006, 0.0007],
        [0.0008, 0.0008],
        [0.0005, 0.0006],
        [0.0003, 0.0006],
        [0.0007, 0.0011],
        [0.0005, 0.0010],
        [0.0002, 0.0003],
        [0.0005, 0.0007],
        [0.0007, 0.0010],
        [0.0006, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0596, 0.0654],
        [0.0651, 0.0599],
        [0.0666, 0.0585],
        [0.0595, 0.0655],
        [0.0599, 0.0650],
        [0.0568, 0.0685],
        [0.0647, 0.0602],
        [0.0676, 0.0576],
        [0.0659, 0.0591],
        [0.0599, 0.0650],
        [0.0620, 0.0628],
        [0.0594, 0.0656],
        [0.0616, 0.0633],
        [0.0618, 0.0630],
        [0.0626, 0.0622],
        [0.0670, 0.0582]], device='cuda:0')
 Batch: 1 of active classification Duration: 0:00:00.330902
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0004, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0003],
        [0.0004, 0.0010],
        [0.0003, 0.0006],
        [0.0006, 0.0011],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0005, 0.0007],
        [0.0002, 0.0005],
        [0.0002, 0.0006],
        [0.0004, 0.0007],
        [0.0008, 0.0014],
        [0.0005, 0.0007],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0653, 0.0597],
        [0.0666, 0.0586],
        [0.0583, 0.0669],
        [0.0605, 0.0644],
        [0.0578, 0.0674],
        [0.0624, 0.0625],
        [0.0620, 0.0629],
        [0.0659, 0.0591],
        [0.0633, 0.0616],
        [0.0646, 0.0604],
        [0.0601, 0.0649],
        [0.0590, 0.0661],
        [0.0635, 0.0614],
        [0.0628, 0.0621],
        [0.0664, 0.0587],
        [0.0616, 0.0633]], device='cuda:0')
 Batch: 2 of active classification Duration: 0:00:00.345336
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0007, 0.0011],
        [0.0003, 0.0006],
        [0.0004, 0.0004],
        [0.0002, 0.0002],
        [0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0005, 0.0006],
        [0.0004, 0.0006],
        [0.0005, 0.0007],
        [0.0004, 0.0006],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0626, 0.0622],
        [0.0618, 0.0630],
        [0.0587, 0.0663],
        [0.0685, 0.0568],
        [0.0734, 0.0530],
        [0.0618, 0.0630],
        [0.0633, 0.0615],
        [0.0678, 0.0574],
        [0.0612, 0.0636],
        [0.0626, 0.0622],
        [0.0636, 0.0611],
        [0.0587, 0.0663],
        [0.0603, 0.0645],
        [0.0582, 0.0669],
        [0.0609, 0.0639],
        [0.0568, 0.0685]], device='cuda:0')
 Batch: 3 of active classification Duration: 0:00:00.342589
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0004, 0.0005],
        [0.0005, 0.0010],
        [0.0005, 0.0007],
        [0.0002, 0.0003],
        [0.0002, 0.0005],
        [0.0002, 0.0002],
        [0.0004, 0.0008],
        [0.0005, 0.0009],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0010],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0586, 0.0665],
        [0.0683, 0.0571],
        [0.0601, 0.0648],
        [0.0640, 0.0609],
        [0.0652, 0.0597],
        [0.0590, 0.0660],
        [0.0680, 0.0573],
        [0.0610, 0.0638],
        [0.0622, 0.0627],
        [0.0647, 0.0602],
        [0.0636, 0.0612],
        [0.0577, 0.0675],
        [0.0648, 0.0601],
        [0.0632, 0.0617],
        [0.0574, 0.0679],
        [0.0621, 0.0627]], device='cuda:0')
 Batch: 4 of active classification Duration: 0:00:00.276766
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0006],
        [0.0004, 0.0006],
        [0.0006, 0.0008],
        [0.0004, 0.0005],
        [0.0004, 0.0008],
        [0.0004, 0.0005],
        [0.0003, 0.0004],
        [0.0005, 0.0010],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0005, 0.0005],
        [0.0005, 0.0008],
        [0.0007, 0.0012],
        [0.0008, 0.0012],
        [0.0005, 0.0006],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0653, 0.0597],
        [0.0617, 0.0632],
        [0.0648, 0.0602],
        [0.0650, 0.0600],
        [0.0594, 0.0656],
        [0.0634, 0.0615],
        [0.0620, 0.0629],
        [0.0579, 0.0674],
        [0.0617, 0.0632],
        [0.0624, 0.0625],
        [0.0684, 0.0570],
        [0.0605, 0.0645],
        [0.0599, 0.0651],
        [0.0633, 0.0616],
        [0.0655, 0.0595],
        [0.0589, 0.0662]], device='cuda:0')
 Batch: 5 of active classification Duration: 0:00:00.354602
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0004],
        [0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0012, 0.0013],
        [0.0003, 0.0009],
        [0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0006, 0.0007],
        [0.0006, 0.0015],
        [0.0004, 0.0006],
        [0.0005, 0.0006],
        [0.0004, 0.0008],
        [0.0005, 0.0011],
        [0.0004, 0.0006],
        [0.0004, 0.0008],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0688, 0.0565],
        [0.0610, 0.0637],
        [0.0619, 0.0628],
        [0.0695, 0.0559],
        [0.0558, 0.0696],
        [0.0606, 0.0642],
        [0.0591, 0.0658],
        [0.0687, 0.0566],
        [0.0564, 0.0690],
        [0.0630, 0.0617],
        [0.0684, 0.0568],
        [0.0602, 0.0645],
        [0.0575, 0.0677],
        [0.0651, 0.0597],
        [0.0597, 0.0651],
        [0.0645, 0.0603]], device='cuda:0')
 Batch: 6 of active classification Duration: 0:00:00.328447
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0004],
        [0.0005, 0.0009],
        [0.0005, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0007, 0.0009],
        [0.0004, 0.0006],
        [0.0003, 0.0009],
        [0.0005, 0.0010],
        [0.0005, 0.0006],
        [0.0006, 0.0007],
        [0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0005, 0.0007],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0688, 0.0566],
        [0.0610, 0.0638],
        [0.0648, 0.0601],
        [0.0601, 0.0648],
        [0.0568, 0.0685],
        [0.0660, 0.0589],
        [0.0658, 0.0592],
        [0.0546, 0.0713],
        [0.0606, 0.0642],
        [0.0656, 0.0593],
        [0.0663, 0.0587],
        [0.0615, 0.0633],
        [0.0619, 0.0628],
        [0.0567, 0.0686],
        [0.0655, 0.0594],
        [0.0643, 0.0605]], device='cuda:0')
 Batch: 7 of active classification Duration: 0:00:00.323844
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0005, 0.0009],
        [0.0005, 0.0010],
        [0.0002, 0.0003],
        [0.0004, 0.0010],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0006, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0593, 0.0657],
        [0.0597, 0.0652],
        [0.0679, 0.0573],
        [0.0608, 0.0640],
        [0.0667, 0.0583],
        [0.0673, 0.0579],
        [0.0621, 0.0627],
        [0.0594, 0.0656],
        [0.0674, 0.0578],
        [0.0572, 0.0680],
        [0.0617, 0.0631],
        [0.0585, 0.0666],
        [0.0688, 0.0565],
        [0.0614, 0.0634],
        [0.0611, 0.0637],
        [0.0607, 0.0641]], device='cuda:0')
 Batch: 8 of active classification Duration: 0:00:00.303497
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0004],
        [0.0006, 0.0009],
        [0.0008, 0.0013],
        [0.0004, 0.0006],
        [0.0003, 0.0004],
        [0.0003, 0.0003],
        [0.0003, 0.0005],
        [0.0003, 0.0004],
        [0.0002, 0.0005],
        [0.0005, 0.0008],
        [0.0005, 0.0007],
        [0.0002, 0.0005],
        [0.0006, 0.0010],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0615, 0.0634],
        [0.0627, 0.0622],
        [0.0633, 0.0616],
        [0.0615, 0.0634],
        [0.0615, 0.0634],
        [0.0653, 0.0597],
        [0.0642, 0.0607],
        [0.0666, 0.0586],
        [0.0615, 0.0634],
        [0.0656, 0.0595],
        [0.0588, 0.0664],
        [0.0611, 0.0638],
        [0.0642, 0.0607],
        [0.0565, 0.0691],
        [0.0627, 0.0622],
        [0.0629, 0.0620]], device='cuda:0')
 Batch: 9 of active classification Duration: 0:00:00.405874
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0004],
        [0.0004, 0.0006],
        [0.0005, 0.0008],
        [0.0003, 0.0007],
        [0.0004, 0.0006],
        [0.0005, 0.0007],
        [0.0002, 0.0003],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0002, 0.0006],
        [0.0007, 0.0009],
        [0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0573, 0.0681],
        [0.0629, 0.0620],
        [0.0673, 0.0579],
        [0.0633, 0.0616],
        [0.0620, 0.0629],
        [0.0608, 0.0642],
        [0.0637, 0.0612],
        [0.0638, 0.0611],
        [0.0659, 0.0592],
        [0.0610, 0.0639],
        [0.0623, 0.0626],
        [0.0584, 0.0667],
        [0.0672, 0.0580],
        [0.0602, 0.0647],
        [0.0597, 0.0653],
        [0.0643, 0.0606]], device='cuda:0')
 Batch: 10 of active classification Duration: 0:00:00.414424
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[4.9448e-04, 9.0265e-04],
        [4.2057e-04, 4.4775e-04],
        [2.7776e-04, 5.5695e-04],
        [5.2547e-04, 9.5892e-04],
        [3.5834e-04, 6.1417e-04],
        [4.7207e-04, 6.0606e-04],
        [2.5773e-04, 4.8542e-04],
        [4.1580e-04, 4.1914e-04],
        [2.7251e-04, 4.7469e-04],
        [3.5739e-04, 7.6246e-04],
        [4.7731e-04, 8.3113e-04],
        [9.5248e-05, 3.7670e-04],
        [2.9922e-04, 5.1308e-04],
        [4.4107e-04, 7.1049e-04],
        [2.3758e-04, 4.7994e-04],
        [3.2997e-04, 6.1178e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0616, 0.0631],
        [0.0702, 0.0554],
        [0.0603, 0.0645],
        [0.0616, 0.0631],
        [0.0625, 0.0622],
        [0.0670, 0.0581],
        [0.0612, 0.0636],
        [0.0711, 0.0547],
        [0.0623, 0.0625],
        [0.0595, 0.0654],
        [0.0623, 0.0625],
        [0.0529, 0.0735],
        [0.0625, 0.0622],
        [0.0634, 0.0613],
        [0.0602, 0.0646],
        [0.0614, 0.0634]], device='cuda:0')
 Batch: 11 of active classification Duration: 0:00:00.390687
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0005, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0004],
        [0.0005, 0.0008],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1251, 0.1245],
        [0.1117, 0.1394],
        [0.1262, 0.1234],
        [0.1367, 0.1139],
        [0.1318, 0.1182],
        [0.1256, 0.1240],
        [0.1233, 0.1263],
        [0.1195, 0.1303]], device='cuda:0')
 Batch: 12 of active classification Duration: 0:00:00.148864
acc:  0.485
Time taken to execute the en SA task with prompt type active, variation 0 and batchsize 16: 0:00:04.525794
path ['42', 'en', 'bloom-big', 'SA', 'active', 'prompt_id_0']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([95, 2])
answers_probs just softmax dim 0: tensor([[0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105]], device='cuda:0')
tensor([[0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105],
        [0.0105, 0.0105]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA active 1 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0006, 0.0005],
        [0.0007, 0.0007],
        [0.0006, 0.0007],
        [0.0008, 0.0007],
        [0.0009, 0.0013],
        [0.0008, 0.0008],
        [0.0006, 0.0014],
        [0.0005, 0.0004],
        [0.0006, 0.0006],
        [0.0008, 0.0010],
        [0.0005, 0.0006],
        [0.0006, 0.0008],
        [0.0003, 0.0006],
        [0.0005, 0.0005],
        [0.0006, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0617, 0.0630],
        [0.0665, 0.0585],
        [0.0654, 0.0594],
        [0.0633, 0.0614],
        [0.0669, 0.0582],
        [0.0585, 0.0664],
        [0.0653, 0.0595],
        [0.0542, 0.0717],
        [0.0683, 0.0569],
        [0.0651, 0.0598],
        [0.0622, 0.0625],
        [0.0630, 0.0617],
        [0.0590, 0.0659],
        [0.0537, 0.0724],
        [0.0650, 0.0598],
        [0.0618, 0.0629]], device='cuda:0')
 Batch: 0 of active classification Duration: 0:00:00.327354
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0005],
        [0.0006, 0.0009],
        [0.0005, 0.0006],
        [0.0013, 0.0015],
        [0.0004, 0.0004],
        [0.0003, 0.0004],
        [0.0005, 0.0007],
        [0.0004, 0.0004],
        [0.0006, 0.0007],
        [0.0004, 0.0005],
        [0.0004, 0.0004],
        [0.0006, 0.0009],
        [0.0006, 0.0009],
        [0.0005, 0.0005],
        [0.0003, 0.0005],
        [0.0009, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0653, 0.0598],
        [0.0603, 0.0647],
        [0.0631, 0.0618],
        [0.0630, 0.0619],
        [0.0663, 0.0588],
        [0.0617, 0.0632],
        [0.0603, 0.0647],
        [0.0645, 0.0605],
        [0.0638, 0.0612],
        [0.0605, 0.0644],
        [0.0630, 0.0619],
        [0.0602, 0.0648],
        [0.0588, 0.0663],
        [0.0646, 0.0603],
        [0.0594, 0.0657],
        [0.0650, 0.0600]], device='cuda:0')
 Batch: 1 of active classification Duration: 0:00:00.435452
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0008, 0.0007],
        [0.0006, 0.0009],
        [0.0004, 0.0007],
        [0.0004, 0.0005],
        [0.0005, 0.0007],
        [0.0007, 0.0008],
        [0.0002, 0.0003],
        [0.0003, 0.0004],
        [0.0004, 0.0004],
        [0.0005, 0.0005],
        [0.0005, 0.0008],
        [0.0006, 0.0007],
        [0.0007, 0.0007],
        [0.0008, 0.0007],
        [0.0006, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0586, 0.0665],
        [0.0668, 0.0583],
        [0.0602, 0.0647],
        [0.0565, 0.0689],
        [0.0614, 0.0635],
        [0.0618, 0.0630],
        [0.0621, 0.0628],
        [0.0614, 0.0635],
        [0.0633, 0.0616],
        [0.0641, 0.0607],
        [0.0675, 0.0577],
        [0.0586, 0.0665],
        [0.0634, 0.0615],
        [0.0663, 0.0588],
        [0.0663, 0.0588],
        [0.0616, 0.0633]], device='cuda:0')
 Batch: 2 of active classification Duration: 0:00:00.345057
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0007],
        [0.0004, 0.0004],
        [0.0005, 0.0005],
        [0.0007, 0.0011],
        [0.0003, 0.0003],
        [0.0003, 0.0004],
        [0.0004, 0.0005],
        [0.0006, 0.0005],
        [0.0009, 0.0008],
        [0.0007, 0.0008],
        [0.0007, 0.0006],
        [0.0009, 0.0008],
        [0.0009, 0.0011],
        [0.0004, 0.0004],
        [0.0003, 0.0003],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0642, 0.0607],
        [0.0629, 0.0620],
        [0.0638, 0.0611],
        [0.0577, 0.0676],
        [0.0620, 0.0629],
        [0.0578, 0.0675],
        [0.0605, 0.0645],
        [0.0681, 0.0573],
        [0.0650, 0.0600],
        [0.0613, 0.0636],
        [0.0661, 0.0589],
        [0.0654, 0.0596],
        [0.0621, 0.0627],
        [0.0627, 0.0621],
        [0.0616, 0.0632],
        [0.0588, 0.0663]], device='cuda:0')
 Batch: 3 of active classification Duration: 0:00:00.518624
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0003, 0.0002],
        [0.0007, 0.0008],
        [0.0011, 0.0012],
        [0.0006, 0.0007],
        [0.0006, 0.0006],
        [0.0008, 0.0010],
        [0.0004, 0.0005],
        [0.0004, 0.0004],
        [0.0007, 0.0008],
        [0.0003, 0.0005],
        [0.0005, 0.0006],
        [0.0004, 0.0005],
        [0.0004, 0.0004],
        [0.0006, 0.0007],
        [0.0006, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0609, 0.0641],
        [0.0697, 0.0559],
        [0.0611, 0.0638],
        [0.0636, 0.0613],
        [0.0622, 0.0627],
        [0.0645, 0.0605],
        [0.0613, 0.0636],
        [0.0597, 0.0653],
        [0.0628, 0.0621],
        [0.0610, 0.0640],
        [0.0587, 0.0665],
        [0.0619, 0.0630],
        [0.0636, 0.0613],
        [0.0628, 0.0621],
        [0.0624, 0.0625],
        [0.0636, 0.0613]], device='cuda:0')
 Batch: 4 of active classification Duration: 0:00:00.416813
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0007],
        [0.0003, 0.0003],
        [0.0006, 0.0011],
        [0.0003, 0.0003],
        [0.0006, 0.0005],
        [0.0007, 0.0012],
        [0.0004, 0.0007],
        [0.0007, 0.0009],
        [0.0005, 0.0007],
        [0.0007, 0.0007],
        [0.0007, 0.0009],
        [0.0003, 0.0005],
        [0.0005, 0.0006],
        [0.0006, 0.0006],
        [0.0005, 0.0007],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0637, 0.0612],
        [0.0674, 0.0578],
        [0.0570, 0.0683],
        [0.0612, 0.0637],
        [0.0695, 0.0560],
        [0.0588, 0.0662],
        [0.0587, 0.0664],
        [0.0634, 0.0614],
        [0.0614, 0.0634],
        [0.0647, 0.0602],
        [0.0619, 0.0630],
        [0.0589, 0.0661],
        [0.0638, 0.0610],
        [0.0670, 0.0581],
        [0.0614, 0.0634],
        [0.0612, 0.0637]], device='cuda:0')
 Batch: 5 of active classification Duration: 0:00:00.325619
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0008],
        [0.0004, 0.0006],
        [0.0010, 0.0009],
        [0.0009, 0.0008],
        [0.0007, 0.0009],
        [0.0006, 0.0007],
        [0.0007, 0.0009],
        [0.0005, 0.0006],
        [0.0003, 0.0004],
        [0.0005, 0.0007],
        [0.0008, 0.0008],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0005, 0.0006],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0628, 0.0621],
        [0.0594, 0.0656],
        [0.0676, 0.0577],
        [0.0666, 0.0586],
        [0.0617, 0.0632],
        [0.0618, 0.0631],
        [0.0617, 0.0632],
        [0.0630, 0.0619],
        [0.0618, 0.0631],
        [0.0614, 0.0636],
        [0.0654, 0.0596],
        [0.0620, 0.0630],
        [0.0590, 0.0662],
        [0.0593, 0.0658],
        [0.0632, 0.0618],
        [0.0632, 0.0617]], device='cuda:0')
 Batch: 6 of active classification Duration: 0:00:00.414251
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0010],
        [0.0006, 0.0006],
        [0.0006, 0.0008],
        [0.0006, 0.0009],
        [0.0006, 0.0006],
        [0.0006, 0.0005],
        [0.0008, 0.0008],
        [0.0005, 0.0005],
        [0.0004, 0.0004],
        [0.0003, 0.0005],
        [0.0007, 0.0006],
        [0.0007, 0.0006],
        [0.0005, 0.0007],
        [0.0003, 0.0003],
        [0.0013, 0.0011],
        [0.0005, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0589, 0.0662],
        [0.0632, 0.0616],
        [0.0592, 0.0658],
        [0.0574, 0.0679],
        [0.0628, 0.0621],
        [0.0658, 0.0593],
        [0.0650, 0.0600],
        [0.0655, 0.0595],
        [0.0647, 0.0602],
        [0.0580, 0.0672],
        [0.0654, 0.0596],
        [0.0659, 0.0591],
        [0.0587, 0.0664],
        [0.0615, 0.0633],
        [0.0658, 0.0592],
        [0.0623, 0.0626]], device='cuda:0')
 Batch: 7 of active classification Duration: 0:00:00.220457
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0006],
        [0.0005, 0.0006],
        [0.0004, 0.0005],
        [0.0006, 0.0006],
        [0.0007, 0.0007],
        [0.0003, 0.0003],
        [0.0005, 0.0004],
        [0.0004, 0.0004],
        [0.0010, 0.0015],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0006, 0.0008],
        [0.0005, 0.0007],
        [0.0005, 0.0009],
        [0.0006, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0639, 0.0610],
        [0.0635, 0.0613],
        [0.0623, 0.0626],
        [0.0650, 0.0599],
        [0.0644, 0.0605],
        [0.0654, 0.0596],
        [0.0683, 0.0571],
        [0.0622, 0.0627],
        [0.0593, 0.0658],
        [0.0616, 0.0633],
        [0.0618, 0.0631],
        [0.0609, 0.0640],
        [0.0593, 0.0658],
        [0.0581, 0.0671],
        [0.0576, 0.0676],
        [0.0666, 0.0585]], device='cuda:0')
 Batch: 8 of active classification Duration: 0:00:00.391640
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0004, 0.0005],
        [0.0004, 0.0006],
        [0.0005, 0.0006],
        [0.0004, 0.0004],
        [0.0005, 0.0006],
        [0.0002, 0.0005],
        [0.0008, 0.0010],
        [0.0005, 0.0005],
        [0.0009, 0.0009],
        [0.0006, 0.0007],
        [0.0005, 0.0006],
        [0.0006, 0.0009],
        [0.0006, 0.0009],
        [0.0004, 0.0005],
        [0.0005, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0604, 0.0645],
        [0.0648, 0.0600],
        [0.0606, 0.0642],
        [0.0648, 0.0600],
        [0.0647, 0.0602],
        [0.0641, 0.0607],
        [0.0515, 0.0756],
        [0.0631, 0.0617],
        [0.0661, 0.0589],
        [0.0664, 0.0586],
        [0.0623, 0.0625],
        [0.0629, 0.0619],
        [0.0623, 0.0625],
        [0.0595, 0.0654],
        [0.0613, 0.0635],
        [0.0652, 0.0597]], device='cuda:0')
 Batch: 9 of active classification Duration: 0:00:00.350803
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0008, 0.0010],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0004, 0.0004],
        [0.0002, 0.0002],
        [0.0005, 0.0006],
        [0.0009, 0.0010],
        [0.0006, 0.0007],
        [0.0008, 0.0009],
        [0.0005, 0.0004],
        [0.0005, 0.0005],
        [0.0006, 0.0007],
        [0.0011, 0.0012],
        [0.0005, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0621, 0.0628],
        [0.0599, 0.0651],
        [0.0549, 0.0710],
        [0.0644, 0.0605],
        [0.0629, 0.0620],
        [0.0632, 0.0617],
        [0.0629, 0.0620],
        [0.0636, 0.0614],
        [0.0634, 0.0615],
        [0.0635, 0.0614],
        [0.0621, 0.0628],
        [0.0669, 0.0583],
        [0.0624, 0.0625],
        [0.0622, 0.0627],
        [0.0639, 0.0610],
        [0.0617, 0.0632]], device='cuda:0')
 Batch: 10 of active classification Duration: 0:00:00.322463
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0005],
        [0.0007, 0.0008],
        [0.0003, 0.0004],
        [0.0006, 0.0008],
        [0.0008, 0.0010],
        [0.0007, 0.0009],
        [0.0006, 0.0006],
        [0.0004, 0.0004],
        [0.0006, 0.0008],
        [0.0007, 0.0007],
        [0.0007, 0.0008],
        [0.0007, 0.0009],
        [0.0004, 0.0006],
        [0.0007, 0.0008],
        [0.0007, 0.0009],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0640, 0.0609],
        [0.0616, 0.0633],
        [0.0613, 0.0637],
        [0.0622, 0.0627],
        [0.0617, 0.0632],
        [0.0615, 0.0635],
        [0.0643, 0.0607],
        [0.0634, 0.0615],
        [0.0600, 0.0651],
        [0.0653, 0.0598],
        [0.0646, 0.0605],
        [0.0628, 0.0621],
        [0.0600, 0.0651],
        [0.0652, 0.0599],
        [0.0621, 0.0629],
        [0.0600, 0.0651]], device='cuda:0')
 Batch: 11 of active classification Duration: 0:00:00.324412
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0005, 0.0005],
        [0.0004, 0.0005],
        [0.0009, 0.0010],
        [0.0003, 0.0005],
        [0.0008, 0.0009],
        [0.0004, 0.0005],
        [0.0006, 0.0007],
        [0.0006, 0.0007]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1251, 0.1248],
        [0.1239, 0.1260],
        [0.1263, 0.1236],
        [0.1193, 0.1309],
        [0.1271, 0.1229],
        [0.1247, 0.1253],
        [0.1237, 0.1263],
        [0.1298, 0.1203]], device='cuda:0')
 Batch: 12 of active classification Duration: 0:00:00.220319
acc:  0.435
Time taken to execute the en SA task with prompt type active, variation 1 and batchsize 16: 0:00:04.629976
path ['42', 'en', 'bloom-big', 'SA', 'active', 'prompt_id_1']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([100, 2])
answers_probs just softmax dim 0: tensor([[0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100]], device='cuda:0')
tensor([[0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA active 2 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0005, 0.0013],
        [0.0002, 0.0004],
        [0.0005, 0.0012],
        [0.0003, 0.0006],
        [0.0005, 0.0008],
        [0.0004, 0.0013],
        [0.0005, 0.0009],
        [0.0002, 0.0003],
        [0.0003, 0.0004],
        [0.0003, 0.0007],
        [0.0007, 0.0012],
        [0.0002, 0.0008],
        [0.0004, 0.0007],
        [0.0001, 0.0001],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0599, 0.0650],
        [0.0594, 0.0655],
        [0.0622, 0.0625],
        [0.0598, 0.0651],
        [0.0606, 0.0641],
        [0.0644, 0.0603],
        [0.0570, 0.0682],
        [0.0641, 0.0607],
        [0.0676, 0.0575],
        [0.0689, 0.0564],
        [0.0601, 0.0646],
        [0.0636, 0.0611],
        [0.0550, 0.0708],
        [0.0634, 0.0613],
        [0.0726, 0.0535],
        [0.0614, 0.0634]], device='cuda:0')
 Batch: 0 of active classification Duration: 0:00:00.466441
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0004, 0.0009],
        [0.0002, 0.0006],
        [0.0004, 0.0009],
        [0.0002, 0.0004],
        [0.0003, 0.0009],
        [0.0005, 0.0012],
        [0.0004, 0.0011],
        [0.0004, 0.0009],
        [0.0003, 0.0004],
        [0.0005, 0.0010],
        [0.0003, 0.0003],
        [0.0002, 0.0007],
        [0.0003, 0.0010],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0599, 0.0651],
        [0.0610, 0.0639],
        [0.0618, 0.0631],
        [0.0608, 0.0641],
        [0.0616, 0.0633],
        [0.0643, 0.0606],
        [0.0593, 0.0656],
        [0.0630, 0.0618],
        [0.0593, 0.0657],
        [0.0637, 0.0611],
        [0.0687, 0.0567],
        [0.0635, 0.0613],
        [0.0706, 0.0552],
        [0.0589, 0.0661],
        [0.0588, 0.0662],
        [0.0649, 0.0601]], device='cuda:0')
 Batch: 1 of active classification Duration: 0:00:00.353745
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0002, 0.0007],
        [0.0003, 0.0007],
        [0.0004, 0.0010],
        [0.0004, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0010],
        [0.0001, 0.0002],
        [0.0003, 0.0009],
        [0.0003, 0.0005],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0628, 0.0622],
        [0.0628, 0.0622],
        [0.0614, 0.0635],
        [0.0662, 0.0590],
        [0.0580, 0.0673],
        [0.0622, 0.0627],
        [0.0614, 0.0635],
        [0.0629, 0.0621],
        [0.0630, 0.0619],
        [0.0631, 0.0618],
        [0.0633, 0.0616],
        [0.0586, 0.0666],
        [0.0662, 0.0590],
        [0.0605, 0.0645],
        [0.0653, 0.0597],
        [0.0625, 0.0625]], device='cuda:0')
 Batch: 2 of active classification Duration: 0:00:00.395031
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0004, 0.0011],
        [0.0005, 0.0010],
        [0.0003, 0.0006],
        [0.0002, 0.0002],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0004, 0.0010],
        [0.0003, 0.0004],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0005, 0.0010],
        [0.0003, 0.0008],
        [0.0001, 0.0002]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0614, 0.0636],
        [0.0635, 0.0614],
        [0.0651, 0.0599],
        [0.0596, 0.0654],
        [0.0617, 0.0632],
        [0.0633, 0.0616],
        [0.0658, 0.0593],
        [0.0646, 0.0604],
        [0.0601, 0.0649],
        [0.0606, 0.0643],
        [0.0673, 0.0580],
        [0.0622, 0.0627],
        [0.0621, 0.0628],
        [0.0610, 0.0639],
        [0.0575, 0.0679],
        [0.0642, 0.0608]], device='cuda:0')
 Batch: 3 of active classification Duration: 0:00:00.523269
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0001, 0.0002],
        [0.0004, 0.0012],
        [0.0004, 0.0006],
        [0.0002, 0.0005],
        [0.0003, 0.0004],
        [0.0003, 0.0008],
        [0.0003, 0.0005],
        [0.0001, 0.0002],
        [0.0002, 0.0005],
        [0.0002, 0.0003],
        [0.0005, 0.0012],
        [0.0004, 0.0006],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0006, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0576, 0.0676],
        [0.0634, 0.0614],
        [0.0561, 0.0693],
        [0.0665, 0.0585],
        [0.0592, 0.0657],
        [0.0667, 0.0583],
        [0.0596, 0.0653],
        [0.0661, 0.0589],
        [0.0661, 0.0589],
        [0.0569, 0.0685],
        [0.0636, 0.0612],
        [0.0609, 0.0639],
        [0.0682, 0.0571],
        [0.0626, 0.0622],
        [0.0646, 0.0603],
        [0.0618, 0.0630]], device='cuda:0')
 Batch: 4 of active classification Duration: 0:00:00.353929
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0001, 0.0002],
        [0.0002, 0.0004],
        [0.0003, 0.0010],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0003, 0.0008],
        [0.0004, 0.0012],
        [0.0004, 0.0009],
        [0.0002, 0.0007],
        [0.0003, 0.0005],
        [0.0002, 0.0002],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0709, 0.0548],
        [0.0627, 0.0619],
        [0.0554, 0.0701],
        [0.0637, 0.0609],
        [0.0589, 0.0659],
        [0.0617, 0.0630],
        [0.0725, 0.0536],
        [0.0571, 0.0680],
        [0.0574, 0.0676],
        [0.0609, 0.0637],
        [0.0568, 0.0683],
        [0.0665, 0.0584],
        [0.0686, 0.0566],
        [0.0622, 0.0624],
        [0.0612, 0.0634],
        [0.0633, 0.0613]], device='cuda:0')
 Batch: 5 of active classification Duration: 0:00:00.388801
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0002, 0.0003],
        [0.0003, 0.0004],
        [0.0004, 0.0009],
        [0.0004, 0.0009],
        [0.0006, 0.0013],
        [0.0004, 0.0009],
        [0.0002, 0.0003],
        [0.0005, 0.0010],
        [0.0002, 0.0004],
        [0.0004, 0.0005],
        [0.0005, 0.0009],
        [0.0003, 0.0007],
        [0.0005, 0.0013],
        [0.0003, 0.0005],
        [0.0003, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0646, 0.0603],
        [0.0669, 0.0582],
        [0.0653, 0.0596],
        [0.0594, 0.0656],
        [0.0587, 0.0664],
        [0.0608, 0.0640],
        [0.0604, 0.0645],
        [0.0665, 0.0585],
        [0.0616, 0.0632],
        [0.0628, 0.0620],
        [0.0675, 0.0577],
        [0.0639, 0.0610],
        [0.0612, 0.0636],
        [0.0580, 0.0671],
        [0.0665, 0.0585],
        [0.0558, 0.0697]], device='cuda:0')
 Batch: 6 of active classification Duration: 0:00:00.416220
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0002, 0.0002],
        [0.0003, 0.0010],
        [0.0003, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0010],
        [0.0005, 0.0009],
        [0.0005, 0.0011],
        [0.0002, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0598, 0.0650],
        [0.0705, 0.0551],
        [0.0695, 0.0559],
        [0.0570, 0.0681],
        [0.0578, 0.0672],
        [0.0588, 0.0660],
        [0.0572, 0.0679],
        [0.0638, 0.0609],
        [0.0615, 0.0632],
        [0.0716, 0.0542],
        [0.0695, 0.0559],
        [0.0633, 0.0613],
        [0.0612, 0.0635],
        [0.0600, 0.0648],
        [0.0579, 0.0670],
        [0.0608, 0.0639]], device='cuda:0')
 Batch: 7 of active classification Duration: 0:00:00.426769
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0009],
        [0.0004, 0.0011],
        [0.0003, 0.0005],
        [0.0003, 0.0009],
        [0.0003, 0.0006],
        [0.0007, 0.0015],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0005, 0.0012],
        [0.0004, 0.0006],
        [0.0001, 0.0003],
        [0.0005, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0008],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0566, 0.0688],
        [0.0592, 0.0658],
        [0.0661, 0.0589],
        [0.0592, 0.0658],
        [0.0633, 0.0615],
        [0.0609, 0.0640],
        [0.0605, 0.0644],
        [0.0678, 0.0574],
        [0.0617, 0.0631],
        [0.0603, 0.0646],
        [0.0674, 0.0577],
        [0.0646, 0.0602],
        [0.0698, 0.0558],
        [0.0616, 0.0632],
        [0.0602, 0.0647],
        [0.0609, 0.0639]], device='cuda:0')
 Batch: 8 of active classification Duration: 0:00:00.320579
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0003, 0.0009],
        [0.0003, 0.0009],
        [0.0002, 0.0003],
        [0.0002, 0.0006],
        [0.0004, 0.0012],
        [0.0004, 0.0008],
        [0.0004, 0.0005],
        [0.0001, 0.0001],
        [0.0004, 0.0007],
        [0.0006, 0.0015],
        [0.0002, 0.0006],
        [0.0003, 0.0004],
        [0.0002, 0.0004],
        [0.0003, 0.0009],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0601, 0.0647],
        [0.0583, 0.0666],
        [0.0583, 0.0667],
        [0.0731, 0.0532],
        [0.0575, 0.0676],
        [0.0587, 0.0662],
        [0.0628, 0.0619],
        [0.0667, 0.0583],
        [0.0705, 0.0551],
        [0.0642, 0.0606],
        [0.0597, 0.0651],
        [0.0598, 0.0650],
        [0.0672, 0.0579],
        [0.0616, 0.0631],
        [0.0601, 0.0647],
        [0.0615, 0.0632]], device='cuda:0')
 Batch: 9 of active classification Duration: 0:00:00.410432
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0002, 0.0003],
        [0.0002, 0.0007],
        [0.0004, 0.0011],
        [0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0004, 0.0006],
        [0.0004, 0.0013],
        [0.0004, 0.0008],
        [0.0007, 0.0018],
        [0.0004, 0.0007],
        [0.0002, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0629, 0.0619],
        [0.0630, 0.0618],
        [0.0689, 0.0565],
        [0.0711, 0.0548],
        [0.0577, 0.0674],
        [0.0609, 0.0639],
        [0.0608, 0.0641],
        [0.0622, 0.0626],
        [0.0668, 0.0583],
        [0.0594, 0.0655],
        [0.0620, 0.0628],
        [0.0616, 0.0632],
        [0.0643, 0.0606],
        [0.0571, 0.0682],
        [0.0608, 0.0641],
        [0.0606, 0.0643]], device='cuda:0')
 Batch: 10 of active classification Duration: 0:00:00.385349
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0012],
        [0.0002, 0.0005],
        [0.0002, 0.0006],
        [0.0003, 0.0005],
        [0.0002, 0.0003],
        [0.0003, 0.0009],
        [0.0002, 0.0004],
        [0.0003, 0.0010],
        [0.0003, 0.0012],
        [0.0004, 0.0007],
        [0.0008, 0.0018],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0006, 0.0013],
        [0.0001, 0.0001],
        [0.0004, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0592, 0.0657],
        [0.0631, 0.0615],
        [0.0571, 0.0681],
        [0.0646, 0.0602],
        [0.0692, 0.0562],
        [0.0580, 0.0670],
        [0.0680, 0.0571],
        [0.0569, 0.0683],
        [0.0563, 0.0690],
        [0.0655, 0.0593],
        [0.0622, 0.0625],
        [0.0635, 0.0612],
        [0.0639, 0.0608],
        [0.0613, 0.0634],
        [0.0724, 0.0536],
        [0.0587, 0.0662]], device='cuda:0')
 Batch: 11 of active classification Duration: 0:00:00.354044
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0003],
        [0.0004, 0.0012],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0005],
        [0.0004, 0.0010],
        [0.0007, 0.0014]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1249],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251]], device='cuda:0')
tensor([[0.1471, 0.1054],
        [0.1117, 0.1389],
        [0.1173, 0.1322],
        [0.1204, 0.1288],
        [0.1219, 0.1273],
        [0.1382, 0.1122],
        [0.1198, 0.1295],
        [0.1235, 0.1256]], device='cuda:0')
 Batch: 12 of active classification Duration: 0:00:00.201068
acc:  0.51
Time taken to execute the en SA task with prompt type active, variation 2 and batchsize 16: 0:00:05.012446
path ['42', 'en', 'bloom-big', 'SA', 'active', 'prompt_id_2']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005],
        [0.0005, 0.0005]], device='cuda:0') torch.Size([107, 2])
answers_probs just softmax dim 0: tensor([[0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093]], device='cuda:0')
tensor([[0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA active 3 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0012],
        [0.0004, 0.0009],
        [0.0006, 0.0011],
        [0.0006, 0.0022],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0007, 0.0014],
        [0.0005, 0.0015],
        [0.0002, 0.0006],
        [0.0002, 0.0007],
        [0.0003, 0.0008],
        [0.0004, 0.0012],
        [0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0004, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0619, 0.0630],
        [0.0647, 0.0602],
        [0.0678, 0.0575],
        [0.0582, 0.0670],
        [0.0643, 0.0606],
        [0.0625, 0.0624],
        [0.0613, 0.0636],
        [0.0648, 0.0602],
        [0.0608, 0.0641],
        [0.0630, 0.0619],
        [0.0599, 0.0651],
        [0.0620, 0.0629],
        [0.0588, 0.0663],
        [0.0655, 0.0595],
        [0.0653, 0.0597],
        [0.0594, 0.0656]], device='cuda:0')
 Batch: 0 of active classification Duration: 0:00:00.353063
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0005, 0.0008],
        [0.0003, 0.0007],
        [0.0006, 0.0013],
        [0.0004, 0.0011],
        [0.0004, 0.0010],
        [0.0004, 0.0011],
        [0.0004, 0.0010],
        [0.0004, 0.0010],
        [0.0003, 0.0009],
        [0.0004, 0.0007],
        [0.0003, 0.0009],
        [0.0003, 0.0006],
        [0.0002, 0.0007],
        [0.0003, 0.0007],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0647, 0.0603],
        [0.0669, 0.0583],
        [0.0632, 0.0617],
        [0.0632, 0.0617],
        [0.0592, 0.0659],
        [0.0619, 0.0630],
        [0.0621, 0.0628],
        [0.0621, 0.0628],
        [0.0613, 0.0636],
        [0.0591, 0.0660],
        [0.0650, 0.0600],
        [0.0579, 0.0673],
        [0.0659, 0.0591],
        [0.0599, 0.0651],
        [0.0626, 0.0623],
        [0.0649, 0.0601]], device='cuda:0')
 Batch: 1 of active classification Duration: 0:00:00.414133
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0005, 0.0012],
        [0.0005, 0.0014],
        [0.0008, 0.0011],
        [0.0003, 0.0006],
        [0.0004, 0.0010],
        [0.0003, 0.0006],
        [0.0005, 0.0016],
        [0.0005, 0.0011],
        [0.0005, 0.0014],
        [0.0003, 0.0008],
        [0.0002, 0.0006],
        [0.0005, 0.0011],
        [0.0006, 0.0010],
        [0.0004, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0624, 0.0624],
        [0.0618, 0.0630],
        [0.0626, 0.0622],
        [0.0603, 0.0646],
        [0.0708, 0.0551],
        [0.0639, 0.0610],
        [0.0623, 0.0625],
        [0.0630, 0.0618],
        [0.0583, 0.0668],
        [0.0616, 0.0632],
        [0.0614, 0.0634],
        [0.0610, 0.0639],
        [0.0585, 0.0666],
        [0.0623, 0.0625],
        [0.0680, 0.0573],
        [0.0615, 0.0633]], device='cuda:0')
 Batch: 2 of active classification Duration: 0:00:00.391803
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0011],
        [0.0003, 0.0007],
        [0.0004, 0.0009],
        [0.0003, 0.0009],
        [0.0007, 0.0015],
        [0.0004, 0.0010],
        [0.0014, 0.0018],
        [0.0003, 0.0009],
        [0.0004, 0.0007],
        [0.0003, 0.0011],
        [0.0005, 0.0007],
        [0.0003, 0.0009],
        [0.0003, 0.0009],
        [0.0004, 0.0012],
        [0.0005, 0.0009],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0626, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0659, 0.0590],
        [0.0637, 0.0611],
        [0.0615, 0.0633],
        [0.0589, 0.0661],
        [0.0635, 0.0613],
        [0.0615, 0.0633],
        [0.0702, 0.0554],
        [0.0587, 0.0664],
        [0.0645, 0.0603],
        [0.0572, 0.0681],
        [0.0702, 0.0554],
        [0.0582, 0.0668],
        [0.0602, 0.0647],
        [0.0587, 0.0663],
        [0.0649, 0.0600],
        [0.0620, 0.0627]], device='cuda:0')
 Batch: 3 of active classification Duration: 0:00:00.355420
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0009],
        [0.0003, 0.0007],
        [0.0004, 0.0009],
        [0.0002, 0.0005],
        [0.0001, 0.0003],
        [0.0003, 0.0005],
        [0.0001, 0.0004],
        [0.0006, 0.0017],
        [0.0002, 0.0005],
        [0.0005, 0.0011],
        [0.0005, 0.0010],
        [0.0005, 0.0013],
        [0.0003, 0.0009],
        [0.0002, 0.0005],
        [0.0004, 0.0008],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0608, 0.0642],
        [0.0605, 0.0645],
        [0.0637, 0.0613],
        [0.0622, 0.0627],
        [0.0620, 0.0629],
        [0.0672, 0.0580],
        [0.0596, 0.0655],
        [0.0612, 0.0637],
        [0.0641, 0.0609],
        [0.0617, 0.0632],
        [0.0641, 0.0609],
        [0.0626, 0.0623],
        [0.0600, 0.0650],
        [0.0612, 0.0638],
        [0.0643, 0.0607],
        [0.0646, 0.0605]], device='cuda:0')
 Batch: 4 of active classification Duration: 0:00:00.411413
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0017],
        [0.0003, 0.0008],
        [0.0006, 0.0013],
        [0.0005, 0.0009],
        [0.0004, 0.0013],
        [0.0007, 0.0013],
        [0.0005, 0.0009],
        [0.0003, 0.0007],
        [0.0004, 0.0013],
        [0.0004, 0.0012],
        [0.0007, 0.0016],
        [0.0009, 0.0013],
        [0.0003, 0.0009],
        [0.0002, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0576, 0.0677],
        [0.0613, 0.0636],
        [0.0640, 0.0609],
        [0.0665, 0.0586],
        [0.0598, 0.0651],
        [0.0660, 0.0590],
        [0.0661, 0.0589],
        [0.0630, 0.0618],
        [0.0588, 0.0663],
        [0.0600, 0.0649],
        [0.0632, 0.0616],
        [0.0692, 0.0563],
        [0.0603, 0.0646],
        [0.0593, 0.0657],
        [0.0634, 0.0614],
        [0.0614, 0.0635]], device='cuda:0')
 Batch: 5 of active classification Duration: 0:00:00.324216
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0004, 0.0011],
        [0.0005, 0.0011],
        [0.0002, 0.0005],
        [0.0005, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0009],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0008, 0.0019],
        [0.0005, 0.0017],
        [0.0005, 0.0013],
        [0.0002, 0.0007],
        [0.0004, 0.0004],
        [0.0007, 0.0011],
        [0.0005, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0610, 0.0638],
        [0.0593, 0.0656],
        [0.0624, 0.0623],
        [0.0612, 0.0636],
        [0.0690, 0.0564],
        [0.0635, 0.0612],
        [0.0594, 0.0655],
        [0.0643, 0.0605],
        [0.0618, 0.0629],
        [0.0617, 0.0630],
        [0.0570, 0.0683],
        [0.0601, 0.0647],
        [0.0581, 0.0669],
        [0.0729, 0.0534],
        [0.0668, 0.0582],
        [0.0613, 0.0635]], device='cuda:0')
 Batch: 6 of active classification Duration: 0:00:00.387781
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0012],
        [0.0002, 0.0004],
        [0.0007, 0.0009],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0004, 0.0010],
        [0.0011, 0.0021],
        [0.0005, 0.0009],
        [0.0005, 0.0008],
        [0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0006, 0.0011],
        [0.0003, 0.0010],
        [0.0004, 0.0013],
        [0.0004, 0.0010],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0577, 0.0674],
        [0.0631, 0.0617],
        [0.0697, 0.0559],
        [0.0659, 0.0591],
        [0.0615, 0.0633],
        [0.0609, 0.0639],
        [0.0642, 0.0607],
        [0.0664, 0.0587],
        [0.0664, 0.0586],
        [0.0569, 0.0684],
        [0.0614, 0.0634],
        [0.0645, 0.0604],
        [0.0577, 0.0675],
        [0.0575, 0.0677],
        [0.0607, 0.0641],
        [0.0657, 0.0593]], device='cuda:0')
 Batch: 7 of active classification Duration: 0:00:00.428580
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0005, 0.0015],
        [0.0004, 0.0008],
        [0.0007, 0.0016],
        [0.0004, 0.0010],
        [0.0004, 0.0009],
        [0.0004, 0.0009],
        [0.0003, 0.0010],
        [0.0001, 0.0005],
        [0.0004, 0.0009],
        [0.0007, 0.0010],
        [0.0002, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0621, 0.0628],
        [0.0641, 0.0608],
        [0.0646, 0.0603],
        [0.0638, 0.0611],
        [0.0634, 0.0615],
        [0.0587, 0.0664],
        [0.0634, 0.0615],
        [0.0626, 0.0623],
        [0.0617, 0.0632],
        [0.0635, 0.0614],
        [0.0621, 0.0628],
        [0.0596, 0.0654],
        [0.0583, 0.0669],
        [0.0618, 0.0631],
        [0.0707, 0.0551],
        [0.0596, 0.0654]], device='cuda:0')
 Batch: 8 of active classification Duration: 0:00:00.397242
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0002, 0.0006],
        [0.0004, 0.0009],
        [0.0002, 0.0006],
        [0.0003, 0.0010],
        [0.0002, 0.0007],
        [0.0003, 0.0006],
        [0.0005, 0.0008],
        [0.0002, 0.0004],
        [0.0004, 0.0010],
        [0.0002, 0.0005],
        [0.0004, 0.0006],
        [0.0004, 0.0010],
        [0.0003, 0.0008],
        [0.0005, 0.0012],
        [0.0004, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0653, 0.0597],
        [0.0599, 0.0651],
        [0.0637, 0.0612],
        [0.0624, 0.0625],
        [0.0598, 0.0652],
        [0.0587, 0.0665],
        [0.0636, 0.0613],
        [0.0675, 0.0577],
        [0.0637, 0.0612],
        [0.0606, 0.0644],
        [0.0600, 0.0650],
        [0.0667, 0.0585],
        [0.0635, 0.0614],
        [0.0624, 0.0625],
        [0.0625, 0.0624],
        [0.0597, 0.0654]], device='cuda:0')
 Batch: 9 of active classification Duration: 0:00:00.524482
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0014],
        [0.0003, 0.0006],
        [0.0007, 0.0016],
        [0.0003, 0.0007],
        [0.0010, 0.0015],
        [0.0005, 0.0013],
        [0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0004, 0.0009],
        [0.0002, 0.0005],
        [0.0005, 0.0009],
        [0.0006, 0.0011],
        [0.0004, 0.0009],
        [0.0004, 0.0010],
        [0.0003, 0.0011],
        [0.0007, 0.0021]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626]], device='cuda:0')
tensor([[0.0625, 0.0624],
        [0.0631, 0.0618],
        [0.0618, 0.0631],
        [0.0631, 0.0618],
        [0.0699, 0.0558],
        [0.0607, 0.0642],
        [0.0623, 0.0626],
        [0.0609, 0.0640],
        [0.0646, 0.0603],
        [0.0620, 0.0629],
        [0.0650, 0.0600],
        [0.0654, 0.0596],
        [0.0611, 0.0638],
        [0.0601, 0.0649],
        [0.0572, 0.0682],
        [0.0603, 0.0647]], device='cuda:0')
 Batch: 10 of active classification Duration: 0:00:00.283416
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0007, 0.0019],
        [0.0003, 0.0008],
        [0.0008, 0.0019],
        [0.0008, 0.0017],
        [0.0005, 0.0012],
        [0.0003, 0.0009],
        [0.0003, 0.0005],
        [0.0004, 0.0011],
        [0.0007, 0.0011],
        [0.0007, 0.0015],
        [0.0007, 0.0016],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0004, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0642, 0.0608],
        [0.0607, 0.0643],
        [0.0603, 0.0647],
        [0.0621, 0.0629],
        [0.0641, 0.0609],
        [0.0613, 0.0637],
        [0.0615, 0.0635],
        [0.0646, 0.0604],
        [0.0616, 0.0634],
        [0.0674, 0.0579],
        [0.0635, 0.0614],
        [0.0631, 0.0618],
        [0.0618, 0.0631],
        [0.0605, 0.0645],
        [0.0618, 0.0632],
        [0.0614, 0.0636]], device='cuda:0')
 Batch: 11 of active classification Duration: 0:00:00.347839
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0009],
        [0.0004, 0.0008],
        [0.0005, 0.0011],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0001, 0.0005],
        [0.0004, 0.0008],
        [0.0008, 0.0017]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1249],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1251, 0.1251]], device='cuda:0')
tensor([[0.1205, 0.1295],
        [0.1274, 0.1225],
        [0.1270, 0.1229],
        [0.1257, 0.1241],
        [0.1245, 0.1253],
        [0.1164, 0.1341],
        [0.1296, 0.1204],
        [0.1287, 0.1212]], device='cuda:0')
 Batch: 12 of active classification Duration: 0:00:00.184153
acc:  0.545
Time taken to execute the en SA task with prompt type active, variation 3 and batchsize 16: 0:00:04.819432
path ['42', 'en', 'bloom-big', 'SA', 'active', 'prompt_id_3']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([99, 2])
answers_probs just softmax dim 0: tensor([[0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101]], device='cuda:0')
tensor([[0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101],
        [0.0101, 0.0101]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA active 4 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0004, 0.0011],
        [0.0003, 0.0011],
        [0.0002, 0.0009],
        [0.0002, 0.0003],
        [0.0002, 0.0005],
        [0.0004, 0.0005],
        [0.0006, 0.0009],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0001, 0.0003],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0621, 0.0626],
        [0.0666, 0.0584],
        [0.0655, 0.0594],
        [0.0612, 0.0635],
        [0.0601, 0.0647],
        [0.0588, 0.0661],
        [0.0571, 0.0682],
        [0.0545, 0.0713],
        [0.0642, 0.0606],
        [0.0608, 0.0640],
        [0.0694, 0.0560],
        [0.0670, 0.0581],
        [0.0628, 0.0620],
        [0.0658, 0.0592],
        [0.0581, 0.0669],
        [0.0658, 0.0591]], device='cuda:0')
 Batch: 0 of active classification Duration: 0:00:00.351864
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0002, 0.0003],
        [0.0002, 0.0007],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0005, 0.0012],
        [0.0004, 0.0008],
        [0.0004, 0.0011],
        [0.0003, 0.0006],
        [0.0009, 0.0019],
        [0.0001, 0.0003],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0667, 0.0585],
        [0.0641, 0.0608],
        [0.0659, 0.0591],
        [0.0630, 0.0618],
        [0.0564, 0.0691],
        [0.0634, 0.0614],
        [0.0614, 0.0635],
        [0.0592, 0.0658],
        [0.0580, 0.0672],
        [0.0609, 0.0640],
        [0.0624, 0.0625],
        [0.0589, 0.0662],
        [0.0659, 0.0591],
        [0.0632, 0.0616],
        [0.0638, 0.0611],
        [0.0668, 0.0583]], device='cuda:0')
 Batch: 1 of active classification Duration: 0:00:00.391183
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0001, 0.0004],
        [0.0003, 0.0010],
        [0.0001, 0.0004],
        [0.0003, 0.0008],
        [0.0004, 0.0016],
        [0.0004, 0.0005],
        [0.0002, 0.0007],
        [0.0004, 0.0006],
        [0.0002, 0.0007],
        [0.0002, 0.0005],
        [0.0005, 0.0013],
        [0.0003, 0.0009],
        [0.0004, 0.0004],
        [0.0003, 0.0009],
        [0.0006, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0702, 0.0552],
        [0.0594, 0.0653],
        [0.0582, 0.0666],
        [0.0587, 0.0660],
        [0.0594, 0.0653],
        [0.0571, 0.0678],
        [0.0698, 0.0555],
        [0.0572, 0.0677],
        [0.0681, 0.0569],
        [0.0565, 0.0686],
        [0.0618, 0.0626],
        [0.0597, 0.0649],
        [0.0576, 0.0672],
        [0.0737, 0.0526],
        [0.0601, 0.0645],
        [0.0724, 0.0535]], device='cuda:0')
 Batch: 2 of active classification Duration: 0:00:00.432145
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[2.3973e-04, 4.3392e-04],
        [5.4455e-04, 1.1711e-03],
        [2.7156e-04, 9.6989e-04],
        [1.8585e-04, 3.7813e-04],
        [3.6073e-04, 9.1410e-04],
        [3.5191e-04, 1.0424e-03],
        [2.0194e-04, 4.8089e-04],
        [1.1557e-04, 1.7214e-04],
        [7.0393e-05, 1.2159e-04],
        [3.2663e-04, 1.1673e-03],
        [8.9407e-04, 2.3003e-03],
        [3.0756e-04, 9.9277e-04],
        [2.8968e-04, 7.0620e-04],
        [1.7428e-04, 4.8876e-04],
        [5.7030e-04, 1.3895e-03],
        [3.3307e-04, 9.8705e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0666, 0.0585],
        [0.0641, 0.0608],
        [0.0581, 0.0671],
        [0.0649, 0.0600],
        [0.0619, 0.0629],
        [0.0601, 0.0649],
        [0.0627, 0.0621],
        [0.0697, 0.0559],
        [0.0673, 0.0579],
        [0.0581, 0.0671],
        [0.0617, 0.0631],
        [0.0591, 0.0659],
        [0.0624, 0.0624],
        [0.0607, 0.0642],
        [0.0624, 0.0624],
        [0.0601, 0.0649]], device='cuda:0')
 Batch: 3 of active classification Duration: 0:00:00.303179
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[2.6536e-04, 7.2098e-04],
        [2.9922e-04, 8.4543e-04],
        [4.3058e-04, 9.2602e-04],
        [2.9540e-04, 5.9223e-04],
        [1.4484e-04, 1.8966e-04],
        [1.9956e-04, 3.4070e-04],
        [3.1614e-04, 8.7309e-04],
        [1.7548e-04, 3.9244e-04],
        [2.1958e-04, 6.5041e-04],
        [4.2963e-04, 7.5436e-04],
        [7.5817e-05, 8.2970e-05],
        [3.6049e-04, 1.1015e-03],
        [2.4581e-04, 5.0020e-04],
        [3.8457e-04, 8.8739e-04],
        [2.7561e-04, 9.2554e-04],
        [3.2330e-04, 8.7881e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0596, 0.0652],
        [0.0591, 0.0657],
        [0.0626, 0.0622],
        [0.0635, 0.0612],
        [0.0702, 0.0554],
        [0.0659, 0.0590],
        [0.0594, 0.0655],
        [0.0620, 0.0627],
        [0.0586, 0.0663],
        [0.0655, 0.0594],
        [0.0734, 0.0530],
        [0.0583, 0.0667],
        [0.0633, 0.0614],
        [0.0616, 0.0631],
        [0.0573, 0.0679],
        [0.0596, 0.0653]], device='cuda:0')
 Batch: 4 of active classification Duration: 0:00:00.435725
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0009],
        [0.0002, 0.0004],
        [0.0002, 0.0002],
        [0.0004, 0.0010],
        [0.0002, 0.0006],
        [0.0002, 0.0006],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0002],
        [0.0004, 0.0005],
        [0.0003, 0.0011],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0572, 0.0679],
        [0.0604, 0.0644],
        [0.0726, 0.0535],
        [0.0590, 0.0658],
        [0.0609, 0.0637],
        [0.0599, 0.0649],
        [0.0654, 0.0594],
        [0.0622, 0.0625],
        [0.0634, 0.0612],
        [0.0729, 0.0533],
        [0.0687, 0.0565],
        [0.0574, 0.0677],
        [0.0613, 0.0633],
        [0.0607, 0.0640],
        [0.0603, 0.0645],
        [0.0576, 0.0674]], device='cuda:0')
 Batch: 5 of active classification Duration: 0:00:00.413126
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0010],
        [0.0004, 0.0009],
        [0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0002, 0.0003],
        [0.0002, 0.0002],
        [0.0001, 0.0006],
        [0.0002, 0.0004],
        [0.0004, 0.0012],
        [0.0003, 0.0007],
        [0.0005, 0.0010],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0583, 0.0668],
        [0.0620, 0.0628],
        [0.0658, 0.0592],
        [0.0645, 0.0604],
        [0.0629, 0.0619],
        [0.0701, 0.0555],
        [0.0548, 0.0711],
        [0.0660, 0.0590],
        [0.0586, 0.0664],
        [0.0590, 0.0660],
        [0.0634, 0.0613],
        [0.0654, 0.0595],
        [0.0633, 0.0615],
        [0.0650, 0.0598],
        [0.0617, 0.0630],
        [0.0592, 0.0657]], device='cuda:0')
 Batch: 6 of active classification Duration: 0:00:00.530862
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0002, 0.0003],
        [0.0001, 0.0005],
        [0.0001, 0.0002],
        [0.0001, 0.0004],
        [0.0003, 0.0008],
        [0.0004, 0.0007],
        [0.0002, 0.0006],
        [0.0004, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0607, 0.0641],
        [0.0601, 0.0648],
        [0.0633, 0.0615],
        [0.0618, 0.0629],
        [0.0602, 0.0647],
        [0.0614, 0.0634],
        [0.0629, 0.0618],
        [0.0586, 0.0664],
        [0.0698, 0.0558],
        [0.0582, 0.0669],
        [0.0740, 0.0526],
        [0.0583, 0.0668],
        [0.0634, 0.0614],
        [0.0652, 0.0596],
        [0.0603, 0.0645],
        [0.0619, 0.0628]], device='cuda:0')
 Batch: 7 of active classification Duration: 0:00:00.391041
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0001, 0.0002],
        [0.0001, 0.0001],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0004, 0.0011],
        [0.0003, 0.0004],
        [0.0002, 0.0003],
        [0.0004, 0.0013],
        [0.0002, 0.0003],
        [0.0001, 0.0001],
        [0.0001, 0.0002],
        [0.0004, 0.0015],
        [0.0003, 0.0009],
        [0.0002, 0.0006],
        [0.0004, 0.0012],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0637, 0.0609],
        [0.0726, 0.0535],
        [0.0644, 0.0602],
        [0.0629, 0.0616],
        [0.0594, 0.0653],
        [0.0684, 0.0567],
        [0.0678, 0.0572],
        [0.0558, 0.0696],
        [0.0651, 0.0596],
        [0.0704, 0.0551],
        [0.0625, 0.0620],
        [0.0561, 0.0692],
        [0.0573, 0.0677],
        [0.0566, 0.0685],
        [0.0577, 0.0673],
        [0.0592, 0.0655]], device='cuda:0')
 Batch: 8 of active classification Duration: 0:00:00.324126
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0009],
        [0.0003, 0.0010],
        [0.0002, 0.0011],
        [0.0002, 0.0006],
        [0.0004, 0.0008],
        [0.0004, 0.0004],
        [0.0002, 0.0005],
        [0.0005, 0.0011],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0005, 0.0009],
        [0.0001, 0.0002],
        [0.0001, 0.0004],
        [0.0001, 0.0002],
        [0.0003, 0.0007],
        [0.0005, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0579, 0.0671],
        [0.0579, 0.0671],
        [0.0544, 0.0714],
        [0.0604, 0.0643],
        [0.0610, 0.0637],
        [0.0742, 0.0523],
        [0.0608, 0.0639],
        [0.0623, 0.0623],
        [0.0657, 0.0591],
        [0.0648, 0.0600],
        [0.0644, 0.0603],
        [0.0692, 0.0561],
        [0.0603, 0.0644],
        [0.0667, 0.0583],
        [0.0585, 0.0664],
        [0.0615, 0.0632]], device='cuda:0')
 Batch: 9 of active classification Duration: 0:00:00.394553
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0008],
        [0.0001, 0.0005],
        [0.0003, 0.0008],
        [0.0002, 0.0007],
        [0.0001, 0.0002],
        [0.0004, 0.0008],
        [0.0001, 0.0003],
        [0.0002, 0.0004],
        [0.0002, 0.0006],
        [0.0002, 0.0004],
        [0.0001, 0.0005],
        [0.0006, 0.0008],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0007],
        [0.0003, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0544, 0.0712],
        [0.0567, 0.0683],
        [0.0617, 0.0629],
        [0.0568, 0.0682],
        [0.0690, 0.0562],
        [0.0633, 0.0612],
        [0.0658, 0.0589],
        [0.0612, 0.0634],
        [0.0570, 0.0680],
        [0.0679, 0.0571],
        [0.0567, 0.0684],
        [0.0710, 0.0546],
        [0.0677, 0.0573],
        [0.0717, 0.0541],
        [0.0588, 0.0659],
        [0.0603, 0.0643]], device='cuda:0')
 Batch: 10 of active classification Duration: 0:00:00.281278
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0003, 0.0009],
        [0.0001, 0.0002],
        [0.0002, 0.0004],
        [0.0003, 0.0009],
        [0.0002, 0.0004],
        [0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0001, 0.0003],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0010],
        [0.0002, 0.0008],
        [0.0006, 0.0014],
        [0.0003, 0.0010],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0637, 0.0612],
        [0.0614, 0.0635],
        [0.0681, 0.0572],
        [0.0653, 0.0597],
        [0.0610, 0.0639],
        [0.0654, 0.0596],
        [0.0612, 0.0637],
        [0.0589, 0.0661],
        [0.0629, 0.0619],
        [0.0602, 0.0647],
        [0.0657, 0.0593],
        [0.0589, 0.0661],
        [0.0580, 0.0672],
        [0.0623, 0.0626],
        [0.0600, 0.0649],
        [0.0668, 0.0584]], device='cuda:0')
 Batch: 11 of active classification Duration: 0:00:00.411572
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0004, 0.0009],
        [0.0001, 0.0002],
        [0.0002, 0.0006],
        [0.0002, 0.0007],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1249],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1253, 0.1242],
        [0.1213, 0.1284],
        [0.1296, 0.1201],
        [0.1199, 0.1298],
        [0.1133, 0.1373],
        [0.1414, 0.1101],
        [0.1288, 0.1208],
        [0.1203, 0.1294]], device='cuda:0')
 Batch: 12 of active classification Duration: 0:00:00.187298
acc:  0.49
Time taken to execute the en SA task with prompt type active, variation 4 and batchsize 16: 0:00:04.863564
path ['42', 'en', 'bloom-big', 'SA', 'active', 'prompt_id_4']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([114, 2])
answers_probs just softmax dim 0: tensor([[0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088]], device='cuda:0')
tensor([[0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA active 5 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0005, 0.0010],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0007, 0.0009],
        [0.0007, 0.0011],
        [0.0005, 0.0007],
        [0.0005, 0.0008],
        [0.0003, 0.0004],
        [0.0004, 0.0008],
        [0.0005, 0.0008],
        [0.0003, 0.0008],
        [0.0002, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0606, 0.0643],
        [0.0615, 0.0634],
        [0.0620, 0.0629],
        [0.0641, 0.0609],
        [0.0615, 0.0634],
        [0.0641, 0.0609],
        [0.0626, 0.0623],
        [0.0665, 0.0586],
        [0.0645, 0.0604],
        [0.0653, 0.0597],
        [0.0620, 0.0629],
        [0.0641, 0.0609],
        [0.0628, 0.0621],
        [0.0638, 0.0611],
        [0.0586, 0.0666],
        [0.0561, 0.0695]], device='cuda:0')
 Batch: 0 of active classification Duration: 0:00:00.469999
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0008, 0.0017],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0004, 0.0010],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0006, 0.0012],
        [0.0005, 0.0008],
        [0.0007, 0.0014],
        [0.0003, 0.0007],
        [0.0006, 0.0012],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0641, 0.0608],
        [0.0619, 0.0630],
        [0.0607, 0.0643],
        [0.0631, 0.0618],
        [0.0639, 0.0611],
        [0.0592, 0.0659],
        [0.0587, 0.0665],
        [0.0652, 0.0598],
        [0.0663, 0.0589],
        [0.0603, 0.0647],
        [0.0619, 0.0630],
        [0.0650, 0.0601],
        [0.0628, 0.0621],
        [0.0610, 0.0640],
        [0.0622, 0.0627],
        [0.0638, 0.0612]], device='cuda:0')
 Batch: 1 of active classification Duration: 0:00:00.345711
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0008, 0.0011],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0005, 0.0009],
        [0.0004, 0.0012],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0005, 0.0008],
        [0.0003, 0.0007],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0654, 0.0596],
        [0.0567, 0.0687],
        [0.0647, 0.0602],
        [0.0657, 0.0593],
        [0.0638, 0.0611],
        [0.0677, 0.0576],
        [0.0620, 0.0629],
        [0.0593, 0.0658],
        [0.0636, 0.0613],
        [0.0578, 0.0674],
        [0.0596, 0.0654],
        [0.0633, 0.0615],
        [0.0631, 0.0618],
        [0.0638, 0.0611],
        [0.0603, 0.0646],
        [0.0632, 0.0617]], device='cuda:0')
 Batch: 2 of active classification Duration: 0:00:00.349954
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0007, 0.0016],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0005, 0.0010],
        [0.0003, 0.0007],
        [0.0008, 0.0016],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0002, 0.0006],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0636, 0.0613],
        [0.0625, 0.0624],
        [0.0636, 0.0613],
        [0.0600, 0.0650],
        [0.0615, 0.0635],
        [0.0633, 0.0617],
        [0.0613, 0.0636],
        [0.0643, 0.0607],
        [0.0623, 0.0626],
        [0.0620, 0.0630],
        [0.0612, 0.0637],
        [0.0654, 0.0597],
        [0.0616, 0.0634],
        [0.0646, 0.0605],
        [0.0596, 0.0655],
        [0.0631, 0.0619]], device='cuda:0')
 Batch: 3 of active classification Duration: 0:00:00.525669
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0003, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0006, 0.0013],
        [0.0003, 0.0006],
        [0.0013, 0.0017],
        [0.0009, 0.0016],
        [0.0002, 0.0005],
        [0.0004, 0.0008],
        [0.0006, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0002, 0.0006],
        [0.0002, 0.0004],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0626, 0.0626],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0619, 0.0631],
        [0.0596, 0.0655],
        [0.0618, 0.0632],
        [0.0637, 0.0613],
        [0.0598, 0.0652],
        [0.0618, 0.0632],
        [0.0678, 0.0575],
        [0.0630, 0.0619],
        [0.0617, 0.0632],
        [0.0623, 0.0626],
        [0.0647, 0.0603],
        [0.0603, 0.0647],
        [0.0664, 0.0587],
        [0.0590, 0.0661],
        [0.0624, 0.0625],
        [0.0639, 0.0611]], device='cuda:0')
 Batch: 4 of active classification Duration: 0:00:00.330964
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0004, 0.0006],
        [0.0005, 0.0011],
        [0.0008, 0.0014],
        [0.0008, 0.0012],
        [0.0009, 0.0011],
        [0.0005, 0.0012],
        [0.0003, 0.0008],
        [0.0003, 0.0009],
        [0.0004, 0.0006],
        [0.0004, 0.0013],
        [0.0005, 0.0009],
        [0.0005, 0.0008],
        [0.0004, 0.0007],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0590, 0.0660],
        [0.0627, 0.0621],
        [0.0653, 0.0597],
        [0.0620, 0.0629],
        [0.0635, 0.0613],
        [0.0675, 0.0577],
        [0.0688, 0.0566],
        [0.0598, 0.0651],
        [0.0594, 0.0656],
        [0.0578, 0.0673],
        [0.0631, 0.0618],
        [0.0565, 0.0690],
        [0.0631, 0.0618],
        [0.0649, 0.0600],
        [0.0627, 0.0621],
        [0.0638, 0.0611]], device='cuda:0')
 Batch: 5 of active classification Duration: 0:00:00.395395
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0002, 0.0007],
        [0.0006, 0.0009],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0005, 0.0011],
        [0.0005, 0.0009],
        [0.0004, 0.0010],
        [0.0004, 0.0009],
        [0.0006, 0.0009],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0615, 0.0634],
        [0.0579, 0.0673],
        [0.0666, 0.0586],
        [0.0634, 0.0616],
        [0.0617, 0.0632],
        [0.0617, 0.0632],
        [0.0641, 0.0609],
        [0.0614, 0.0635],
        [0.0613, 0.0636],
        [0.0625, 0.0624],
        [0.0588, 0.0664],
        [0.0618, 0.0631],
        [0.0655, 0.0596],
        [0.0617, 0.0632],
        [0.0649, 0.0601],
        [0.0652, 0.0598]], device='cuda:0')
 Batch: 6 of active classification Duration: 0:00:00.389567
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0002, 0.0003],
        [0.0006, 0.0012],
        [0.0004, 0.0006],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0004, 0.0011],
        [0.0002, 0.0004],
        [0.0002, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0007, 0.0009],
        [0.0004, 0.0006],
        [0.0003, 0.0007],
        [0.0006, 0.0009],
        [0.0006, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0639, 0.0609],
        [0.0654, 0.0596],
        [0.0628, 0.0620],
        [0.0648, 0.0602],
        [0.0617, 0.0631],
        [0.0614, 0.0635],
        [0.0572, 0.0681],
        [0.0616, 0.0632],
        [0.0581, 0.0671],
        [0.0601, 0.0649],
        [0.0606, 0.0643],
        [0.0692, 0.0563],
        [0.0646, 0.0603],
        [0.0599, 0.0651],
        [0.0672, 0.0580],
        [0.0614, 0.0635]], device='cuda:0')
 Batch: 7 of active classification Duration: 0:00:00.386333
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0004, 0.0005],
        [0.0005, 0.0010],
        [0.0004, 0.0010],
        [0.0010, 0.0015],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0006, 0.0014],
        [0.0003, 0.0008],
        [0.0007, 0.0008],
        [0.0006, 0.0018],
        [0.0005, 0.0009],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0637, 0.0611],
        [0.0688, 0.0566],
        [0.0632, 0.0617],
        [0.0592, 0.0658],
        [0.0653, 0.0597],
        [0.0625, 0.0624],
        [0.0607, 0.0642],
        [0.0627, 0.0621],
        [0.0611, 0.0638],
        [0.0606, 0.0643],
        [0.0607, 0.0642],
        [0.0596, 0.0654],
        [0.0694, 0.0562],
        [0.0568, 0.0686],
        [0.0635, 0.0614],
        [0.0623, 0.0626]], device='cuda:0')
 Batch: 8 of active classification Duration: 0:00:00.281827
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0005, 0.0009],
        [0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0002, 0.0006],
        [0.0005, 0.0015],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0617, 0.0632],
        [0.0643, 0.0607],
        [0.0601, 0.0649],
        [0.0657, 0.0594],
        [0.0628, 0.0621],
        [0.0600, 0.0650],
        [0.0581, 0.0672],
        [0.0623, 0.0626],
        [0.0607, 0.0643],
        [0.0654, 0.0596],
        [0.0612, 0.0638],
        [0.0621, 0.0628],
        [0.0649, 0.0602],
        [0.0612, 0.0638],
        [0.0638, 0.0611],
        [0.0657, 0.0594]], device='cuda:0')
 Batch: 9 of active classification Duration: 0:00:00.324930
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0006, 0.0008],
        [0.0003, 0.0008],
        [0.0006, 0.0013],
        [0.0004, 0.0012],
        [0.0006, 0.0011],
        [0.0003, 0.0005],
        [0.0006, 0.0014],
        [0.0004, 0.0011],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0007, 0.0011],
        [0.0004, 0.0005],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0632, 0.0617],
        [0.0685, 0.0569],
        [0.0580, 0.0672],
        [0.0622, 0.0626],
        [0.0571, 0.0682],
        [0.0625, 0.0623],
        [0.0634, 0.0614],
        [0.0614, 0.0635],
        [0.0604, 0.0645],
        [0.0661, 0.0589],
        [0.0602, 0.0648],
        [0.0604, 0.0645],
        [0.0618, 0.0631],
        [0.0648, 0.0601],
        [0.0689, 0.0565],
        [0.0612, 0.0637]], device='cuda:0')
 Batch: 10 of active classification Duration: 0:00:00.414406
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0005, 0.0010],
        [0.0003, 0.0007],
        [0.0011, 0.0017],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0004, 0.0008],
        [0.0005, 0.0011],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0006, 0.0019],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0645, 0.0604],
        [0.0711, 0.0548],
        [0.0643, 0.0606],
        [0.0608, 0.0641],
        [0.0658, 0.0592],
        [0.0622, 0.0626],
        [0.0609, 0.0640],
        [0.0633, 0.0615],
        [0.0609, 0.0640],
        [0.0646, 0.0603],
        [0.0598, 0.0652],
        [0.0566, 0.0688],
        [0.0626, 0.0623],
        [0.0596, 0.0654],
        [0.0621, 0.0627],
        [0.0609, 0.0640]], device='cuda:0')
 Batch: 11 of active classification Duration: 0:00:00.433879
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0004, 0.0009],
        [0.0003, 0.0003],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0002, 0.0005],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1166, 0.1334],
        [0.1228, 0.1266],
        [0.1237, 0.1258],
        [0.1450, 0.1073],
        [0.1277, 0.1218],
        [0.1281, 0.1214],
        [0.1152, 0.1351],
        [0.1210, 0.1286]], device='cuda:0')
 Batch: 12 of active classification Duration: 0:00:00.219993
acc:  0.535
Time taken to execute the en SA task with prompt type active, variation 5 and batchsize 16: 0:00:04.885454
path ['42', 'en', 'bloom-big', 'SA', 'active', 'prompt_id_5']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([109, 2])
answers_probs just softmax dim 0: tensor([[0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092]], device='cuda:0')
tensor([[0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA active 6 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0001, 0.0003],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0001, 0.0003],
        [0.0002, 0.0004],
        [0.0002, 0.0007],
        [0.0003, 0.0005],
        [0.0001, 0.0003],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0599, 0.0650],
        [0.0656, 0.0594],
        [0.0621, 0.0628],
        [0.0604, 0.0645],
        [0.0640, 0.0609],
        [0.0637, 0.0613],
        [0.0630, 0.0619],
        [0.0617, 0.0632],
        [0.0657, 0.0593],
        [0.0682, 0.0572],
        [0.0637, 0.0613],
        [0.0618, 0.0631],
        [0.0574, 0.0679],
        [0.0628, 0.0621],
        [0.0585, 0.0667],
        [0.0614, 0.0635]], device='cuda:0')
 Batch: 0 of active classification Duration: 0:00:00.402820
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[3.4547e-04, 6.2084e-04],
        [2.3031e-04, 5.2738e-04],
        [1.1110e-04, 2.3699e-04],
        [8.3029e-05, 1.8060e-04],
        [2.8586e-04, 5.9128e-04],
        [1.4389e-04, 2.9993e-04],
        [1.9062e-04, 5.3883e-04],
        [3.7622e-04, 7.6008e-04],
        [1.9145e-04, 5.5838e-04],
        [2.5797e-04, 2.7680e-04],
        [5.5170e-04, 1.3237e-03],
        [3.0971e-04, 8.2874e-04],
        [2.6155e-04, 4.3464e-04],
        [1.3947e-04, 4.7541e-04],
        [3.3188e-04, 6.3992e-04],
        [2.6417e-04, 5.5504e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0648, 0.0601],
        [0.0614, 0.0634],
        [0.0624, 0.0624],
        [0.0621, 0.0627],
        [0.0628, 0.0620],
        [0.0627, 0.0621],
        [0.0589, 0.0661],
        [0.0631, 0.0617],
        [0.0585, 0.0665],
        [0.0735, 0.0530],
        [0.0609, 0.0640],
        [0.0595, 0.0654],
        [0.0660, 0.0590],
        [0.0569, 0.0684],
        [0.0638, 0.0610],
        [0.0626, 0.0622]], device='cuda:0')
 Batch: 1 of active classification Duration: 0:00:00.357696
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0005, 0.0008],
        [0.0003, 0.0007],
        [0.0005, 0.0011],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0004, 0.0007],
        [0.0003, 0.0007],
        [0.0001, 0.0003],
        [0.0001, 0.0002],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0001, 0.0003],
        [0.0003, 0.0006],
        [0.0001, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0609, 0.0640],
        [0.0645, 0.0605],
        [0.0675, 0.0578],
        [0.0600, 0.0651],
        [0.0625, 0.0624],
        [0.0627, 0.0622],
        [0.0625, 0.0624],
        [0.0630, 0.0619],
        [0.0607, 0.0642],
        [0.0588, 0.0664],
        [0.0657, 0.0594],
        [0.0617, 0.0633],
        [0.0653, 0.0597],
        [0.0621, 0.0629],
        [0.0610, 0.0639],
        [0.0611, 0.0638]], device='cuda:0')
 Batch: 2 of active classification Duration: 0:00:00.462751
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0013],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0003, 0.0004],
        [0.0006, 0.0011],
        [0.0001, 0.0003],
        [0.0002, 0.0005],
        [0.0002, 0.0003],
        [0.0006, 0.0008],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0005, 0.0011],
        [0.0002, 0.0004],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0603, 0.0647],
        [0.0616, 0.0633],
        [0.0609, 0.0641],
        [0.0649, 0.0601],
        [0.0642, 0.0607],
        [0.0590, 0.0661],
        [0.0619, 0.0630],
        [0.0624, 0.0625],
        [0.0684, 0.0570],
        [0.0642, 0.0607],
        [0.0651, 0.0599],
        [0.0653, 0.0598],
        [0.0625, 0.0624],
        [0.0602, 0.0648],
        [0.0605, 0.0645],
        [0.0587, 0.0665]], device='cuda:0')
 Batch: 3 of active classification Duration: 0:00:00.346986
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0001, 0.0003],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0006],
        [0.0002, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0006, 0.0013],
        [0.0003, 0.0006],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0682, 0.0572],
        [0.0609, 0.0640],
        [0.0602, 0.0648],
        [0.0612, 0.0637],
        [0.0668, 0.0584],
        [0.0638, 0.0612],
        [0.0619, 0.0630],
        [0.0605, 0.0644],
        [0.0588, 0.0663],
        [0.0618, 0.0631],
        [0.0591, 0.0660],
        [0.0619, 0.0630],
        [0.0662, 0.0589],
        [0.0621, 0.0628],
        [0.0634, 0.0615],
        [0.0630, 0.0619]], device='cuda:0')
 Batch: 4 of active classification Duration: 0:00:00.326671
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0011],
        [0.0004, 0.0009],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0002, 0.0007],
        [0.0001, 0.0003],
        [0.0002, 0.0003],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0623, 0.0626],
        [0.0613, 0.0636],
        [0.0612, 0.0637],
        [0.0622, 0.0627],
        [0.0574, 0.0679],
        [0.0627, 0.0623],
        [0.0641, 0.0609],
        [0.0635, 0.0614],
        [0.0619, 0.0630],
        [0.0595, 0.0655],
        [0.0619, 0.0630],
        [0.0637, 0.0612],
        [0.0658, 0.0593],
        [0.0650, 0.0600],
        [0.0650, 0.0601],
        [0.0623, 0.0627]], device='cuda:0')
 Batch: 5 of active classification Duration: 0:00:00.350567
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[2.7180e-04, 5.3215e-04],
        [1.5020e-04, 2.1851e-04],
        [2.3389e-04, 5.0688e-04],
        [3.6836e-04, 8.6308e-04],
        [3.6836e-04, 8.0442e-04],
        [8.7678e-05, 2.8419e-04],
        [2.3818e-04, 7.5102e-04],
        [1.4222e-04, 3.7169e-04],
        [1.5032e-04, 3.0136e-04],
        [4.1556e-04, 1.3523e-03],
        [2.8658e-04, 5.6124e-04],
        [9.3579e-05, 1.8036e-04],
        [2.3305e-04, 7.0667e-04],
        [2.5678e-04, 5.8317e-04],
        [1.8060e-04, 4.5037e-04],
        [1.6081e-04, 3.5954e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0648, 0.0602],
        [0.0694, 0.0562],
        [0.0633, 0.0616],
        [0.0623, 0.0626],
        [0.0632, 0.0617],
        [0.0585, 0.0667],
        [0.0588, 0.0663],
        [0.0609, 0.0640],
        [0.0644, 0.0605],
        [0.0584, 0.0667],
        [0.0648, 0.0602],
        [0.0650, 0.0600],
        [0.0592, 0.0659],
        [0.0627, 0.0622],
        [0.0615, 0.0634],
        [0.0629, 0.0620]], device='cuda:0')
 Batch: 6 of active classification Duration: 0:00:00.544417
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0005, 0.0012],
        [0.0003, 0.0007],
        [0.0004, 0.0010],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0002, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0004, 0.0009],
        [0.0001, 0.0005],
        [0.0002, 0.0004],
        [0.0004, 0.0015]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626]], device='cuda:0')
tensor([[0.0650, 0.0600],
        [0.0625, 0.0623],
        [0.0613, 0.0636],
        [0.0599, 0.0651],
        [0.0625, 0.0623],
        [0.0628, 0.0621],
        [0.0632, 0.0617],
        [0.0638, 0.0611],
        [0.0589, 0.0661],
        [0.0666, 0.0585],
        [0.0659, 0.0592],
        [0.0635, 0.0614],
        [0.0631, 0.0618],
        [0.0583, 0.0669],
        [0.0651, 0.0599],
        [0.0576, 0.0677]], device='cuda:0')
 Batch: 7 of active classification Duration: 0:00:00.414912
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0003, 0.0009],
        [0.0003, 0.0004],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0003],
        [0.0002, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0005, 0.0008],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0619, 0.0630],
        [0.0584, 0.0667],
        [0.0697, 0.0559],
        [0.0587, 0.0664],
        [0.0605, 0.0644],
        [0.0665, 0.0586],
        [0.0570, 0.0683],
        [0.0634, 0.0614],
        [0.0618, 0.0631],
        [0.0611, 0.0638],
        [0.0650, 0.0599],
        [0.0618, 0.0631],
        [0.0646, 0.0604],
        [0.0661, 0.0589],
        [0.0602, 0.0648],
        [0.0635, 0.0613]], device='cuda:0')
 Batch: 8 of active classification Duration: 0:00:00.350763
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0009],
        [0.0001, 0.0002],
        [0.0003, 0.0008],
        [0.0001, 0.0003],
        [0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0003, 0.0010],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0005, 0.0007],
        [0.0003, 0.0006],
        [0.0009, 0.0015],
        [0.0001, 0.0002]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0624, 0.0624],
        [0.0652, 0.0597],
        [0.0599, 0.0650],
        [0.0625, 0.0623],
        [0.0592, 0.0658],
        [0.0610, 0.0639],
        [0.0604, 0.0645],
        [0.0689, 0.0566],
        [0.0556, 0.0700],
        [0.0626, 0.0622],
        [0.0611, 0.0638],
        [0.0614, 0.0635],
        [0.0680, 0.0573],
        [0.0620, 0.0628],
        [0.0660, 0.0591],
        [0.0638, 0.0610]], device='cuda:0')
 Batch: 9 of active classification Duration: 0:00:00.244274
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0003, 0.0007],
        [0.0004, 0.0010],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0003, 0.0008],
        [0.0004, 0.0010],
        [0.0004, 0.0008],
        [0.0005, 0.0008],
        [0.0003, 0.0007],
        [0.0001, 0.0002],
        [0.0003, 0.0007],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0695, 0.0561],
        [0.0588, 0.0663],
        [0.0616, 0.0633],
        [0.0602, 0.0647],
        [0.0627, 0.0621],
        [0.0638, 0.0611],
        [0.0631, 0.0618],
        [0.0610, 0.0639],
        [0.0603, 0.0646],
        [0.0603, 0.0646],
        [0.0632, 0.0617],
        [0.0668, 0.0584],
        [0.0626, 0.0622],
        [0.0666, 0.0585],
        [0.0594, 0.0656],
        [0.0601, 0.0648]], device='cuda:0')
 Batch: 10 of active classification Duration: 0:00:00.436080
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0011],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0006, 0.0013],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0003, 0.0009],
        [0.0004, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0620, 0.0628],
        [0.0625, 0.0623],
        [0.0568, 0.0686],
        [0.0588, 0.0662],
        [0.0578, 0.0675],
        [0.0628, 0.0621],
        [0.0637, 0.0611],
        [0.0641, 0.0608],
        [0.0631, 0.0618],
        [0.0629, 0.0620],
        [0.0650, 0.0600],
        [0.0627, 0.0622],
        [0.0706, 0.0552],
        [0.0650, 0.0600],
        [0.0600, 0.0650],
        [0.0623, 0.0625]], device='cuda:0')
 Batch: 11 of active classification Duration: 0:00:00.308339
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0002, 0.0003],
        [0.0002, 0.0005],
        [0.0004, 0.0012],
        [0.0005, 0.0008],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1319, 0.1183],
        [0.1292, 0.1207],
        [0.1184, 0.1317],
        [0.1154, 0.1352],
        [0.1295, 0.1205],
        [0.1249, 0.1249],
        [0.1265, 0.1233],
        [0.1243, 0.1255]], device='cuda:0')
 Batch: 12 of active classification Duration: 0:00:00.173641
acc:  0.52
Time taken to execute the en SA task with prompt type active, variation 6 and batchsize 16: 0:00:04.736164
path ['42', 'en', 'bloom-big', 'SA', 'active', 'prompt_id_6']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([156, 2])
answers_probs just softmax dim 0: tensor([[0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064]], device='cuda:0')
tensor([[0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064],
        [0.0064, 0.0064]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA active 7 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0006, 0.0010],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0005, 0.0008],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0005, 0.0009],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0006, 0.0009],
        [0.0002, 0.0005],
        [0.0004, 0.0005],
        [0.0005, 0.0008],
        [0.0007, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0631, 0.0618],
        [0.0634, 0.0615],
        [0.0583, 0.0668],
        [0.0591, 0.0660],
        [0.0622, 0.0626],
        [0.0664, 0.0587],
        [0.0609, 0.0640],
        [0.0620, 0.0629],
        [0.0598, 0.0652],
        [0.0617, 0.0632],
        [0.0583, 0.0668],
        [0.0632, 0.0616],
        [0.0613, 0.0635],
        [0.0691, 0.0564],
        [0.0652, 0.0597],
        [0.0659, 0.0592]], device='cuda:0')
 Batch: 0 of active classification Duration: 0:00:00.584325
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0004, 0.0005],
        [0.0001, 0.0003],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0594, 0.0658],
        [0.0632, 0.0618],
        [0.0656, 0.0595],
        [0.0628, 0.0621],
        [0.0608, 0.0642],
        [0.0604, 0.0647],
        [0.0632, 0.0618],
        [0.0634, 0.0616],
        [0.0631, 0.0619],
        [0.0623, 0.0627],
        [0.0633, 0.0617],
        [0.0626, 0.0623],
        [0.0657, 0.0594],
        [0.0604, 0.0647],
        [0.0630, 0.0620],
        [0.0610, 0.0640]], device='cuda:0')
 Batch: 1 of active classification Duration: 0:00:00.328782
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0005, 0.0009],
        [0.0005, 0.0007],
        [0.0002, 0.0007],
        [0.0004, 0.0005],
        [0.0005, 0.0009],
        [0.0005, 0.0010],
        [0.0005, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0005, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0611, 0.0638],
        [0.0623, 0.0626],
        [0.0603, 0.0646],
        [0.0625, 0.0624],
        [0.0630, 0.0619],
        [0.0643, 0.0607],
        [0.0562, 0.0694],
        [0.0688, 0.0566],
        [0.0629, 0.0620],
        [0.0609, 0.0640],
        [0.0654, 0.0596],
        [0.0647, 0.0602],
        [0.0600, 0.0649],
        [0.0654, 0.0596],
        [0.0634, 0.0614],
        [0.0589, 0.0662]], device='cuda:0')
 Batch: 2 of active classification Duration: 0:00:00.439293
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0006, 0.0011],
        [0.0005, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0006, 0.0008],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0006, 0.0009],
        [0.0005, 0.0007],
        [0.0002, 0.0004],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0007, 0.0010],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0610, 0.0640],
        [0.0631, 0.0618],
        [0.0655, 0.0596],
        [0.0593, 0.0658],
        [0.0592, 0.0659],
        [0.0624, 0.0625],
        [0.0658, 0.0592],
        [0.0596, 0.0654],
        [0.0632, 0.0617],
        [0.0641, 0.0608],
        [0.0652, 0.0598],
        [0.0620, 0.0630],
        [0.0620, 0.0630],
        [0.0598, 0.0652],
        [0.0661, 0.0590],
        [0.0616, 0.0633]], device='cuda:0')
 Batch: 3 of active classification Duration: 0:00:00.414445
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0006, 0.0008],
        [0.0006, 0.0008],
        [0.0007, 0.0013],
        [0.0004, 0.0006],
        [0.0005, 0.0008],
        [0.0005, 0.0006],
        [0.0005, 0.0006],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0005, 0.0006],
        [0.0005, 0.0010],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0603, 0.0647],
        [0.0577, 0.0676],
        [0.0641, 0.0609],
        [0.0667, 0.0585],
        [0.0599, 0.0651],
        [0.0622, 0.0627],
        [0.0635, 0.0614],
        [0.0658, 0.0593],
        [0.0673, 0.0579],
        [0.0631, 0.0618],
        [0.0617, 0.0632],
        [0.0644, 0.0605],
        [0.0607, 0.0642],
        [0.0606, 0.0643],
        [0.0617, 0.0632],
        [0.0603, 0.0647]], device='cuda:0')
 Batch: 4 of active classification Duration: 0:00:00.471280
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0007, 0.0010],
        [0.0002, 0.0003],
        [0.0008, 0.0009],
        [0.0002, 0.0005],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0005, 0.0009],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0607, 0.0642],
        [0.0592, 0.0658],
        [0.0583, 0.0668],
        [0.0650, 0.0600],
        [0.0619, 0.0629],
        [0.0691, 0.0564],
        [0.0590, 0.0660],
        [0.0631, 0.0618],
        [0.0636, 0.0612],
        [0.0679, 0.0574],
        [0.0643, 0.0606],
        [0.0608, 0.0642],
        [0.0634, 0.0615],
        [0.0586, 0.0665],
        [0.0617, 0.0631],
        [0.0633, 0.0616]], device='cuda:0')
 Batch: 5 of active classification Duration: 0:00:00.486449
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0002, 0.0003],
        [0.0003, 0.0008],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0006, 0.0008],
        [0.0004, 0.0006],
        [0.0005, 0.0007],
        [0.0005, 0.0008],
        [0.0007, 0.0009],
        [0.0003, 0.0006],
        [0.0007, 0.0010],
        [0.0005, 0.0010],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0571, 0.0683],
        [0.0661, 0.0590],
        [0.0570, 0.0684],
        [0.0649, 0.0600],
        [0.0627, 0.0622],
        [0.0607, 0.0643],
        [0.0602, 0.0647],
        [0.0640, 0.0610],
        [0.0657, 0.0594],
        [0.0643, 0.0606],
        [0.0634, 0.0615],
        [0.0651, 0.0599],
        [0.0610, 0.0639],
        [0.0636, 0.0613],
        [0.0604, 0.0645],
        [0.0641, 0.0608]], device='cuda:0')
 Batch: 6 of active classification Duration: 0:00:00.423003
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0002, 0.0003],
        [0.0004, 0.0007],
        [0.0005, 0.0008],
        [0.0005, 0.0007],
        [0.0004, 0.0010],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0622, 0.0627],
        [0.0596, 0.0654],
        [0.0600, 0.0650],
        [0.0620, 0.0629],
        [0.0632, 0.0617],
        [0.0613, 0.0637],
        [0.0655, 0.0596],
        [0.0620, 0.0629],
        [0.0630, 0.0619],
        [0.0611, 0.0639],
        [0.0614, 0.0636],
        [0.0630, 0.0619],
        [0.0659, 0.0592],
        [0.0670, 0.0582],
        [0.0591, 0.0660],
        [0.0637, 0.0613]], device='cuda:0')
 Batch: 7 of active classification Duration: 0:00:00.440586
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0006, 0.0010],
        [0.0002, 0.0004],
        [0.0008, 0.0019],
        [0.0002, 0.0003],
        [0.0003, 0.0003],
        [0.0007, 0.0011],
        [0.0002, 0.0004],
        [0.0004, 0.0005],
        [0.0002, 0.0004],
        [0.0005, 0.0007],
        [0.0004, 0.0009],
        [0.0005, 0.0007],
        [0.0003, 0.0006],
        [0.0005, 0.0007],
        [0.0006, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0604, 0.0644],
        [0.0623, 0.0625],
        [0.0615, 0.0633],
        [0.0575, 0.0678],
        [0.0668, 0.0583],
        [0.0702, 0.0555],
        [0.0637, 0.0612],
        [0.0603, 0.0646],
        [0.0675, 0.0577],
        [0.0580, 0.0671],
        [0.0630, 0.0618],
        [0.0576, 0.0676],
        [0.0636, 0.0613],
        [0.0609, 0.0640],
        [0.0650, 0.0599],
        [0.0617, 0.0631]], device='cuda:0')
 Batch: 8 of active classification Duration: 0:00:00.411141
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0006, 0.0009],
        [0.0011, 0.0013],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0006, 0.0010],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0005, 0.0008],
        [0.0005, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0004, 0.0005],
        [0.0004, 0.0006],
        [0.0006, 0.0006],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0606, 0.0644],
        [0.0622, 0.0626],
        [0.0662, 0.0589],
        [0.0632, 0.0617],
        [0.0602, 0.0647],
        [0.0625, 0.0624],
        [0.0598, 0.0652],
        [0.0603, 0.0646],
        [0.0617, 0.0632],
        [0.0639, 0.0610],
        [0.0612, 0.0637],
        [0.0578, 0.0675],
        [0.0666, 0.0585],
        [0.0659, 0.0592],
        [0.0683, 0.0571],
        [0.0597, 0.0653]], device='cuda:0')
 Batch: 9 of active classification Duration: 0:00:00.481930
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0005, 0.0010],
        [0.0006, 0.0011],
        [0.0002, 0.0005],
        [0.0007, 0.0009],
        [0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0004, 0.0006],
        [0.0005, 0.0010],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0005, 0.0009],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0596, 0.0654],
        [0.0603, 0.0646],
        [0.0628, 0.0621],
        [0.0595, 0.0655],
        [0.0685, 0.0569],
        [0.0579, 0.0674],
        [0.0619, 0.0630],
        [0.0618, 0.0631],
        [0.0615, 0.0634],
        [0.0603, 0.0646],
        [0.0663, 0.0588],
        [0.0627, 0.0622],
        [0.0638, 0.0611],
        [0.0633, 0.0616],
        [0.0640, 0.0609],
        [0.0657, 0.0594]], device='cuda:0')
 Batch: 10 of active classification Duration: 0:00:00.393970
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0005, 0.0013],
        [0.0003, 0.0007],
        [0.0005, 0.0014],
        [0.0002, 0.0003],
        [0.0004, 0.0006],
        [0.0003, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0005, 0.0012],
        [0.0005, 0.0008],
        [0.0002, 0.0004],
        [0.0004, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0628, 0.0621],
        [0.0646, 0.0603],
        [0.0590, 0.0661],
        [0.0618, 0.0631],
        [0.0585, 0.0666],
        [0.0655, 0.0595],
        [0.0637, 0.0612],
        [0.0597, 0.0652],
        [0.0619, 0.0629],
        [0.0609, 0.0639],
        [0.0612, 0.0637],
        [0.0588, 0.0663],
        [0.0605, 0.0644],
        [0.0655, 0.0595],
        [0.0641, 0.0607],
        [0.0715, 0.0545]], device='cuda:0')
 Batch: 11 of active classification Duration: 0:00:00.354815
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0007, 0.0008],
        [0.0005, 0.0010],
        [0.0004, 0.0007],
        [0.0005, 0.0008],
        [0.0005, 0.0005],
        [0.0003, 0.0009],
        [0.0005, 0.0008],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1365, 0.1140],
        [0.1203, 0.1293],
        [0.1214, 0.1282],
        [0.1234, 0.1261],
        [0.1373, 0.1134],
        [0.1122, 0.1388],
        [0.1250, 0.1245],
        [0.1239, 0.1257]], device='cuda:0')
 Batch: 12 of active classification Duration: 0:00:00.185836
acc:  0.505
Time taken to execute the en SA task with prompt type active, variation 7 and batchsize 16: 0:00:05.431927
path ['42', 'en', 'bloom-big', 'SA', 'active', 'prompt_id_7']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([127, 2])
answers_probs just softmax dim 0: tensor([[0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079]], device='cuda:0')
tensor([[0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA active 8 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0011],
        [0.0006, 0.0014],
        [0.0005, 0.0011],
        [0.0006, 0.0013],
        [0.0005, 0.0011],
        [0.0003, 0.0006],
        [0.0006, 0.0012],
        [0.0003, 0.0009],
        [0.0003, 0.0007],
        [0.0006, 0.0011],
        [0.0004, 0.0010],
        [0.0007, 0.0012],
        [0.0005, 0.0012],
        [0.0004, 0.0011],
        [0.0003, 0.0008],
        [0.0004, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0644, 0.0606],
        [0.0624, 0.0625],
        [0.0633, 0.0616],
        [0.0630, 0.0620],
        [0.0630, 0.0620],
        [0.0660, 0.0591],
        [0.0635, 0.0614],
        [0.0600, 0.0651],
        [0.0618, 0.0631],
        [0.0638, 0.0611],
        [0.0615, 0.0634],
        [0.0665, 0.0587],
        [0.0607, 0.0643],
        [0.0593, 0.0658],
        [0.0609, 0.0640],
        [0.0597, 0.0654]], device='cuda:0')
 Batch: 0 of active classification Duration: 0:00:00.290023
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0011],
        [0.0007, 0.0012],
        [0.0003, 0.0010],
        [0.0005, 0.0009],
        [0.0009, 0.0018],
        [0.0004, 0.0008],
        [0.0003, 0.0009],
        [0.0008, 0.0016],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0002, 0.0006],
        [0.0004, 0.0007],
        [0.0006, 0.0009],
        [0.0007, 0.0014],
        [0.0007, 0.0017],
        [0.0008, 0.0015]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0613, 0.0636],
        [0.0641, 0.0608],
        [0.0564, 0.0692],
        [0.0652, 0.0598],
        [0.0631, 0.0618],
        [0.0638, 0.0611],
        [0.0586, 0.0666],
        [0.0627, 0.0622],
        [0.0638, 0.0611],
        [0.0623, 0.0626],
        [0.0610, 0.0639],
        [0.0642, 0.0607],
        [0.0669, 0.0583],
        [0.0631, 0.0618],
        [0.0601, 0.0648],
        [0.0633, 0.0616]], device='cuda:0')
 Batch: 1 of active classification Duration: 0:00:00.394281
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0009],
        [0.0005, 0.0011],
        [0.0005, 0.0007],
        [0.0003, 0.0010],
        [0.0004, 0.0007],
        [0.0005, 0.0015],
        [0.0005, 0.0012],
        [0.0005, 0.0011],
        [0.0004, 0.0005],
        [0.0004, 0.0014],
        [0.0004, 0.0011],
        [0.0005, 0.0008],
        [0.0002, 0.0005],
        [0.0004, 0.0009],
        [0.0004, 0.0010],
        [0.0006, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0674, 0.0577],
        [0.0626, 0.0622],
        [0.0690, 0.0564],
        [0.0574, 0.0679],
        [0.0646, 0.0603],
        [0.0591, 0.0659],
        [0.0605, 0.0644],
        [0.0622, 0.0626],
        [0.0684, 0.0569],
        [0.0567, 0.0687],
        [0.0610, 0.0639],
        [0.0669, 0.0582],
        [0.0594, 0.0656],
        [0.0604, 0.0645],
        [0.0613, 0.0635],
        [0.0633, 0.0615]], device='cuda:0')
 Batch: 2 of active classification Duration: 0:00:00.416778
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0013],
        [0.0004, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0009],
        [0.0007, 0.0012],
        [0.0005, 0.0009],
        [0.0004, 0.0009],
        [0.0005, 0.0013],
        [0.0006, 0.0012],
        [0.0005, 0.0012],
        [0.0003, 0.0009],
        [0.0005, 0.0010],
        [0.0007, 0.0020],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0617, 0.0631],
        [0.0655, 0.0595],
        [0.0569, 0.0684],
        [0.0708, 0.0550],
        [0.0601, 0.0648],
        [0.0581, 0.0670],
        [0.0660, 0.0590],
        [0.0665, 0.0586],
        [0.0623, 0.0625],
        [0.0602, 0.0647],
        [0.0633, 0.0616],
        [0.0610, 0.0639],
        [0.0608, 0.0641],
        [0.0636, 0.0613],
        [0.0590, 0.0660],
        [0.0641, 0.0607]], device='cuda:0')
 Batch: 3 of active classification Duration: 0:00:00.483667
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0005, 0.0010],
        [0.0006, 0.0010],
        [0.0003, 0.0009],
        [0.0003, 0.0006],
        [0.0004, 0.0010],
        [0.0007, 0.0011],
        [0.0005, 0.0011],
        [0.0008, 0.0016],
        [0.0003, 0.0007],
        [0.0004, 0.0006],
        [0.0005, 0.0012],
        [0.0007, 0.0016],
        [0.0008, 0.0017],
        [0.0007, 0.0016]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0635, 0.0614],
        [0.0603, 0.0647],
        [0.0623, 0.0626],
        [0.0658, 0.0592],
        [0.0586, 0.0666],
        [0.0622, 0.0627],
        [0.0623, 0.0626],
        [0.0659, 0.0592],
        [0.0611, 0.0638],
        [0.0630, 0.0619],
        [0.0616, 0.0633],
        [0.0680, 0.0574],
        [0.0616, 0.0633],
        [0.0614, 0.0635],
        [0.0619, 0.0630],
        [0.0603, 0.0647]], device='cuda:0')
 Batch: 4 of active classification Duration: 0:00:00.416708
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0007, 0.0010],
        [0.0004, 0.0014],
        [0.0005, 0.0006],
        [0.0004, 0.0011],
        [0.0006, 0.0012],
        [0.0003, 0.0007],
        [0.0006, 0.0014],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0008, 0.0013],
        [0.0005, 0.0013],
        [0.0003, 0.0006],
        [0.0007, 0.0010],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0605, 0.0644],
        [0.0667, 0.0584],
        [0.0561, 0.0695],
        [0.0681, 0.0572],
        [0.0599, 0.0650],
        [0.0618, 0.0630],
        [0.0612, 0.0637],
        [0.0604, 0.0645],
        [0.0636, 0.0612],
        [0.0596, 0.0653],
        [0.0623, 0.0625],
        [0.0664, 0.0587],
        [0.0603, 0.0646],
        [0.0649, 0.0600],
        [0.0672, 0.0580],
        [0.0609, 0.0640]], device='cuda:0')
 Batch: 5 of active classification Duration: 0:00:00.357594
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0008, 0.0015],
        [0.0008, 0.0014],
        [0.0004, 0.0009],
        [0.0008, 0.0016],
        [0.0004, 0.0010],
        [0.0003, 0.0007],
        [0.0004, 0.0011],
        [0.0005, 0.0007],
        [0.0005, 0.0010],
        [0.0004, 0.0010],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0002, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0645, 0.0604],
        [0.0646, 0.0603],
        [0.0630, 0.0618],
        [0.0634, 0.0615],
        [0.0615, 0.0634],
        [0.0618, 0.0631],
        [0.0575, 0.0678],
        [0.0700, 0.0557],
        [0.0633, 0.0616],
        [0.0604, 0.0645],
        [0.0629, 0.0619],
        [0.0629, 0.0619],
        [0.0634, 0.0615],
        [0.0649, 0.0601],
        [0.0603, 0.0647],
        [0.0557, 0.0699]], device='cuda:0')
 Batch: 6 of active classification Duration: 0:00:00.436627
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0006],
        [0.0003, 0.0008],
        [0.0006, 0.0010],
        [0.0006, 0.0010],
        [0.0005, 0.0013],
        [0.0005, 0.0009],
        [0.0006, 0.0017],
        [0.0005, 0.0009],
        [0.0007, 0.0014],
        [0.0005, 0.0014],
        [0.0003, 0.0005],
        [0.0008, 0.0015],
        [0.0005, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0596, 0.0654],
        [0.0592, 0.0658],
        [0.0664, 0.0587],
        [0.0659, 0.0591],
        [0.0591, 0.0659],
        [0.0646, 0.0603],
        [0.0583, 0.0668],
        [0.0651, 0.0599],
        [0.0625, 0.0624],
        [0.0577, 0.0675],
        [0.0666, 0.0585],
        [0.0645, 0.0604],
        [0.0625, 0.0624],
        [0.0600, 0.0649],
        [0.0611, 0.0638],
        [0.0670, 0.0582]], device='cuda:0')
 Batch: 7 of active classification Duration: 0:00:00.441135
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0017],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0006, 0.0014],
        [0.0003, 0.0006],
        [0.0012, 0.0015],
        [0.0004, 0.0006],
        [0.0005, 0.0010],
        [0.0005, 0.0007],
        [0.0004, 0.0010],
        [0.0005, 0.0011],
        [0.0004, 0.0010],
        [0.0005, 0.0010],
        [0.0008, 0.0019],
        [0.0004, 0.0007],
        [0.0005, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0561, 0.0695],
        [0.0625, 0.0624],
        [0.0622, 0.0627],
        [0.0608, 0.0641],
        [0.0641, 0.0608],
        [0.0690, 0.0564],
        [0.0672, 0.0580],
        [0.0617, 0.0631],
        [0.0671, 0.0581],
        [0.0589, 0.0662],
        [0.0604, 0.0645],
        [0.0614, 0.0634],
        [0.0631, 0.0617],
        [0.0601, 0.0648],
        [0.0639, 0.0609],
        [0.0614, 0.0634]], device='cuda:0')
 Batch: 8 of active classification Duration: 0:00:00.329719
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0005, 0.0013],
        [0.0004, 0.0010],
        [0.0004, 0.0007],
        [0.0004, 0.0010],
        [0.0006, 0.0011],
        [0.0003, 0.0005],
        [0.0004, 0.0010],
        [0.0005, 0.0008],
        [0.0006, 0.0012],
        [0.0005, 0.0011],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0005, 0.0012],
        [0.0004, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0648, 0.0602],
        [0.0598, 0.0652],
        [0.0604, 0.0646],
        [0.0644, 0.0606],
        [0.0600, 0.0650],
        [0.0640, 0.0610],
        [0.0650, 0.0601],
        [0.0611, 0.0639],
        [0.0657, 0.0594],
        [0.0634, 0.0616],
        [0.0633, 0.0617],
        [0.0593, 0.0658],
        [0.0630, 0.0619],
        [0.0632, 0.0617],
        [0.0611, 0.0639],
        [0.0616, 0.0634]], device='cuda:0')
 Batch: 9 of active classification Duration: 0:00:00.547179
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0006, 0.0014],
        [0.0004, 0.0006],
        [0.0007, 0.0012],
        [0.0002, 0.0006],
        [0.0006, 0.0011],
        [0.0004, 0.0009],
        [0.0005, 0.0009],
        [0.0004, 0.0006],
        [0.0007, 0.0014],
        [0.0007, 0.0014],
        [0.0006, 0.0014],
        [0.0003, 0.0005],
        [0.0004, 0.0010],
        [0.0003, 0.0008],
        [0.0003, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0658, 0.0592],
        [0.0603, 0.0647],
        [0.0639, 0.0610],
        [0.0629, 0.0620],
        [0.0595, 0.0655],
        [0.0636, 0.0613],
        [0.0596, 0.0654],
        [0.0657, 0.0593],
        [0.0678, 0.0575],
        [0.0624, 0.0625],
        [0.0616, 0.0633],
        [0.0601, 0.0649],
        [0.0662, 0.0589],
        [0.0604, 0.0646],
        [0.0599, 0.0651],
        [0.0601, 0.0649]], device='cuda:0')
 Batch: 10 of active classification Duration: 0:00:00.445210
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0003, 0.0011],
        [0.0004, 0.0010],
        [0.0005, 0.0012],
        [0.0006, 0.0016],
        [0.0005, 0.0013],
        [0.0006, 0.0014],
        [0.0007, 0.0014],
        [0.0002, 0.0004],
        [0.0006, 0.0018],
        [0.0004, 0.0008],
        [0.0005, 0.0008],
        [0.0003, 0.0007],
        [0.0005, 0.0010],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0620, 0.0629],
        [0.0627, 0.0622],
        [0.0581, 0.0671],
        [0.0613, 0.0636],
        [0.0607, 0.0642],
        [0.0616, 0.0633],
        [0.0617, 0.0632],
        [0.0617, 0.0632],
        [0.0649, 0.0601],
        [0.0661, 0.0590],
        [0.0593, 0.0658],
        [0.0634, 0.0616],
        [0.0663, 0.0588],
        [0.0608, 0.0641],
        [0.0635, 0.0615],
        [0.0658, 0.0592]], device='cuda:0')
 Batch: 11 of active classification Duration: 0:00:00.398311
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0005, 0.0011],
        [0.0004, 0.0011],
        [0.0005, 0.0013],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0009, 0.0019]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1249],
        [0.1250, 0.1250],
        [0.1250, 0.1251]], device='cuda:0')
tensor([[0.1315, 0.1187],
        [0.1251, 0.1249],
        [0.1196, 0.1306],
        [0.1213, 0.1288],
        [0.1259, 0.1240],
        [0.1263, 0.1236],
        [0.1248, 0.1251],
        [0.1255, 0.1244]], device='cuda:0')
 Batch: 12 of active classification Duration: 0:00:00.178180
acc:  0.515
Time taken to execute the en SA task with prompt type active, variation 8 and batchsize 16: 0:00:05.154130
path ['42', 'en', 'bloom-big', 'SA', 'active', 'prompt_id_8']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([124, 2])
answers_probs just softmax dim 0: tensor([[0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081]], device='cuda:0')
tensor([[0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA active 9 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0006, 0.0015],
        [0.0003, 0.0008],
        [0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0002, 0.0004],
        [0.0002, 0.0006],
        [0.0002, 0.0006],
        [0.0002, 0.0003],
        [0.0003, 0.0007],
        [0.0002, 0.0006],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0002, 0.0006],
        [0.0004, 0.0005],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0603, 0.0646],
        [0.0599, 0.0650],
        [0.0597, 0.0652],
        [0.0644, 0.0605],
        [0.0630, 0.0618],
        [0.0617, 0.0630],
        [0.0573, 0.0679],
        [0.0606, 0.0643],
        [0.0656, 0.0593],
        [0.0601, 0.0648],
        [0.0605, 0.0644],
        [0.0712, 0.0547],
        [0.0664, 0.0586],
        [0.0584, 0.0667],
        [0.0705, 0.0552],
        [0.0607, 0.0642]], device='cuda:0')
 Batch: 0 of active classification Duration: 0:00:00.405925
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0004, 0.0010],
        [0.0001, 0.0003],
        [0.0002, 0.0005],
        [0.0002, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0008],
        [0.0005, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0636, 0.0612],
        [0.0602, 0.0648],
        [0.0622, 0.0626],
        [0.0633, 0.0616],
        [0.0581, 0.0670],
        [0.0600, 0.0650],
        [0.0624, 0.0624],
        [0.0573, 0.0680],
        [0.0649, 0.0600],
        [0.0651, 0.0598],
        [0.0622, 0.0626],
        [0.0731, 0.0533],
        [0.0616, 0.0633],
        [0.0628, 0.0620],
        [0.0633, 0.0616],
        [0.0601, 0.0649]], device='cuda:0')
 Batch: 1 of active classification Duration: 0:00:00.326449
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0004, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0708, 0.0551],
        [0.0654, 0.0596],
        [0.0593, 0.0658],
        [0.0624, 0.0625],
        [0.0629, 0.0619],
        [0.0613, 0.0636],
        [0.0625, 0.0623],
        [0.0619, 0.0630],
        [0.0608, 0.0641],
        [0.0657, 0.0593],
        [0.0608, 0.0641],
        [0.0604, 0.0646],
        [0.0598, 0.0652],
        [0.0660, 0.0591],
        [0.0597, 0.0653],
        [0.0603, 0.0647]], device='cuda:0')
 Batch: 2 of active classification Duration: 0:00:00.413875
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0003, 0.0007],
        [0.0001, 0.0004],
        [0.0003, 0.0010],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0002, 0.0002],
        [0.0002, 0.0005],
        [0.0004, 0.0009],
        [0.0005, 0.0009],
        [0.0003, 0.0006],
        [0.0004, 0.0005],
        [0.0004, 0.0011],
        [0.0003, 0.0007],
        [0.0006, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0613, 0.0635],
        [0.0596, 0.0653],
        [0.0617, 0.0630],
        [0.0571, 0.0681],
        [0.0599, 0.0649],
        [0.0610, 0.0638],
        [0.0636, 0.0612],
        [0.0761, 0.0511],
        [0.0588, 0.0662],
        [0.0620, 0.0627],
        [0.0663, 0.0586],
        [0.0606, 0.0642],
        [0.0683, 0.0569],
        [0.0587, 0.0663],
        [0.0617, 0.0630],
        [0.0634, 0.0614]], device='cuda:0')
 Batch: 3 of active classification Duration: 0:00:00.308534
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0002, 0.0008],
        [0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0002, 0.0004],
        [0.0004, 0.0006],
        [0.0002, 0.0005],
        [0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0006, 0.0020],
        [0.0004, 0.0010],
        [0.0002, 0.0003],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0008, 0.0017]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626]], device='cuda:0')
tensor([[0.0628, 0.0620],
        [0.0567, 0.0687],
        [0.0622, 0.0627],
        [0.0666, 0.0585],
        [0.0659, 0.0591],
        [0.0671, 0.0580],
        [0.0624, 0.0625],
        [0.0645, 0.0604],
        [0.0599, 0.0651],
        [0.0581, 0.0671],
        [0.0599, 0.0651],
        [0.0672, 0.0579],
        [0.0590, 0.0660],
        [0.0633, 0.0615],
        [0.0614, 0.0635],
        [0.0630, 0.0618]], device='cuda:0')
 Batch: 4 of active classification Duration: 0:00:00.470839
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0010],
        [0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0004, 0.0009],
        [0.0006, 0.0016],
        [0.0002, 0.0004],
        [0.0004, 0.0010],
        [0.0002, 0.0006],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0005, 0.0008],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0013],
        [0.0002, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0547, 0.0712],
        [0.0648, 0.0601],
        [0.0666, 0.0585],
        [0.0609, 0.0639],
        [0.0599, 0.0650],
        [0.0625, 0.0623],
        [0.0616, 0.0631],
        [0.0612, 0.0636],
        [0.0633, 0.0615],
        [0.0656, 0.0593],
        [0.0648, 0.0601],
        [0.0682, 0.0571],
        [0.0677, 0.0575],
        [0.0625, 0.0623],
        [0.0562, 0.0693],
        [0.0595, 0.0654]], device='cuda:0')
 Batch: 5 of active classification Duration: 0:00:00.418400
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0002, 0.0003],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0002, 0.0002],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0617, 0.0630],
        [0.0603, 0.0646],
        [0.0628, 0.0620],
        [0.0574, 0.0679],
        [0.0674, 0.0578],
        [0.0612, 0.0636],
        [0.0594, 0.0655],
        [0.0605, 0.0643],
        [0.0642, 0.0607],
        [0.0651, 0.0598],
        [0.0616, 0.0632],
        [0.0616, 0.0632],
        [0.0733, 0.0531],
        [0.0611, 0.0637],
        [0.0645, 0.0603],
        [0.0577, 0.0675]], device='cuda:0')
 Batch: 6 of active classification Duration: 0:00:00.396038
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0001, 0.0004],
        [0.0002, 0.0005],
        [0.0001, 0.0002],
        [0.0002, 0.0005],
        [0.0002, 0.0002],
        [0.0004, 0.0007],
        [0.0002, 0.0003],
        [0.0002, 0.0002],
        [0.0003, 0.0006],
        [0.0004, 0.0005],
        [0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0006, 0.0011],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0004, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0565, 0.0688],
        [0.0608, 0.0640],
        [0.0687, 0.0566],
        [0.0567, 0.0686],
        [0.0665, 0.0585],
        [0.0606, 0.0642],
        [0.0648, 0.0600],
        [0.0731, 0.0532],
        [0.0593, 0.0655],
        [0.0650, 0.0599],
        [0.0594, 0.0654],
        [0.0605, 0.0643],
        [0.0619, 0.0628],
        [0.0583, 0.0667],
        [0.0627, 0.0620],
        [0.0653, 0.0595]], device='cuda:0')
 Batch: 7 of active classification Duration: 0:00:00.432366
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0009],
        [0.0002, 0.0005],
        [0.0002, 0.0007],
        [0.0003, 0.0008],
        [0.0004, 0.0008],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0002, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0002, 0.0006],
        [0.0005, 0.0013],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0680, 0.0573],
        [0.0586, 0.0665],
        [0.0616, 0.0632],
        [0.0582, 0.0670],
        [0.0582, 0.0670],
        [0.0656, 0.0594],
        [0.0638, 0.0610],
        [0.0609, 0.0640],
        [0.0635, 0.0614],
        [0.0673, 0.0579],
        [0.0606, 0.0643],
        [0.0649, 0.0601],
        [0.0659, 0.0591],
        [0.0597, 0.0653],
        [0.0600, 0.0650],
        [0.0632, 0.0617]], device='cuda:0')
 Batch: 8 of active classification Duration: 0:00:00.443209
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0001, 0.0004],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0002, 0.0009],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0009],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0001, 0.0004],
        [0.0001, 0.0003],
        [0.0006, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0634, 0.0615],
        [0.0620, 0.0629],
        [0.0590, 0.0660],
        [0.0597, 0.0653],
        [0.0616, 0.0632],
        [0.0554, 0.0703],
        [0.0619, 0.0630],
        [0.0638, 0.0611],
        [0.0678, 0.0575],
        [0.0638, 0.0611],
        [0.0595, 0.0655],
        [0.0647, 0.0602],
        [0.0665, 0.0586],
        [0.0602, 0.0648],
        [0.0623, 0.0625],
        [0.0685, 0.0568]], device='cuda:0')
 Batch: 9 of active classification Duration: 0:00:00.414887
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0003, 0.0004],
        [0.0002, 0.0005],
        [0.0003, 0.0009],
        [0.0003, 0.0008],
        [0.0003, 0.0009],
        [0.0003, 0.0007],
        [0.0004, 0.0006],
        [0.0002, 0.0003],
        [0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0007, 0.0015]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626]], device='cuda:0')
tensor([[0.0655, 0.0594],
        [0.0625, 0.0623],
        [0.0680, 0.0572],
        [0.0684, 0.0569],
        [0.0594, 0.0656],
        [0.0565, 0.0689],
        [0.0577, 0.0675],
        [0.0585, 0.0665],
        [0.0599, 0.0650],
        [0.0651, 0.0598],
        [0.0693, 0.0561],
        [0.0614, 0.0634],
        [0.0607, 0.0641],
        [0.0624, 0.0624],
        [0.0624, 0.0624],
        [0.0624, 0.0624]], device='cuda:0')
 Batch: 10 of active classification Duration: 0:00:00.399212
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0002, 0.0003],
        [0.0005, 0.0009],
        [0.0002, 0.0004],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0002, 0.0003],
        [0.0006, 0.0012],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0005, 0.0011],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0004, 0.0009],
        [0.0003, 0.0008],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0636, 0.0612],
        [0.0688, 0.0566],
        [0.0641, 0.0608],
        [0.0602, 0.0648],
        [0.0610, 0.0639],
        [0.0672, 0.0579],
        [0.0647, 0.0602],
        [0.0613, 0.0636],
        [0.0650, 0.0599],
        [0.0659, 0.0591],
        [0.0611, 0.0638],
        [0.0608, 0.0641],
        [0.0605, 0.0644],
        [0.0601, 0.0649],
        [0.0574, 0.0679],
        [0.0584, 0.0667]], device='cuda:0')
 Batch: 11 of active classification Duration: 0:00:00.355925
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0001, 0.0002],
        [0.0004, 0.0008],
        [0.0002, 0.0007],
        [0.0004, 0.0010],
        [0.0002, 0.0003],
        [0.0004, 0.0006],
        [0.0003, 0.0011]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1249],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1216, 0.1278],
        [0.1335, 0.1164],
        [0.1237, 0.1257],
        [0.1150, 0.1352],
        [0.1179, 0.1319],
        [0.1411, 0.1102],
        [0.1325, 0.1173],
        [0.1148, 0.1354]], device='cuda:0')
 Batch: 12 of active classification Duration: 0:00:00.292875
acc:  0.525
Time taken to execute the en SA task with prompt type active, variation 9 and batchsize 16: 0:00:05.099681
path ['42', 'en', 'bloom-big', 'SA', 'active', 'prompt_id_9']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v73.pickle' as a pickle file.

prompt_type passive has 10 prompts in it
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([98, 2])
answers_probs just softmax dim 0: tensor([[0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102]], device='cuda:0')
tensor([[0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102],
        [0.0102, 0.0102]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA passive 0 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0006],
        [0.0004, 0.0009],
        [0.0006, 0.0013],
        [0.0001, 0.0004],
        [0.0003, 0.0010],
        [0.0004, 0.0007],
        [0.0004, 0.0011],
        [0.0004, 0.0010],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0005, 0.0013],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0003, 0.0011],
        [0.0004, 0.0009],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0601, 0.0648],
        [0.0620, 0.0629],
        [0.0631, 0.0618],
        [0.0600, 0.0650],
        [0.0605, 0.0645],
        [0.0691, 0.0564],
        [0.0597, 0.0653],
        [0.0603, 0.0647],
        [0.0666, 0.0586],
        [0.0642, 0.0607],
        [0.0621, 0.0628],
        [0.0672, 0.0580],
        [0.0623, 0.0626],
        [0.0591, 0.0660],
        [0.0620, 0.0629],
        [0.0618, 0.0631]], device='cuda:0')
 Batch: 0 of passive classification Duration: 0:00:00.467088
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0006],
        [0.0003, 0.0010],
        [0.0002, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0009],
        [0.0004, 0.0007],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0639, 0.0610],
        [0.0676, 0.0577],
        [0.0635, 0.0614],
        [0.0626, 0.0623],
        [0.0603, 0.0647],
        [0.0613, 0.0636],
        [0.0596, 0.0655],
        [0.0606, 0.0643],
        [0.0605, 0.0645],
        [0.0605, 0.0644],
        [0.0622, 0.0627],
        [0.0626, 0.0623],
        [0.0661, 0.0589],
        [0.0585, 0.0666],
        [0.0682, 0.0571],
        [0.0619, 0.0630]], device='cuda:0')
 Batch: 1 of passive classification Duration: 0:00:00.357878
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0002, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0007, 0.0014],
        [0.0003, 0.0007],
        [0.0001, 0.0005],
        [0.0005, 0.0010],
        [0.0003, 0.0008],
        [0.0002, 0.0007],
        [0.0003, 0.0008],
        [0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0659, 0.0592],
        [0.0647, 0.0602],
        [0.0568, 0.0686],
        [0.0632, 0.0617],
        [0.0623, 0.0625],
        [0.0638, 0.0611],
        [0.0638, 0.0611],
        [0.0633, 0.0616],
        [0.0582, 0.0670],
        [0.0636, 0.0613],
        [0.0591, 0.0660],
        [0.0588, 0.0663],
        [0.0619, 0.0630],
        [0.0657, 0.0593],
        [0.0663, 0.0588],
        [0.0625, 0.0623]], device='cuda:0')
 Batch: 2 of passive classification Duration: 0:00:00.391056
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0009],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0002, 0.0002],
        [0.0005, 0.0011],
        [0.0004, 0.0006],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0002, 0.0006],
        [0.0004, 0.0011],
        [0.0002, 0.0005],
        [0.0004, 0.0006],
        [0.0001, 0.0005],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0662, 0.0586],
        [0.0614, 0.0633],
        [0.0570, 0.0681],
        [0.0637, 0.0609],
        [0.0597, 0.0650],
        [0.0772, 0.0503],
        [0.0600, 0.0647],
        [0.0663, 0.0585],
        [0.0607, 0.0640],
        [0.0637, 0.0609],
        [0.0573, 0.0677],
        [0.0574, 0.0676],
        [0.0615, 0.0632],
        [0.0668, 0.0581],
        [0.0572, 0.0679],
        [0.0637, 0.0609]], device='cuda:0')
 Batch: 3 of passive classification Duration: 0:00:00.354277
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0008],
        [0.0003, 0.0010],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0004, 0.0006],
        [0.0003, 0.0008],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0576, 0.0677],
        [0.0583, 0.0669],
        [0.0601, 0.0649],
        [0.0687, 0.0567],
        [0.0620, 0.0629],
        [0.0631, 0.0618],
        [0.0631, 0.0618],
        [0.0659, 0.0592],
        [0.0605, 0.0644],
        [0.0623, 0.0626],
        [0.0633, 0.0616],
        [0.0625, 0.0624],
        [0.0626, 0.0623],
        [0.0677, 0.0576],
        [0.0614, 0.0635],
        [0.0612, 0.0637]], device='cuda:0')
 Batch: 4 of passive classification Duration: 0:00:00.528496
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0005, 0.0011],
        [0.0003, 0.0004],
        [0.0003, 0.0009],
        [0.0005, 0.0012],
        [0.0004, 0.0005],
        [0.0002, 0.0005],
        [0.0004, 0.0010],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0002, 0.0007],
        [0.0002, 0.0006],
        [0.0002, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0629, 0.0619],
        [0.0629, 0.0619],
        [0.0628, 0.0621],
        [0.0697, 0.0559],
        [0.0605, 0.0644],
        [0.0618, 0.0630],
        [0.0704, 0.0554],
        [0.0590, 0.0660],
        [0.0617, 0.0631],
        [0.0641, 0.0608],
        [0.0656, 0.0594],
        [0.0582, 0.0670],
        [0.0613, 0.0635],
        [0.0596, 0.0653],
        [0.0585, 0.0666],
        [0.0611, 0.0637]], device='cuda:0')
 Batch: 5 of passive classification Duration: 0:00:00.314717
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0011],
        [0.0003, 0.0009],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0002, 0.0007],
        [0.0001, 0.0004],
        [0.0002, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0005, 0.0011],
        [0.0002, 0.0006],
        [0.0004, 0.0008],
        [0.0006, 0.0012],
        [0.0003, 0.0008],
        [0.0002, 0.0007],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0577, 0.0675],
        [0.0622, 0.0626],
        [0.0680, 0.0573],
        [0.0632, 0.0616],
        [0.0572, 0.0682],
        [0.0595, 0.0655],
        [0.0643, 0.0606],
        [0.0656, 0.0594],
        [0.0625, 0.0623],
        [0.0636, 0.0612],
        [0.0590, 0.0660],
        [0.0647, 0.0602],
        [0.0673, 0.0579],
        [0.0616, 0.0633],
        [0.0610, 0.0638],
        [0.0624, 0.0624]], device='cuda:0')
 Batch: 6 of passive classification Duration: 0:00:00.360554
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0007, 0.0016],
        [0.0002, 0.0006],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0005, 0.0007],
        [0.0002, 0.0006],
        [0.0004, 0.0009],
        [0.0004, 0.0007],
        [0.0001, 0.0004],
        [0.0003, 0.0004],
        [0.0002, 0.0006],
        [0.0002, 0.0006],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0584, 0.0667],
        [0.0640, 0.0608],
        [0.0587, 0.0663],
        [0.0622, 0.0626],
        [0.0584, 0.0667],
        [0.0635, 0.0613],
        [0.0630, 0.0619],
        [0.0678, 0.0574],
        [0.0603, 0.0646],
        [0.0628, 0.0620],
        [0.0645, 0.0604],
        [0.0595, 0.0654],
        [0.0722, 0.0539],
        [0.0599, 0.0650],
        [0.0604, 0.0644],
        [0.0643, 0.0606]], device='cuda:0')
 Batch: 7 of passive classification Duration: 0:00:00.252423
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0005, 0.0014],
        [0.0002, 0.0008],
        [0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0005, 0.0013],
        [0.0002, 0.0004],
        [0.0002, 0.0006],
        [0.0002, 0.0006],
        [0.0003, 0.0007],
        [0.0004, 0.0014],
        [0.0002, 0.0005],
        [0.0006, 0.0011],
        [0.0001, 0.0005],
        [0.0004, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0679, 0.0574],
        [0.0615, 0.0634],
        [0.0589, 0.0662],
        [0.0659, 0.0591],
        [0.0661, 0.0590],
        [0.0631, 0.0617],
        [0.0601, 0.0648],
        [0.0625, 0.0623],
        [0.0620, 0.0629],
        [0.0619, 0.0629],
        [0.0648, 0.0602],
        [0.0580, 0.0672],
        [0.0624, 0.0624],
        [0.0650, 0.0600],
        [0.0578, 0.0675],
        [0.0619, 0.0629]], device='cuda:0')
 Batch: 8 of passive classification Duration: 0:00:00.419279
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0002, 0.0006],
        [0.0004, 0.0007],
        [0.0005, 0.0011],
        [0.0003, 0.0006],
        [0.0003, 0.0009],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0007],
        [0.0007, 0.0013],
        [0.0006, 0.0008],
        [0.0003, 0.0010],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0587, 0.0664],
        [0.0620, 0.0628],
        [0.0666, 0.0585],
        [0.0614, 0.0635],
        [0.0611, 0.0638],
        [0.0591, 0.0660],
        [0.0633, 0.0616],
        [0.0599, 0.0651],
        [0.0637, 0.0612],
        [0.0592, 0.0658],
        [0.0651, 0.0599],
        [0.0685, 0.0569],
        [0.0579, 0.0673],
        [0.0645, 0.0604],
        [0.0625, 0.0623],
        [0.0665, 0.0586]], device='cuda:0')
 Batch: 9 of passive classification Duration: 0:00:00.286065
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[2.0373e-04, 4.6277e-04],
        [2.1112e-04, 4.6468e-04],
        [4.3130e-04, 5.0020e-04],
        [3.4094e-04, 5.5361e-04],
        [2.5964e-04, 4.9639e-04],
        [3.3927e-04, 8.1396e-04],
        [4.5800e-04, 1.0738e-03],
        [1.8525e-04, 4.5156e-04],
        [2.5034e-04, 5.0592e-04],
        [1.8835e-04, 4.2772e-04],
        [3.4928e-04, 6.8378e-04],
        [3.0231e-04, 7.3099e-04],
        [6.9082e-05, 3.4928e-04],
        [7.7629e-04, 1.0204e-03],
        [3.0184e-04, 7.1859e-04],
        [2.8062e-04, 5.0020e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0611, 0.0636],
        [0.0616, 0.0632],
        [0.0716, 0.0544],
        [0.0659, 0.0590],
        [0.0635, 0.0613],
        [0.0604, 0.0644],
        [0.0607, 0.0641],
        [0.0602, 0.0646],
        [0.0627, 0.0620],
        [0.0611, 0.0636],
        [0.0632, 0.0616],
        [0.0603, 0.0645],
        [0.0531, 0.0732],
        [0.0694, 0.0561],
        [0.0605, 0.0643],
        [0.0645, 0.0603]], device='cuda:0')
 Batch: 10 of passive classification Duration: 0:00:00.323388
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0004],
        [0.0006, 0.0009],
        [0.0002, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0004, 0.0007],
        [0.0002, 0.0003],
        [0.0002, 0.0002],
        [0.0005, 0.0010],
        [0.0003, 0.0009],
        [0.0004, 0.0007],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0628, 0.0620],
        [0.0575, 0.0677],
        [0.0673, 0.0578],
        [0.0673, 0.0578],
        [0.0557, 0.0699],
        [0.0641, 0.0607],
        [0.0596, 0.0653],
        [0.0617, 0.0631],
        [0.0599, 0.0649],
        [0.0644, 0.0604],
        [0.0691, 0.0563],
        [0.0671, 0.0580],
        [0.0622, 0.0625],
        [0.0579, 0.0672],
        [0.0653, 0.0596],
        [0.0582, 0.0669]], device='cuda:0')
 Batch: 11 of passive classification Duration: 0:00:00.397800
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0009],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0002, 0.0003],
        [0.0006, 0.0019],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1249],
        [0.1250, 0.1251],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1239, 0.1257],
        [0.1314, 0.1186],
        [0.1235, 0.1262],
        [0.1326, 0.1175],
        [0.1248, 0.1249],
        [0.1326, 0.1175],
        [0.1141, 0.1366],
        [0.1171, 0.1330]], device='cuda:0')
 Batch: 12 of passive classification Duration: 0:00:00.206118
acc:  0.45
Time taken to execute the en SA task with prompt type passive, variation 0 and batchsize 16: 0:00:04.681036
path ['42', 'en', 'bloom-big', 'SA', 'passive', 'prompt_id_0']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003]], device='cuda:0') torch.Size([105, 2])
answers_probs just softmax dim 0: tensor([[0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095]], device='cuda:0')
tensor([[0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA passive 1 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0007],
        [0.0007, 0.0015],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0002, 0.0006],
        [0.0001, 0.0004],
        [0.0004, 0.0007],
        [0.0004, 0.0011],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0005, 0.0009],
        [0.0001, 0.0005],
        [0.0003, 0.0008],
        [0.0005, 0.0006],
        [0.0004, 0.0008],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0571, 0.0681],
        [0.0627, 0.0620],
        [0.0681, 0.0571],
        [0.0663, 0.0587],
        [0.0577, 0.0674],
        [0.0570, 0.0682],
        [0.0664, 0.0586],
        [0.0597, 0.0651],
        [0.0653, 0.0596],
        [0.0609, 0.0638],
        [0.0633, 0.0614],
        [0.0564, 0.0689],
        [0.0608, 0.0639],
        [0.0715, 0.0544],
        [0.0612, 0.0635],
        [0.0654, 0.0594]], device='cuda:0')
 Batch: 0 of passive classification Duration: 0:00:00.339511
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0007],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0002, 0.0006],
        [0.0007, 0.0014],
        [0.0005, 0.0008],
        [0.0005, 0.0007],
        [0.0003, 0.0012],
        [0.0002, 0.0011],
        [0.0007, 0.0014],
        [0.0002, 0.0004],
        [0.0009, 0.0011],
        [0.0003, 0.0010],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0573, 0.0677],
        [0.0643, 0.0604],
        [0.0608, 0.0639],
        [0.0603, 0.0644],
        [0.0626, 0.0620],
        [0.0672, 0.0578],
        [0.0675, 0.0575],
        [0.0558, 0.0696],
        [0.0528, 0.0735],
        [0.0630, 0.0616],
        [0.0642, 0.0605],
        [0.0714, 0.0544],
        [0.0571, 0.0680],
        [0.0645, 0.0602],
        [0.0656, 0.0592],
        [0.0657, 0.0591]], device='cuda:0')
 Batch: 1 of passive classification Duration: 0:00:00.400923
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[1.9133e-04, 5.2023e-04],
        [5.9891e-04, 9.2077e-04],
        [4.2415e-04, 1.3580e-03],
        [2.6035e-04, 5.7745e-04],
        [3.8362e-04, 6.6805e-04],
        [4.4894e-04, 7.8821e-04],
        [2.1923e-04, 4.2582e-04],
        [1.8907e-04, 4.5371e-04],
        [3.4857e-04, 7.0953e-04],
        [2.2101e-04, 7.5960e-04],
        [1.8334e-04, 6.3467e-04],
        [3.4356e-04, 4.9973e-04],
        [4.0126e-04, 7.9823e-04],
        [3.8290e-04, 7.9775e-04],
        [3.2592e-04, 7.4577e-04],
        [9.3520e-05, 4.3225e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0601, 0.0648],
        [0.0681, 0.0571],
        [0.0583, 0.0668],
        [0.0627, 0.0621],
        [0.0661, 0.0588],
        [0.0660, 0.0589],
        [0.0645, 0.0603],
        [0.0616, 0.0631],
        [0.0638, 0.0609],
        [0.0575, 0.0676],
        [0.0575, 0.0677],
        [0.0690, 0.0564],
        [0.0642, 0.0606],
        [0.0635, 0.0613],
        [0.0622, 0.0625],
        [0.0549, 0.0709]], device='cuda:0')
 Batch: 2 of passive classification Duration: 0:00:00.400761
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0002, 0.0006],
        [0.0005, 0.0015],
        [0.0002, 0.0006],
        [0.0003, 0.0008],
        [0.0004, 0.0006],
        [0.0002, 0.0006],
        [0.0003, 0.0007],
        [0.0002, 0.0008],
        [0.0003, 0.0007],
        [0.0005, 0.0007],
        [0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0706, 0.0551],
        [0.0599, 0.0649],
        [0.0575, 0.0677],
        [0.0604, 0.0644],
        [0.0598, 0.0650],
        [0.0689, 0.0565],
        [0.0580, 0.0670],
        [0.0590, 0.0659],
        [0.0572, 0.0680],
        [0.0620, 0.0627],
        [0.0669, 0.0582],
        [0.0633, 0.0614],
        [0.0645, 0.0604],
        [0.0608, 0.0640],
        [0.0662, 0.0587],
        [0.0648, 0.0600]], device='cuda:0')
 Batch: 3 of passive classification Duration: 0:00:00.529647
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0005, 0.0008],
        [0.0003, 0.0008],
        [0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0001, 0.0003],
        [0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0004, 0.0012],
        [0.0004, 0.0011],
        [0.0002, 0.0004],
        [0.0002, 0.0007],
        [0.0006, 0.0014],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0671, 0.0581],
        [0.0639, 0.0610],
        [0.0665, 0.0586],
        [0.0615, 0.0634],
        [0.0583, 0.0669],
        [0.0607, 0.0642],
        [0.0622, 0.0627],
        [0.0587, 0.0664],
        [0.0646, 0.0603],
        [0.0641, 0.0608],
        [0.0602, 0.0648],
        [0.0610, 0.0639],
        [0.0648, 0.0602],
        [0.0566, 0.0688],
        [0.0633, 0.0615],
        [0.0666, 0.0585]], device='cuda:0')
 Batch: 4 of passive classification Duration: 0:00:00.471907
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0006],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0005, 0.0011],
        [0.0005, 0.0012],
        [0.0003, 0.0007],
        [0.0004, 0.0011],
        [0.0004, 0.0005],
        [0.0005, 0.0010],
        [0.0003, 0.0007],
        [0.0005, 0.0007],
        [0.0004, 0.0009],
        [0.0002, 0.0005],
        [0.0007, 0.0015]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0636, 0.0613],
        [0.0614, 0.0635],
        [0.0594, 0.0656],
        [0.0637, 0.0612],
        [0.0569, 0.0684],
        [0.0608, 0.0641],
        [0.0619, 0.0630],
        [0.0605, 0.0644],
        [0.0599, 0.0650],
        [0.0716, 0.0544],
        [0.0632, 0.0617],
        [0.0611, 0.0638],
        [0.0685, 0.0569],
        [0.0621, 0.0627],
        [0.0628, 0.0620],
        [0.0627, 0.0621]], device='cuda:0')
 Batch: 5 of passive classification Duration: 0:00:00.351702
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0011],
        [0.0003, 0.0005],
        [0.0002, 0.0007],
        [0.0003, 0.0007],
        [0.0005, 0.0008],
        [0.0002, 0.0006],
        [0.0001, 0.0006],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0006, 0.0009],
        [0.0003, 0.0005],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0612, 0.0635],
        [0.0651, 0.0597],
        [0.0625, 0.0623],
        [0.0578, 0.0674],
        [0.0679, 0.0573],
        [0.0553, 0.0703],
        [0.0612, 0.0636],
        [0.0657, 0.0592],
        [0.0610, 0.0638],
        [0.0562, 0.0692],
        [0.0627, 0.0621],
        [0.0646, 0.0603],
        [0.0602, 0.0646],
        [0.0690, 0.0564],
        [0.0663, 0.0587],
        [0.0633, 0.0614]], device='cuda:0')
 Batch: 6 of passive classification Duration: 0:00:00.306577
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0004, 0.0010],
        [0.0005, 0.0007],
        [0.0002, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0004],
        [0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0009],
        [0.0005, 0.0009],
        [0.0002, 0.0004],
        [0.0004, 0.0010],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0610, 0.0638],
        [0.0587, 0.0663],
        [0.0582, 0.0669],
        [0.0676, 0.0576],
        [0.0595, 0.0655],
        [0.0653, 0.0597],
        [0.0695, 0.0560],
        [0.0624, 0.0624],
        [0.0659, 0.0591],
        [0.0575, 0.0677],
        [0.0655, 0.0595],
        [0.0606, 0.0642],
        [0.0609, 0.0639],
        [0.0651, 0.0598],
        [0.0632, 0.0616],
        [0.0589, 0.0661]], device='cuda:0')
 Batch: 7 of passive classification Duration: 0:00:00.420651
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0003, 0.0009],
        [0.0002, 0.0005],
        [0.0004, 0.0005],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0007, 0.0012],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0002],
        [0.0005, 0.0009],
        [0.0001, 0.0004],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0592, 0.0656],
        [0.0622, 0.0624],
        [0.0572, 0.0678],
        [0.0619, 0.0626],
        [0.0691, 0.0562],
        [0.0657, 0.0591],
        [0.0583, 0.0666],
        [0.0662, 0.0586],
        [0.0611, 0.0635],
        [0.0623, 0.0623],
        [0.0792, 0.0490],
        [0.0641, 0.0605],
        [0.0571, 0.0679],
        [0.0599, 0.0647],
        [0.0590, 0.0658],
        [0.0575, 0.0674]], device='cuda:0')
 Batch: 8 of passive classification Duration: 0:00:00.390741
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[3.2592e-04, 5.6744e-04],
        [2.6369e-04, 4.8876e-04],
        [2.2078e-04, 5.0545e-04],
        [2.6083e-04, 7.4291e-04],
        [3.4547e-04, 6.8140e-04],
        [8.5652e-05, 6.6328e-04],
        [4.7112e-04, 6.3372e-04],
        [3.1185e-04, 5.6458e-04],
        [3.3236e-04, 1.1244e-03],
        [4.1580e-04, 5.5933e-04],
        [2.0647e-04, 5.0688e-04],
        [1.2827e-04, 3.4332e-04],
        [4.1533e-04, 6.7949e-04],
        [3.1304e-04, 6.7806e-04],
        [1.7905e-04, 3.4523e-04],
        [4.1819e-04, 4.6301e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0647, 0.0600],
        [0.0637, 0.0609],
        [0.0608, 0.0638],
        [0.0582, 0.0666],
        [0.0628, 0.0617],
        [0.0503, 0.0771],
        [0.0688, 0.0564],
        [0.0641, 0.0605],
        [0.0564, 0.0688],
        [0.0688, 0.0564],
        [0.0600, 0.0647],
        [0.0589, 0.0658],
        [0.0656, 0.0591],
        [0.0616, 0.0630],
        [0.0632, 0.0614],
        [0.0722, 0.0538]], device='cuda:0')
 Batch: 9 of passive classification Duration: 0:00:00.350723
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0003, 0.0003],
        [0.0004, 0.0009],
        [0.0005, 0.0008],
        [0.0003, 0.0008],
        [0.0007, 0.0009],
        [0.0005, 0.0008],
        [0.0004, 0.0011],
        [0.0004, 0.0014],
        [0.0004, 0.0009],
        [0.0005, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0593, 0.0657],
        [0.0699, 0.0557],
        [0.0606, 0.0642],
        [0.0668, 0.0583],
        [0.0591, 0.0659],
        [0.0700, 0.0556],
        [0.0674, 0.0577],
        [0.0590, 0.0660],
        [0.0572, 0.0681],
        [0.0609, 0.0639],
        [0.0640, 0.0608],
        [0.0613, 0.0635],
        [0.0607, 0.0641],
        [0.0590, 0.0660],
        [0.0625, 0.0623],
        [0.0625, 0.0623]], device='cuda:0')
 Batch: 10 of passive classification Duration: 0:00:00.356922
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0007],
        [0.0004, 0.0009],
        [0.0002, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0006, 0.0011],
        [0.0003, 0.0004],
        [0.0004, 0.0009],
        [0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0004, 0.0012],
        [0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0594, 0.0656],
        [0.0638, 0.0611],
        [0.0574, 0.0679],
        [0.0623, 0.0626],
        [0.0643, 0.0607],
        [0.0641, 0.0608],
        [0.0693, 0.0563],
        [0.0628, 0.0620],
        [0.0619, 0.0630],
        [0.0623, 0.0626],
        [0.0624, 0.0625],
        [0.0593, 0.0657],
        [0.0595, 0.0655],
        [0.0667, 0.0584],
        [0.0641, 0.0608],
        [0.0603, 0.0646]], device='cuda:0')
 Batch: 11 of passive classification Duration: 0:00:00.394014
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0009],
        [0.0005, 0.0012],
        [0.0002, 0.0005],
        [0.0002, 0.0006],
        [0.0005, 0.0017],
        [0.0004, 0.0006],
        [0.0003, 0.0007],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1195, 0.1304],
        [0.1258, 0.1239],
        [0.1203, 0.1296],
        [0.1204, 0.1294],
        [0.1170, 0.1333],
        [0.1354, 0.1151],
        [0.1284, 0.1214],
        [0.1332, 0.1170]], device='cuda:0')
 Batch: 12 of passive classification Duration: 0:00:00.118534
acc:  0.4
Time taken to execute the en SA task with prompt type passive, variation 1 and batchsize 16: 0:00:04.853401
path ['42', 'en', 'bloom-big', 'SA', 'passive', 'prompt_id_1']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002]], device='cuda:0') torch.Size([110, 2])
answers_probs just softmax dim 0: tensor([[0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091]], device='cuda:0')
tensor([[0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA passive 2 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0006],
        [0.0003, 0.0008],
        [0.0002, 0.0007],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0001, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0601, 0.0650],
        [0.0612, 0.0638],
        [0.0623, 0.0626],
        [0.0659, 0.0592],
        [0.0621, 0.0628],
        [0.0616, 0.0634],
        [0.0629, 0.0620],
        [0.0651, 0.0599],
        [0.0622, 0.0627],
        [0.0632, 0.0617],
        [0.0646, 0.0604],
        [0.0623, 0.0626],
        [0.0587, 0.0665],
        [0.0643, 0.0607],
        [0.0639, 0.0610],
        [0.0596, 0.0655]], device='cuda:0')
 Batch: 0 of passive classification Duration: 0:00:00.401259
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0002, 0.0006],
        [0.0002, 0.0006],
        [0.0003, 0.0008],
        [0.0005, 0.0015],
        [0.0003, 0.0005],
        [0.0001, 0.0003],
        [0.0002, 0.0002],
        [0.0002, 0.0003],
        [0.0005, 0.0011],
        [0.0002, 0.0006],
        [0.0004, 0.0010],
        [0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0006],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0621, 0.0627],
        [0.0575, 0.0677],
        [0.0602, 0.0647],
        [0.0627, 0.0621],
        [0.0585, 0.0666],
        [0.0653, 0.0596],
        [0.0615, 0.0633],
        [0.0707, 0.0551],
        [0.0698, 0.0558],
        [0.0626, 0.0622],
        [0.0621, 0.0627],
        [0.0620, 0.0628],
        [0.0609, 0.0640],
        [0.0599, 0.0649],
        [0.0583, 0.0667],
        [0.0657, 0.0593]], device='cuda:0')
 Batch: 1 of passive classification Duration: 0:00:00.358400
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0009],
        [0.0002, 0.0003],
        [0.0002, 0.0006],
        [0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0001, 0.0004],
        [0.0003, 0.0011],
        [0.0001, 0.0004],
        [0.0002, 0.0006],
        [0.0001, 0.0004],
        [0.0003, 0.0006],
        [0.0001, 0.0003],
        [0.0003, 0.0006],
        [0.0001, 0.0003],
        [0.0002, 0.0004],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0625, 0.0624],
        [0.0674, 0.0578],
        [0.0637, 0.0612],
        [0.0620, 0.0629],
        [0.0590, 0.0661],
        [0.0590, 0.0661],
        [0.0599, 0.0652],
        [0.0616, 0.0634],
        [0.0620, 0.0629],
        [0.0598, 0.0652],
        [0.0647, 0.0603],
        [0.0627, 0.0622],
        [0.0652, 0.0598],
        [0.0628, 0.0621],
        [0.0648, 0.0602],
        [0.0627, 0.0622]], device='cuda:0')
 Batch: 2 of passive classification Duration: 0:00:00.326790
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[1.0836e-04, 4.0913e-04],
        [2.5916e-04, 8.6308e-04],
        [1.3483e-04, 3.7217e-04],
        [3.3545e-04, 8.1110e-04],
        [7.2122e-05, 1.5390e-04],
        [1.0318e-04, 2.7728e-04],
        [2.3484e-04, 8.4591e-04],
        [2.5201e-04, 5.9032e-04],
        [1.6344e-04, 4.0460e-04],
        [2.0683e-04, 7.2193e-04],
        [3.0661e-04, 6.6423e-04],
        [1.1826e-04, 3.0327e-04],
        [1.1599e-04, 3.2926e-04],
        [2.9087e-04, 9.9945e-04],
        [2.1613e-04, 7.4863e-04],
        [1.8895e-04, 4.5681e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0592, 0.0659],
        [0.0605, 0.0645],
        [0.0626, 0.0623],
        [0.0643, 0.0607],
        [0.0660, 0.0591],
        [0.0629, 0.0620],
        [0.0596, 0.0654],
        [0.0647, 0.0603],
        [0.0640, 0.0610],
        [0.0600, 0.0651],
        [0.0658, 0.0593],
        [0.0635, 0.0614],
        [0.0623, 0.0626],
        [0.0601, 0.0649],
        [0.0600, 0.0650],
        [0.0643, 0.0607]], device='cuda:0')
 Batch: 3 of passive classification Duration: 0:00:00.329803
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0006],
        [0.0001, 0.0004],
        [0.0003, 0.0007],
        [0.0003, 0.0008],
        [0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0001, 0.0003],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0001, 0.0003],
        [0.0003, 0.0009],
        [0.0002, 0.0005],
        [0.0001, 0.0005],
        [0.0001, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0600, 0.0651],
        [0.0625, 0.0624],
        [0.0629, 0.0620],
        [0.0611, 0.0638],
        [0.0609, 0.0641],
        [0.0656, 0.0595],
        [0.0644, 0.0606],
        [0.0667, 0.0585],
        [0.0623, 0.0626],
        [0.0625, 0.0624],
        [0.0640, 0.0610],
        [0.0639, 0.0611],
        [0.0589, 0.0662],
        [0.0629, 0.0620],
        [0.0605, 0.0645],
        [0.0608, 0.0642]], device='cuda:0')
 Batch: 4 of passive classification Duration: 0:00:00.325877
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0001, 0.0004],
        [0.0001, 0.0005],
        [0.0001, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0006],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0604, 0.0645],
        [0.0629, 0.0620],
        [0.0632, 0.0617],
        [0.0613, 0.0636],
        [0.0596, 0.0654],
        [0.0569, 0.0685],
        [0.0628, 0.0621],
        [0.0606, 0.0643],
        [0.0662, 0.0589],
        [0.0671, 0.0581],
        [0.0629, 0.0620],
        [0.0673, 0.0580],
        [0.0598, 0.0652],
        [0.0632, 0.0617],
        [0.0648, 0.0601],
        [0.0608, 0.0641]], device='cuda:0')
 Batch: 5 of passive classification Duration: 0:00:00.312126
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0002, 0.0006],
        [0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0004, 0.0010],
        [0.0002, 0.0006],
        [0.0002, 0.0006],
        [0.0002, 0.0004],
        [0.0001, 0.0004],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0002, 0.0006],
        [0.0003, 0.0012],
        [0.0002, 0.0004],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0621, 0.0628],
        [0.0618, 0.0631],
        [0.0618, 0.0631],
        [0.0620, 0.0629],
        [0.0649, 0.0601],
        [0.0625, 0.0624],
        [0.0603, 0.0647],
        [0.0616, 0.0633],
        [0.0613, 0.0636],
        [0.0640, 0.0610],
        [0.0662, 0.0590],
        [0.0671, 0.0581],
        [0.0605, 0.0644],
        [0.0564, 0.0692],
        [0.0636, 0.0614],
        [0.0641, 0.0609]], device='cuda:0')
 Batch: 6 of passive classification Duration: 0:00:00.313688
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[1.6224e-04, 4.1103e-04],
        [1.7321e-04, 3.9029e-04],
        [2.3329e-04, 6.8569e-04],
        [1.5914e-04, 4.9973e-04],
        [8.9705e-05, 1.5080e-04],
        [1.7107e-04, 4.6873e-04],
        [4.2272e-04, 1.1578e-03],
        [1.7583e-04, 3.7503e-04],
        [2.6608e-04, 7.5197e-04],
        [1.6797e-04, 4.4584e-04],
        [1.5402e-04, 4.0889e-04],
        [9.4771e-05, 2.2554e-04],
        [2.1720e-04, 4.7064e-04],
        [2.8300e-04, 7.9393e-04],
        [6.7830e-05, 2.5201e-04],
        [2.8658e-04, 6.2084e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0625, 0.0624],
        [0.0640, 0.0609],
        [0.0607, 0.0643],
        [0.0599, 0.0651],
        [0.0684, 0.0571],
        [0.0615, 0.0634],
        [0.0615, 0.0634],
        [0.0648, 0.0602],
        [0.0611, 0.0638],
        [0.0619, 0.0630],
        [0.0619, 0.0630],
        [0.0633, 0.0616],
        [0.0646, 0.0604],
        [0.0612, 0.0637],
        [0.0582, 0.0670],
        [0.0646, 0.0604]], device='cuda:0')
 Batch: 7 of passive classification Duration: 0:00:00.423484
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0001, 0.0003],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0001, 0.0004],
        [0.0002, 0.0008],
        [0.0003, 0.0009],
        [0.0002, 0.0003],
        [0.0002, 0.0007],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0629, 0.0620],
        [0.0638, 0.0611],
        [0.0639, 0.0610],
        [0.0614, 0.0635],
        [0.0598, 0.0652],
        [0.0640, 0.0609],
        [0.0626, 0.0623],
        [0.0645, 0.0604],
        [0.0653, 0.0597],
        [0.0640, 0.0610],
        [0.0608, 0.0642],
        [0.0577, 0.0675],
        [0.0598, 0.0651],
        [0.0691, 0.0564],
        [0.0588, 0.0663],
        [0.0615, 0.0634]], device='cuda:0')
 Batch: 8 of passive classification Duration: 0:00:00.553924
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[8.9109e-05, 1.9383e-04],
        [4.9257e-04, 8.9216e-04],
        [3.0708e-04, 5.6076e-04],
        [1.6451e-04, 3.5667e-04],
        [2.2674e-04, 6.0225e-04],
        [2.8849e-04, 7.1383e-04],
        [1.4389e-04, 2.6059e-04],
        [2.4331e-04, 8.3590e-04],
        [1.8406e-04, 4.9639e-04],
        [2.3437e-04, 7.5674e-04],
        [3.8004e-04, 7.3814e-04],
        [2.3878e-04, 6.0987e-04],
        [1.4234e-04, 2.6178e-04],
        [2.9159e-04, 6.7806e-04],
        [1.5783e-04, 3.2640e-04],
        [2.9230e-04, 8.3876e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0632, 0.0617],
        [0.0658, 0.0592],
        [0.0657, 0.0594],
        [0.0632, 0.0617],
        [0.0606, 0.0643],
        [0.0615, 0.0634],
        [0.0658, 0.0592],
        [0.0578, 0.0675],
        [0.0604, 0.0645],
        [0.0584, 0.0667],
        [0.0648, 0.0602],
        [0.0611, 0.0638],
        [0.0656, 0.0594],
        [0.0623, 0.0626],
        [0.0639, 0.0610],
        [0.0597, 0.0653]], device='cuda:0')
 Batch: 9 of passive classification Duration: 0:00:00.469067
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[1.2493e-04, 3.2401e-04],
        [9.7334e-05, 2.4378e-04],
        [1.9634e-04, 4.7827e-04],
        [2.0432e-04, 5.6839e-04],
        [3.9411e-04, 8.8120e-04],
        [2.2662e-04, 7.0381e-04],
        [1.5867e-04, 4.4847e-04],
        [1.8287e-04, 5.7650e-04],
        [2.8014e-04, 6.3658e-04],
        [2.4605e-04, 7.3481e-04],
        [3.2687e-04, 6.9761e-04],
        [3.7074e-04, 6.2609e-04],
        [2.0897e-04, 5.0926e-04],
        [2.9325e-04, 7.0906e-04],
        [1.6904e-04, 5.8508e-04],
        [1.3876e-04, 4.0483e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0623, 0.0626],
        [0.0628, 0.0621],
        [0.0631, 0.0618],
        [0.0615, 0.0635],
        [0.0643, 0.0607],
        [0.0602, 0.0648],
        [0.0613, 0.0637],
        [0.0600, 0.0650],
        [0.0641, 0.0609],
        [0.0607, 0.0643],
        [0.0649, 0.0601],
        [0.0685, 0.0570],
        [0.0631, 0.0618],
        [0.0632, 0.0617],
        [0.0591, 0.0661],
        [0.0609, 0.0640]], device='cuda:0')
 Batch: 10 of passive classification Duration: 0:00:00.349481
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[2.0730e-04, 7.6437e-04],
        [1.7929e-04, 6.1607e-04],
        [1.5104e-04, 3.7670e-04],
        [1.9026e-04, 4.0603e-04],
        [2.3043e-04, 7.3242e-04],
        [1.1140e-04, 3.6526e-04],
        [1.3530e-04, 2.1613e-04],
        [1.8787e-04, 5.5647e-04],
        [1.9276e-04, 6.3181e-04],
        [3.2473e-04, 8.1635e-04],
        [2.3305e-04, 7.3481e-04],
        [7.7367e-05, 8.9765e-05],
        [2.6655e-04, 6.5994e-04],
        [3.2496e-04, 6.4611e-04],
        [1.9288e-04, 4.4155e-04],
        [1.7703e-04, 5.5408e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0581, 0.0669],
        [0.0588, 0.0661],
        [0.0625, 0.0622],
        [0.0646, 0.0602],
        [0.0596, 0.0652],
        [0.0593, 0.0656],
        [0.0690, 0.0564],
        [0.0604, 0.0644],
        [0.0593, 0.0656],
        [0.0624, 0.0623],
        [0.0597, 0.0651],
        [0.0746, 0.0522],
        [0.0626, 0.0621],
        [0.0656, 0.0593],
        [0.0636, 0.0611],
        [0.0598, 0.0650]], device='cuda:0')
 Batch: 11 of passive classification Duration: 0:00:00.357994
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0002, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0006],
        [0.0002, 0.0006],
        [0.0002, 0.0007],
        [0.0001, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1238, 0.1262],
        [0.1264, 0.1235],
        [0.1253, 0.1246],
        [0.1196, 0.1305],
        [0.1216, 0.1284],
        [0.1251, 0.1249],
        [0.1304, 0.1198],
        [0.1278, 0.1221]], device='cuda:0')
 Batch: 12 of passive classification Duration: 0:00:00.228642
acc:  0.565
Time taken to execute the en SA task with prompt type passive, variation 2 and batchsize 16: 0:00:04.771409
path ['42', 'en', 'bloom-big', 'SA', 'passive', 'prompt_id_2']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([114, 2])
answers_probs just softmax dim 0: tensor([[0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088]], device='cuda:0')
tensor([[0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA passive 3 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0003, 0.0010],
        [0.0004, 0.0009],
        [0.0003, 0.0008],
        [0.0005, 0.0011],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0005, 0.0016],
        [0.0003, 0.0010],
        [0.0008, 0.0010],
        [0.0004, 0.0007],
        [0.0009, 0.0019],
        [0.0008, 0.0016],
        [0.0005, 0.0009],
        [0.0004, 0.0009],
        [0.0005, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0636, 0.0613],
        [0.0585, 0.0666],
        [0.0608, 0.0641],
        [0.0607, 0.0642],
        [0.0623, 0.0625],
        [0.0627, 0.0621],
        [0.0665, 0.0586],
        [0.0576, 0.0676],
        [0.0577, 0.0676],
        [0.0704, 0.0554],
        [0.0648, 0.0601],
        [0.0625, 0.0623],
        [0.0637, 0.0612],
        [0.0658, 0.0592],
        [0.0620, 0.0628],
        [0.0604, 0.0645]], device='cuda:0')
 Batch: 0 of passive classification Duration: 0:00:00.310052
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0006, 0.0013],
        [0.0008, 0.0011],
        [0.0004, 0.0009],
        [0.0005, 0.0011],
        [0.0005, 0.0009],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0003, 0.0009],
        [0.0004, 0.0010],
        [0.0007, 0.0014],
        [0.0005, 0.0008],
        [0.0005, 0.0010],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0004, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0621, 0.0628],
        [0.0622, 0.0627],
        [0.0683, 0.0571],
        [0.0607, 0.0643],
        [0.0617, 0.0632],
        [0.0640, 0.0609],
        [0.0635, 0.0614],
        [0.0644, 0.0606],
        [0.0597, 0.0653],
        [0.0594, 0.0656],
        [0.0621, 0.0628],
        [0.0660, 0.0590],
        [0.0643, 0.0607],
        [0.0647, 0.0602],
        [0.0583, 0.0669],
        [0.0587, 0.0664]], device='cuda:0')
 Batch: 1 of passive classification Duration: 0:00:00.465000
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0012],
        [0.0002, 0.0005],
        [0.0004, 0.0011],
        [0.0007, 0.0017],
        [0.0004, 0.0013],
        [0.0005, 0.0012],
        [0.0006, 0.0014],
        [0.0007, 0.0015],
        [0.0004, 0.0010],
        [0.0003, 0.0010],
        [0.0003, 0.0012],
        [0.0005, 0.0013],
        [0.0005, 0.0010],
        [0.0006, 0.0013],
        [0.0005, 0.0008],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0631, 0.0618],
        [0.0626, 0.0623],
        [0.0608, 0.0641],
        [0.0630, 0.0619],
        [0.0582, 0.0670],
        [0.0634, 0.0615],
        [0.0619, 0.0630],
        [0.0638, 0.0611],
        [0.0618, 0.0631],
        [0.0598, 0.0652],
        [0.0573, 0.0681],
        [0.0628, 0.0621],
        [0.0648, 0.0602],
        [0.0639, 0.0610],
        [0.0693, 0.0563],
        [0.0637, 0.0612]], device='cuda:0')
 Batch: 2 of passive classification Duration: 0:00:00.419088
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0011],
        [0.0005, 0.0012],
        [0.0004, 0.0010],
        [0.0004, 0.0010],
        [0.0004, 0.0014],
        [0.0003, 0.0009],
        [0.0004, 0.0009],
        [0.0003, 0.0009],
        [0.0008, 0.0014],
        [0.0003, 0.0008],
        [0.0006, 0.0021],
        [0.0008, 0.0015],
        [0.0005, 0.0017],
        [0.0004, 0.0008],
        [0.0007, 0.0014],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0685, 0.0569],
        [0.0627, 0.0621],
        [0.0609, 0.0640],
        [0.0620, 0.0628],
        [0.0588, 0.0663],
        [0.0602, 0.0647],
        [0.0629, 0.0620],
        [0.0606, 0.0643],
        [0.0656, 0.0594],
        [0.0620, 0.0628],
        [0.0582, 0.0670],
        [0.0658, 0.0593],
        [0.0569, 0.0685],
        [0.0659, 0.0592],
        [0.0650, 0.0599],
        [0.0642, 0.0607]], device='cuda:0')
 Batch: 3 of passive classification Duration: 0:00:00.396871
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0014],
        [0.0005, 0.0012],
        [0.0003, 0.0005],
        [0.0004, 0.0012],
        [0.0004, 0.0007],
        [0.0004, 0.0011],
        [0.0003, 0.0007],
        [0.0005, 0.0017],
        [0.0005, 0.0014],
        [0.0007, 0.0010],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0008, 0.0019],
        [0.0003, 0.0007],
        [0.0006, 0.0020],
        [0.0007, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0617, 0.0631],
        [0.0614, 0.0634],
        [0.0679, 0.0574],
        [0.0590, 0.0661],
        [0.0657, 0.0593],
        [0.0619, 0.0629],
        [0.0618, 0.0630],
        [0.0580, 0.0672],
        [0.0601, 0.0648],
        [0.0689, 0.0565],
        [0.0661, 0.0590],
        [0.0597, 0.0653],
        [0.0626, 0.0622],
        [0.0613, 0.0635],
        [0.0591, 0.0659],
        [0.0645, 0.0604]], device='cuda:0')
 Batch: 4 of passive classification Duration: 0:00:00.358482
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0012],
        [0.0006, 0.0012],
        [0.0003, 0.0009],
        [0.0006, 0.0012],
        [0.0009, 0.0017],
        [0.0003, 0.0011],
        [0.0002, 0.0008],
        [0.0004, 0.0011],
        [0.0007, 0.0016],
        [0.0005, 0.0009],
        [0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0007, 0.0012],
        [0.0006, 0.0011],
        [0.0004, 0.0012],
        [0.0006, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0566, 0.0688],
        [0.0644, 0.0605],
        [0.0587, 0.0663],
        [0.0641, 0.0607],
        [0.0663, 0.0587],
        [0.0580, 0.0671],
        [0.0581, 0.0670],
        [0.0590, 0.0660],
        [0.0617, 0.0632],
        [0.0662, 0.0588],
        [0.0656, 0.0593],
        [0.0634, 0.0614],
        [0.0663, 0.0587],
        [0.0661, 0.0589],
        [0.0600, 0.0649],
        [0.0654, 0.0595]], device='cuda:0')
 Batch: 5 of passive classification Duration: 0:00:00.358599
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0009, 0.0017],
        [0.0006, 0.0013],
        [0.0004, 0.0009],
        [0.0005, 0.0011],
        [0.0004, 0.0008],
        [0.0006, 0.0016],
        [0.0002, 0.0005],
        [0.0005, 0.0009],
        [0.0006, 0.0015],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0004, 0.0013],
        [0.0004, 0.0010],
        [0.0004, 0.0010],
        [0.0004, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0647, 0.0603],
        [0.0658, 0.0593],
        [0.0628, 0.0622],
        [0.0610, 0.0640],
        [0.0644, 0.0606],
        [0.0629, 0.0621],
        [0.0605, 0.0645],
        [0.0636, 0.0614],
        [0.0656, 0.0595],
        [0.0615, 0.0634],
        [0.0616, 0.0633],
        [0.0620, 0.0629],
        [0.0591, 0.0660],
        [0.0620, 0.0629],
        [0.0619, 0.0630],
        [0.0605, 0.0645]], device='cuda:0')
 Batch: 6 of passive classification Duration: 0:00:00.324857
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0004, 0.0014],
        [0.0003, 0.0009],
        [0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0007, 0.0019],
        [0.0006, 0.0007],
        [0.0004, 0.0008],
        [0.0005, 0.0011],
        [0.0003, 0.0011],
        [0.0002, 0.0005],
        [0.0002, 0.0007],
        [0.0005, 0.0013],
        [0.0002, 0.0005],
        [0.0004, 0.0008],
        [0.0008, 0.0016]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0617, 0.0631],
        [0.0596, 0.0653],
        [0.0606, 0.0643],
        [0.0604, 0.0645],
        [0.0642, 0.0608],
        [0.0609, 0.0640],
        [0.0720, 0.0541],
        [0.0634, 0.0615],
        [0.0639, 0.0609],
        [0.0589, 0.0662],
        [0.0610, 0.0639],
        [0.0594, 0.0656],
        [0.0626, 0.0623],
        [0.0621, 0.0628],
        [0.0638, 0.0611],
        [0.0654, 0.0596]], device='cuda:0')
 Batch: 7 of passive classification Duration: 0:00:00.552308
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0012],
        [0.0004, 0.0012],
        [0.0004, 0.0009],
        [0.0008, 0.0014],
        [0.0005, 0.0009],
        [0.0003, 0.0006],
        [0.0007, 0.0008],
        [0.0004, 0.0009],
        [0.0005, 0.0009],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0007, 0.0017],
        [0.0004, 0.0011],
        [0.0002, 0.0006],
        [0.0005, 0.0010],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0571, 0.0682],
        [0.0582, 0.0669],
        [0.0601, 0.0648],
        [0.0653, 0.0597],
        [0.0639, 0.0610],
        [0.0634, 0.0614],
        [0.0706, 0.0552],
        [0.0607, 0.0642],
        [0.0642, 0.0607],
        [0.0618, 0.0631],
        [0.0641, 0.0608],
        [0.0612, 0.0637],
        [0.0602, 0.0647],
        [0.0609, 0.0640],
        [0.0629, 0.0620],
        [0.0654, 0.0596]], device='cuda:0')
 Batch: 8 of passive classification Duration: 0:00:00.395934
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0008, 0.0015],
        [0.0005, 0.0011],
        [0.0005, 0.0010],
        [0.0002, 0.0006],
        [0.0005, 0.0010],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0009],
        [0.0005, 0.0011],
        [0.0003, 0.0009],
        [0.0002, 0.0006],
        [0.0010, 0.0016],
        [0.0003, 0.0007],
        [0.0005, 0.0010],
        [0.0006, 0.0014],
        [0.0003, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0648, 0.0601],
        [0.0622, 0.0627],
        [0.0651, 0.0598],
        [0.0612, 0.0637],
        [0.0650, 0.0599],
        [0.0642, 0.0607],
        [0.0678, 0.0575],
        [0.0597, 0.0652],
        [0.0622, 0.0627],
        [0.0578, 0.0674],
        [0.0578, 0.0674],
        [0.0667, 0.0584],
        [0.0593, 0.0657],
        [0.0635, 0.0614],
        [0.0615, 0.0634],
        [0.0611, 0.0638]], device='cuda:0')
 Batch: 9 of passive classification Duration: 0:00:00.399173
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0004, 0.0012],
        [0.0004, 0.0008],
        [0.0006, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0011],
        [0.0004, 0.0007],
        [0.0008, 0.0013],
        [0.0003, 0.0005],
        [0.0002, 0.0007],
        [0.0008, 0.0016],
        [0.0004, 0.0009],
        [0.0002, 0.0007],
        [0.0005, 0.0015],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0634, 0.0614],
        [0.0608, 0.0640],
        [0.0603, 0.0645],
        [0.0635, 0.0613],
        [0.0692, 0.0563],
        [0.0665, 0.0585],
        [0.0571, 0.0681],
        [0.0643, 0.0606],
        [0.0670, 0.0581],
        [0.0649, 0.0600],
        [0.0583, 0.0668],
        [0.0637, 0.0611],
        [0.0603, 0.0645],
        [0.0594, 0.0656],
        [0.0574, 0.0679],
        [0.0637, 0.0611]], device='cuda:0')
 Batch: 10 of passive classification Duration: 0:00:00.400386
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0007],
        [0.0008, 0.0019],
        [0.0004, 0.0009],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0004, 0.0009],
        [0.0006, 0.0011],
        [0.0004, 0.0007],
        [0.0004, 0.0011],
        [0.0005, 0.0013],
        [0.0004, 0.0009],
        [0.0002, 0.0004],
        [0.0004, 0.0010],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0556, 0.0702],
        [0.0612, 0.0637],
        [0.0632, 0.0617],
        [0.0636, 0.0613],
        [0.0623, 0.0626],
        [0.0636, 0.0613],
        [0.0642, 0.0608],
        [0.0656, 0.0595],
        [0.0606, 0.0643],
        [0.0605, 0.0645],
        [0.0629, 0.0620],
        [0.0652, 0.0598],
        [0.0613, 0.0636],
        [0.0644, 0.0606],
        [0.0625, 0.0624],
        [0.0632, 0.0617]], device='cuda:0')
 Batch: 11 of passive classification Duration: 0:00:00.419617
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0004, 0.0004],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0004, 0.0012],
        [0.0004, 0.0012]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1249],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1279, 0.1216],
        [0.1468, 0.1060],
        [0.1207, 0.1288],
        [0.1236, 0.1259],
        [0.1263, 0.1231],
        [0.1183, 0.1315],
        [0.1181, 0.1317],
        [0.1183, 0.1315]], device='cuda:0')
 Batch: 12 of passive classification Duration: 0:00:00.210218
acc:  0.525
Time taken to execute the en SA task with prompt type passive, variation 3 and batchsize 16: 0:00:05.032657
path ['42', 'en', 'bloom-big', 'SA', 'passive', 'prompt_id_3']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0005]], device='cuda:0') torch.Size([122, 2])
answers_probs just softmax dim 0: tensor([[0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082]], device='cuda:0')
tensor([[0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082],
        [0.0082, 0.0082]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA passive 4 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0016],
        [0.0003, 0.0005],
        [0.0005, 0.0022],
        [0.0003, 0.0011],
        [0.0002, 0.0005],
        [0.0004, 0.0015],
        [0.0002, 0.0005],
        [0.0001, 0.0004],
        [0.0004, 0.0015],
        [0.0004, 0.0012],
        [0.0003, 0.0009],
        [0.0006, 0.0010],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0012],
        [0.0004, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0608, 0.0640],
        [0.0695, 0.0561],
        [0.0584, 0.0667],
        [0.0600, 0.0649],
        [0.0602, 0.0647],
        [0.0600, 0.0649],
        [0.0629, 0.0619],
        [0.0612, 0.0637],
        [0.0607, 0.0642],
        [0.0610, 0.0638],
        [0.0615, 0.0633],
        [0.0693, 0.0562],
        [0.0674, 0.0578],
        [0.0654, 0.0596],
        [0.0614, 0.0635],
        [0.0603, 0.0646]], device='cuda:0')
 Batch: 0 of passive classification Duration: 0:00:00.425377
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0005, 0.0016],
        [0.0004, 0.0012],
        [0.0004, 0.0010],
        [0.0001, 0.0006],
        [0.0004, 0.0014],
        [0.0003, 0.0010],
        [0.0003, 0.0006],
        [0.0003, 0.0009],
        [0.0002, 0.0006],
        [0.0002, 0.0006],
        [0.0002, 0.0008],
        [0.0004, 0.0012],
        [0.0002, 0.0007],
        [0.0003, 0.0010],
        [0.0005, 0.0018]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626]], device='cuda:0')
tensor([[0.0689, 0.0566],
        [0.0632, 0.0617],
        [0.0629, 0.0620],
        [0.0639, 0.0610],
        [0.0595, 0.0656],
        [0.0600, 0.0650],
        [0.0613, 0.0636],
        [0.0660, 0.0591],
        [0.0615, 0.0634],
        [0.0643, 0.0606],
        [0.0616, 0.0634],
        [0.0600, 0.0651],
        [0.0637, 0.0613],
        [0.0618, 0.0631],
        [0.0606, 0.0644],
        [0.0608, 0.0641]], device='cuda:0')
 Batch: 1 of passive classification Duration: 0:00:00.397698
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0013],
        [0.0003, 0.0010],
        [0.0007, 0.0023],
        [0.0003, 0.0013],
        [0.0003, 0.0008],
        [0.0005, 0.0012],
        [0.0002, 0.0007],
        [0.0004, 0.0016],
        [0.0004, 0.0011],
        [0.0005, 0.0014],
        [0.0004, 0.0010],
        [0.0004, 0.0009],
        [0.0007, 0.0020],
        [0.0003, 0.0011],
        [0.0004, 0.0014],
        [0.0004, 0.0014]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0609, 0.0641],
        [0.0619, 0.0631],
        [0.0618, 0.0631],
        [0.0604, 0.0646],
        [0.0631, 0.0619],
        [0.0656, 0.0595],
        [0.0608, 0.0642],
        [0.0591, 0.0660],
        [0.0632, 0.0618],
        [0.0644, 0.0606],
        [0.0648, 0.0602],
        [0.0665, 0.0587],
        [0.0635, 0.0614],
        [0.0598, 0.0653],
        [0.0611, 0.0639],
        [0.0633, 0.0617]], device='cuda:0')
 Batch: 2 of passive classification Duration: 0:00:00.437309
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0002, 0.0007],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0005, 0.0017],
        [0.0002, 0.0009],
        [0.0004, 0.0010],
        [0.0012, 0.0018],
        [0.0002, 0.0007],
        [0.0003, 0.0008],
        [0.0002, 0.0007],
        [0.0004, 0.0011],
        [0.0005, 0.0009],
        [0.0002, 0.0007],
        [0.0004, 0.0010],
        [0.0004, 0.0016]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0634, 0.0614],
        [0.0587, 0.0662],
        [0.0703, 0.0553],
        [0.0679, 0.0573],
        [0.0583, 0.0668],
        [0.0580, 0.0671],
        [0.0632, 0.0616],
        [0.0695, 0.0560],
        [0.0599, 0.0650],
        [0.0619, 0.0629],
        [0.0608, 0.0640],
        [0.0613, 0.0635],
        [0.0661, 0.0589],
        [0.0606, 0.0642],
        [0.0634, 0.0614],
        [0.0568, 0.0684]], device='cuda:0')
 Batch: 3 of passive classification Duration: 0:00:00.482679
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0011],
        [0.0005, 0.0009],
        [0.0004, 0.0012],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0004, 0.0009],
        [0.0003, 0.0009],
        [0.0002, 0.0006],
        [0.0004, 0.0012],
        [0.0002, 0.0006],
        [0.0001, 0.0003],
        [0.0005, 0.0012],
        [0.0004, 0.0012],
        [0.0007, 0.0016],
        [0.0003, 0.0010],
        [0.0004, 0.0017]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0648, 0.0602],
        [0.0678, 0.0575],
        [0.0611, 0.0639],
        [0.0623, 0.0626],
        [0.0612, 0.0637],
        [0.0651, 0.0599],
        [0.0619, 0.0631],
        [0.0594, 0.0657],
        [0.0600, 0.0650],
        [0.0635, 0.0614],
        [0.0637, 0.0612],
        [0.0641, 0.0608],
        [0.0619, 0.0630],
        [0.0644, 0.0605],
        [0.0614, 0.0635],
        [0.0574, 0.0680]], device='cuda:0')
 Batch: 4 of passive classification Duration: 0:00:00.441042
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0004, 0.0015],
        [0.0005, 0.0012],
        [0.0003, 0.0010],
        [0.0007, 0.0015],
        [0.0004, 0.0014],
        [0.0002, 0.0009],
        [0.0002, 0.0009],
        [0.0002, 0.0008],
        [0.0003, 0.0011],
        [0.0005, 0.0013],
        [0.0002, 0.0006],
        [0.0004, 0.0010],
        [0.0003, 0.0010],
        [0.0003, 0.0006],
        [0.0003, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0675, 0.0577],
        [0.0589, 0.0661],
        [0.0638, 0.0611],
        [0.0610, 0.0639],
        [0.0669, 0.0582],
        [0.0610, 0.0639],
        [0.0578, 0.0675],
        [0.0597, 0.0653],
        [0.0584, 0.0668],
        [0.0614, 0.0634],
        [0.0642, 0.0607],
        [0.0633, 0.0615],
        [0.0652, 0.0598],
        [0.0623, 0.0625],
        [0.0670, 0.0581],
        [0.0615, 0.0633]], device='cuda:0')
 Batch: 5 of passive classification Duration: 0:00:00.358942
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0012],
        [0.0002, 0.0006],
        [0.0002, 0.0006],
        [0.0006, 0.0022],
        [0.0003, 0.0007],
        [0.0003, 0.0008],
        [0.0003, 0.0011],
        [0.0002, 0.0006],
        [0.0002, 0.0008],
        [0.0003, 0.0012],
        [0.0005, 0.0012],
        [0.0005, 0.0018],
        [0.0002, 0.0007],
        [0.0001, 0.0004],
        [0.0003, 0.0008],
        [0.0004, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0639, 0.0611],
        [0.0600, 0.0650],
        [0.0628, 0.0622],
        [0.0619, 0.0630],
        [0.0661, 0.0590],
        [0.0638, 0.0612],
        [0.0622, 0.0628],
        [0.0654, 0.0597],
        [0.0605, 0.0645],
        [0.0595, 0.0656],
        [0.0649, 0.0602],
        [0.0624, 0.0625],
        [0.0611, 0.0639],
        [0.0604, 0.0646],
        [0.0628, 0.0622],
        [0.0624, 0.0625]], device='cuda:0')
 Batch: 6 of passive classification Duration: 0:00:00.441616
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0013],
        [0.0002, 0.0007],
        [0.0005, 0.0012],
        [0.0004, 0.0011],
        [0.0004, 0.0010],
        [0.0004, 0.0012],
        [0.0002, 0.0003],
        [0.0008, 0.0023],
        [0.0003, 0.0010],
        [0.0003, 0.0014],
        [0.0007, 0.0022],
        [0.0010, 0.0023],
        [0.0003, 0.0007],
        [0.0007, 0.0019],
        [0.0002, 0.0007],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0624],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0604, 0.0645],
        [0.0605, 0.0644],
        [0.0650, 0.0600],
        [0.0629, 0.0620],
        [0.0646, 0.0603],
        [0.0627, 0.0622],
        [0.0709, 0.0550],
        [0.0610, 0.0639],
        [0.0584, 0.0667],
        [0.0575, 0.0678],
        [0.0613, 0.0636],
        [0.0645, 0.0604],
        [0.0652, 0.0598],
        [0.0628, 0.0621],
        [0.0607, 0.0642],
        [0.0616, 0.0632]], device='cuda:0')
 Batch: 7 of passive classification Duration: 0:00:00.356409
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0004, 0.0012],
        [0.0006, 0.0017],
        [0.0002, 0.0010],
        [0.0003, 0.0009],
        [0.0005, 0.0013],
        [0.0002, 0.0009],
        [0.0002, 0.0009],
        [0.0001, 0.0004],
        [0.0003, 0.0012],
        [0.0003, 0.0009],
        [0.0002, 0.0007],
        [0.0007, 0.0016],
        [0.0003, 0.0009],
        [0.0005, 0.0012],
        [0.0002, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0652, 0.0598],
        [0.0632, 0.0617],
        [0.0635, 0.0614],
        [0.0591, 0.0661],
        [0.0619, 0.0630],
        [0.0658, 0.0593],
        [0.0580, 0.0673],
        [0.0596, 0.0655],
        [0.0634, 0.0615],
        [0.0602, 0.0648],
        [0.0621, 0.0628],
        [0.0627, 0.0622],
        [0.0651, 0.0599],
        [0.0641, 0.0609],
        [0.0652, 0.0598],
        [0.0609, 0.0640]], device='cuda:0')
 Batch: 8 of passive classification Duration: 0:00:00.330215
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0004, 0.0012],
        [0.0005, 0.0014],
        [0.0002, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0004, 0.0015],
        [0.0004, 0.0017],
        [0.0004, 0.0015],
        [0.0003, 0.0014],
        [0.0004, 0.0012],
        [0.0002, 0.0009],
        [0.0003, 0.0009],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0003, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0641, 0.0608],
        [0.0636, 0.0612],
        [0.0631, 0.0617],
        [0.0591, 0.0660],
        [0.0629, 0.0619],
        [0.0697, 0.0559],
        [0.0592, 0.0658],
        [0.0583, 0.0668],
        [0.0604, 0.0645],
        [0.0579, 0.0673],
        [0.0630, 0.0618],
        [0.0602, 0.0647],
        [0.0627, 0.0621],
        [0.0692, 0.0563],
        [0.0662, 0.0589],
        [0.0604, 0.0645]], device='cuda:0')
 Batch: 9 of passive classification Duration: 0:00:00.551808
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0010],
        [0.0004, 0.0011],
        [0.0002, 0.0007],
        [0.0003, 0.0008],
        [0.0003, 0.0009],
        [0.0003, 0.0011],
        [0.0002, 0.0005],
        [0.0003, 0.0011],
        [0.0002, 0.0007],
        [0.0003, 0.0013],
        [0.0001, 0.0007],
        [0.0006, 0.0023],
        [0.0005, 0.0010],
        [0.0006, 0.0010],
        [0.0002, 0.0003],
        [0.0005, 0.0015]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0584, 0.0666],
        [0.0640, 0.0607],
        [0.0589, 0.0660],
        [0.0624, 0.0623],
        [0.0633, 0.0614],
        [0.0587, 0.0662],
        [0.0664, 0.0586],
        [0.0605, 0.0643],
        [0.0604, 0.0643],
        [0.0589, 0.0660],
        [0.0576, 0.0675],
        [0.0600, 0.0649],
        [0.0666, 0.0584],
        [0.0706, 0.0551],
        [0.0724, 0.0537],
        [0.0609, 0.0638]], device='cuda:0')
 Batch: 10 of passive classification Duration: 0:00:00.395834
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0011],
        [0.0004, 0.0013],
        [0.0002, 0.0005],
        [0.0007, 0.0016],
        [0.0003, 0.0009],
        [0.0001, 0.0006],
        [0.0003, 0.0010],
        [0.0005, 0.0016],
        [0.0004, 0.0012],
        [0.0004, 0.0010],
        [0.0002, 0.0009],
        [0.0002, 0.0009],
        [0.0003, 0.0005],
        [0.0003, 0.0011],
        [0.0003, 0.0010],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0615, 0.0634],
        [0.0623, 0.0625],
        [0.0643, 0.0606],
        [0.0670, 0.0581],
        [0.0608, 0.0641],
        [0.0591, 0.0659],
        [0.0606, 0.0643],
        [0.0612, 0.0636],
        [0.0631, 0.0617],
        [0.0657, 0.0593],
        [0.0566, 0.0688],
        [0.0601, 0.0648],
        [0.0712, 0.0547],
        [0.0596, 0.0653],
        [0.0602, 0.0647],
        [0.0667, 0.0583]], device='cuda:0')
 Batch: 11 of passive classification Duration: 0:00:00.396084
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0004, 0.0013],
        [0.0002, 0.0007],
        [0.0005, 0.0017],
        [0.0006, 0.0026],
        [0.0002, 0.0009],
        [0.0002, 0.0009],
        [0.0004, 0.0010]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1249],
        [0.1250, 0.1251],
        [0.1250, 0.1252],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1336, 0.1168],
        [0.1227, 0.1272],
        [0.1276, 0.1223],
        [0.1237, 0.1261],
        [0.1193, 0.1307],
        [0.1220, 0.1279],
        [0.1203, 0.1297],
        [0.1308, 0.1193]], device='cuda:0')
 Batch: 12 of passive classification Duration: 0:00:00.151499
acc:  0.54
Time taken to execute the en SA task with prompt type passive, variation 4 and batchsize 16: 0:00:05.188068
path ['42', 'en', 'bloom-big', 'SA', 'passive', 'prompt_id_4']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([119, 2])
answers_probs just softmax dim 0: tensor([[0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084]], device='cuda:0')
tensor([[0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA passive 5 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0005, 0.0015],
        [0.0002, 0.0004],
        [0.0007, 0.0012],
        [0.0005, 0.0007],
        [0.0003, 0.0004],
        [0.0004, 0.0006],
        [0.0003, 0.0011],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0005, 0.0006],
        [0.0006, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0648, 0.0602],
        [0.0562, 0.0694],
        [0.0632, 0.0616],
        [0.0638, 0.0611],
        [0.0660, 0.0591],
        [0.0651, 0.0598],
        [0.0628, 0.0621],
        [0.0557, 0.0700],
        [0.0606, 0.0643],
        [0.0605, 0.0644],
        [0.0634, 0.0615],
        [0.0626, 0.0623],
        [0.0621, 0.0627],
        [0.0621, 0.0627],
        [0.0674, 0.0578],
        [0.0637, 0.0612]], device='cuda:0')
 Batch: 0 of passive classification Duration: 0:00:00.367672
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0005, 0.0010],
        [0.0005, 0.0010],
        [0.0005, 0.0007],
        [0.0002, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0007, 0.0011],
        [0.0005, 0.0007],
        [0.0003, 0.0006],
        [0.0007, 0.0015],
        [0.0004, 0.0006],
        [0.0004, 0.0014]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0640, 0.0609],
        [0.0668, 0.0583],
        [0.0627, 0.0621],
        [0.0626, 0.0622],
        [0.0606, 0.0643],
        [0.0657, 0.0593],
        [0.0580, 0.0672],
        [0.0642, 0.0607],
        [0.0597, 0.0653],
        [0.0637, 0.0611],
        [0.0649, 0.0600],
        [0.0648, 0.0601],
        [0.0595, 0.0655],
        [0.0610, 0.0639],
        [0.0665, 0.0586],
        [0.0554, 0.0704]], device='cuda:0')
 Batch: 1 of passive classification Duration: 0:00:00.401254
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0003, 0.0008],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0010, 0.0013],
        [0.0003, 0.0009],
        [0.0004, 0.0008],
        [0.0005, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0010],
        [0.0004, 0.0012],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0005, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0603, 0.0645],
        [0.0581, 0.0669],
        [0.0642, 0.0606],
        [0.0592, 0.0657],
        [0.0637, 0.0610],
        [0.0685, 0.0568],
        [0.0580, 0.0671],
        [0.0625, 0.0622],
        [0.0706, 0.0551],
        [0.0609, 0.0639],
        [0.0566, 0.0687],
        [0.0576, 0.0675],
        [0.0671, 0.0580],
        [0.0690, 0.0563],
        [0.0631, 0.0617],
        [0.0606, 0.0642]], device='cuda:0')
 Batch: 2 of passive classification Duration: 0:00:00.439739
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0005],
        [0.0004, 0.0006],
        [0.0006, 0.0020],
        [0.0005, 0.0011],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0006, 0.0012],
        [0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0005, 0.0008],
        [0.0003, 0.0009],
        [0.0004, 0.0006],
        [0.0004, 0.0011],
        [0.0002, 0.0004],
        [0.0008, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0694, 0.0561],
        [0.0641, 0.0607],
        [0.0567, 0.0687],
        [0.0603, 0.0646],
        [0.0601, 0.0648],
        [0.0623, 0.0625],
        [0.0611, 0.0638],
        [0.0633, 0.0615],
        [0.0621, 0.0627],
        [0.0601, 0.0648],
        [0.0666, 0.0584],
        [0.0579, 0.0673],
        [0.0667, 0.0584],
        [0.0586, 0.0665],
        [0.0642, 0.0606],
        [0.0665, 0.0585]], device='cuda:0')
 Batch: 3 of passive classification Duration: 0:00:00.424837
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0003, 0.0009],
        [0.0003, 0.0007],
        [0.0004, 0.0013],
        [0.0003, 0.0004],
        [0.0007, 0.0010],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0004, 0.0013],
        [0.0004, 0.0006],
        [0.0004, 0.0009],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0006, 0.0008],
        [0.0003, 0.0007],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0613, 0.0635],
        [0.0590, 0.0661],
        [0.0614, 0.0634],
        [0.0563, 0.0692],
        [0.0664, 0.0587],
        [0.0655, 0.0594],
        [0.0648, 0.0601],
        [0.0624, 0.0624],
        [0.0573, 0.0679],
        [0.0646, 0.0603],
        [0.0603, 0.0646],
        [0.0651, 0.0599],
        [0.0647, 0.0602],
        [0.0677, 0.0576],
        [0.0612, 0.0636],
        [0.0619, 0.0630]], device='cuda:0')
 Batch: 4 of passive classification Duration: 0:00:00.476243
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0012],
        [0.0005, 0.0007],
        [0.0004, 0.0011],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0005, 0.0015],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0006, 0.0011],
        [0.0007, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0686, 0.0568],
        [0.0630, 0.0618],
        [0.0561, 0.0695],
        [0.0672, 0.0580],
        [0.0591, 0.0659],
        [0.0653, 0.0596],
        [0.0599, 0.0650],
        [0.0632, 0.0616],
        [0.0574, 0.0678],
        [0.0616, 0.0632],
        [0.0606, 0.0643],
        [0.0652, 0.0597],
        [0.0638, 0.0610],
        [0.0604, 0.0645],
        [0.0644, 0.0605],
        [0.0640, 0.0608]], device='cuda:0')
 Batch: 5 of passive classification Duration: 0:00:00.327574
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0015],
        [0.0005, 0.0010],
        [0.0008, 0.0018],
        [0.0007, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0009],
        [0.0006, 0.0015],
        [0.0004, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0553, 0.0703],
        [0.0629, 0.0618],
        [0.0615, 0.0633],
        [0.0680, 0.0572],
        [0.0602, 0.0647],
        [0.0652, 0.0597],
        [0.0584, 0.0666],
        [0.0632, 0.0616],
        [0.0643, 0.0605],
        [0.0670, 0.0581],
        [0.0573, 0.0679],
        [0.0589, 0.0661],
        [0.0675, 0.0577],
        [0.0643, 0.0605],
        [0.0640, 0.0609],
        [0.0619, 0.0629]], device='cuda:0')
 Batch: 6 of passive classification Duration: 0:00:00.315777
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0012],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0003],
        [0.0004, 0.0009],
        [0.0005, 0.0010],
        [0.0005, 0.0012],
        [0.0006, 0.0017],
        [0.0008, 0.0015],
        [0.0003, 0.0004],
        [0.0005, 0.0008],
        [0.0004, 0.0007],
        [0.0005, 0.0008],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0587, 0.0662],
        [0.0609, 0.0639],
        [0.0625, 0.0622],
        [0.0622, 0.0626],
        [0.0621, 0.0627],
        [0.0759, 0.0513],
        [0.0607, 0.0641],
        [0.0594, 0.0654],
        [0.0577, 0.0674],
        [0.0573, 0.0679],
        [0.0614, 0.0633],
        [0.0665, 0.0585],
        [0.0643, 0.0605],
        [0.0625, 0.0622],
        [0.0630, 0.0618],
        [0.0650, 0.0599]], device='cuda:0')
 Batch: 7 of passive classification Duration: 0:00:00.360329
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0002, 0.0009],
        [0.0004, 0.0011],
        [0.0003, 0.0008],
        [0.0005, 0.0008],
        [0.0009, 0.0012],
        [0.0006, 0.0010],
        [0.0004, 0.0007],
        [0.0006, 0.0010],
        [0.0004, 0.0007],
        [0.0005, 0.0009],
        [0.0004, 0.0006],
        [0.0002, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0006, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0604, 0.0645],
        [0.0549, 0.0710],
        [0.0575, 0.0677],
        [0.0599, 0.0651],
        [0.0661, 0.0589],
        [0.0677, 0.0575],
        [0.0651, 0.0598],
        [0.0626, 0.0622],
        [0.0641, 0.0608],
        [0.0638, 0.0610],
        [0.0641, 0.0608],
        [0.0659, 0.0592],
        [0.0609, 0.0640],
        [0.0626, 0.0623],
        [0.0638, 0.0610],
        [0.0608, 0.0641]], device='cuda:0')
 Batch: 8 of passive classification Duration: 0:00:00.556714
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0005, 0.0010],
        [0.0006, 0.0012],
        [0.0004, 0.0009],
        [0.0006, 0.0008],
        [0.0005, 0.0009],
        [0.0005, 0.0008],
        [0.0004, 0.0006],
        [0.0003, 0.0007],
        [0.0004, 0.0009],
        [0.0004, 0.0011],
        [0.0004, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0638, 0.0611],
        [0.0627, 0.0622],
        [0.0612, 0.0636],
        [0.0608, 0.0641],
        [0.0651, 0.0599],
        [0.0613, 0.0636],
        [0.0620, 0.0629],
        [0.0594, 0.0656],
        [0.0693, 0.0563],
        [0.0645, 0.0604],
        [0.0648, 0.0601],
        [0.0666, 0.0586],
        [0.0593, 0.0657],
        [0.0618, 0.0631],
        [0.0583, 0.0668],
        [0.0591, 0.0660]], device='cuda:0')
 Batch: 9 of passive classification Duration: 0:00:00.354632
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0014],
        [0.0003, 0.0005],
        [0.0005, 0.0009],
        [0.0004, 0.0007],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0005, 0.0009],
        [0.0005, 0.0010],
        [0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0005, 0.0009],
        [0.0006, 0.0008],
        [0.0006, 0.0008],
        [0.0006, 0.0009],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0574, 0.0680],
        [0.0631, 0.0619],
        [0.0606, 0.0644],
        [0.0617, 0.0633],
        [0.0660, 0.0591],
        [0.0621, 0.0628],
        [0.0596, 0.0654],
        [0.0609, 0.0641],
        [0.0632, 0.0617],
        [0.0652, 0.0598],
        [0.0629, 0.0620],
        [0.0626, 0.0623],
        [0.0640, 0.0610],
        [0.0644, 0.0606],
        [0.0638, 0.0612],
        [0.0625, 0.0624]], device='cuda:0')
 Batch: 10 of passive classification Duration: 0:00:00.419045
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0012],
        [0.0004, 0.0011],
        [0.0003, 0.0009],
        [0.0003, 0.0008],
        [0.0003, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0005, 0.0011],
        [0.0005, 0.0009],
        [0.0003, 0.0009],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0638, 0.0611],
        [0.0579, 0.0673],
        [0.0573, 0.0680],
        [0.0595, 0.0655],
        [0.0682, 0.0571],
        [0.0655, 0.0595],
        [0.0607, 0.0642],
        [0.0649, 0.0600],
        [0.0634, 0.0614],
        [0.0618, 0.0631],
        [0.0636, 0.0613],
        [0.0579, 0.0673],
        [0.0625, 0.0623],
        [0.0641, 0.0608],
        [0.0664, 0.0587],
        [0.0624, 0.0624]], device='cuda:0')
 Batch: 11 of passive classification Duration: 0:00:00.445841
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0005, 0.0011],
        [0.0005, 0.0010],
        [0.0003, 0.0006],
        [0.0006, 0.0011],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0005, 0.0010],
        [0.0003, 0.0010]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1225, 0.1273],
        [0.1237, 0.1260],
        [0.1303, 0.1197],
        [0.1246, 0.1252],
        [0.1270, 0.1228],
        [0.1317, 0.1184],
        [0.1275, 0.1223],
        [0.1128, 0.1382]], device='cuda:0')
 Batch: 12 of passive classification Duration: 0:00:00.215483
acc:  0.535
Time taken to execute the en SA task with prompt type passive, variation 5 and batchsize 16: 0:00:05.126610
path ['42', 'en', 'bloom-big', 'SA', 'passive', 'prompt_id_5']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([107, 2])
answers_probs just softmax dim 0: tensor([[0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093]], device='cuda:0')
tensor([[0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA passive 6 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0001, 0.0002],
        [0.0004, 0.0009],
        [0.0004, 0.0009],
        [0.0005, 0.0012],
        [0.0002, 0.0005],
        [0.0004, 0.0009],
        [0.0005, 0.0012],
        [0.0003, 0.0005],
        [0.0003, 0.0009],
        [0.0003, 0.0005],
        [0.0005, 0.0013],
        [0.0003, 0.0007],
        [0.0002, 0.0008],
        [0.0005, 0.0010],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0634, 0.0615],
        [0.0665, 0.0586],
        [0.0640, 0.0609],
        [0.0636, 0.0613],
        [0.0606, 0.0643],
        [0.0590, 0.0661],
        [0.0637, 0.0612],
        [0.0621, 0.0628],
        [0.0664, 0.0587],
        [0.0600, 0.0650],
        [0.0664, 0.0588],
        [0.0614, 0.0635],
        [0.0605, 0.0644],
        [0.0567, 0.0688],
        [0.0640, 0.0609],
        [0.0618, 0.0631]], device='cuda:0')
 Batch: 0 of passive classification Duration: 0:00:00.315600
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0005, 0.0009],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0009],
        [0.0003, 0.0009],
        [0.0003, 0.0007],
        [0.0004, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0012],
        [0.0004, 0.0010],
        [0.0004, 0.0007],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0644, 0.0606],
        [0.0654, 0.0596],
        [0.0635, 0.0614],
        [0.0607, 0.0643],
        [0.0623, 0.0626],
        [0.0650, 0.0600],
        [0.0605, 0.0645],
        [0.0596, 0.0654],
        [0.0632, 0.0618],
        [0.0615, 0.0635],
        [0.0623, 0.0626],
        [0.0635, 0.0614],
        [0.0568, 0.0686],
        [0.0609, 0.0641],
        [0.0670, 0.0582],
        [0.0635, 0.0614]], device='cuda:0')
 Batch: 1 of passive classification Duration: 0:00:00.310465
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0009, 0.0016],
        [0.0006, 0.0014],
        [0.0004, 0.0006],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0009],
        [0.0004, 0.0009],
        [0.0002, 0.0006],
        [0.0002, 0.0004],
        [0.0006, 0.0019],
        [0.0004, 0.0009],
        [0.0006, 0.0013],
        [0.0004, 0.0009],
        [0.0005, 0.0013],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0647, 0.0602],
        [0.0646, 0.0603],
        [0.0614, 0.0635],
        [0.0675, 0.0578],
        [0.0611, 0.0638],
        [0.0664, 0.0587],
        [0.0604, 0.0645],
        [0.0619, 0.0630],
        [0.0592, 0.0659],
        [0.0633, 0.0616],
        [0.0580, 0.0672],
        [0.0618, 0.0631],
        [0.0634, 0.0615],
        [0.0620, 0.0629],
        [0.0602, 0.0648],
        [0.0638, 0.0611]], device='cuda:0')
 Batch: 2 of passive classification Duration: 0:00:00.363037
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0009],
        [0.0001, 0.0004],
        [0.0005, 0.0009],
        [0.0004, 0.0009],
        [0.0007, 0.0011],
        [0.0005, 0.0009],
        [0.0002, 0.0005],
        [0.0004, 0.0012],
        [0.0005, 0.0010],
        [0.0002, 0.0005],
        [0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0009, 0.0012],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0002, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0604, 0.0646],
        [0.0606, 0.0643],
        [0.0645, 0.0604],
        [0.0632, 0.0617],
        [0.0679, 0.0574],
        [0.0635, 0.0614],
        [0.0639, 0.0610],
        [0.0579, 0.0673],
        [0.0634, 0.0615],
        [0.0624, 0.0625],
        [0.0593, 0.0658],
        [0.0603, 0.0647],
        [0.0693, 0.0562],
        [0.0621, 0.0627],
        [0.0623, 0.0626],
        [0.0590, 0.0660]], device='cuda:0')
 Batch: 3 of passive classification Duration: 0:00:00.397285
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0007, 0.0015],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0004, 0.0011],
        [0.0003, 0.0008],
        [0.0002, 0.0004],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0624, 0.0625],
        [0.0608, 0.0641],
        [0.0592, 0.0659],
        [0.0621, 0.0628],
        [0.0596, 0.0655],
        [0.0631, 0.0618],
        [0.0675, 0.0577],
        [0.0648, 0.0601],
        [0.0651, 0.0599],
        [0.0662, 0.0589],
        [0.0644, 0.0606],
        [0.0610, 0.0639],
        [0.0597, 0.0654],
        [0.0607, 0.0642],
        [0.0636, 0.0613],
        [0.0598, 0.0652]], device='cuda:0')
 Batch: 4 of passive classification Duration: 0:00:00.401636
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0004, 0.0009],
        [0.0003, 0.0010],
        [0.0004, 0.0009],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0004, 0.0008],
        [0.0009, 0.0013],
        [0.0003, 0.0008],
        [0.0002, 0.0004],
        [0.0005, 0.0010],
        [0.0005, 0.0013],
        [0.0002, 0.0007],
        [0.0005, 0.0011],
        [0.0003, 0.0007],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0614, 0.0635],
        [0.0636, 0.0613],
        [0.0577, 0.0676],
        [0.0640, 0.0609],
        [0.0623, 0.0626],
        [0.0629, 0.0620],
        [0.0662, 0.0589],
        [0.0696, 0.0561],
        [0.0606, 0.0643],
        [0.0638, 0.0611],
        [0.0638, 0.0611],
        [0.0602, 0.0648],
        [0.0601, 0.0649],
        [0.0616, 0.0633],
        [0.0633, 0.0615],
        [0.0591, 0.0660]], device='cuda:0')
 Batch: 5 of passive classification Duration: 0:00:00.417566
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0008, 0.0016],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0004, 0.0013],
        [0.0005, 0.0012],
        [0.0004, 0.0014],
        [0.0005, 0.0009],
        [0.0006, 0.0011],
        [0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0007, 0.0016],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0613, 0.0636],
        [0.0611, 0.0638],
        [0.0677, 0.0576],
        [0.0643, 0.0606],
        [0.0614, 0.0636],
        [0.0618, 0.0631],
        [0.0582, 0.0670],
        [0.0611, 0.0639],
        [0.0583, 0.0669],
        [0.0642, 0.0607],
        [0.0663, 0.0588],
        [0.0655, 0.0596],
        [0.0634, 0.0615],
        [0.0623, 0.0626],
        [0.0627, 0.0622],
        [0.0606, 0.0644]], device='cuda:0')
 Batch: 6 of passive classification Duration: 0:00:00.354868
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0006],
        [0.0005, 0.0008],
        [0.0007, 0.0011],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0008, 0.0013],
        [0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0005, 0.0009],
        [0.0005, 0.0006],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0004, 0.0010],
        [0.0006, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0574, 0.0680],
        [0.0631, 0.0617],
        [0.0657, 0.0593],
        [0.0586, 0.0665],
        [0.0612, 0.0637],
        [0.0632, 0.0616],
        [0.0638, 0.0611],
        [0.0612, 0.0637],
        [0.0657, 0.0593],
        [0.0620, 0.0628],
        [0.0687, 0.0568],
        [0.0659, 0.0592],
        [0.0600, 0.0650],
        [0.0628, 0.0621],
        [0.0586, 0.0665],
        [0.0621, 0.0627]], device='cuda:0')
 Batch: 7 of passive classification Duration: 0:00:00.401644
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0002, 0.0005],
        [0.0004, 0.0010],
        [0.0005, 0.0013],
        [0.0004, 0.0008],
        [0.0004, 0.0009],
        [0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0008, 0.0011],
        [0.0002, 0.0004],
        [0.0004, 0.0011],
        [0.0004, 0.0009],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0621, 0.0628],
        [0.0604, 0.0646],
        [0.0608, 0.0641],
        [0.0594, 0.0657],
        [0.0630, 0.0619],
        [0.0623, 0.0626],
        [0.0640, 0.0610],
        [0.0651, 0.0599],
        [0.0668, 0.0584],
        [0.0683, 0.0571],
        [0.0593, 0.0658],
        [0.0591, 0.0660],
        [0.0624, 0.0625],
        [0.0657, 0.0594],
        [0.0623, 0.0626],
        [0.0592, 0.0659]], device='cuda:0')
 Batch: 8 of passive classification Duration: 0:00:00.555985
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0006, 0.0014],
        [0.0005, 0.0009],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0002, 0.0006],
        [0.0006, 0.0008],
        [0.0003, 0.0009],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0625, 0.0624],
        [0.0640, 0.0610],
        [0.0611, 0.0638],
        [0.0619, 0.0630],
        [0.0620, 0.0629],
        [0.0667, 0.0585],
        [0.0622, 0.0627],
        [0.0629, 0.0620],
        [0.0610, 0.0640],
        [0.0696, 0.0560],
        [0.0596, 0.0654],
        [0.0627, 0.0622],
        [0.0635, 0.0614],
        [0.0584, 0.0668],
        [0.0607, 0.0643],
        [0.0612, 0.0637]], device='cuda:0')
 Batch: 9 of passive classification Duration: 0:00:00.421424
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0013],
        [0.0002, 0.0002],
        [0.0002, 0.0003],
        [0.0002, 0.0005],
        [0.0005, 0.0008],
        [0.0002, 0.0006],
        [0.0003, 0.0010],
        [0.0003, 0.0006],
        [0.0004, 0.0010],
        [0.0007, 0.0018],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0012],
        [0.0002, 0.0008],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0573, 0.0678],
        [0.0761, 0.0511],
        [0.0650, 0.0598],
        [0.0600, 0.0648],
        [0.0668, 0.0582],
        [0.0571, 0.0681],
        [0.0596, 0.0652],
        [0.0626, 0.0621],
        [0.0604, 0.0643],
        [0.0613, 0.0634],
        [0.0635, 0.0612],
        [0.0669, 0.0581],
        [0.0641, 0.0606],
        [0.0578, 0.0673],
        [0.0579, 0.0671],
        [0.0636, 0.0611]], device='cuda:0')
 Batch: 10 of passive classification Duration: 0:00:00.472550
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0003, 0.0007],
        [0.0003, 0.0008],
        [0.0005, 0.0010],
        [0.0006, 0.0014],
        [0.0005, 0.0008],
        [0.0003, 0.0007],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0002, 0.0006],
        [0.0002, 0.0004],
        [0.0005, 0.0008],
        [0.0003, 0.0010],
        [0.0002, 0.0006],
        [0.0005, 0.0010],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0628, 0.0620],
        [0.0603, 0.0645],
        [0.0604, 0.0644],
        [0.0630, 0.0618],
        [0.0614, 0.0634],
        [0.0647, 0.0602],
        [0.0627, 0.0621],
        [0.0724, 0.0538],
        [0.0644, 0.0604],
        [0.0584, 0.0667],
        [0.0627, 0.0621],
        [0.0666, 0.0585],
        [0.0564, 0.0691],
        [0.0588, 0.0662],
        [0.0639, 0.0610],
        [0.0612, 0.0636]], device='cuda:0')
 Batch: 11 of passive classification Duration: 0:00:00.398639
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0002, 0.0006],
        [0.0001, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0004, 0.0005],
        [0.0005, 0.0016],
        [0.0005, 0.0010],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1193, 0.1301],
        [0.1080, 0.1437],
        [0.1227, 0.1265],
        [0.1363, 0.1139],
        [0.1355, 0.1146],
        [0.1148, 0.1352],
        [0.1269, 0.1223],
        [0.1365, 0.1137]], device='cuda:0')
 Batch: 12 of passive classification Duration: 0:00:00.155949
acc:  0.47
Time taken to execute the en SA task with prompt type passive, variation 6 and batchsize 16: 0:00:04.988166
path ['42', 'en', 'bloom-big', 'SA', 'passive', 'prompt_id_6']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([154, 2])
answers_probs just softmax dim 0: tensor([[0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065]], device='cuda:0')
tensor([[0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA passive 7 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0006, 0.0007],
        [0.0005, 0.0010],
        [0.0004, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0010],
        [0.0007, 0.0013],
        [0.0004, 0.0009],
        [0.0005, 0.0007],
        [0.0006, 0.0008],
        [0.0004, 0.0006],
        [0.0005, 0.0005],
        [0.0003, 0.0008],
        [0.0004, 0.0005],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0607, 0.0641],
        [0.0673, 0.0578],
        [0.0588, 0.0661],
        [0.0709, 0.0549],
        [0.0622, 0.0625],
        [0.0586, 0.0664],
        [0.0564, 0.0690],
        [0.0610, 0.0637],
        [0.0580, 0.0670],
        [0.0635, 0.0612],
        [0.0645, 0.0603],
        [0.0635, 0.0612],
        [0.0683, 0.0569],
        [0.0584, 0.0666],
        [0.0671, 0.0579],
        [0.0606, 0.0642]], device='cuda:0')
 Batch: 0 of passive classification Duration: 0:00:00.430167
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0008],
        [0.0004, 0.0008],
        [0.0004, 0.0004],
        [0.0004, 0.0007],
        [0.0007, 0.0012],
        [0.0002, 0.0003],
        [0.0006, 0.0010],
        [0.0006, 0.0009],
        [0.0005, 0.0007],
        [0.0004, 0.0005],
        [0.0009, 0.0013],
        [0.0007, 0.0015],
        [0.0002, 0.0006],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0660, 0.0591],
        [0.0613, 0.0636],
        [0.0665, 0.0587],
        [0.0610, 0.0640],
        [0.0609, 0.0641],
        [0.0653, 0.0597],
        [0.0615, 0.0634],
        [0.0628, 0.0621],
        [0.0648, 0.0601],
        [0.0642, 0.0607],
        [0.0634, 0.0615],
        [0.0581, 0.0672],
        [0.0567, 0.0687],
        [0.0651, 0.0599],
        [0.0609, 0.0641],
        [0.0617, 0.0631]], device='cuda:0')
 Batch: 1 of passive classification Duration: 0:00:00.476876
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0004],
        [0.0005, 0.0010],
        [0.0002, 0.0004],
        [0.0006, 0.0009],
        [0.0003, 0.0009],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0004, 0.0005],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0638, 0.0611],
        [0.0635, 0.0613],
        [0.0652, 0.0598],
        [0.0605, 0.0644],
        [0.0640, 0.0609],
        [0.0614, 0.0635],
        [0.0631, 0.0618],
        [0.0658, 0.0592],
        [0.0553, 0.0704],
        [0.0615, 0.0633],
        [0.0622, 0.0627],
        [0.0592, 0.0659],
        [0.0661, 0.0590],
        [0.0609, 0.0640],
        [0.0600, 0.0650],
        [0.0675, 0.0578]], device='cuda:0')
 Batch: 2 of passive classification Duration: 0:00:00.498990
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0005, 0.0008],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0005, 0.0013],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0005, 0.0007],
        [0.0008, 0.0020],
        [0.0005, 0.0009],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0608, 0.0640],
        [0.0645, 0.0604],
        [0.0604, 0.0645],
        [0.0645, 0.0604],
        [0.0635, 0.0613],
        [0.0672, 0.0579],
        [0.0578, 0.0674],
        [0.0614, 0.0635],
        [0.0605, 0.0644],
        [0.0612, 0.0637],
        [0.0588, 0.0662],
        [0.0691, 0.0564],
        [0.0677, 0.0575],
        [0.0571, 0.0682],
        [0.0622, 0.0627],
        [0.0633, 0.0615]], device='cuda:0')
 Batch: 3 of passive classification Duration: 0:00:00.420375
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0007, 0.0010],
        [0.0002, 0.0004],
        [0.0005, 0.0010],
        [0.0006, 0.0010],
        [0.0005, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0004, 0.0006],
        [0.0011, 0.0014],
        [0.0004, 0.0006],
        [0.0005, 0.0007],
        [0.0005, 0.0007],
        [0.0005, 0.0007],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0593, 0.0658],
        [0.0630, 0.0619],
        [0.0647, 0.0603],
        [0.0605, 0.0645],
        [0.0589, 0.0663],
        [0.0610, 0.0640],
        [0.0660, 0.0591],
        [0.0612, 0.0637],
        [0.0606, 0.0643],
        [0.0621, 0.0628],
        [0.0655, 0.0596],
        [0.0618, 0.0632],
        [0.0636, 0.0613],
        [0.0639, 0.0611],
        [0.0650, 0.0601],
        [0.0630, 0.0619]], device='cuda:0')
 Batch: 4 of passive classification Duration: 0:00:00.357996
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0005, 0.0007],
        [0.0003, 0.0006],
        [0.0006, 0.0007],
        [0.0005, 0.0010],
        [0.0006, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0005, 0.0008],
        [0.0004, 0.0009],
        [0.0004, 0.0007],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0009],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0618, 0.0631],
        [0.0611, 0.0638],
        [0.0649, 0.0601],
        [0.0602, 0.0648],
        [0.0673, 0.0579],
        [0.0607, 0.0643],
        [0.0651, 0.0600],
        [0.0599, 0.0652],
        [0.0661, 0.0590],
        [0.0621, 0.0628],
        [0.0580, 0.0673],
        [0.0622, 0.0627],
        [0.0631, 0.0618],
        [0.0651, 0.0599],
        [0.0610, 0.0639],
        [0.0615, 0.0635]], device='cuda:0')
 Batch: 5 of passive classification Duration: 0:00:00.317181
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0006, 0.0014],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0006],
        [0.0005, 0.0009],
        [0.0005, 0.0008],
        [0.0004, 0.0006],
        [0.0003, 0.0003],
        [0.0004, 0.0008],
        [0.0007, 0.0013],
        [0.0005, 0.0007],
        [0.0003, 0.0005],
        [0.0006, 0.0009],
        [0.0004, 0.0008],
        [0.0005, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0625, 0.0624],
        [0.0569, 0.0686],
        [0.0632, 0.0617],
        [0.0628, 0.0620],
        [0.0664, 0.0587],
        [0.0631, 0.0618],
        [0.0645, 0.0604],
        [0.0641, 0.0608],
        [0.0674, 0.0578],
        [0.0601, 0.0649],
        [0.0615, 0.0634],
        [0.0661, 0.0589],
        [0.0609, 0.0640],
        [0.0631, 0.0618],
        [0.0605, 0.0644],
        [0.0568, 0.0686]], device='cuda:0')
 Batch: 6 of passive classification Duration: 0:00:00.310862
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0005, 0.0007],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0002, 0.0003],
        [0.0004, 0.0006],
        [0.0004, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0004, 0.0005],
        [0.0003, 0.0006],
        [0.0005, 0.0009],
        [0.0004, 0.0005],
        [0.0004, 0.0008],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0595, 0.0655],
        [0.0634, 0.0615],
        [0.0639, 0.0611],
        [0.0614, 0.0636],
        [0.0607, 0.0643],
        [0.0635, 0.0614],
        [0.0640, 0.0609],
        [0.0609, 0.0640],
        [0.0625, 0.0624],
        [0.0621, 0.0628],
        [0.0690, 0.0566],
        [0.0603, 0.0647],
        [0.0621, 0.0628],
        [0.0662, 0.0589],
        [0.0618, 0.0631],
        [0.0587, 0.0664]], device='cuda:0')
 Batch: 7 of passive classification Duration: 0:00:00.482755
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0005, 0.0007],
        [0.0005, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0008],
        [0.0002, 0.0006],
        [0.0007, 0.0008],
        [0.0003, 0.0004],
        [0.0004, 0.0010],
        [0.0006, 0.0010],
        [0.0003, 0.0003],
        [0.0004, 0.0007],
        [0.0008, 0.0013],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0633, 0.0615],
        [0.0615, 0.0633],
        [0.0626, 0.0622],
        [0.0653, 0.0597],
        [0.0689, 0.0565],
        [0.0604, 0.0645],
        [0.0607, 0.0641],
        [0.0569, 0.0685],
        [0.0674, 0.0578],
        [0.0627, 0.0621],
        [0.0578, 0.0674],
        [0.0633, 0.0615],
        [0.0677, 0.0575],
        [0.0608, 0.0640],
        [0.0621, 0.0628],
        [0.0585, 0.0666]], device='cuda:0')
 Batch: 8 of passive classification Duration: 0:00:00.425833
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0005, 0.0006],
        [0.0005, 0.0008],
        [0.0004, 0.0005],
        [0.0004, 0.0009],
        [0.0004, 0.0007],
        [0.0005, 0.0009],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0006, 0.0008],
        [0.0007, 0.0013],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0002, 0.0006],
        [0.0005, 0.0013],
        [0.0006, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0610, 0.0639],
        [0.0657, 0.0594],
        [0.0637, 0.0612],
        [0.0643, 0.0606],
        [0.0592, 0.0659],
        [0.0637, 0.0612],
        [0.0604, 0.0645],
        [0.0636, 0.0613],
        [0.0641, 0.0608],
        [0.0658, 0.0592],
        [0.0615, 0.0634],
        [0.0589, 0.0662],
        [0.0652, 0.0598],
        [0.0582, 0.0670],
        [0.0569, 0.0685],
        [0.0680, 0.0573]], device='cuda:0')
 Batch: 9 of passive classification Duration: 0:00:00.397668
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0011],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0006, 0.0013],
        [0.0005, 0.0008],
        [0.0004, 0.0007],
        [0.0006, 0.0010],
        [0.0004, 0.0007],
        [0.0007, 0.0010],
        [0.0005, 0.0012],
        [0.0005, 0.0008],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0005],
        [0.0005, 0.0009],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0584, 0.0667],
        [0.0596, 0.0654],
        [0.0599, 0.0651],
        [0.0596, 0.0654],
        [0.0635, 0.0614],
        [0.0615, 0.0634],
        [0.0621, 0.0627],
        [0.0638, 0.0611],
        [0.0642, 0.0607],
        [0.0583, 0.0668],
        [0.0639, 0.0610],
        [0.0651, 0.0599],
        [0.0621, 0.0627],
        [0.0697, 0.0559],
        [0.0625, 0.0624],
        [0.0658, 0.0592]], device='cuda:0')
 Batch: 10 of passive classification Duration: 0:00:00.582631
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0011],
        [0.0006, 0.0010],
        [0.0004, 0.0008],
        [0.0004, 0.0006],
        [0.0001, 0.0002],
        [0.0003, 0.0003],
        [0.0005, 0.0008],
        [0.0005, 0.0007],
        [0.0003, 0.0007],
        [0.0008, 0.0011],
        [0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0005, 0.0008],
        [0.0005, 0.0010],
        [0.0002, 0.0003],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0580, 0.0671],
        [0.0625, 0.0623],
        [0.0583, 0.0668],
        [0.0649, 0.0600],
        [0.0648, 0.0601],
        [0.0713, 0.0547],
        [0.0636, 0.0613],
        [0.0624, 0.0624],
        [0.0595, 0.0655],
        [0.0656, 0.0594],
        [0.0615, 0.0634],
        [0.0623, 0.0626],
        [0.0626, 0.0622],
        [0.0600, 0.0650],
        [0.0615, 0.0634],
        [0.0612, 0.0637]], device='cuda:0')
 Batch: 11 of passive classification Duration: 0:00:00.484570
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0005, 0.0008],
        [0.0002, 0.0002],
        [0.0004, 0.0006],
        [0.0005, 0.0010],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0007, 0.0009]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1249],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1210, 0.1289],
        [0.1255, 0.1242],
        [0.1361, 0.1146],
        [0.1294, 0.1205],
        [0.1176, 0.1326],
        [0.1221, 0.1277],
        [0.1201, 0.1298],
        [0.1282, 0.1217]], device='cuda:0')
 Batch: 12 of passive classification Duration: 0:00:00.227589
acc:  0.515
Time taken to execute the en SA task with prompt type passive, variation 7 and batchsize 16: 0:00:05.434589
path ['42', 'en', 'bloom-big', 'SA', 'passive', 'prompt_id_7']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([134, 2])
answers_probs just softmax dim 0: tensor([[0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075]], device='cuda:0')
tensor([[0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075],
        [0.0075, 0.0075]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA passive 8 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0012],
        [0.0006, 0.0013],
        [0.0005, 0.0012],
        [0.0003, 0.0009],
        [0.0004, 0.0012],
        [0.0005, 0.0012],
        [0.0005, 0.0012],
        [0.0004, 0.0009],
        [0.0003, 0.0009],
        [0.0005, 0.0010],
        [0.0006, 0.0019],
        [0.0003, 0.0005],
        [0.0004, 0.0010],
        [0.0005, 0.0009],
        [0.0002, 0.0005],
        [0.0011, 0.0023]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626]], device='cuda:0')
tensor([[0.0606, 0.0644],
        [0.0625, 0.0624],
        [0.0607, 0.0643],
        [0.0607, 0.0643],
        [0.0607, 0.0643],
        [0.0616, 0.0633],
        [0.0626, 0.0623],
        [0.0646, 0.0604],
        [0.0606, 0.0644],
        [0.0654, 0.0597],
        [0.0586, 0.0665],
        [0.0667, 0.0585],
        [0.0612, 0.0637],
        [0.0668, 0.0584],
        [0.0630, 0.0619],
        [0.0638, 0.0611]], device='cuda:0')
 Batch: 0 of passive classification Duration: 0:00:00.426221
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0005, 0.0010],
        [0.0004, 0.0011],
        [0.0008, 0.0024],
        [0.0003, 0.0007],
        [0.0006, 0.0014],
        [0.0003, 0.0010],
        [0.0002, 0.0005],
        [0.0004, 0.0007],
        [0.0007, 0.0013],
        [0.0005, 0.0010],
        [0.0008, 0.0017],
        [0.0004, 0.0011],
        [0.0003, 0.0004],
        [0.0004, 0.0017],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0624, 0.0625],
        [0.0648, 0.0602],
        [0.0621, 0.0628],
        [0.0590, 0.0660],
        [0.0630, 0.0618],
        [0.0623, 0.0626],
        [0.0591, 0.0659],
        [0.0646, 0.0603],
        [0.0638, 0.0611],
        [0.0648, 0.0602],
        [0.0652, 0.0598],
        [0.0633, 0.0615],
        [0.0597, 0.0653],
        [0.0682, 0.0571],
        [0.0549, 0.0710],
        [0.0629, 0.0620]], device='cuda:0')
 Batch: 1 of passive classification Duration: 0:00:00.568073
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0009, 0.0018],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0004, 0.0007],
        [0.0005, 0.0007],
        [0.0005, 0.0010],
        [0.0003, 0.0006],
        [0.0006, 0.0017],
        [0.0004, 0.0012],
        [0.0005, 0.0012],
        [0.0006, 0.0019],
        [0.0005, 0.0009],
        [0.0005, 0.0010],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0630, 0.0619],
        [0.0665, 0.0587],
        [0.0607, 0.0642],
        [0.0655, 0.0595],
        [0.0673, 0.0579],
        [0.0632, 0.0617],
        [0.0611, 0.0638],
        [0.0587, 0.0665],
        [0.0589, 0.0662],
        [0.0595, 0.0656],
        [0.0586, 0.0666],
        [0.0627, 0.0622],
        [0.0643, 0.0606],
        [0.0629, 0.0620],
        [0.0640, 0.0609],
        [0.0632, 0.0617]], device='cuda:0')
 Batch: 2 of passive classification Duration: 0:00:00.449262
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0006, 0.0016],
        [0.0006, 0.0017],
        [0.0003, 0.0008],
        [0.0004, 0.0006],
        [0.0006, 0.0022],
        [0.0004, 0.0015],
        [0.0005, 0.0014],
        [0.0005, 0.0014],
        [0.0005, 0.0013],
        [0.0003, 0.0008],
        [0.0006, 0.0012],
        [0.0003, 0.0008],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0006, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0661, 0.0589],
        [0.0606, 0.0642],
        [0.0610, 0.0638],
        [0.0590, 0.0660],
        [0.0684, 0.0569],
        [0.0573, 0.0679],
        [0.0579, 0.0673],
        [0.0598, 0.0651],
        [0.0602, 0.0646],
        [0.0600, 0.0648],
        [0.0601, 0.0648],
        [0.0654, 0.0595],
        [0.0617, 0.0631],
        [0.0678, 0.0574],
        [0.0668, 0.0583],
        [0.0679, 0.0573]], device='cuda:0')
 Batch: 3 of passive classification Duration: 0:00:00.401118
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0005, 0.0018],
        [0.0002, 0.0004],
        [0.0004, 0.0010],
        [0.0003, 0.0008],
        [0.0004, 0.0013],
        [0.0002, 0.0005],
        [0.0007, 0.0018],
        [0.0005, 0.0009],
        [0.0004, 0.0012],
        [0.0005, 0.0013],
        [0.0004, 0.0009],
        [0.0005, 0.0014],
        [0.0005, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0652, 0.0598],
        [0.0601, 0.0649],
        [0.0646, 0.0603],
        [0.0566, 0.0688],
        [0.0698, 0.0558],
        [0.0620, 0.0629],
        [0.0624, 0.0624],
        [0.0600, 0.0650],
        [0.0633, 0.0616],
        [0.0620, 0.0629],
        [0.0674, 0.0578],
        [0.0608, 0.0641],
        [0.0622, 0.0627],
        [0.0636, 0.0613],
        [0.0593, 0.0657],
        [0.0609, 0.0640]], device='cuda:0')
 Batch: 4 of passive classification Duration: 0:00:00.416516
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0005, 0.0013],
        [0.0007, 0.0016],
        [0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0003, 0.0011],
        [0.0004, 0.0009],
        [0.0003, 0.0007],
        [0.0006, 0.0011],
        [0.0003, 0.0008],
        [0.0004, 0.0006],
        [0.0008, 0.0020],
        [0.0004, 0.0011],
        [0.0005, 0.0014],
        [0.0005, 0.0011],
        [0.0006, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0651, 0.0599],
        [0.0620, 0.0629],
        [0.0632, 0.0617],
        [0.0607, 0.0642],
        [0.0585, 0.0666],
        [0.0588, 0.0663],
        [0.0629, 0.0621],
        [0.0640, 0.0609],
        [0.0648, 0.0602],
        [0.0606, 0.0643],
        [0.0683, 0.0571],
        [0.0617, 0.0633],
        [0.0603, 0.0646],
        [0.0616, 0.0633],
        [0.0641, 0.0608],
        [0.0633, 0.0616]], device='cuda:0')
 Batch: 5 of passive classification Duration: 0:00:00.397620
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0003, 0.0009],
        [0.0007, 0.0018],
        [0.0006, 0.0017],
        [0.0005, 0.0008],
        [0.0005, 0.0010],
        [0.0005, 0.0008],
        [0.0005, 0.0013],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0010],
        [0.0004, 0.0012],
        [0.0006, 0.0013],
        [0.0005, 0.0012],
        [0.0002, 0.0004],
        [0.0006, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0630, 0.0619],
        [0.0589, 0.0662],
        [0.0604, 0.0646],
        [0.0605, 0.0645],
        [0.0662, 0.0589],
        [0.0640, 0.0610],
        [0.0679, 0.0574],
        [0.0600, 0.0650],
        [0.0650, 0.0600],
        [0.0611, 0.0639],
        [0.0609, 0.0641],
        [0.0592, 0.0659],
        [0.0629, 0.0620],
        [0.0606, 0.0644],
        [0.0638, 0.0612],
        [0.0659, 0.0592]], device='cuda:0')
 Batch: 6 of passive classification Duration: 0:00:00.366214
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0006, 0.0010],
        [0.0004, 0.0013],
        [0.0004, 0.0009],
        [0.0005, 0.0012],
        [0.0003, 0.0006],
        [0.0005, 0.0015],
        [0.0004, 0.0005],
        [0.0007, 0.0017],
        [0.0003, 0.0007],
        [0.0004, 0.0010],
        [0.0005, 0.0010],
        [0.0005, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0667, 0.0584],
        [0.0598, 0.0652],
        [0.0637, 0.0612],
        [0.0610, 0.0639],
        [0.0657, 0.0594],
        [0.0578, 0.0674],
        [0.0626, 0.0622],
        [0.0611, 0.0638],
        [0.0630, 0.0619],
        [0.0595, 0.0655],
        [0.0705, 0.0553],
        [0.0618, 0.0631],
        [0.0611, 0.0638],
        [0.0607, 0.0642],
        [0.0640, 0.0609],
        [0.0609, 0.0640]], device='cuda:0')
 Batch: 7 of passive classification Duration: 0:00:00.353644
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0005, 0.0010],
        [0.0006, 0.0023],
        [0.0005, 0.0020],
        [0.0004, 0.0012],
        [0.0003, 0.0013],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0006, 0.0013],
        [0.0005, 0.0010],
        [0.0004, 0.0010],
        [0.0002, 0.0005],
        [0.0005, 0.0012],
        [0.0003, 0.0005],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0636, 0.0613],
        [0.0645, 0.0604],
        [0.0568, 0.0686],
        [0.0569, 0.0685],
        [0.0606, 0.0643],
        [0.0572, 0.0681],
        [0.0640, 0.0609],
        [0.0636, 0.0613],
        [0.0655, 0.0595],
        [0.0623, 0.0625],
        [0.0633, 0.0616],
        [0.0625, 0.0623],
        [0.0629, 0.0620],
        [0.0635, 0.0614],
        [0.0681, 0.0572],
        [0.0648, 0.0601]], device='cuda:0')
 Batch: 8 of passive classification Duration: 0:00:00.334284
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0011],
        [0.0005, 0.0009],
        [0.0004, 0.0010],
        [0.0005, 0.0009],
        [0.0004, 0.0009],
        [0.0006, 0.0010],
        [0.0005, 0.0010],
        [0.0003, 0.0013],
        [0.0004, 0.0011],
        [0.0004, 0.0010],
        [0.0003, 0.0006],
        [0.0005, 0.0008],
        [0.0005, 0.0015],
        [0.0002, 0.0005],
        [0.0005, 0.0012],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0573, 0.0680],
        [0.0655, 0.0596],
        [0.0620, 0.0629],
        [0.0640, 0.0609],
        [0.0627, 0.0622],
        [0.0663, 0.0588],
        [0.0646, 0.0603],
        [0.0571, 0.0682],
        [0.0608, 0.0641],
        [0.0612, 0.0637],
        [0.0635, 0.0614],
        [0.0663, 0.0588],
        [0.0594, 0.0656],
        [0.0621, 0.0628],
        [0.0626, 0.0623],
        [0.0646, 0.0603]], device='cuda:0')
 Batch: 9 of passive classification Duration: 0:00:00.401685
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0009, 0.0019],
        [0.0003, 0.0003],
        [0.0005, 0.0011],
        [0.0003, 0.0007],
        [0.0004, 0.0012],
        [0.0003, 0.0005],
        [0.0010, 0.0014],
        [0.0004, 0.0009],
        [0.0009, 0.0020],
        [0.0005, 0.0013],
        [0.0003, 0.0007],
        [0.0003, 0.0004],
        [0.0004, 0.0015],
        [0.0006, 0.0014],
        [0.0009, 0.0020]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0624],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626]], device='cuda:0')
tensor([[0.0607, 0.0641],
        [0.0623, 0.0624],
        [0.0706, 0.0551],
        [0.0610, 0.0638],
        [0.0596, 0.0653],
        [0.0589, 0.0660],
        [0.0671, 0.0580],
        [0.0681, 0.0572],
        [0.0614, 0.0634],
        [0.0613, 0.0635],
        [0.0611, 0.0637],
        [0.0595, 0.0654],
        [0.0688, 0.0565],
        [0.0562, 0.0692],
        [0.0623, 0.0624],
        [0.0610, 0.0638]], device='cuda:0')
 Batch: 10 of passive classification Duration: 0:00:00.426907
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0017],
        [0.0006, 0.0013],
        [0.0003, 0.0008],
        [0.0006, 0.0016],
        [0.0003, 0.0009],
        [0.0006, 0.0015],
        [0.0003, 0.0009],
        [0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0005, 0.0013],
        [0.0005, 0.0011],
        [0.0003, 0.0006],
        [0.0005, 0.0016],
        [0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0005, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0614, 0.0635],
        [0.0632, 0.0617],
        [0.0606, 0.0644],
        [0.0604, 0.0646],
        [0.0597, 0.0654],
        [0.0611, 0.0638],
        [0.0594, 0.0657],
        [0.0674, 0.0579],
        [0.0635, 0.0615],
        [0.0624, 0.0625],
        [0.0643, 0.0606],
        [0.0651, 0.0599],
        [0.0599, 0.0651],
        [0.0659, 0.0592],
        [0.0633, 0.0617],
        [0.0623, 0.0626]], device='cuda:0')
 Batch: 11 of passive classification Duration: 0:00:00.482544
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0005, 0.0018],
        [0.0004, 0.0005],
        [0.0004, 0.0010],
        [0.0003, 0.0011],
        [0.0007, 0.0013],
        [0.0006, 0.0012],
        [0.0005, 0.0015],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1251],
        [0.1250, 0.1249],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1165, 0.1335],
        [0.1405, 0.1107],
        [0.1219, 0.1276],
        [0.1153, 0.1349],
        [0.1298, 0.1198],
        [0.1264, 0.1231],
        [0.1174, 0.1326],
        [0.1322, 0.1177]], device='cuda:0')
 Batch: 12 of passive classification Duration: 0:00:00.221597
acc:  0.59
Time taken to execute the en SA task with prompt type passive, variation 8 and batchsize 16: 0:00:05.267028
path ['42', 'en', 'bloom-big', 'SA', 'passive', 'prompt_id_8']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([127, 2])
answers_probs just softmax dim 0: tensor([[0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079]], device='cuda:0')
tensor([[0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079],
        [0.0079, 0.0079]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA passive 9 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0012],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0005, 0.0010],
        [0.0002, 0.0005],
        [0.0005, 0.0010],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0010, 0.0015],
        [0.0004, 0.0008],
        [0.0005, 0.0010],
        [0.0005, 0.0008],
        [0.0003, 0.0004],
        [0.0005, 0.0009],
        [0.0003, 0.0007],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0634, 0.0616],
        [0.0623, 0.0627],
        [0.0624, 0.0626],
        [0.0619, 0.0631],
        [0.0621, 0.0629],
        [0.0610, 0.0640],
        [0.0620, 0.0630],
        [0.0604, 0.0646],
        [0.0666, 0.0586],
        [0.0622, 0.0628],
        [0.0608, 0.0642],
        [0.0653, 0.0598],
        [0.0663, 0.0589],
        [0.0631, 0.0619],
        [0.0602, 0.0648],
        [0.0603, 0.0647]], device='cuda:0')
 Batch: 0 of passive classification Duration: 0:00:00.409860
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0012, 0.0025],
        [0.0003, 0.0010],
        [0.0007, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0005, 0.0009],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0635, 0.0613],
        [0.0648, 0.0601],
        [0.0614, 0.0635],
        [0.0561, 0.0695],
        [0.0685, 0.0569],
        [0.0611, 0.0638],
        [0.0610, 0.0639],
        [0.0609, 0.0640],
        [0.0658, 0.0593],
        [0.0592, 0.0658],
        [0.0644, 0.0605],
        [0.0605, 0.0645],
        [0.0629, 0.0620],
        [0.0618, 0.0631],
        [0.0612, 0.0637],
        [0.0671, 0.0581]], device='cuda:0')
 Batch: 1 of passive classification Duration: 0:00:00.420234
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0006, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0010],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0003],
        [0.0002, 0.0004],
        [0.0005, 0.0013],
        [0.0005, 0.0009],
        [0.0004, 0.0007],
        [0.0006, 0.0008],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0627, 0.0622],
        [0.0642, 0.0607],
        [0.0626, 0.0623],
        [0.0656, 0.0594],
        [0.0594, 0.0656],
        [0.0555, 0.0702],
        [0.0652, 0.0598],
        [0.0648, 0.0601],
        [0.0616, 0.0633],
        [0.0669, 0.0582],
        [0.0615, 0.0634],
        [0.0584, 0.0668],
        [0.0619, 0.0629],
        [0.0629, 0.0619],
        [0.0677, 0.0576],
        [0.0593, 0.0657]], device='cuda:0')
 Batch: 2 of passive classification Duration: 0:00:00.407198
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0004, 0.0010],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0002, 0.0006],
        [0.0004, 0.0010],
        [0.0005, 0.0011],
        [0.0006, 0.0008],
        [0.0003, 0.0008],
        [0.0002, 0.0003],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0005, 0.0011],
        [0.0003, 0.0008],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0635, 0.0613],
        [0.0599, 0.0649],
        [0.0608, 0.0641],
        [0.0654, 0.0595],
        [0.0645, 0.0604],
        [0.0574, 0.0678],
        [0.0579, 0.0672],
        [0.0601, 0.0648],
        [0.0680, 0.0572],
        [0.0578, 0.0673],
        [0.0662, 0.0588],
        [0.0679, 0.0574],
        [0.0641, 0.0607],
        [0.0605, 0.0644],
        [0.0584, 0.0667],
        [0.0676, 0.0576]], device='cuda:0')
 Batch: 3 of passive classification Duration: 0:00:00.418613
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0004, 0.0009],
        [0.0009, 0.0016],
        [0.0005, 0.0008],
        [0.0002, 0.0006],
        [0.0003, 0.0006],
        [0.0005, 0.0008],
        [0.0004, 0.0011],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0005, 0.0008],
        [0.0006, 0.0015],
        [0.0004, 0.0006],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0624, 0.0625],
        [0.0671, 0.0580],
        [0.0616, 0.0632],
        [0.0636, 0.0612],
        [0.0654, 0.0596],
        [0.0563, 0.0692],
        [0.0632, 0.0617],
        [0.0646, 0.0604],
        [0.0571, 0.0683],
        [0.0615, 0.0633],
        [0.0619, 0.0630],
        [0.0623, 0.0626],
        [0.0641, 0.0608],
        [0.0592, 0.0658],
        [0.0668, 0.0584],
        [0.0630, 0.0619]], device='cuda:0')
 Batch: 4 of passive classification Duration: 0:00:00.356726
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0004, 0.0006],
        [0.0007, 0.0022],
        [0.0003, 0.0006],
        [0.0005, 0.0012],
        [0.0004, 0.0006],
        [0.0006, 0.0010],
        [0.0005, 0.0011],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0008, 0.0010],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0617, 0.0631],
        [0.0651, 0.0599],
        [0.0567, 0.0686],
        [0.0604, 0.0645],
        [0.0594, 0.0656],
        [0.0657, 0.0593],
        [0.0639, 0.0610],
        [0.0595, 0.0655],
        [0.0640, 0.0609],
        [0.0589, 0.0661],
        [0.0653, 0.0596],
        [0.0586, 0.0665],
        [0.0700, 0.0556],
        [0.0651, 0.0599],
        [0.0616, 0.0632],
        [0.0642, 0.0606]], device='cuda:0')
 Batch: 5 of passive classification Duration: 0:00:00.442936
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0006, 0.0009],
        [0.0003, 0.0006],
        [0.0005, 0.0011],
        [0.0004, 0.0010],
        [0.0002, 0.0003],
        [0.0002, 0.0005],
        [0.0004, 0.0010],
        [0.0004, 0.0005],
        [0.0003, 0.0004],
        [0.0005, 0.0007],
        [0.0003, 0.0005],
        [0.0006, 0.0016],
        [0.0005, 0.0009],
        [0.0002, 0.0004],
        [0.0004, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0617, 0.0631],
        [0.0645, 0.0604],
        [0.0624, 0.0624],
        [0.0587, 0.0663],
        [0.0584, 0.0667],
        [0.0675, 0.0577],
        [0.0586, 0.0664],
        [0.0570, 0.0683],
        [0.0681, 0.0571],
        [0.0684, 0.0569],
        [0.0658, 0.0591],
        [0.0627, 0.0621],
        [0.0577, 0.0674],
        [0.0610, 0.0639],
        [0.0622, 0.0626],
        [0.0653, 0.0596]], device='cuda:0')
 Batch: 6 of passive classification Duration: 0:00:00.331244
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0005, 0.0013],
        [0.0005, 0.0008],
        [0.0007, 0.0008],
        [0.0002, 0.0005],
        [0.0008, 0.0013],
        [0.0002, 0.0004],
        [0.0006, 0.0014],
        [0.0004, 0.0009],
        [0.0004, 0.0006],
        [0.0009, 0.0020],
        [0.0006, 0.0014],
        [0.0004, 0.0006],
        [0.0005, 0.0009],
        [0.0003, 0.0003],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0705, 0.0552],
        [0.0567, 0.0686],
        [0.0637, 0.0611],
        [0.0678, 0.0574],
        [0.0581, 0.0669],
        [0.0627, 0.0620],
        [0.0648, 0.0600],
        [0.0585, 0.0664],
        [0.0592, 0.0657],
        [0.0656, 0.0593],
        [0.0595, 0.0653],
        [0.0578, 0.0673],
        [0.0640, 0.0607],
        [0.0600, 0.0648],
        [0.0704, 0.0553],
        [0.0607, 0.0641]], device='cuda:0')
 Batch: 7 of passive classification Duration: 0:00:00.362139
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0015],
        [0.0005, 0.0012],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0005, 0.0014],
        [0.0005, 0.0014],
        [0.0007, 0.0010],
        [0.0002, 0.0003],
        [0.0006, 0.0009],
        [0.0003, 0.0009],
        [0.0004, 0.0012],
        [0.0003, 0.0005],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0004],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0615, 0.0633],
        [0.0609, 0.0639],
        [0.0578, 0.0672],
        [0.0594, 0.0654],
        [0.0589, 0.0661],
        [0.0583, 0.0668],
        [0.0684, 0.0568],
        [0.0674, 0.0577],
        [0.0668, 0.0582],
        [0.0591, 0.0658],
        [0.0568, 0.0685],
        [0.0650, 0.0598],
        [0.0634, 0.0614],
        [0.0616, 0.0632],
        [0.0717, 0.0543],
        [0.0631, 0.0617]], device='cuda:0')
 Batch: 8 of passive classification Duration: 0:00:00.395224
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0006, 0.0011],
        [0.0002, 0.0006],
        [0.0002, 0.0003],
        [0.0002, 0.0005],
        [0.0006, 0.0009],
        [0.0004, 0.0010],
        [0.0004, 0.0006],
        [0.0004, 0.0010],
        [0.0005, 0.0011],
        [0.0009, 0.0020],
        [0.0003, 0.0004],
        [0.0004, 0.0009],
        [0.0004, 0.0010],
        [0.0004, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0612, 0.0636],
        [0.0667, 0.0584],
        [0.0631, 0.0617],
        [0.0565, 0.0689],
        [0.0646, 0.0603],
        [0.0621, 0.0627],
        [0.0674, 0.0577],
        [0.0605, 0.0643],
        [0.0663, 0.0587],
        [0.0581, 0.0670],
        [0.0618, 0.0630],
        [0.0603, 0.0645],
        [0.0713, 0.0546],
        [0.0611, 0.0637],
        [0.0606, 0.0642],
        [0.0585, 0.0666]], device='cuda:0')
 Batch: 9 of passive classification Duration: 0:00:00.557783
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0015],
        [0.0005, 0.0012],
        [0.0005, 0.0011],
        [0.0003, 0.0005],
        [0.0002, 0.0006],
        [0.0004, 0.0007],
        [0.0006, 0.0010],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0005, 0.0011],
        [0.0002, 0.0003],
        [0.0006, 0.0017],
        [0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0005, 0.0010],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0620, 0.0629],
        [0.0584, 0.0668],
        [0.0606, 0.0643],
        [0.0626, 0.0623],
        [0.0599, 0.0651],
        [0.0618, 0.0630],
        [0.0640, 0.0609],
        [0.0622, 0.0627],
        [0.0655, 0.0595],
        [0.0600, 0.0650],
        [0.0704, 0.0553],
        [0.0584, 0.0668],
        [0.0639, 0.0610],
        [0.0638, 0.0611],
        [0.0621, 0.0628],
        [0.0646, 0.0604]], device='cuda:0')
 Batch: 10 of passive classification Duration: 0:00:00.448936
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0003, 0.0009],
        [0.0004, 0.0006],
        [0.0002, 0.0006],
        [0.0005, 0.0008],
        [0.0003, 0.0008],
        [0.0005, 0.0009],
        [0.0002, 0.0002],
        [0.0005, 0.0012],
        [0.0005, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0624, 0.0624],
        [0.0621, 0.0627],
        [0.0637, 0.0611],
        [0.0603, 0.0645],
        [0.0576, 0.0676],
        [0.0566, 0.0687],
        [0.0651, 0.0597],
        [0.0574, 0.0677],
        [0.0641, 0.0607],
        [0.0589, 0.0660],
        [0.0637, 0.0611],
        [0.0714, 0.0545],
        [0.0596, 0.0653],
        [0.0696, 0.0559],
        [0.0647, 0.0602],
        [0.0628, 0.0619]], device='cuda:0')
 Batch: 11 of passive classification Duration: 0:00:00.315078
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0007, 0.0016],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1230, 0.1269],
        [0.1259, 0.1240],
        [0.1173, 0.1331],
        [0.1268, 0.1231],
        [0.1250, 0.1249],
        [0.1271, 0.1229],
        [0.1273, 0.1227],
        [0.1275, 0.1224]], device='cuda:0')
 Batch: 12 of passive classification Duration: 0:00:00.208056
acc:  0.565
Time taken to execute the en SA task with prompt type passive, variation 9 and batchsize 16: 0:00:05.094920
path ['42', 'en', 'bloom-big', 'SA', 'passive', 'prompt_id_9']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v73.pickle' as a pickle file.

prompt_type auxiliary has 10 prompts in it
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([87, 2])
answers_probs just softmax dim 0: tensor([[0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115]], device='cuda:0')
tensor([[0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115],
        [0.0115, 0.0115]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA auxiliary 0 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[6.6805e-04, 1.2283e-03],
        [2.6941e-04, 3.3808e-04],
        [3.9649e-04, 9.1505e-04],
        [3.7527e-04, 4.8184e-04],
        [5.2214e-04, 9.0885e-04],
        [3.5834e-04, 6.1417e-04],
        [2.9516e-04, 4.8661e-04],
        [3.1257e-04, 5.3167e-04],
        [2.7490e-04, 4.3607e-04],
        [3.9577e-04, 5.8937e-04],
        [4.6968e-04, 7.2765e-04],
        [9.5248e-05, 3.7670e-04],
        [3.6764e-04, 4.0078e-04],
        [2.0456e-04, 4.5729e-04],
        [2.1279e-04, 4.6849e-04],
        [1.7405e-04, 3.4881e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0616, 0.0631],
        [0.0675, 0.0576],
        [0.0586, 0.0664],
        [0.0671, 0.0580],
        [0.0624, 0.0623],
        [0.0626, 0.0621],
        [0.0632, 0.0616],
        [0.0627, 0.0620],
        [0.0638, 0.0610],
        [0.0647, 0.0601],
        [0.0641, 0.0607],
        [0.0530, 0.0734],
        [0.0699, 0.0557],
        [0.0590, 0.0659],
        [0.0592, 0.0657],
        [0.0604, 0.0644]], device='cuda:0')
 Batch: 0 of auxiliary classification Duration: 0:00:00.404157
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0004],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0006, 0.0010],
        [0.0005, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0010],
        [0.0004, 0.0005],
        [0.0008, 0.0013],
        [0.0002, 0.0005],
        [0.0004, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0694, 0.0561],
        [0.0633, 0.0616],
        [0.0611, 0.0638],
        [0.0626, 0.0622],
        [0.0633, 0.0616],
        [0.0637, 0.0612],
        [0.0621, 0.0628],
        [0.0622, 0.0627],
        [0.0573, 0.0681],
        [0.0658, 0.0593],
        [0.0626, 0.0622],
        [0.0577, 0.0676],
        [0.0636, 0.0613],
        [0.0607, 0.0642],
        [0.0628, 0.0621],
        [0.0617, 0.0632]], device='cuda:0')
 Batch: 1 of auxiliary classification Duration: 0:00:00.415565
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0005, 0.0008],
        [0.0002, 0.0004],
        [0.0004, 0.0008],
        [0.0007, 0.0011],
        [0.0004, 0.0006],
        [0.0004, 0.0009],
        [0.0005, 0.0006],
        [0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0005, 0.0007],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0006, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0601, 0.0648],
        [0.0627, 0.0622],
        [0.0642, 0.0607],
        [0.0612, 0.0637],
        [0.0611, 0.0638],
        [0.0632, 0.0616],
        [0.0640, 0.0609],
        [0.0565, 0.0690],
        [0.0681, 0.0572],
        [0.0613, 0.0636],
        [0.0629, 0.0620],
        [0.0640, 0.0609],
        [0.0648, 0.0601],
        [0.0587, 0.0664],
        [0.0590, 0.0661],
        [0.0684, 0.0570]], device='cuda:0')
 Batch: 2 of auxiliary classification Duration: 0:00:00.357873
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0005, 0.0006],
        [0.0004, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0006],
        [0.0005, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0012, 0.0013],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0005, 0.0005],
        [0.0008, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0615, 0.0633],
        [0.0660, 0.0591],
        [0.0589, 0.0661],
        [0.0612, 0.0636],
        [0.0657, 0.0593],
        [0.0631, 0.0617],
        [0.0591, 0.0659],
        [0.0569, 0.0685],
        [0.0616, 0.0632],
        [0.0593, 0.0657],
        [0.0692, 0.0562],
        [0.0633, 0.0616],
        [0.0608, 0.0641],
        [0.0602, 0.0647],
        [0.0692, 0.0563],
        [0.0640, 0.0609]], device='cuda:0')
 Batch: 3 of auxiliary classification Duration: 0:00:00.443349
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0005, 0.0006],
        [0.0005, 0.0011],
        [0.0003, 0.0004],
        [0.0004, 0.0008],
        [0.0007, 0.0011],
        [0.0002, 0.0002],
        [0.0004, 0.0004],
        [0.0004, 0.0008],
        [0.0006, 0.0007],
        [0.0002, 0.0003],
        [0.0008, 0.0013],
        [0.0003, 0.0005],
        [0.0006, 0.0007],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0578, 0.0673],
        [0.0617, 0.0630],
        [0.0660, 0.0589],
        [0.0561, 0.0694],
        [0.0626, 0.0622],
        [0.0574, 0.0678],
        [0.0610, 0.0638],
        [0.0725, 0.0537],
        [0.0686, 0.0567],
        [0.0589, 0.0660],
        [0.0649, 0.0600],
        [0.0635, 0.0612],
        [0.0606, 0.0642],
        [0.0637, 0.0610],
        [0.0651, 0.0597],
        [0.0596, 0.0652]], device='cuda:0')
 Batch: 4 of auxiliary classification Duration: 0:00:00.353807
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0008],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0004],
        [0.0003, 0.0007],
        [0.0002, 0.0006],
        [0.0005, 0.0010],
        [0.0002, 0.0005],
        [0.0005, 0.0007],
        [0.0005, 0.0010],
        [0.0002, 0.0004],
        [0.0004, 0.0008],
        [0.0004, 0.0009],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0717, 0.0543],
        [0.0627, 0.0621],
        [0.0571, 0.0682],
        [0.0659, 0.0591],
        [0.0588, 0.0662],
        [0.0599, 0.0650],
        [0.0630, 0.0619],
        [0.0588, 0.0662],
        [0.0654, 0.0595],
        [0.0607, 0.0641],
        [0.0600, 0.0649],
        [0.0608, 0.0640],
        [0.0613, 0.0635],
        [0.0652, 0.0597],
        [0.0640, 0.0609],
        [0.0645, 0.0604]], device='cuda:0')
 Batch: 5 of auxiliary classification Duration: 0:00:00.313867
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0006, 0.0011],
        [0.0005, 0.0007],
        [0.0002, 0.0003],
        [0.0004, 0.0007],
        [0.0004, 0.0005],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0007, 0.0010],
        [0.0004, 0.0009],
        [0.0002, 0.0006],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0589, 0.0661],
        [0.0608, 0.0641],
        [0.0649, 0.0600],
        [0.0667, 0.0584],
        [0.0600, 0.0650],
        [0.0664, 0.0587],
        [0.0643, 0.0606],
        [0.0630, 0.0619],
        [0.0638, 0.0611],
        [0.0568, 0.0686],
        [0.0578, 0.0674],
        [0.0658, 0.0592],
        [0.0616, 0.0633],
        [0.0612, 0.0637],
        [0.0624, 0.0625],
        [0.0655, 0.0595]], device='cuda:0')
 Batch: 6 of auxiliary classification Duration: 0:00:00.537199
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0005, 0.0007],
        [0.0005, 0.0010],
        [0.0005, 0.0006],
        [0.0003, 0.0003],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0005, 0.0007],
        [0.0005, 0.0008],
        [0.0002, 0.0005],
        [0.0004, 0.0010],
        [0.0003, 0.0007],
        [0.0005, 0.0007],
        [0.0005, 0.0007],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0665, 0.0586],
        [0.0656, 0.0594],
        [0.0606, 0.0643],
        [0.0671, 0.0580],
        [0.0667, 0.0584],
        [0.0600, 0.0649],
        [0.0612, 0.0636],
        [0.0635, 0.0613],
        [0.0640, 0.0609],
        [0.0630, 0.0618],
        [0.0589, 0.0662],
        [0.0566, 0.0688],
        [0.0570, 0.0683],
        [0.0651, 0.0598],
        [0.0644, 0.0605],
        [0.0597, 0.0652]], device='cuda:0')
 Batch: 7 of auxiliary classification Duration: 0:00:00.353881
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0006, 0.0007],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0006, 0.0009],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0004, 0.0004],
        [0.0004, 0.0006],
        [0.0005, 0.0009],
        [0.0003, 0.0004],
        [0.0005, 0.0007],
        [0.0007, 0.0009],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0616, 0.0633],
        [0.0613, 0.0636],
        [0.0673, 0.0579],
        [0.0645, 0.0605],
        [0.0568, 0.0686],
        [0.0607, 0.0642],
        [0.0646, 0.0603],
        [0.0597, 0.0654],
        [0.0634, 0.0615],
        [0.0671, 0.0581],
        [0.0620, 0.0629],
        [0.0598, 0.0652],
        [0.0611, 0.0638],
        [0.0646, 0.0603],
        [0.0656, 0.0594],
        [0.0600, 0.0650]], device='cuda:0')
 Batch: 8 of auxiliary classification Duration: 0:00:00.396857
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0009],
        [0.0003, 0.0006],
        [0.0003, 0.0009],
        [0.0005, 0.0009],
        [0.0004, 0.0007],
        [0.0004, 0.0005],
        [0.0005, 0.0007],
        [0.0005, 0.0006],
        [0.0004, 0.0010],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0005, 0.0006],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0563, 0.0691],
        [0.0622, 0.0626],
        [0.0555, 0.0701],
        [0.0621, 0.0627],
        [0.0631, 0.0617],
        [0.0665, 0.0585],
        [0.0655, 0.0594],
        [0.0669, 0.0582],
        [0.0576, 0.0676],
        [0.0622, 0.0626],
        [0.0627, 0.0621],
        [0.0602, 0.0646],
        [0.0649, 0.0600],
        [0.0611, 0.0637],
        [0.0687, 0.0566],
        [0.0644, 0.0604]], device='cuda:0')
 Batch: 9 of auxiliary classification Duration: 0:00:00.360638
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0004, 0.0005],
        [0.0004, 0.0004],
        [0.0003, 0.0006],
        [0.0004, 0.0004],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0005, 0.0010],
        [0.0005, 0.0008],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0008, 0.0014],
        [0.0005, 0.0006],
        [0.0005, 0.0007],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0655, 0.0595],
        [0.0627, 0.0622],
        [0.0675, 0.0577],
        [0.0591, 0.0660],
        [0.0669, 0.0582],
        [0.0593, 0.0657],
        [0.0645, 0.0604],
        [0.0583, 0.0669],
        [0.0594, 0.0656],
        [0.0596, 0.0654],
        [0.0651, 0.0599],
        [0.0656, 0.0594],
        [0.0603, 0.0647],
        [0.0647, 0.0602],
        [0.0617, 0.0631],
        [0.0598, 0.0651]], device='cuda:0')
 Batch: 10 of auxiliary classification Duration: 0:00:00.334668
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0006, 0.0009],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0005, 0.0010],
        [0.0003, 0.0007],
        [0.0003, 0.0008],
        [0.0006, 0.0015],
        [0.0004, 0.0008],
        [0.0006, 0.0007],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0007, 0.0009],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0638, 0.0611],
        [0.0631, 0.0617],
        [0.0604, 0.0645],
        [0.0630, 0.0619],
        [0.0623, 0.0625],
        [0.0602, 0.0648],
        [0.0609, 0.0640],
        [0.0591, 0.0660],
        [0.0574, 0.0679],
        [0.0613, 0.0635],
        [0.0701, 0.0556],
        [0.0616, 0.0633],
        [0.0645, 0.0604],
        [0.0637, 0.0612],
        [0.0678, 0.0575],
        [0.0608, 0.0641]], device='cuda:0')
 Batch: 11 of auxiliary classification Duration: 0:00:00.430086
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0005],
        [0.0005, 0.0010],
        [0.0004, 0.0005],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1264, 0.1234],
        [0.1250, 0.1247],
        [0.1351, 0.1154],
        [0.1187, 0.1314],
        [0.1338, 0.1165],
        [0.1208, 0.1291],
        [0.1218, 0.1279],
        [0.1185, 0.1316]], device='cuda:0')
 Batch: 12 of auxiliary classification Duration: 0:00:00.160196
acc:  0.49
Time taken to execute the en SA task with prompt type auxiliary, variation 0 and batchsize 16: 0:00:04.882887
path ['42', 'en', 'bloom-big', 'SA', 'auxiliary', 'prompt_id_0']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([100, 2])
answers_probs just softmax dim 0: tensor([[0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100]], device='cuda:0')
tensor([[0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA auxiliary 1 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0007, 0.0008],
        [0.0004, 0.0006],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0002, 0.0002],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0006, 0.0009],
        [0.0003, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0009],
        [0.0002, 0.0005],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0650, 0.0598],
        [0.0703, 0.0552],
        [0.0633, 0.0614],
        [0.0573, 0.0678],
        [0.0609, 0.0639],
        [0.0625, 0.0622],
        [0.0608, 0.0639],
        [0.0748, 0.0519],
        [0.0624, 0.0623],
        [0.0616, 0.0631],
        [0.0649, 0.0599],
        [0.0568, 0.0685],
        [0.0605, 0.0642],
        [0.0597, 0.0651],
        [0.0555, 0.0700],
        [0.0637, 0.0610]], device='cuda:0')
 Batch: 0 of auxiliary classification Duration: 0:00:00.363638
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0005],
        [0.0002, 0.0003],
        [0.0006, 0.0012],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0007],
        [0.0002, 0.0006],
        [0.0004, 0.0008],
        [0.0004, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0659, 0.0591],
        [0.0637, 0.0611],
        [0.0569, 0.0684],
        [0.0636, 0.0612],
        [0.0674, 0.0577],
        [0.0616, 0.0632],
        [0.0590, 0.0660],
        [0.0621, 0.0627],
        [0.0606, 0.0642],
        [0.0634, 0.0614],
        [0.0603, 0.0645],
        [0.0577, 0.0675],
        [0.0606, 0.0642],
        [0.0707, 0.0550],
        [0.0592, 0.0657],
        [0.0671, 0.0580]], device='cuda:0')
 Batch: 1 of auxiliary classification Duration: 0:00:00.419408
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0002, 0.0006],
        [0.0005, 0.0008],
        [0.0004, 0.0007],
        [0.0003, 0.0010],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0005, 0.0007],
        [0.0002, 0.0005],
        [0.0007, 0.0013],
        [0.0002, 0.0005],
        [0.0004, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0605, 0.0644],
        [0.0597, 0.0653],
        [0.0646, 0.0604],
        [0.0650, 0.0599],
        [0.0569, 0.0685],
        [0.0618, 0.0631],
        [0.0641, 0.0608],
        [0.0677, 0.0576],
        [0.0613, 0.0636],
        [0.0635, 0.0614],
        [0.0619, 0.0630],
        [0.0660, 0.0591],
        [0.0596, 0.0654],
        [0.0634, 0.0615],
        [0.0601, 0.0648],
        [0.0637, 0.0612]], device='cuda:0')
 Batch: 2 of auxiliary classification Duration: 0:00:00.357358
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0002, 0.0006],
        [0.0003, 0.0009],
        [0.0002, 0.0003],
        [0.0002, 0.0006],
        [0.0006, 0.0012],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0004, 0.0007],
        [0.0004, 0.0005],
        [0.0005, 0.0006],
        [0.0005, 0.0008],
        [0.0003, 0.0008],
        [0.0007, 0.0011],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0644, 0.0604],
        [0.0562, 0.0692],
        [0.0580, 0.0672],
        [0.0665, 0.0585],
        [0.0579, 0.0673],
        [0.0622, 0.0626],
        [0.0641, 0.0608],
        [0.0617, 0.0631],
        [0.0595, 0.0655],
        [0.0628, 0.0620],
        [0.0664, 0.0586],
        [0.0699, 0.0557],
        [0.0628, 0.0620],
        [0.0594, 0.0656],
        [0.0636, 0.0612],
        [0.0644, 0.0604]], device='cuda:0')
 Batch: 3 of auxiliary classification Duration: 0:00:00.331118
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0002, 0.0006],
        [0.0003, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0008],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0005, 0.0006],
        [0.0004, 0.0010],
        [0.0004, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0641, 0.0608],
        [0.0653, 0.0597],
        [0.0615, 0.0633],
        [0.0569, 0.0684],
        [0.0596, 0.0654],
        [0.0616, 0.0632],
        [0.0566, 0.0688],
        [0.0665, 0.0586],
        [0.0628, 0.0620],
        [0.0678, 0.0575],
        [0.0580, 0.0672],
        [0.0666, 0.0584],
        [0.0606, 0.0643],
        [0.0627, 0.0621],
        [0.0645, 0.0603],
        [0.0650, 0.0599]], device='cuda:0')
 Batch: 4 of auxiliary classification Duration: 0:00:00.447024
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0005, 0.0008],
        [0.0002, 0.0005],
        [0.0005, 0.0013],
        [0.0004, 0.0008],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0010],
        [0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0006, 0.0009],
        [0.0004, 0.0005],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0589, 0.0662],
        [0.0639, 0.0610],
        [0.0597, 0.0653],
        [0.0580, 0.0672],
        [0.0626, 0.0622],
        [0.0650, 0.0600],
        [0.0629, 0.0620],
        [0.0671, 0.0581],
        [0.0652, 0.0597],
        [0.0592, 0.0658],
        [0.0639, 0.0610],
        [0.0602, 0.0648],
        [0.0600, 0.0650],
        [0.0638, 0.0611],
        [0.0688, 0.0567],
        [0.0609, 0.0640]], device='cuda:0')
 Batch: 5 of auxiliary classification Duration: 0:00:00.400987
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0007],
        [0.0003, 0.0009],
        [0.0003, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0007, 0.0008],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0693, 0.0561],
        [0.0580, 0.0671],
        [0.0596, 0.0652],
        [0.0652, 0.0596],
        [0.0585, 0.0665],
        [0.0635, 0.0613],
        [0.0712, 0.0546],
        [0.0647, 0.0601],
        [0.0637, 0.0611],
        [0.0627, 0.0621],
        [0.0574, 0.0677],
        [0.0574, 0.0677],
        [0.0587, 0.0663],
        [0.0605, 0.0643],
        [0.0646, 0.0602],
        [0.0649, 0.0600]], device='cuda:0')
 Batch: 6 of auxiliary classification Duration: 0:00:00.541199
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0004, 0.0010],
        [0.0004, 0.0009],
        [0.0001, 0.0003],
        [0.0004, 0.0008],
        [0.0005, 0.0006],
        [0.0003, 0.0004],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0005, 0.0014],
        [0.0003, 0.0010],
        [0.0003, 0.0005],
        [0.0010, 0.0012],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0642, 0.0606],
        [0.0584, 0.0666],
        [0.0576, 0.0676],
        [0.0600, 0.0649],
        [0.0605, 0.0643],
        [0.0689, 0.0565],
        [0.0649, 0.0600],
        [0.0649, 0.0600],
        [0.0660, 0.0589],
        [0.0559, 0.0696],
        [0.0568, 0.0685],
        [0.0638, 0.0610],
        [0.0687, 0.0566],
        [0.0656, 0.0593],
        [0.0623, 0.0624],
        [0.0617, 0.0631]], device='cuda:0')
 Batch: 7 of auxiliary classification Duration: 0:00:00.358698
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0005, 0.0012],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0007, 0.0011],
        [0.0004, 0.0007],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0004, 0.0008],
        [0.0004, 0.0004],
        [0.0003, 0.0006],
        [0.0005, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0632, 0.0617],
        [0.0590, 0.0660],
        [0.0589, 0.0661],
        [0.0601, 0.0648],
        [0.0592, 0.0658],
        [0.0603, 0.0646],
        [0.0647, 0.0602],
        [0.0628, 0.0620],
        [0.0613, 0.0635],
        [0.0632, 0.0617],
        [0.0637, 0.0611],
        [0.0607, 0.0642],
        [0.0612, 0.0636],
        [0.0724, 0.0538],
        [0.0620, 0.0629],
        [0.0673, 0.0579]], device='cuda:0')
 Batch: 8 of auxiliary classification Duration: 0:00:00.329624
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0011],
        [0.0004, 0.0006],
        [0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0001, 0.0003],
        [0.0002, 0.0006],
        [0.0008, 0.0009],
        [0.0003, 0.0008],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0005, 0.0009],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0622, 0.0626],
        [0.0639, 0.0610],
        [0.0602, 0.0648],
        [0.0654, 0.0596],
        [0.0596, 0.0654],
        [0.0567, 0.0687],
        [0.0702, 0.0555],
        [0.0601, 0.0648],
        [0.0648, 0.0601],
        [0.0629, 0.0620],
        [0.0636, 0.0613],
        [0.0625, 0.0623],
        [0.0633, 0.0616],
        [0.0601, 0.0648],
        [0.0615, 0.0634],
        [0.0629, 0.0620]], device='cuda:0')
 Batch: 9 of auxiliary classification Duration: 0:00:00.440009
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0005],
        [0.0004, 0.0006],
        [0.0006, 0.0012],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0009],
        [0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0004, 0.0010],
        [0.0001, 0.0003],
        [0.0001, 0.0003],
        [0.0002, 0.0004],
        [0.0008, 0.0016],
        [0.0005, 0.0006],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0679, 0.0574],
        [0.0670, 0.0581],
        [0.0626, 0.0623],
        [0.0620, 0.0628],
        [0.0602, 0.0647],
        [0.0616, 0.0632],
        [0.0577, 0.0674],
        [0.0598, 0.0651],
        [0.0686, 0.0568],
        [0.0601, 0.0648],
        [0.0577, 0.0675],
        [0.0606, 0.0643],
        [0.0604, 0.0645],
        [0.0621, 0.0627],
        [0.0680, 0.0572],
        [0.0636, 0.0613]], device='cuda:0')
 Batch: 10 of auxiliary classification Duration: 0:00:00.290207
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0009],
        [0.0001, 0.0002],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0005, 0.0008],
        [0.0004, 0.0007],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0004, 0.0005],
        [0.0005, 0.0008],
        [0.0002, 0.0004],
        [0.0004, 0.0005],
        [0.0003, 0.0008],
        [0.0004, 0.0008],
        [0.0002, 0.0005],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0587, 0.0664],
        [0.0629, 0.0620],
        [0.0623, 0.0626],
        [0.0599, 0.0652],
        [0.0662, 0.0590],
        [0.0623, 0.0626],
        [0.0614, 0.0636],
        [0.0621, 0.0628],
        [0.0668, 0.0584],
        [0.0633, 0.0616],
        [0.0631, 0.0618],
        [0.0660, 0.0591],
        [0.0609, 0.0641],
        [0.0626, 0.0624],
        [0.0584, 0.0668],
        [0.0632, 0.0617]], device='cuda:0')
 Batch: 11 of auxiliary classification Duration: 0:00:00.421788
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0002, 0.0003],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0011],
        [0.0002, 0.0006],
        [0.0003, 0.0004],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1322, 0.1176],
        [0.1301, 0.1196],
        [0.1238, 0.1256],
        [0.1350, 0.1152],
        [0.1103, 0.1410],
        [0.1142, 0.1362],
        [0.1294, 0.1202],
        [0.1249, 0.1246]], device='cuda:0')
 Batch: 12 of auxiliary classification Duration: 0:00:00.215182
acc:  0.51
Time taken to execute the en SA task with prompt type auxiliary, variation 1 and batchsize 16: 0:00:04.935006
path ['42', 'en', 'bloom-big', 'SA', 'auxiliary', 'prompt_id_1']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([100, 2])
answers_probs just softmax dim 0: tensor([[0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100]], device='cuda:0')
tensor([[0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA auxiliary 2 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0007],
        [0.0003, 0.0008],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0003],
        [0.0002, 0.0008],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0001, 0.0001],
        [0.0004, 0.0009],
        [0.0002, 0.0003],
        [0.0002, 0.0006],
        [0.0002, 0.0002],
        [0.0004, 0.0009],
        [0.0003, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0564, 0.0687],
        [0.0585, 0.0663],
        [0.0617, 0.0628],
        [0.0649, 0.0598],
        [0.0739, 0.0525],
        [0.0549, 0.0706],
        [0.0589, 0.0658],
        [0.0618, 0.0627],
        [0.0613, 0.0633],
        [0.0710, 0.0547],
        [0.0613, 0.0633],
        [0.0684, 0.0567],
        [0.0585, 0.0663],
        [0.0695, 0.0558],
        [0.0612, 0.0634],
        [0.0576, 0.0673]], device='cuda:0')
 Batch: 0 of auxiliary classification Duration: 0:00:00.414801
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0008, 0.0018],
        [0.0004, 0.0012],
        [0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0002, 0.0004],
        [0.0002, 0.0007],
        [0.0003, 0.0004],
        [0.0004, 0.0005],
        [0.0003, 0.0009],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0006, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0575, 0.0676],
        [0.0670, 0.0581],
        [0.0610, 0.0638],
        [0.0638, 0.0610],
        [0.0618, 0.0629],
        [0.0570, 0.0683],
        [0.0627, 0.0621],
        [0.0601, 0.0647],
        [0.0628, 0.0620],
        [0.0572, 0.0680],
        [0.0666, 0.0584],
        [0.0705, 0.0552],
        [0.0584, 0.0666],
        [0.0673, 0.0579],
        [0.0652, 0.0597],
        [0.0609, 0.0639]], device='cuda:0')
 Batch: 1 of auxiliary classification Duration: 0:00:00.336173
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0003, 0.0007],
        [0.0002, 0.0008],
        [0.0004, 0.0008],
        [0.0004, 0.0013],
        [0.0003, 0.0008],
        [0.0002, 0.0007],
        [0.0002, 0.0004],
        [0.0004, 0.0012],
        [0.0002, 0.0004],
        [0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0005, 0.0011],
        [0.0003, 0.0004],
        [0.0003, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0633, 0.0615],
        [0.0638, 0.0610],
        [0.0567, 0.0687],
        [0.0643, 0.0606],
        [0.0593, 0.0657],
        [0.0596, 0.0654],
        [0.0588, 0.0662],
        [0.0617, 0.0631],
        [0.0600, 0.0649],
        [0.0691, 0.0564],
        [0.0647, 0.0602],
        [0.0649, 0.0600],
        [0.0615, 0.0634],
        [0.0638, 0.0610],
        [0.0686, 0.0568],
        [0.0598, 0.0652]], device='cuda:0')
 Batch: 2 of auxiliary classification Duration: 0:00:00.426450
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0009],
        [0.0001, 0.0002],
        [0.0004, 0.0008],
        [0.0007, 0.0013],
        [0.0003, 0.0006],
        [0.0004, 0.0011],
        [0.0002, 0.0006],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0005, 0.0010],
        [0.0003, 0.0004],
        [0.0002, 0.0004],
        [0.0004, 0.0011],
        [0.0001, 0.0002],
        [0.0002, 0.0006],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0567, 0.0687],
        [0.0650, 0.0599],
        [0.0608, 0.0641],
        [0.0630, 0.0617],
        [0.0605, 0.0644],
        [0.0596, 0.0653],
        [0.0599, 0.0650],
        [0.0643, 0.0606],
        [0.0674, 0.0577],
        [0.0626, 0.0622],
        [0.0678, 0.0574],
        [0.0633, 0.0615],
        [0.0584, 0.0666],
        [0.0672, 0.0580],
        [0.0568, 0.0686],
        [0.0668, 0.0583]], device='cuda:0')
 Batch: 3 of auxiliary classification Duration: 0:00:00.476943
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0010],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0005, 0.0008],
        [0.0003, 0.0012],
        [0.0003, 0.0004],
        [0.0005, 0.0009],
        [0.0003, 0.0009],
        [0.0002, 0.0006],
        [0.0003, 0.0007],
        [0.0006, 0.0013],
        [0.0001, 0.0002],
        [0.0004, 0.0009],
        [0.0002, 0.0003],
        [0.0004, 0.0011],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0579, 0.0672],
        [0.0616, 0.0631],
        [0.0620, 0.0627],
        [0.0649, 0.0599],
        [0.0559, 0.0696],
        [0.0689, 0.0564],
        [0.0652, 0.0597],
        [0.0601, 0.0647],
        [0.0575, 0.0676],
        [0.0608, 0.0640],
        [0.0619, 0.0628],
        [0.0715, 0.0544],
        [0.0616, 0.0631],
        [0.0686, 0.0567],
        [0.0592, 0.0657],
        [0.0622, 0.0625]], device='cuda:0')
 Batch: 4 of auxiliary classification Duration: 0:00:00.440771
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0003, 0.0004],
        [0.0001, 0.0002],
        [0.0003, 0.0006],
        [0.0005, 0.0011],
        [0.0002, 0.0005],
        [0.0001, 0.0003],
        [0.0003, 0.0007],
        [0.0004, 0.0009],
        [0.0003, 0.0008],
        [0.0002, 0.0004],
        [0.0005, 0.0009],
        [0.0005, 0.0010],
        [0.0003, 0.0008],
        [0.0002, 0.0004],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0614, 0.0634],
        [0.0720, 0.0541],
        [0.0645, 0.0603],
        [0.0604, 0.0645],
        [0.0617, 0.0631],
        [0.0569, 0.0684],
        [0.0637, 0.0611],
        [0.0607, 0.0642],
        [0.0598, 0.0651],
        [0.0588, 0.0663],
        [0.0636, 0.0612],
        [0.0638, 0.0610],
        [0.0613, 0.0635],
        [0.0596, 0.0653],
        [0.0633, 0.0616],
        [0.0683, 0.0570]], device='cuda:0')
 Batch: 5 of auxiliary classification Duration: 0:00:00.404592
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0003, 0.0009],
        [0.0003, 0.0010],
        [0.0004, 0.0012],
        [0.0003, 0.0005],
        [0.0007, 0.0015],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0005, 0.0013],
        [0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0603, 0.0646],
        [0.0610, 0.0639],
        [0.0568, 0.0686],
        [0.0600, 0.0649],
        [0.0654, 0.0596],
        [0.0620, 0.0629],
        [0.0628, 0.0621],
        [0.0665, 0.0586],
        [0.0628, 0.0621],
        [0.0610, 0.0639],
        [0.0613, 0.0636],
        [0.0654, 0.0596],
        [0.0611, 0.0638],
        [0.0618, 0.0631],
        [0.0693, 0.0563],
        [0.0627, 0.0622]], device='cuda:0')
 Batch: 6 of auxiliary classification Duration: 0:00:00.288008
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0010],
        [0.0004, 0.0006],
        [0.0004, 0.0009],
        [0.0004, 0.0013],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0003, 0.0010],
        [0.0003, 0.0005],
        [0.0005, 0.0010],
        [0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0008],
        [0.0001, 0.0002],
        [0.0002, 0.0004],
        [0.0001, 0.0001],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0567, 0.0686],
        [0.0644, 0.0604],
        [0.0607, 0.0641],
        [0.0567, 0.0686],
        [0.0669, 0.0581],
        [0.0668, 0.0582],
        [0.0572, 0.0679],
        [0.0646, 0.0602],
        [0.0614, 0.0633],
        [0.0585, 0.0665],
        [0.0588, 0.0661],
        [0.0599, 0.0649],
        [0.0695, 0.0559],
        [0.0646, 0.0602],
        [0.0696, 0.0559],
        [0.0637, 0.0611]], device='cuda:0')
 Batch: 7 of auxiliary classification Duration: 0:00:00.534546
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0009],
        [0.0003, 0.0007],
        [0.0004, 0.0010],
        [0.0005, 0.0012],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0004, 0.0010],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0007, 0.0018],
        [0.0004, 0.0012],
        [0.0003, 0.0009],
        [0.0004, 0.0012],
        [0.0004, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0706, 0.0551],
        [0.0659, 0.0591],
        [0.0616, 0.0632],
        [0.0600, 0.0649],
        [0.0629, 0.0619],
        [0.0615, 0.0633],
        [0.0639, 0.0610],
        [0.0687, 0.0567],
        [0.0620, 0.0628],
        [0.0641, 0.0608],
        [0.0620, 0.0628],
        [0.0615, 0.0633],
        [0.0591, 0.0659],
        [0.0589, 0.0661],
        [0.0582, 0.0670],
        [0.0591, 0.0659]], device='cuda:0')
 Batch: 8 of auxiliary classification Duration: 0:00:00.358268
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0004, 0.0005],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0010],
        [0.0003, 0.0009],
        [0.0003, 0.0010],
        [0.0005, 0.0010],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0004],
        [0.0005, 0.0012],
        [0.0001, 0.0002],
        [0.0004, 0.0010],
        [0.0004, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0641, 0.0607],
        [0.0605, 0.0644],
        [0.0666, 0.0585],
        [0.0629, 0.0619],
        [0.0615, 0.0633],
        [0.0577, 0.0675],
        [0.0582, 0.0669],
        [0.0565, 0.0689],
        [0.0627, 0.0620],
        [0.0614, 0.0634],
        [0.0613, 0.0635],
        [0.0713, 0.0546],
        [0.0617, 0.0631],
        [0.0642, 0.0606],
        [0.0610, 0.0638],
        [0.0687, 0.0566]], device='cuda:0')
 Batch: 9 of auxiliary classification Duration: 0:00:00.311553
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0001, 0.0002],
        [0.0003, 0.0004],
        [0.0005, 0.0012],
        [0.0001, 0.0001],
        [0.0005, 0.0009],
        [0.0002, 0.0002],
        [0.0003, 0.0009],
        [0.0007, 0.0012],
        [0.0003, 0.0004],
        [0.0004, 0.0011],
        [0.0005, 0.0013],
        [0.0003, 0.0006],
        [0.0002, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0006, 0.0015]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0629, 0.0618],
        [0.0681, 0.0570],
        [0.0590, 0.0658],
        [0.0717, 0.0541],
        [0.0633, 0.0613],
        [0.0710, 0.0547],
        [0.0567, 0.0685],
        [0.0629, 0.0618],
        [0.0667, 0.0583],
        [0.0591, 0.0657],
        [0.0579, 0.0670],
        [0.0609, 0.0637],
        [0.0552, 0.0703],
        [0.0603, 0.0644],
        [0.0657, 0.0591],
        [0.0585, 0.0664]], device='cuda:0')
 Batch: 10 of auxiliary classification Duration: 0:00:00.423502
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0009],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0002, 0.0004],
        [0.0004, 0.0006],
        [0.0003, 0.0009],
        [0.0003, 0.0010],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0005, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0633, 0.0615],
        [0.0628, 0.0621],
        [0.0583, 0.0669],
        [0.0618, 0.0630],
        [0.0680, 0.0573],
        [0.0629, 0.0619],
        [0.0673, 0.0579],
        [0.0589, 0.0662],
        [0.0568, 0.0686],
        [0.0658, 0.0592],
        [0.0615, 0.0634],
        [0.0630, 0.0618],
        [0.0607, 0.0642],
        [0.0618, 0.0630],
        [0.0658, 0.0592],
        [0.0613, 0.0636]], device='cuda:0')
 Batch: 11 of auxiliary classification Duration: 0:00:00.328264
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0004, 0.0006],
        [0.0002, 0.0003],
        [0.0002, 0.0005],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1413, 0.1101],
        [0.1235, 0.1259],
        [0.1185, 0.1311],
        [0.1148, 0.1354],
        [0.1346, 0.1155],
        [0.1315, 0.1182],
        [0.1161, 0.1339],
        [0.1197, 0.1298]], device='cuda:0')
 Batch: 12 of auxiliary classification Duration: 0:00:00.122043
acc:  0.535
Time taken to execute the en SA task with prompt type auxiliary, variation 2 and batchsize 16: 0:00:04.886826
path ['42', 'en', 'bloom-big', 'SA', 'auxiliary', 'prompt_id_2']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0001, 0.0002]], device='cuda:0') torch.Size([121, 2])
answers_probs just softmax dim 0: tensor([[0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083]], device='cuda:0')
tensor([[0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083],
        [0.0083, 0.0083]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA auxiliary 3 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[3.8362e-04, 6.6280e-04],
        [3.4690e-04, 8.3208e-04],
        [2.5034e-04, 6.6948e-04],
        [2.2328e-04, 7.3242e-04],
        [4.5252e-04, 5.2929e-04],
        [4.1080e-04, 5.6601e-04],
        [2.6941e-04, 4.0126e-04],
        [4.0364e-04, 1.0471e-03],
        [4.3917e-04, 7.4673e-04],
        [1.5831e-04, 3.6526e-04],
        [1.8144e-04, 3.9935e-04],
        [1.7393e-04, 3.1734e-04],
        [1.2070e-04, 1.5438e-04],
        [5.1355e-04, 8.9455e-04],
        [4.4131e-04, 7.1621e-04],
        [9.3400e-05, 1.4520e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0633, 0.0615],
        [0.0588, 0.0661],
        [0.0576, 0.0676],
        [0.0554, 0.0703],
        [0.0695, 0.0560],
        [0.0668, 0.0583],
        [0.0655, 0.0594],
        [0.0579, 0.0672],
        [0.0635, 0.0613],
        [0.0593, 0.0656],
        [0.0599, 0.0649],
        [0.0625, 0.0623],
        [0.0680, 0.0572],
        [0.0631, 0.0616],
        [0.0642, 0.0606],
        [0.0648, 0.0600]], device='cuda:0')
 Batch: 0 of auxiliary classification Duration: 0:00:00.370172
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0004, 0.0008],
        [0.0001, 0.0002],
        [0.0006, 0.0014],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0002, 0.0007],
        [0.0005, 0.0010],
        [0.0002, 0.0003],
        [0.0003, 0.0007],
        [0.0004, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0622, 0.0626],
        [0.0610, 0.0639],
        [0.0619, 0.0629],
        [0.0638, 0.0611],
        [0.0645, 0.0604],
        [0.0600, 0.0649],
        [0.0653, 0.0596],
        [0.0604, 0.0645],
        [0.0645, 0.0604],
        [0.0580, 0.0672],
        [0.0621, 0.0627],
        [0.0579, 0.0673],
        [0.0611, 0.0638],
        [0.0675, 0.0578],
        [0.0599, 0.0650],
        [0.0698, 0.0558]], device='cuda:0')
 Batch: 1 of auxiliary classification Duration: 0:00:00.420859
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[3.3569e-04, 5.9366e-04],
        [2.2697e-04, 3.9816e-04],
        [1.4198e-04, 2.3580e-04],
        [4.1747e-04, 6.4182e-04],
        [5.5933e-04, 9.8896e-04],
        [4.2772e-04, 8.2445e-04],
        [2.4438e-04, 4.5991e-04],
        [1.0741e-04, 1.7643e-04],
        [6.8665e-05, 1.0890e-04],
        [2.5344e-04, 6.0320e-04],
        [2.4033e-04, 2.8086e-04],
        [3.9315e-04, 6.2799e-04],
        [1.8132e-04, 2.6584e-04],
        [4.0293e-04, 7.3528e-04],
        [5.0545e-04, 9.6607e-04],
        [3.0136e-04, 9.5749e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0624, 0.0625],
        [0.0625, 0.0624],
        [0.0633, 0.0616],
        [0.0645, 0.0605],
        [0.0624, 0.0625],
        [0.0612, 0.0637],
        [0.0615, 0.0634],
        [0.0635, 0.0614],
        [0.0640, 0.0609],
        [0.0584, 0.0667],
        [0.0689, 0.0565],
        [0.0639, 0.0610],
        [0.0652, 0.0598],
        [0.0619, 0.0629],
        [0.0613, 0.0636],
        [0.0552, 0.0706]], device='cuda:0')
 Batch: 2 of auxiliary classification Duration: 0:00:00.398294
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[3.6144e-04, 8.3351e-04],
        [2.6393e-04, 3.1590e-04],
        [3.2043e-04, 4.2796e-04],
        [2.9445e-04, 4.7421e-04],
        [1.3053e-04, 2.0373e-04],
        [2.0170e-04, 3.3784e-04],
        [3.5167e-04, 4.6229e-04],
        [9.4056e-05, 1.6129e-04],
        [3.2330e-04, 4.3845e-04],
        [1.9443e-04, 4.2129e-04],
        [2.0301e-04, 3.9124e-04],
        [5.2166e-04, 7.8344e-04],
        [1.6260e-04, 5.6744e-04],
        [4.3178e-04, 4.9686e-04],
        [3.2949e-04, 5.2261e-04],
        [1.8597e-04, 2.2614e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0575, 0.0677],
        [0.0670, 0.0581],
        [0.0652, 0.0597],
        [0.0623, 0.0624],
        [0.0628, 0.0620],
        [0.0618, 0.0630],
        [0.0655, 0.0594],
        [0.0614, 0.0633],
        [0.0650, 0.0599],
        [0.0583, 0.0668],
        [0.0598, 0.0651],
        [0.0634, 0.0614],
        [0.0531, 0.0733],
        [0.0677, 0.0575],
        [0.0626, 0.0622],
        [0.0667, 0.0583]], device='cuda:0')
 Batch: 3 of auxiliary classification Duration: 0:00:00.484575
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0006, 0.0006],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0002, 0.0002],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0005, 0.0010],
        [0.0004, 0.0007],
        [0.0002, 0.0003],
        [0.0002, 0.0002],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0001, 0.0002]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0613, 0.0637],
        [0.0693, 0.0563],
        [0.0609, 0.0640],
        [0.0618, 0.0631],
        [0.0653, 0.0597],
        [0.0645, 0.0605],
        [0.0621, 0.0628],
        [0.0614, 0.0635],
        [0.0593, 0.0658],
        [0.0606, 0.0643],
        [0.0610, 0.0639],
        [0.0640, 0.0609],
        [0.0657, 0.0593],
        [0.0604, 0.0646],
        [0.0598, 0.0653],
        [0.0626, 0.0623]], device='cuda:0')
 Batch: 4 of auxiliary classification Duration: 0:00:00.407126
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0004, 0.0005],
        [0.0003, 0.0007],
        [0.0005, 0.0008],
        [0.0003, 0.0004],
        [0.0002, 0.0002],
        [0.0008, 0.0012],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0005, 0.0011],
        [0.0003, 0.0010],
        [0.0002, 0.0006],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0628, 0.0620],
        [0.0630, 0.0618],
        [0.0628, 0.0620],
        [0.0613, 0.0635],
        [0.0686, 0.0567],
        [0.0600, 0.0649],
        [0.0637, 0.0611],
        [0.0673, 0.0579],
        [0.0668, 0.0583],
        [0.0650, 0.0599],
        [0.0637, 0.0611],
        [0.0637, 0.0611],
        [0.0588, 0.0662],
        [0.0542, 0.0718],
        [0.0576, 0.0676],
        [0.0607, 0.0641]], device='cuda:0')
 Batch: 5 of auxiliary classification Duration: 0:00:00.397410
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0003, 0.0011],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0005],
        [0.0002, 0.0003],
        [0.0002, 0.0004],
        [0.0003, 0.0008],
        [0.0003, 0.0004],
        [0.0003, 0.0007],
        [0.0003, 0.0004],
        [0.0003, 0.0007],
        [0.0003, 0.0009],
        [0.0002, 0.0005],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0652, 0.0597],
        [0.0653, 0.0595],
        [0.0556, 0.0700],
        [0.0675, 0.0576],
        [0.0675, 0.0576],
        [0.0650, 0.0599],
        [0.0657, 0.0592],
        [0.0586, 0.0664],
        [0.0562, 0.0693],
        [0.0645, 0.0603],
        [0.0587, 0.0663],
        [0.0663, 0.0586],
        [0.0610, 0.0638],
        [0.0574, 0.0678],
        [0.0609, 0.0639],
        [0.0648, 0.0600]], device='cuda:0')
 Batch: 6 of auxiliary classification Duration: 0:00:00.445214
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0006],
        [0.0007, 0.0016],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0007],
        [0.0005, 0.0011],
        [0.0003, 0.0004],
        [0.0002, 0.0006],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0609, 0.0640],
        [0.0645, 0.0604],
        [0.0612, 0.0637],
        [0.0624, 0.0624],
        [0.0657, 0.0593],
        [0.0640, 0.0609],
        [0.0614, 0.0634],
        [0.0602, 0.0647],
        [0.0670, 0.0581],
        [0.0654, 0.0596],
        [0.0659, 0.0591],
        [0.0597, 0.0653],
        [0.0585, 0.0666],
        [0.0665, 0.0585],
        [0.0553, 0.0704],
        [0.0613, 0.0635]], device='cuda:0')
 Batch: 7 of auxiliary classification Duration: 0:00:00.333797
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[3.0947e-04, 6.8665e-04],
        [3.1495e-04, 4.7278e-04],
        [1.7834e-04, 4.5896e-04],
        [1.6999e-04, 1.7953e-04],
        [3.2163e-04, 7.8392e-04],
        [2.7347e-04, 4.6539e-04],
        [7.3731e-05, 8.3864e-05],
        [3.6287e-04, 5.7077e-04],
        [1.2243e-04, 2.9492e-04],
        [1.4806e-04, 2.8658e-04],
        [3.7575e-04, 5.0974e-04],
        [8.5163e-04, 1.2779e-03],
        [2.3270e-04, 5.2834e-04],
        [2.8276e-04, 6.6805e-04],
        [1.7703e-04, 3.3593e-04],
        [1.0723e-04, 1.8311e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0593, 0.0656],
        [0.0649, 0.0600],
        [0.0575, 0.0676],
        [0.0707, 0.0550],
        [0.0582, 0.0669],
        [0.0630, 0.0618],
        [0.0694, 0.0560],
        [0.0642, 0.0607],
        [0.0583, 0.0667],
        [0.0611, 0.0636],
        [0.0665, 0.0585],
        [0.0649, 0.0600],
        [0.0590, 0.0659],
        [0.0586, 0.0665],
        [0.0614, 0.0634],
        [0.0629, 0.0618]], device='cuda:0')
 Batch: 8 of auxiliary classification Duration: 0:00:00.441366
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0002, 0.0006],
        [0.0003, 0.0010],
        [0.0002, 0.0006],
        [0.0002, 0.0007],
        [0.0002, 0.0005],
        [0.0005, 0.0011],
        [0.0003, 0.0004],
        [0.0005, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0609, 0.0640],
        [0.0618, 0.0631],
        [0.0630, 0.0618],
        [0.0629, 0.0619],
        [0.0568, 0.0686],
        [0.0587, 0.0663],
        [0.0611, 0.0638],
        [0.0582, 0.0669],
        [0.0618, 0.0631],
        [0.0612, 0.0637],
        [0.0674, 0.0578],
        [0.0677, 0.0576],
        [0.0624, 0.0625],
        [0.0638, 0.0611],
        [0.0660, 0.0591],
        [0.0665, 0.0586]], device='cuda:0')
 Batch: 9 of auxiliary classification Duration: 0:00:00.422317
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0001, 0.0003],
        [0.0001, 0.0002],
        [0.0005, 0.0011],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0005, 0.0009],
        [0.0005, 0.0008],
        [0.0003, 0.0007],
        [0.0001, 0.0003],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0600, 0.0651],
        [0.0632, 0.0617],
        [0.0653, 0.0598],
        [0.0615, 0.0635],
        [0.0602, 0.0649],
        [0.0658, 0.0593],
        [0.0636, 0.0614],
        [0.0644, 0.0606],
        [0.0622, 0.0627],
        [0.0633, 0.0616],
        [0.0621, 0.0628],
        [0.0621, 0.0628],
        [0.0598, 0.0653],
        [0.0626, 0.0624],
        [0.0628, 0.0622],
        [0.0613, 0.0637]], device='cuda:0')
 Batch: 10 of auxiliary classification Duration: 0:00:00.559323
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[3.3689e-04, 6.5422e-04],
        [3.2449e-04, 6.3038e-04],
        [1.9884e-04, 5.1165e-04],
        [4.0054e-04, 9.3889e-04],
        [3.4809e-04, 7.9632e-04],
        [1.4174e-04, 2.4486e-04],
        [1.3888e-04, 2.2709e-04],
        [8.9169e-05, 1.5652e-04],
        [2.9206e-04, 6.5327e-04],
        [5.2977e-04, 7.9489e-04],
        [3.6097e-04, 7.8821e-04],
        [2.6560e-04, 6.2227e-04],
        [1.6534e-04, 5.9986e-04],
        [1.3494e-04, 2.1994e-04],
        [2.1875e-04, 3.6645e-04],
        [3.2258e-04, 8.4352e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0632, 0.0617],
        [0.0632, 0.0617],
        [0.0595, 0.0655],
        [0.0607, 0.0642],
        [0.0610, 0.0639],
        [0.0649, 0.0600],
        [0.0658, 0.0593],
        [0.0647, 0.0603],
        [0.0613, 0.0636],
        [0.0671, 0.0581],
        [0.0616, 0.0633],
        [0.0607, 0.0642],
        [0.0558, 0.0698],
        [0.0658, 0.0592],
        [0.0654, 0.0596],
        [0.0593, 0.0657]], device='cuda:0')
 Batch: 11 of auxiliary classification Duration: 0:00:00.364293
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1187, 0.1313],
        [0.1263, 0.1234],
        [0.1284, 0.1214],
        [0.1126, 0.1384],
        [0.1353, 0.1151],
        [0.1261, 0.1236],
        [0.1272, 0.1225],
        [0.1254, 0.1243]], device='cuda:0')
 Batch: 12 of auxiliary classification Duration: 0:00:00.211182
acc:  0.43
Time taken to execute the en SA task with prompt type auxiliary, variation 3 and batchsize 16: 0:00:05.276990
path ['42', 'en', 'bloom-big', 'SA', 'auxiliary', 'prompt_id_3']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([114, 2])
answers_probs just softmax dim 0: tensor([[0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088]], device='cuda:0')
tensor([[0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088],
        [0.0088, 0.0088]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA auxiliary 4 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0004, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0004, 0.0012],
        [0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0006, 0.0009],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0007, 0.0016],
        [0.0005, 0.0012],
        [0.0006, 0.0012],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0612, 0.0637],
        [0.0663, 0.0588],
        [0.0629, 0.0620],
        [0.0629, 0.0620],
        [0.0572, 0.0681],
        [0.0582, 0.0669],
        [0.0648, 0.0601],
        [0.0634, 0.0615],
        [0.0614, 0.0635],
        [0.0671, 0.0581],
        [0.0642, 0.0607],
        [0.0659, 0.0592],
        [0.0604, 0.0646],
        [0.0605, 0.0645],
        [0.0634, 0.0614],
        [0.0601, 0.0649]], device='cuda:0')
 Batch: 0 of auxiliary classification Duration: 0:00:00.317624
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0003, 0.0009],
        [0.0003, 0.0007],
        [0.0004, 0.0010],
        [0.0004, 0.0009],
        [0.0007, 0.0009],
        [0.0004, 0.0013],
        [0.0005, 0.0010],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0004, 0.0007],
        [0.0009, 0.0011],
        [0.0002, 0.0006],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0630, 0.0619],
        [0.0592, 0.0658],
        [0.0628, 0.0620],
        [0.0599, 0.0650],
        [0.0630, 0.0619],
        [0.0687, 0.0567],
        [0.0577, 0.0675],
        [0.0635, 0.0613],
        [0.0588, 0.0662],
        [0.0607, 0.0642],
        [0.0626, 0.0622],
        [0.0608, 0.0641],
        [0.0656, 0.0594],
        [0.0703, 0.0554],
        [0.0599, 0.0650],
        [0.0635, 0.0613]], device='cuda:0')
 Batch: 1 of auxiliary classification Duration: 0:00:00.312612
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0006, 0.0009],
        [0.0006, 0.0012],
        [0.0002, 0.0005],
        [0.0002, 0.0007],
        [0.0011, 0.0017],
        [0.0003, 0.0008],
        [0.0004, 0.0008],
        [0.0005, 0.0008],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0635, 0.0614],
        [0.0631, 0.0618],
        [0.0621, 0.0629],
        [0.0617, 0.0632],
        [0.0609, 0.0640],
        [0.0645, 0.0605],
        [0.0622, 0.0628],
        [0.0659, 0.0592],
        [0.0626, 0.0623],
        [0.0602, 0.0648],
        [0.0574, 0.0679],
        [0.0658, 0.0593],
        [0.0579, 0.0673],
        [0.0640, 0.0609],
        [0.0635, 0.0614],
        [0.0646, 0.0604]], device='cuda:0')
 Batch: 2 of auxiliary classification Duration: 0:00:00.440440
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0007, 0.0011],
        [0.0003, 0.0006],
        [0.0005, 0.0009],
        [0.0003, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0013, 0.0017],
        [0.0005, 0.0008],
        [0.0004, 0.0007],
        [0.0005, 0.0011],
        [0.0003, 0.0005],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0626, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0631, 0.0618],
        [0.0581, 0.0672],
        [0.0645, 0.0605],
        [0.0624, 0.0625],
        [0.0631, 0.0618],
        [0.0618, 0.0631],
        [0.0673, 0.0580],
        [0.0629, 0.0620],
        [0.0600, 0.0650],
        [0.0592, 0.0659],
        [0.0675, 0.0578],
        [0.0623, 0.0626],
        [0.0644, 0.0606],
        [0.0595, 0.0655],
        [0.0630, 0.0619],
        [0.0609, 0.0640]], device='cuda:0')
 Batch: 3 of auxiliary classification Duration: 0:00:00.406415
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0008, 0.0014],
        [0.0003, 0.0008],
        [0.0005, 0.0010],
        [0.0005, 0.0008],
        [0.0002, 0.0003],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0006, 0.0009],
        [0.0002, 0.0004],
        [0.0005, 0.0009],
        [0.0004, 0.0008],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0591, 0.0661],
        [0.0633, 0.0616],
        [0.0592, 0.0658],
        [0.0618, 0.0631],
        [0.0644, 0.0606],
        [0.0646, 0.0604],
        [0.0646, 0.0604],
        [0.0607, 0.0642],
        [0.0670, 0.0583],
        [0.0605, 0.0645],
        [0.0627, 0.0623],
        [0.0624, 0.0625],
        [0.0639, 0.0610],
        [0.0645, 0.0605],
        [0.0623, 0.0626],
        [0.0589, 0.0663]], device='cuda:0')
 Batch: 4 of auxiliary classification Duration: 0:00:00.536823
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0005, 0.0009],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0003],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0005, 0.0009],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0006, 0.0014],
        [0.0004, 0.0006],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0639, 0.0610],
        [0.0625, 0.0624],
        [0.0636, 0.0612],
        [0.0627, 0.0621],
        [0.0587, 0.0663],
        [0.0711, 0.0548],
        [0.0619, 0.0629],
        [0.0581, 0.0671],
        [0.0622, 0.0626],
        [0.0587, 0.0663],
        [0.0689, 0.0565],
        [0.0626, 0.0622],
        [0.0602, 0.0647],
        [0.0595, 0.0655],
        [0.0619, 0.0629],
        [0.0634, 0.0614]], device='cuda:0')
 Batch: 5 of auxiliary classification Duration: 0:00:00.409584
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0002, 0.0005],
        [0.0005, 0.0015],
        [0.0004, 0.0008],
        [0.0006, 0.0019],
        [0.0003, 0.0006],
        [0.0009, 0.0015],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0004, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0004, 0.0006],
        [0.0006, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0641, 0.0607],
        [0.0612, 0.0636],
        [0.0577, 0.0675],
        [0.0625, 0.0623],
        [0.0570, 0.0684],
        [0.0629, 0.0619],
        [0.0662, 0.0588],
        [0.0601, 0.0648],
        [0.0592, 0.0658],
        [0.0700, 0.0556],
        [0.0626, 0.0622],
        [0.0623, 0.0624],
        [0.0656, 0.0593],
        [0.0688, 0.0566],
        [0.0626, 0.0622],
        [0.0573, 0.0679]], device='cuda:0')
 Batch: 6 of auxiliary classification Duration: 0:00:00.334132
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0011],
        [0.0006, 0.0012],
        [0.0005, 0.0010],
        [0.0002, 0.0004],
        [0.0006, 0.0011],
        [0.0006, 0.0013],
        [0.0003, 0.0008],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0009],
        [0.0004, 0.0006],
        [0.0007, 0.0014],
        [0.0003, 0.0006],
        [0.0005, 0.0007],
        [0.0005, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0615, 0.0634],
        [0.0611, 0.0638],
        [0.0632, 0.0618],
        [0.0624, 0.0625],
        [0.0613, 0.0636],
        [0.0598, 0.0653],
        [0.0596, 0.0655],
        [0.0647, 0.0603],
        [0.0664, 0.0587],
        [0.0641, 0.0609],
        [0.0614, 0.0635],
        [0.0644, 0.0606],
        [0.0620, 0.0630],
        [0.0615, 0.0634],
        [0.0656, 0.0595],
        [0.0609, 0.0641]], device='cuda:0')
 Batch: 7 of auxiliary classification Duration: 0:00:00.328798
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0008, 0.0012],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0007, 0.0016],
        [0.0002, 0.0005],
        [0.0009, 0.0016],
        [0.0002, 0.0004],
        [0.0002, 0.0007],
        [0.0002, 0.0004],
        [0.0008, 0.0011],
        [0.0007, 0.0009],
        [0.0002, 0.0006],
        [0.0002, 0.0004],
        [0.0005, 0.0012],
        [0.0006, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0588, 0.0662],
        [0.0671, 0.0581],
        [0.0644, 0.0605],
        [0.0638, 0.0611],
        [0.0605, 0.0644],
        [0.0599, 0.0651],
        [0.0630, 0.0619],
        [0.0635, 0.0613],
        [0.0574, 0.0679],
        [0.0620, 0.0629],
        [0.0671, 0.0581],
        [0.0686, 0.0568],
        [0.0588, 0.0662],
        [0.0634, 0.0614],
        [0.0607, 0.0642],
        [0.0610, 0.0639]], device='cuda:0')
 Batch: 8 of auxiliary classification Duration: 0:00:00.422163
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0007, 0.0012],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0006, 0.0009],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0002, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0619, 0.0631],
        [0.0607, 0.0643],
        [0.0642, 0.0608],
        [0.0615, 0.0634],
        [0.0602, 0.0648],
        [0.0637, 0.0612],
        [0.0630, 0.0619],
        [0.0644, 0.0606],
        [0.0615, 0.0634],
        [0.0656, 0.0595],
        [0.0651, 0.0599],
        [0.0610, 0.0639],
        [0.0583, 0.0669],
        [0.0635, 0.0614],
        [0.0655, 0.0596],
        [0.0597, 0.0653]], device='cuda:0')
 Batch: 9 of auxiliary classification Duration: 0:00:00.400253
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0004, 0.0010],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0005, 0.0010],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0008, 0.0017],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0005, 0.0010],
        [0.0002, 0.0003],
        [0.0004, 0.0007],
        [0.0007, 0.0008],
        [0.0006, 0.0014],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0624, 0.0625],
        [0.0583, 0.0668],
        [0.0614, 0.0635],
        [0.0593, 0.0658],
        [0.0633, 0.0616],
        [0.0607, 0.0642],
        [0.0616, 0.0633],
        [0.0617, 0.0632],
        [0.0659, 0.0592],
        [0.0612, 0.0638],
        [0.0625, 0.0624],
        [0.0636, 0.0614],
        [0.0654, 0.0596],
        [0.0695, 0.0561],
        [0.0608, 0.0641],
        [0.0623, 0.0626]], device='cuda:0')
 Batch: 10 of auxiliary classification Duration: 0:00:00.361121
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0011],
        [0.0003, 0.0006],
        [0.0005, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0005, 0.0009],
        [0.0005, 0.0008],
        [0.0004, 0.0011],
        [0.0004, 0.0008],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0579, 0.0674],
        [0.0635, 0.0614],
        [0.0639, 0.0611],
        [0.0611, 0.0639],
        [0.0638, 0.0612],
        [0.0601, 0.0649],
        [0.0609, 0.0641],
        [0.0643, 0.0607],
        [0.0634, 0.0615],
        [0.0645, 0.0605],
        [0.0604, 0.0646],
        [0.0641, 0.0609],
        [0.0652, 0.0599],
        [0.0623, 0.0626],
        [0.0636, 0.0614],
        [0.0611, 0.0639]], device='cuda:0')
 Batch: 11 of auxiliary classification Duration: 0:00:00.426021
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0006, 0.0018],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1249],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1276, 0.1223],
        [0.1208, 0.1292],
        [0.1290, 0.1210],
        [0.1278, 0.1221],
        [0.1168, 0.1336],
        [0.1238, 0.1261],
        [0.1236, 0.1263],
        [0.1306, 0.1195]], device='cuda:0')
 Batch: 12 of auxiliary classification Duration: 0:00:00.153806
acc:  0.565
Time taken to execute the en SA task with prompt type auxiliary, variation 4 and batchsize 16: 0:00:04.870774
path ['42', 'en', 'bloom-big', 'SA', 'auxiliary', 'prompt_id_4']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([109, 2])
answers_probs just softmax dim 0: tensor([[0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092]], device='cuda:0')
tensor([[0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA auxiliary 5 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[4.6229e-04, 1.1177e-03],
        [2.6894e-04, 4.5037e-04],
        [2.5845e-04, 5.5122e-04],
        [1.6415e-04, 3.3426e-04],
        [3.6693e-04, 8.0156e-04],
        [2.8586e-04, 5.9128e-04],
        [3.8075e-04, 9.7227e-04],
        [3.4547e-04, 6.2084e-04],
        [2.8610e-04, 6.3992e-04],
        [1.0961e-04, 3.2210e-04],
        [8.7440e-05, 2.8443e-04],
        [2.9969e-04, 5.3883e-04],
        [1.9968e-04, 4.7135e-04],
        [2.7895e-04, 6.7425e-04],
        [2.0111e-04, 2.7490e-04],
        [2.6441e-04, 9.9850e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0613, 0.0636],
        [0.0665, 0.0586],
        [0.0629, 0.0619],
        [0.0636, 0.0613],
        [0.0626, 0.0622],
        [0.0634, 0.0615],
        [0.0606, 0.0643],
        [0.0654, 0.0596],
        [0.0623, 0.0625],
        [0.0590, 0.0661],
        [0.0579, 0.0673],
        [0.0654, 0.0596],
        [0.0616, 0.0632],
        [0.0613, 0.0636],
        [0.0698, 0.0558],
        [0.0564, 0.0691]], device='cuda:0')
 Batch: 0 of auxiliary classification Duration: 0:00:00.317304
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0006, 0.0012],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0002, 0.0005],
        [0.0002, 0.0007],
        [0.0002, 0.0005],
        [0.0001, 0.0003],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0011],
        [0.0002, 0.0004],
        [0.0001, 0.0002],
        [0.0005, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0684, 0.0570],
        [0.0638, 0.0611],
        [0.0635, 0.0614],
        [0.0628, 0.0620],
        [0.0596, 0.0653],
        [0.0584, 0.0667],
        [0.0605, 0.0644],
        [0.0640, 0.0608],
        [0.0620, 0.0629],
        [0.0621, 0.0628],
        [0.0565, 0.0690],
        [0.0645, 0.0604],
        [0.0631, 0.0617],
        [0.0695, 0.0560],
        [0.0574, 0.0678],
        [0.0641, 0.0607]], device='cuda:0')
 Batch: 1 of auxiliary classification Duration: 0:00:00.419137
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0001, 0.0003],
        [0.0002, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0008],
        [0.0004, 0.0007],
        [0.0001, 0.0003],
        [0.0002, 0.0006],
        [0.0002, 0.0003],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0001, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0641, 0.0608],
        [0.0637, 0.0612],
        [0.0626, 0.0623],
        [0.0604, 0.0646],
        [0.0595, 0.0656],
        [0.0595, 0.0656],
        [0.0618, 0.0631],
        [0.0637, 0.0612],
        [0.0598, 0.0653],
        [0.0638, 0.0611],
        [0.0602, 0.0647],
        [0.0614, 0.0635],
        [0.0680, 0.0574],
        [0.0626, 0.0623],
        [0.0670, 0.0583],
        [0.0619, 0.0630]], device='cuda:0')
 Batch: 2 of auxiliary classification Duration: 0:00:00.360939
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0006],
        [0.0005, 0.0008],
        [0.0003, 0.0007],
        [0.0006, 0.0013],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0001, 0.0005],
        [0.0001, 0.0003],
        [0.0003, 0.0011],
        [0.0004, 0.0009],
        [0.0002, 0.0006],
        [0.0002, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0639, 0.0610],
        [0.0637, 0.0612],
        [0.0605, 0.0644],
        [0.0669, 0.0583],
        [0.0628, 0.0621],
        [0.0622, 0.0627],
        [0.0626, 0.0623],
        [0.0628, 0.0621],
        [0.0635, 0.0614],
        [0.0672, 0.0580],
        [0.0586, 0.0666],
        [0.0635, 0.0614],
        [0.0581, 0.0671],
        [0.0635, 0.0614],
        [0.0598, 0.0652],
        [0.0603, 0.0646]], device='cuda:0')
 Batch: 3 of auxiliary classification Duration: 0:00:00.330180
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0001, 0.0002],
        [0.0003, 0.0007],
        [0.0005, 0.0008],
        [0.0002, 0.0007],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0001, 0.0004],
        [0.0002, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0664, 0.0587],
        [0.0626, 0.0623],
        [0.0658, 0.0593],
        [0.0575, 0.0679],
        [0.0677, 0.0576],
        [0.0638, 0.0611],
        [0.0598, 0.0652],
        [0.0606, 0.0644],
        [0.0628, 0.0620],
        [0.0618, 0.0631],
        [0.0600, 0.0650],
        [0.0636, 0.0613],
        [0.0652, 0.0598],
        [0.0614, 0.0635],
        [0.0601, 0.0649],
        [0.0610, 0.0640]], device='cuda:0')
 Batch: 4 of auxiliary classification Duration: 0:00:00.399975
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0001, 0.0002],
        [0.0002, 0.0003],
        [0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0001, 0.0003],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0004, 0.0010],
        [0.0002, 0.0004],
        [0.0001, 0.0005],
        [0.0002, 0.0003],
        [0.0002, 0.0005],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0610, 0.0639],
        [0.0627, 0.0622],
        [0.0647, 0.0602],
        [0.0687, 0.0567],
        [0.0600, 0.0649],
        [0.0600, 0.0649],
        [0.0614, 0.0635],
        [0.0621, 0.0628],
        [0.0640, 0.0609],
        [0.0587, 0.0664],
        [0.0595, 0.0655],
        [0.0646, 0.0604],
        [0.0574, 0.0678],
        [0.0645, 0.0605],
        [0.0631, 0.0617],
        [0.0676, 0.0577]], device='cuda:0')
 Batch: 5 of auxiliary classification Duration: 0:00:00.426713
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0001, 0.0002],
        [0.0003, 0.0005],
        [0.0002, 0.0003],
        [0.0004, 0.0009],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0001, 0.0003],
        [0.0002, 0.0004],
        [0.0004, 0.0008],
        [0.0002, 0.0005],
        [0.0001, 0.0003],
        [0.0004, 0.0006],
        [0.0001, 0.0002],
        [0.0003, 0.0004],
        [0.0005, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0609, 0.0640],
        [0.0651, 0.0599],
        [0.0629, 0.0620],
        [0.0639, 0.0610],
        [0.0618, 0.0631],
        [0.0610, 0.0639],
        [0.0585, 0.0666],
        [0.0620, 0.0629],
        [0.0604, 0.0646],
        [0.0625, 0.0624],
        [0.0627, 0.0622],
        [0.0606, 0.0644],
        [0.0661, 0.0590],
        [0.0617, 0.0632],
        [0.0698, 0.0559],
        [0.0602, 0.0648]], device='cuda:0')
 Batch: 6 of auxiliary classification Duration: 0:00:00.475309
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0004, 0.0015],
        [0.0005, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0005, 0.0012],
        [0.0002, 0.0005],
        [0.0003, 0.0004],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0002, 0.0007],
        [0.0002, 0.0003],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0638, 0.0611],
        [0.0616, 0.0632],
        [0.0562, 0.0694],
        [0.0658, 0.0592],
        [0.0613, 0.0635],
        [0.0652, 0.0598],
        [0.0692, 0.0563],
        [0.0624, 0.0625],
        [0.0609, 0.0640],
        [0.0615, 0.0633],
        [0.0650, 0.0600],
        [0.0628, 0.0620],
        [0.0617, 0.0631],
        [0.0572, 0.0681],
        [0.0650, 0.0600],
        [0.0603, 0.0646]], device='cuda:0')
 Batch: 7 of auxiliary classification Duration: 0:00:00.355391
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[2.7537e-04, 7.0333e-04],
        [2.8825e-04, 5.5981e-04],
        [2.5463e-04, 4.8327e-04],
        [2.3687e-04, 7.4720e-04],
        [4.3726e-04, 9.8515e-04],
        [2.3293e-04, 4.7421e-04],
        [3.3140e-04, 6.1893e-04],
        [5.8651e-04, 8.0776e-04],
        [3.9220e-04, 7.9870e-04],
        [6.0749e-04, 1.0920e-03],
        [2.7227e-04, 5.6267e-04],
        [3.8385e-04, 7.9393e-04],
        [8.3327e-05, 1.8060e-04],
        [1.7071e-04, 4.3941e-04],
        [2.6941e-04, 6.2180e-04],
        [2.8658e-04, 4.9543e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0597, 0.0653],
        [0.0633, 0.0616],
        [0.0637, 0.0613],
        [0.0573, 0.0680],
        [0.0613, 0.0636],
        [0.0627, 0.0622],
        [0.0639, 0.0610],
        [0.0686, 0.0568],
        [0.0627, 0.0622],
        [0.0644, 0.0605],
        [0.0625, 0.0624],
        [0.0624, 0.0625],
        [0.0618, 0.0631],
        [0.0596, 0.0654],
        [0.0610, 0.0640],
        [0.0650, 0.0600]], device='cuda:0')
 Batch: 8 of auxiliary classification Duration: 0:00:00.326031
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0004, 0.0009],
        [0.0004, 0.0009],
        [0.0002, 0.0003],
        [0.0004, 0.0009],
        [0.0002, 0.0004],
        [0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0009, 0.0015],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0627, 0.0622],
        [0.0658, 0.0593],
        [0.0607, 0.0643],
        [0.0605, 0.0645],
        [0.0624, 0.0625],
        [0.0635, 0.0614],
        [0.0615, 0.0634],
        [0.0623, 0.0626],
        [0.0583, 0.0670],
        [0.0619, 0.0630],
        [0.0666, 0.0586],
        [0.0632, 0.0618],
        [0.0593, 0.0658],
        [0.0660, 0.0591],
        [0.0634, 0.0616],
        [0.0620, 0.0629]], device='cuda:0')
 Batch: 9 of auxiliary classification Duration: 0:00:00.557228
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[3.8075e-04, 8.5163e-04],
        [2.1732e-04, 4.0913e-04],
        [2.2984e-04, 3.9387e-04],
        [2.1505e-04, 5.2404e-04],
        [1.8060e-04, 4.5037e-04],
        [1.5879e-04, 3.5501e-04],
        [2.6417e-04, 5.5456e-04],
        [3.5477e-04, 6.5756e-04],
        [4.1556e-04, 1.3523e-03],
        [5.0592e-04, 9.4461e-04],
        [3.0756e-04, 6.8760e-04],
        [2.6584e-04, 6.2275e-04],
        [2.3448e-04, 5.0020e-04],
        [5.9748e-04, 1.2951e-03],
        [9.3579e-05, 1.8036e-04],
        [2.1291e-04, 5.3930e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0621, 0.0628],
        [0.0645, 0.0605],
        [0.0659, 0.0592],
        [0.0610, 0.0640],
        [0.0607, 0.0643],
        [0.0621, 0.0628],
        [0.0630, 0.0620],
        [0.0647, 0.0603],
        [0.0577, 0.0676],
        [0.0646, 0.0604],
        [0.0621, 0.0628],
        [0.0615, 0.0634],
        [0.0627, 0.0622],
        [0.0625, 0.0624],
        [0.0642, 0.0608],
        [0.0605, 0.0645]], device='cuda:0')
 Batch: 10 of auxiliary classification Duration: 0:00:00.336548
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0003, 0.0003],
        [0.0003, 0.0007],
        [0.0005, 0.0011],
        [0.0003, 0.0007],
        [0.0004, 0.0006],
        [0.0002, 0.0003],
        [0.0004, 0.0010],
        [0.0002, 0.0004],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0612, 0.0636],
        [0.0605, 0.0644],
        [0.0607, 0.0642],
        [0.0626, 0.0622],
        [0.0642, 0.0607],
        [0.0630, 0.0618],
        [0.0619, 0.0629],
        [0.0714, 0.0545],
        [0.0568, 0.0685],
        [0.0609, 0.0640],
        [0.0594, 0.0656],
        [0.0649, 0.0600],
        [0.0664, 0.0587],
        [0.0597, 0.0653],
        [0.0599, 0.0651],
        [0.0665, 0.0586]], device='cuda:0')
 Batch: 11 of auxiliary classification Duration: 0:00:00.423199
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0001, 0.0003],
        [0.0004, 0.0012],
        [0.0001, 0.0003],
        [0.0003, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0009],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1339, 0.1166],
        [0.1273, 0.1226],
        [0.1198, 0.1303],
        [0.1258, 0.1241],
        [0.1211, 0.1289],
        [0.1242, 0.1257],
        [0.1212, 0.1287],
        [0.1268, 0.1231]], device='cuda:0')
 Batch: 12 of auxiliary classification Duration: 0:00:00.217866
acc:  0.55
Time taken to execute the en SA task with prompt type auxiliary, variation 5 and batchsize 16: 0:00:04.966677
path ['42', 'en', 'bloom-big', 'SA', 'auxiliary', 'prompt_id_5']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003]], device='cuda:0') torch.Size([150, 2])
answers_probs just softmax dim 0: tensor([[0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067]], device='cuda:0')
tensor([[0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067],
        [0.0067, 0.0067]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA auxiliary 6 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0004],
        [0.0005, 0.0005],
        [0.0003, 0.0005],
        [0.0006, 0.0007],
        [0.0003, 0.0005],
        [0.0005, 0.0009],
        [0.0005, 0.0008],
        [0.0002, 0.0003],
        [0.0006, 0.0006],
        [0.0005, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0577, 0.0675],
        [0.0587, 0.0664],
        [0.0633, 0.0615],
        [0.0695, 0.0560],
        [0.0626, 0.0622],
        [0.0656, 0.0594],
        [0.0620, 0.0628],
        [0.0607, 0.0642],
        [0.0618, 0.0630],
        [0.0632, 0.0616],
        [0.0700, 0.0556],
        [0.0657, 0.0593],
        [0.0597, 0.0652],
        [0.0580, 0.0671],
        [0.0613, 0.0635],
        [0.0601, 0.0648]], device='cuda:0')
 Batch: 0 of auxiliary classification Duration: 0:00:00.408967
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0005, 0.0006],
        [0.0005, 0.0009],
        [0.0003, 0.0004],
        [0.0005, 0.0007],
        [0.0004, 0.0007],
        [0.0007, 0.0009],
        [0.0005, 0.0008],
        [0.0007, 0.0011],
        [0.0004, 0.0005],
        [0.0004, 0.0006],
        [0.0006, 0.0008],
        [0.0004, 0.0006],
        [0.0006, 0.0007],
        [0.0002, 0.0003],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0592, 0.0659],
        [0.0652, 0.0599],
        [0.0589, 0.0662],
        [0.0617, 0.0633],
        [0.0640, 0.0610],
        [0.0607, 0.0643],
        [0.0644, 0.0605],
        [0.0615, 0.0635],
        [0.0612, 0.0637],
        [0.0622, 0.0628],
        [0.0629, 0.0621],
        [0.0624, 0.0625],
        [0.0607, 0.0643],
        [0.0646, 0.0604],
        [0.0665, 0.0587],
        [0.0641, 0.0609]], device='cuda:0')
 Batch: 1 of auxiliary classification Duration: 0:00:00.447529
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0004, 0.0007],
        [0.0007, 0.0009],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0005, 0.0006],
        [0.0005, 0.0006],
        [0.0006, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0008, 0.0018],
        [0.0004, 0.0007],
        [0.0006, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0627, 0.0622],
        [0.0605, 0.0644],
        [0.0656, 0.0595],
        [0.0599, 0.0651],
        [0.0586, 0.0665],
        [0.0646, 0.0604],
        [0.0647, 0.0603],
        [0.0671, 0.0581],
        [0.0607, 0.0642],
        [0.0631, 0.0618],
        [0.0575, 0.0678],
        [0.0630, 0.0619],
        [0.0668, 0.0583],
        [0.0600, 0.0650],
        [0.0620, 0.0629],
        [0.0632, 0.0616]], device='cuda:0')
 Batch: 2 of auxiliary classification Duration: 0:00:00.402747
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0009],
        [0.0007, 0.0009],
        [0.0003, 0.0005],
        [0.0004, 0.0004],
        [0.0008, 0.0009],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0005, 0.0005],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0006],
        [0.0007, 0.0010],
        [0.0005, 0.0007],
        [0.0005, 0.0007],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0625, 0.0624],
        [0.0651, 0.0598],
        [0.0604, 0.0645],
        [0.0675, 0.0578],
        [0.0665, 0.0586],
        [0.0556, 0.0701],
        [0.0625, 0.0624],
        [0.0617, 0.0631],
        [0.0663, 0.0588],
        [0.0615, 0.0633],
        [0.0603, 0.0646],
        [0.0644, 0.0605],
        [0.0623, 0.0625],
        [0.0622, 0.0626],
        [0.0636, 0.0612],
        [0.0576, 0.0677]], device='cuda:0')
 Batch: 3 of auxiliary classification Duration: 0:00:00.329282
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0004],
        [0.0002, 0.0003],
        [0.0003, 0.0008],
        [0.0003, 0.0005],
        [0.0005, 0.0009],
        [0.0006, 0.0008],
        [0.0006, 0.0008],
        [0.0002, 0.0003],
        [0.0005, 0.0006],
        [0.0002, 0.0004],
        [0.0011, 0.0012],
        [0.0003, 0.0006],
        [0.0005, 0.0007],
        [0.0002, 0.0003],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0611, 0.0639],
        [0.0645, 0.0605],
        [0.0608, 0.0641],
        [0.0558, 0.0699],
        [0.0625, 0.0623],
        [0.0612, 0.0637],
        [0.0633, 0.0616],
        [0.0641, 0.0608],
        [0.0642, 0.0607],
        [0.0650, 0.0600],
        [0.0601, 0.0649],
        [0.0676, 0.0577],
        [0.0591, 0.0660],
        [0.0644, 0.0606],
        [0.0652, 0.0598],
        [0.0613, 0.0636]], device='cuda:0')
 Batch: 4 of auxiliary classification Duration: 0:00:00.490816
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0007],
        [0.0006, 0.0008],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0006],
        [0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0005, 0.0009],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0658, 0.0593],
        [0.0622, 0.0627],
        [0.0598, 0.0653],
        [0.0647, 0.0603],
        [0.0597, 0.0654],
        [0.0639, 0.0611],
        [0.0605, 0.0645],
        [0.0634, 0.0616],
        [0.0664, 0.0588],
        [0.0636, 0.0613],
        [0.0626, 0.0624],
        [0.0621, 0.0628],
        [0.0611, 0.0639],
        [0.0609, 0.0641],
        [0.0613, 0.0636],
        [0.0620, 0.0630]], device='cuda:0')
 Batch: 5 of auxiliary classification Duration: 0:00:00.320011
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0007, 0.0008],
        [0.0005, 0.0006],
        [0.0007, 0.0007],
        [0.0006, 0.0006],
        [0.0005, 0.0007],
        [0.0002, 0.0003],
        [0.0002, 0.0004],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0002, 0.0002],
        [0.0004, 0.0004],
        [0.0006, 0.0008],
        [0.0003, 0.0003],
        [0.0002, 0.0004],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0586, 0.0665],
        [0.0645, 0.0604],
        [0.0635, 0.0613],
        [0.0668, 0.0583],
        [0.0655, 0.0594],
        [0.0626, 0.0623],
        [0.0597, 0.0653],
        [0.0608, 0.0640],
        [0.0619, 0.0630],
        [0.0566, 0.0688],
        [0.0674, 0.0578],
        [0.0655, 0.0594],
        [0.0629, 0.0619],
        [0.0656, 0.0594],
        [0.0585, 0.0666],
        [0.0595, 0.0654]], device='cuda:0')
 Batch: 6 of auxiliary classification Duration: 0:00:00.405442
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0006, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0005],
        [0.0004, 0.0008],
        [0.0005, 0.0007],
        [0.0007, 0.0009],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0005, 0.0006],
        [0.0004, 0.0007],
        [0.0005, 0.0007],
        [0.0007, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0625, 0.0624],
        [0.0660, 0.0591],
        [0.0599, 0.0651],
        [0.0639, 0.0610],
        [0.0584, 0.0667],
        [0.0633, 0.0616],
        [0.0646, 0.0603],
        [0.0584, 0.0667],
        [0.0639, 0.0610],
        [0.0649, 0.0601],
        [0.0593, 0.0658],
        [0.0582, 0.0669],
        [0.0663, 0.0588],
        [0.0615, 0.0634],
        [0.0645, 0.0605],
        [0.0645, 0.0604]], device='cuda:0')
 Batch: 7 of auxiliary classification Duration: 0:00:00.453783
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0008, 0.0008],
        [0.0005, 0.0007],
        [0.0006, 0.0007],
        [0.0006, 0.0008],
        [0.0004, 0.0005],
        [0.0002, 0.0003],
        [0.0005, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0005, 0.0010],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0006, 0.0009],
        [0.0004, 0.0006],
        [0.0006, 0.0009],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0695, 0.0561],
        [0.0634, 0.0615],
        [0.0661, 0.0589],
        [0.0634, 0.0614],
        [0.0663, 0.0588],
        [0.0618, 0.0631],
        [0.0654, 0.0596],
        [0.0577, 0.0675],
        [0.0584, 0.0667],
        [0.0600, 0.0649],
        [0.0587, 0.0664],
        [0.0628, 0.0620],
        [0.0625, 0.0624],
        [0.0617, 0.0632],
        [0.0614, 0.0634],
        [0.0609, 0.0640]], device='cuda:0')
 Batch: 8 of auxiliary classification Duration: 0:00:00.431608
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0004, 0.0005],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0002, 0.0004],
        [0.0005, 0.0005],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0004, 0.0005],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0004, 0.0006],
        [0.0005, 0.0007],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0612, 0.0637],
        [0.0653, 0.0597],
        [0.0636, 0.0612],
        [0.0626, 0.0623],
        [0.0598, 0.0651],
        [0.0672, 0.0579],
        [0.0673, 0.0578],
        [0.0668, 0.0583],
        [0.0578, 0.0674],
        [0.0620, 0.0628],
        [0.0661, 0.0590],
        [0.0587, 0.0663],
        [0.0555, 0.0701],
        [0.0629, 0.0619],
        [0.0608, 0.0640],
        [0.0623, 0.0625]], device='cuda:0')
 Batch: 9 of auxiliary classification Duration: 0:00:00.423453
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0005, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0004, 0.0005],
        [0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0004],
        [0.0002, 0.0004],
        [0.0005, 0.0008],
        [0.0005, 0.0010],
        [0.0005, 0.0009],
        [0.0003, 0.0005],
        [0.0006, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0636, 0.0613],
        [0.0674, 0.0579],
        [0.0635, 0.0614],
        [0.0607, 0.0643],
        [0.0634, 0.0615],
        [0.0665, 0.0586],
        [0.0622, 0.0627],
        [0.0598, 0.0652],
        [0.0608, 0.0641],
        [0.0656, 0.0594],
        [0.0580, 0.0672],
        [0.0636, 0.0613],
        [0.0589, 0.0662],
        [0.0605, 0.0645],
        [0.0620, 0.0629],
        [0.0634, 0.0615]], device='cuda:0')
 Batch: 10 of auxiliary classification Duration: 0:00:00.489386
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0008],
        [0.0003, 0.0005],
        [0.0002, 0.0002],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0005, 0.0006],
        [0.0004, 0.0005],
        [0.0005, 0.0007],
        [0.0005, 0.0008],
        [0.0006, 0.0008],
        [0.0004, 0.0006],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0647, 0.0603],
        [0.0611, 0.0638],
        [0.0632, 0.0617],
        [0.0623, 0.0626],
        [0.0589, 0.0662],
        [0.0613, 0.0637],
        [0.0635, 0.0615],
        [0.0589, 0.0662],
        [0.0585, 0.0667],
        [0.0657, 0.0594],
        [0.0672, 0.0580],
        [0.0635, 0.0615],
        [0.0624, 0.0625],
        [0.0643, 0.0606],
        [0.0636, 0.0613],
        [0.0610, 0.0639]], device='cuda:0')
 Batch: 11 of auxiliary classification Duration: 0:00:00.592059
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0004, 0.0005],
        [0.0004, 0.0004],
        [0.0005, 0.0007],
        [0.0005, 0.0012],
        [0.0003, 0.0004],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1284, 0.1213],
        [0.1391, 0.1120],
        [0.1252, 0.1244],
        [0.1128, 0.1380],
        [0.1238, 0.1258],
        [0.1279, 0.1218],
        [0.1247, 0.1248],
        [0.1180, 0.1319]], device='cuda:0')
 Batch: 12 of auxiliary classification Duration: 0:00:00.249884
acc:  0.48
Time taken to execute the en SA task with prompt type auxiliary, variation 6 and batchsize 16: 0:00:05.466840
path ['42', 'en', 'bloom-big', 'SA', 'auxiliary', 'prompt_id_6']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([124, 2])
answers_probs just softmax dim 0: tensor([[0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081]], device='cuda:0')
tensor([[0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA auxiliary 7 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0004, 0.0005],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0008, 0.0017],
        [0.0002, 0.0007],
        [0.0002, 0.0002],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0002, 0.0006],
        [0.0002, 0.0006],
        [0.0006, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0606, 0.0642],
        [0.0608, 0.0639],
        [0.0589, 0.0661],
        [0.0682, 0.0570],
        [0.0653, 0.0596],
        [0.0627, 0.0620],
        [0.0617, 0.0631],
        [0.0577, 0.0673],
        [0.0767, 0.0507],
        [0.0623, 0.0624],
        [0.0627, 0.0620],
        [0.0625, 0.0622],
        [0.0592, 0.0657],
        [0.0580, 0.0670],
        [0.0602, 0.0646],
        [0.0626, 0.0621]], device='cuda:0')
 Batch: 0 of auxiliary classification Duration: 0:00:00.456647
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0003, 0.0009],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0004, 0.0007],
        [0.0001, 0.0004],
        [0.0003, 0.0010],
        [0.0001, 0.0002],
        [0.0004, 0.0008],
        [0.0002, 0.0005],
        [0.0002, 0.0006],
        [0.0003, 0.0007],
        [0.0006, 0.0015],
        [0.0004, 0.0010],
        [0.0005, 0.0008],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0632, 0.0616],
        [0.0580, 0.0672],
        [0.0590, 0.0660],
        [0.0630, 0.0618],
        [0.0644, 0.0605],
        [0.0606, 0.0643],
        [0.0576, 0.0676],
        [0.0736, 0.0529],
        [0.0637, 0.0611],
        [0.0617, 0.0631],
        [0.0620, 0.0628],
        [0.0616, 0.0632],
        [0.0608, 0.0640],
        [0.0602, 0.0647],
        [0.0668, 0.0583],
        [0.0639, 0.0609]], device='cuda:0')
 Batch: 1 of auxiliary classification Duration: 0:00:00.356635
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0001, 0.0004],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0003, 0.0004],
        [0.0002, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0001, 0.0003],
        [0.0002, 0.0004],
        [0.0003, 0.0008],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0635, 0.0614],
        [0.0616, 0.0633],
        [0.0605, 0.0644],
        [0.0603, 0.0646],
        [0.0661, 0.0590],
        [0.0644, 0.0605],
        [0.0670, 0.0581],
        [0.0662, 0.0589],
        [0.0589, 0.0662],
        [0.0677, 0.0576],
        [0.0578, 0.0674],
        [0.0596, 0.0653],
        [0.0626, 0.0622],
        [0.0644, 0.0605],
        [0.0580, 0.0671],
        [0.0615, 0.0634]], device='cuda:0')
 Batch: 2 of auxiliary classification Duration: 0:00:00.421908
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0006, 0.0012],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0001, 0.0004],
        [0.0001, 0.0003],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0004, 0.0008],
        [0.0002, 0.0003],
        [0.0001, 0.0004],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0650, 0.0599],
        [0.0623, 0.0626],
        [0.0614, 0.0635],
        [0.0647, 0.0603],
        [0.0621, 0.0628],
        [0.0606, 0.0644],
        [0.0618, 0.0631],
        [0.0578, 0.0674],
        [0.0660, 0.0591],
        [0.0608, 0.0641],
        [0.0612, 0.0637],
        [0.0692, 0.0564],
        [0.0586, 0.0665],
        [0.0626, 0.0622],
        [0.0613, 0.0636],
        [0.0646, 0.0604]], device='cuda:0')
 Batch: 3 of auxiliary classification Duration: 0:00:00.441818
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0002, 0.0002],
        [0.0006, 0.0020],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0002, 0.0006],
        [0.0003, 0.0013],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0004, 0.0006],
        [0.0005, 0.0008],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0578, 0.0672],
        [0.0596, 0.0652],
        [0.0603, 0.0644],
        [0.0743, 0.0523],
        [0.0571, 0.0681],
        [0.0607, 0.0640],
        [0.0602, 0.0645],
        [0.0593, 0.0655],
        [0.0556, 0.0698],
        [0.0661, 0.0588],
        [0.0623, 0.0624],
        [0.0628, 0.0619],
        [0.0622, 0.0624],
        [0.0647, 0.0601],
        [0.0675, 0.0576],
        [0.0694, 0.0560]], device='cuda:0')
 Batch: 4 of auxiliary classification Duration: 0:00:00.335907
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0011],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0004, 0.0011],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0010],
        [0.0002, 0.0002],
        [0.0006, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0682, 0.0571],
        [0.0625, 0.0623],
        [0.0585, 0.0666],
        [0.0658, 0.0592],
        [0.0648, 0.0601],
        [0.0569, 0.0684],
        [0.0602, 0.0647],
        [0.0629, 0.0619],
        [0.0623, 0.0625],
        [0.0598, 0.0651],
        [0.0580, 0.0671],
        [0.0635, 0.0613],
        [0.0633, 0.0615],
        [0.0576, 0.0676],
        [0.0685, 0.0569],
        [0.0672, 0.0580]], device='cuda:0')
 Batch: 5 of auxiliary classification Duration: 0:00:00.418048
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0002, 0.0007],
        [0.0004, 0.0009],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0003, 0.0009],
        [0.0002, 0.0008],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0004, 0.0010],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0599, 0.0651],
        [0.0605, 0.0645],
        [0.0614, 0.0635],
        [0.0645, 0.0605],
        [0.0606, 0.0643],
        [0.0647, 0.0603],
        [0.0675, 0.0577],
        [0.0661, 0.0590],
        [0.0637, 0.0612],
        [0.0638, 0.0611],
        [0.0605, 0.0644],
        [0.0573, 0.0681],
        [0.0622, 0.0627],
        [0.0620, 0.0629],
        [0.0632, 0.0617],
        [0.0621, 0.0628]], device='cuda:0')
 Batch: 6 of auxiliary classification Duration: 0:00:00.317332
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0008],
        [0.0001, 0.0002],
        [0.0005, 0.0009],
        [0.0004, 0.0007],
        [0.0002, 0.0003],
        [0.0005, 0.0011],
        [0.0002, 0.0006],
        [0.0007, 0.0015],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0003, 0.0009],
        [0.0003, 0.0005],
        [0.0004, 0.0005],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0608, 0.0641],
        [0.0596, 0.0653],
        [0.0584, 0.0667],
        [0.0668, 0.0583],
        [0.0655, 0.0595],
        [0.0636, 0.0612],
        [0.0679, 0.0573],
        [0.0616, 0.0633],
        [0.0582, 0.0670],
        [0.0624, 0.0624],
        [0.0601, 0.0648],
        [0.0634, 0.0614],
        [0.0593, 0.0656],
        [0.0643, 0.0606],
        [0.0700, 0.0556],
        [0.0582, 0.0669]], device='cuda:0')
 Batch: 7 of auxiliary classification Duration: 0:00:00.362240
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0011],
        [0.0003, 0.0009],
        [0.0004, 0.0009],
        [0.0002, 0.0005],
        [0.0002, 0.0009],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0002, 0.0003],
        [0.0004, 0.0005],
        [0.0002, 0.0007],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0651, 0.0598],
        [0.0583, 0.0668],
        [0.0604, 0.0644],
        [0.0593, 0.0656],
        [0.0554, 0.0703],
        [0.0639, 0.0609],
        [0.0653, 0.0596],
        [0.0596, 0.0653],
        [0.0619, 0.0629],
        [0.0659, 0.0590],
        [0.0709, 0.0549],
        [0.0687, 0.0567],
        [0.0589, 0.0660],
        [0.0598, 0.0651],
        [0.0620, 0.0628],
        [0.0647, 0.0601]], device='cuda:0')
 Batch: 8 of auxiliary classification Duration: 0:00:00.331168
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0006],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0006, 0.0016],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0004, 0.0005],
        [0.0004, 0.0008],
        [0.0003, 0.0004],
        [0.0002, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0560, 0.0694],
        [0.0642, 0.0606],
        [0.0597, 0.0651],
        [0.0613, 0.0634],
        [0.0626, 0.0621],
        [0.0582, 0.0668],
        [0.0624, 0.0623],
        [0.0602, 0.0646],
        [0.0618, 0.0630],
        [0.0642, 0.0606],
        [0.0663, 0.0587],
        [0.0622, 0.0625],
        [0.0675, 0.0576],
        [0.0565, 0.0688],
        [0.0627, 0.0620],
        [0.0740, 0.0526]], device='cuda:0')
 Batch: 9 of auxiliary classification Duration: 0:00:00.361798
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0004, 0.0009],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0004, 0.0010],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0652, 0.0599],
        [0.0611, 0.0639],
        [0.0630, 0.0619],
        [0.0595, 0.0656],
        [0.0648, 0.0602],
        [0.0631, 0.0618],
        [0.0658, 0.0593],
        [0.0594, 0.0657],
        [0.0646, 0.0604],
        [0.0646, 0.0604],
        [0.0653, 0.0598],
        [0.0611, 0.0639],
        [0.0608, 0.0642],
        [0.0610, 0.0640],
        [0.0601, 0.0649],
        [0.0607, 0.0643]], device='cuda:0')
 Batch: 10 of auxiliary classification Duration: 0:00:00.480707
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0011],
        [0.0002, 0.0006],
        [0.0005, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0004, 0.0010],
        [0.0002, 0.0003],
        [0.0004, 0.0008],
        [0.0002, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0568, 0.0684],
        [0.0603, 0.0645],
        [0.0725, 0.0536],
        [0.0610, 0.0637],
        [0.0635, 0.0612],
        [0.0676, 0.0575],
        [0.0670, 0.0580],
        [0.0657, 0.0591],
        [0.0580, 0.0669],
        [0.0605, 0.0642],
        [0.0603, 0.0645],
        [0.0641, 0.0606],
        [0.0603, 0.0644],
        [0.0676, 0.0575],
        [0.0613, 0.0634],
        [0.0536, 0.0724]], device='cuda:0')
 Batch: 11 of auxiliary classification Duration: 0:00:00.565499
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0005, 0.0013],
        [0.0004, 0.0010],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1249],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1416, 0.1099],
        [0.1192, 0.1306],
        [0.1209, 0.1287],
        [0.1209, 0.1287],
        [0.1205, 0.1291],
        [0.1355, 0.1148],
        [0.1160, 0.1342],
        [0.1256, 0.1239]], device='cuda:0')
 Batch: 12 of auxiliary classification Duration: 0:00:00.160781
acc:  0.55
Time taken to execute the en SA task with prompt type auxiliary, variation 7 and batchsize 16: 0:00:05.032382
path ['42', 'en', 'bloom-big', 'SA', 'auxiliary', 'prompt_id_7']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([112, 2])
answers_probs just softmax dim 0: tensor([[0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089]], device='cuda:0')
tensor([[0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA auxiliary 8 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0002, 0.0006],
        [0.0002, 0.0003],
        [0.0004, 0.0009],
        [0.0004, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0011],
        [0.0008, 0.0014],
        [0.0002, 0.0007],
        [0.0005, 0.0012],
        [0.0002, 0.0006],
        [0.0004, 0.0008],
        [0.0003, 0.0009],
        [0.0004, 0.0007],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0635, 0.0614],
        [0.0625, 0.0624],
        [0.0606, 0.0643],
        [0.0679, 0.0574],
        [0.0617, 0.0632],
        [0.0661, 0.0590],
        [0.0622, 0.0627],
        [0.0582, 0.0670],
        [0.0660, 0.0591],
        [0.0606, 0.0644],
        [0.0623, 0.0626],
        [0.0592, 0.0659],
        [0.0625, 0.0624],
        [0.0593, 0.0658],
        [0.0661, 0.0590],
        [0.0613, 0.0636]], device='cuda:0')
 Batch: 0 of auxiliary classification Duration: 0:00:00.408935
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0016],
        [0.0004, 0.0012],
        [0.0002, 0.0007],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0006, 0.0012],
        [0.0010, 0.0025],
        [0.0003, 0.0013],
        [0.0003, 0.0011],
        [0.0004, 0.0009],
        [0.0003, 0.0008],
        [0.0004, 0.0011],
        [0.0003, 0.0005],
        [0.0005, 0.0010],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0559, 0.0697],
        [0.0599, 0.0650],
        [0.0600, 0.0649],
        [0.0657, 0.0593],
        [0.0652, 0.0597],
        [0.0658, 0.0592],
        [0.0658, 0.0592],
        [0.0626, 0.0622],
        [0.0568, 0.0685],
        [0.0584, 0.0666],
        [0.0651, 0.0598],
        [0.0607, 0.0642],
        [0.0617, 0.0631],
        [0.0667, 0.0584],
        [0.0645, 0.0604],
        [0.0651, 0.0598]], device='cuda:0')
 Batch: 1 of auxiliary classification Duration: 0:00:00.403564
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0009],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0005, 0.0013],
        [0.0003, 0.0011],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0011],
        [0.0005, 0.0012],
        [0.0005, 0.0015],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0698, 0.0558],
        [0.0691, 0.0563],
        [0.0592, 0.0658],
        [0.0609, 0.0640],
        [0.0619, 0.0630],
        [0.0620, 0.0629],
        [0.0647, 0.0602],
        [0.0664, 0.0586],
        [0.0604, 0.0644],
        [0.0586, 0.0664],
        [0.0618, 0.0631],
        [0.0640, 0.0608],
        [0.0574, 0.0679],
        [0.0618, 0.0631],
        [0.0590, 0.0660],
        [0.0631, 0.0617]], device='cuda:0')
 Batch: 2 of auxiliary classification Duration: 0:00:00.446423
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0003, 0.0009],
        [0.0002, 0.0006],
        [0.0004, 0.0010],
        [0.0004, 0.0009],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0005, 0.0020],
        [0.0003, 0.0009],
        [0.0002, 0.0006],
        [0.0002, 0.0010],
        [0.0002, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0012],
        [0.0003, 0.0007],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0610, 0.0639],
        [0.0623, 0.0626],
        [0.0621, 0.0628],
        [0.0634, 0.0615],
        [0.0634, 0.0615],
        [0.0634, 0.0615],
        [0.0662, 0.0589],
        [0.0571, 0.0683],
        [0.0617, 0.0632],
        [0.0623, 0.0626],
        [0.0578, 0.0674],
        [0.0594, 0.0657],
        [0.0671, 0.0581],
        [0.0621, 0.0628],
        [0.0649, 0.0601],
        [0.0657, 0.0594]], device='cuda:0')
 Batch: 3 of auxiliary classification Duration: 0:00:00.333142
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0004, 0.0012],
        [0.0003, 0.0009],
        [0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0006, 0.0013],
        [0.0002, 0.0007],
        [0.0004, 0.0011],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0012],
        [0.0002, 0.0003],
        [0.0004, 0.0009],
        [0.0005, 0.0008],
        [0.0006, 0.0015]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0640, 0.0609],
        [0.0592, 0.0659],
        [0.0584, 0.0668],
        [0.0643, 0.0606],
        [0.0626, 0.0623],
        [0.0628, 0.0620],
        [0.0583, 0.0668],
        [0.0603, 0.0646],
        [0.0627, 0.0621],
        [0.0604, 0.0645],
        [0.0673, 0.0579],
        [0.0605, 0.0644],
        [0.0691, 0.0564],
        [0.0624, 0.0625],
        [0.0662, 0.0589],
        [0.0615, 0.0634]], device='cuda:0')
 Batch: 4 of auxiliary classification Duration: 0:00:00.317301
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0005, 0.0009],
        [0.0002, 0.0006],
        [0.0002, 0.0006],
        [0.0006, 0.0011],
        [0.0006, 0.0013],
        [0.0002, 0.0003],
        [0.0003, 0.0012],
        [0.0001, 0.0002],
        [0.0009, 0.0019],
        [0.0004, 0.0008],
        [0.0003, 0.0004],
        [0.0004, 0.0012],
        [0.0006, 0.0010],
        [0.0005, 0.0010],
        [0.0004, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0648, 0.0601],
        [0.0657, 0.0593],
        [0.0598, 0.0651],
        [0.0596, 0.0654],
        [0.0649, 0.0600],
        [0.0614, 0.0634],
        [0.0631, 0.0617],
        [0.0562, 0.0693],
        [0.0677, 0.0575],
        [0.0612, 0.0636],
        [0.0614, 0.0634],
        [0.0687, 0.0567],
        [0.0587, 0.0663],
        [0.0653, 0.0596],
        [0.0630, 0.0618],
        [0.0583, 0.0668]], device='cuda:0')
 Batch: 5 of auxiliary classification Duration: 0:00:00.427441
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0002, 0.0007],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0004, 0.0011],
        [0.0004, 0.0011],
        [0.0003, 0.0007],
        [0.0002, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0006, 0.0013],
        [0.0005, 0.0012],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0684, 0.0570],
        [0.0571, 0.0682],
        [0.0668, 0.0583],
        [0.0606, 0.0642],
        [0.0593, 0.0657],
        [0.0593, 0.0657],
        [0.0617, 0.0631],
        [0.0584, 0.0667],
        [0.0631, 0.0617],
        [0.0637, 0.0612],
        [0.0701, 0.0556],
        [0.0638, 0.0611],
        [0.0623, 0.0625],
        [0.0608, 0.0640],
        [0.0627, 0.0621],
        [0.0621, 0.0627]], device='cuda:0')
 Batch: 6 of auxiliary classification Duration: 0:00:00.355248
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0007],
        [0.0003, 0.0009],
        [0.0004, 0.0004],
        [0.0004, 0.0012],
        [0.0005, 0.0013],
        [0.0002, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0008],
        [0.0005, 0.0012],
        [0.0004, 0.0006],
        [0.0004, 0.0011],
        [0.0006, 0.0013],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0002, 0.0007],
        [0.0003, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0581, 0.0670],
        [0.0601, 0.0647],
        [0.0719, 0.0541],
        [0.0598, 0.0650],
        [0.0605, 0.0643],
        [0.0579, 0.0672],
        [0.0677, 0.0575],
        [0.0663, 0.0587],
        [0.0614, 0.0633],
        [0.0684, 0.0569],
        [0.0586, 0.0664],
        [0.0635, 0.0613],
        [0.0627, 0.0620],
        [0.0638, 0.0610],
        [0.0580, 0.0671],
        [0.0614, 0.0633]], device='cuda:0')
 Batch: 7 of auxiliary classification Duration: 0:00:00.560153
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0013],
        [0.0005, 0.0014],
        [0.0005, 0.0011],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0005, 0.0008],
        [0.0006, 0.0014],
        [0.0008, 0.0017],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0004, 0.0011],
        [0.0007, 0.0013],
        [0.0003, 0.0006],
        [0.0004, 0.0011],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0578, 0.0675],
        [0.0590, 0.0661],
        [0.0637, 0.0612],
        [0.0625, 0.0624],
        [0.0616, 0.0633],
        [0.0661, 0.0590],
        [0.0634, 0.0615],
        [0.0628, 0.0621],
        [0.0594, 0.0657],
        [0.0631, 0.0618],
        [0.0635, 0.0614],
        [0.0594, 0.0657],
        [0.0654, 0.0596],
        [0.0629, 0.0620],
        [0.0615, 0.0634],
        [0.0680, 0.0574]], device='cuda:0')
 Batch: 8 of auxiliary classification Duration: 0:00:00.423631
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0013],
        [0.0005, 0.0011],
        [0.0005, 0.0014],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0010],
        [0.0003, 0.0011],
        [0.0003, 0.0008],
        [0.0005, 0.0006],
        [0.0004, 0.0010],
        [0.0003, 0.0006],
        [0.0005, 0.0009],
        [0.0003, 0.0005],
        [0.0005, 0.0012],
        [0.0002, 0.0003],
        [0.0003, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0585, 0.0667],
        [0.0619, 0.0629],
        [0.0593, 0.0657],
        [0.0628, 0.0620],
        [0.0659, 0.0591],
        [0.0609, 0.0640],
        [0.0570, 0.0683],
        [0.0613, 0.0636],
        [0.0697, 0.0559],
        [0.0618, 0.0630],
        [0.0634, 0.0615],
        [0.0670, 0.0582],
        [0.0653, 0.0597],
        [0.0614, 0.0635],
        [0.0643, 0.0606],
        [0.0596, 0.0654]], device='cuda:0')
 Batch: 9 of auxiliary classification Duration: 0:00:00.472180
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0014],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0005, 0.0009],
        [0.0003, 0.0009],
        [0.0002, 0.0004],
        [0.0004, 0.0011],
        [0.0007, 0.0014],
        [0.0004, 0.0010],
        [0.0004, 0.0010],
        [0.0005, 0.0014],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0004, 0.0009],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0584, 0.0667],
        [0.0635, 0.0615],
        [0.0639, 0.0611],
        [0.0657, 0.0594],
        [0.0583, 0.0669],
        [0.0671, 0.0581],
        [0.0615, 0.0634],
        [0.0650, 0.0600],
        [0.0611, 0.0638],
        [0.0604, 0.0646],
        [0.0606, 0.0643],
        [0.0612, 0.0637],
        [0.0640, 0.0610],
        [0.0638, 0.0612],
        [0.0640, 0.0610],
        [0.0616, 0.0633]], device='cuda:0')
 Batch: 10 of auxiliary classification Duration: 0:00:00.420526
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0003, 0.0010],
        [0.0004, 0.0006],
        [0.0004, 0.0008],
        [0.0002, 0.0003],
        [0.0003, 0.0012],
        [0.0007, 0.0018],
        [0.0002, 0.0003],
        [0.0004, 0.0009],
        [0.0005, 0.0014],
        [0.0004, 0.0013],
        [0.0002, 0.0003],
        [0.0004, 0.0009],
        [0.0004, 0.0011],
        [0.0003, 0.0008],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0641, 0.0608],
        [0.0597, 0.0652],
        [0.0681, 0.0572],
        [0.0634, 0.0614],
        [0.0664, 0.0587],
        [0.0573, 0.0680],
        [0.0605, 0.0643],
        [0.0702, 0.0555],
        [0.0627, 0.0621],
        [0.0597, 0.0652],
        [0.0594, 0.0656],
        [0.0633, 0.0615],
        [0.0633, 0.0615],
        [0.0593, 0.0657],
        [0.0603, 0.0646],
        [0.0622, 0.0626]], device='cuda:0')
 Batch: 11 of auxiliary classification Duration: 0:00:00.403642
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0002, 0.0007],
        [0.0003, 0.0014],
        [0.0002, 0.0007],
        [0.0001, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0002, 0.0003],
        [0.0005, 0.0014]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1249],
        [0.1250, 0.1251]], device='cuda:0')
tensor([[0.1189, 0.1310],
        [0.1166, 0.1336],
        [0.1222, 0.1275],
        [0.1184, 0.1316],
        [0.1319, 0.1181],
        [0.1282, 0.1215],
        [0.1381, 0.1128],
        [0.1257, 0.1239]], device='cuda:0')
 Batch: 12 of auxiliary classification Duration: 0:00:00.185002
acc:  0.58
Time taken to execute the en SA task with prompt type auxiliary, variation 8 and batchsize 16: 0:00:05.177054
path ['42', 'en', 'bloom-big', 'SA', 'auxiliary', 'prompt_id_8']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([110, 2])
answers_probs just softmax dim 0: tensor([[0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091]], device='cuda:0')
tensor([[0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA auxiliary 9 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0009],
        [0.0004, 0.0007],
        [0.0005, 0.0009],
        [0.0004, 0.0006],
        [0.0005, 0.0010],
        [0.0003, 0.0006],
        [0.0004, 0.0013],
        [0.0004, 0.0010],
        [0.0004, 0.0010],
        [0.0006, 0.0009],
        [0.0007, 0.0010],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0009],
        [0.0008, 0.0012],
        [0.0003, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0590, 0.0661],
        [0.0638, 0.0611],
        [0.0637, 0.0612],
        [0.0644, 0.0605],
        [0.0626, 0.0623],
        [0.0630, 0.0618],
        [0.0572, 0.0681],
        [0.0600, 0.0649],
        [0.0595, 0.0655],
        [0.0664, 0.0587],
        [0.0672, 0.0580],
        [0.0619, 0.0629],
        [0.0646, 0.0603],
        [0.0604, 0.0645],
        [0.0677, 0.0576],
        [0.0585, 0.0666]], device='cuda:0')
 Batch: 0 of auxiliary classification Duration: 0:00:00.411407
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0020],
        [0.0004, 0.0007],
        [0.0006, 0.0012],
        [0.0006, 0.0016],
        [0.0005, 0.0008],
        [0.0003, 0.0008],
        [0.0004, 0.0008],
        [0.0003, 0.0010],
        [0.0005, 0.0007],
        [0.0003, 0.0006],
        [0.0008, 0.0019],
        [0.0005, 0.0011],
        [0.0004, 0.0007],
        [0.0005, 0.0006],
        [0.0004, 0.0008],
        [0.0008, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0574, 0.0678],
        [0.0647, 0.0602],
        [0.0607, 0.0642],
        [0.0582, 0.0669],
        [0.0651, 0.0598],
        [0.0589, 0.0661],
        [0.0625, 0.0623],
        [0.0576, 0.0676],
        [0.0679, 0.0574],
        [0.0642, 0.0607],
        [0.0591, 0.0659],
        [0.0613, 0.0635],
        [0.0644, 0.0604],
        [0.0672, 0.0579],
        [0.0625, 0.0623],
        [0.0684, 0.0569]], device='cuda:0')
 Batch: 1 of auxiliary classification Duration: 0:00:00.399217
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0011],
        [0.0004, 0.0007],
        [0.0005, 0.0009],
        [0.0006, 0.0016],
        [0.0005, 0.0011],
        [0.0009, 0.0018],
        [0.0006, 0.0012],
        [0.0004, 0.0010],
        [0.0002, 0.0004],
        [0.0005, 0.0008],
        [0.0006, 0.0016],
        [0.0003, 0.0007],
        [0.0005, 0.0008],
        [0.0004, 0.0006],
        [0.0010, 0.0016],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0582, 0.0670],
        [0.0636, 0.0613],
        [0.0640, 0.0609],
        [0.0595, 0.0655],
        [0.0613, 0.0636],
        [0.0620, 0.0629],
        [0.0631, 0.0618],
        [0.0581, 0.0671],
        [0.0633, 0.0616],
        [0.0657, 0.0594],
        [0.0591, 0.0660],
        [0.0605, 0.0645],
        [0.0653, 0.0597],
        [0.0656, 0.0595],
        [0.0651, 0.0599],
        [0.0656, 0.0595]], device='cuda:0')
 Batch: 2 of auxiliary classification Duration: 0:00:00.399814
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0004, 0.0007],
        [0.0007, 0.0010],
        [0.0004, 0.0013],
        [0.0008, 0.0014],
        [0.0006, 0.0011],
        [0.0004, 0.0010],
        [0.0003, 0.0005],
        [0.0005, 0.0007],
        [0.0006, 0.0015],
        [0.0004, 0.0010],
        [0.0004, 0.0012],
        [0.0006, 0.0011],
        [0.0004, 0.0008],
        [0.0007, 0.0010],
        [0.0003, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0603, 0.0647],
        [0.0645, 0.0605],
        [0.0661, 0.0589],
        [0.0573, 0.0681],
        [0.0643, 0.0606],
        [0.0630, 0.0619],
        [0.0597, 0.0653],
        [0.0660, 0.0590],
        [0.0655, 0.0595],
        [0.0594, 0.0656],
        [0.0602, 0.0648],
        [0.0587, 0.0664],
        [0.0644, 0.0606],
        [0.0628, 0.0621],
        [0.0670, 0.0582],
        [0.0609, 0.0640]], device='cuda:0')
 Batch: 3 of auxiliary classification Duration: 0:00:00.356826
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0005],
        [0.0004, 0.0007],
        [0.0006, 0.0010],
        [0.0010, 0.0013],
        [0.0003, 0.0008],
        [0.0006, 0.0012],
        [0.0007, 0.0011],
        [0.0003, 0.0004],
        [0.0006, 0.0013],
        [0.0005, 0.0008],
        [0.0002, 0.0005],
        [0.0004, 0.0008],
        [0.0005, 0.0012],
        [0.0003, 0.0008],
        [0.0008, 0.0010],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0660, 0.0590],
        [0.0633, 0.0616],
        [0.0626, 0.0623],
        [0.0677, 0.0576],
        [0.0583, 0.0669],
        [0.0609, 0.0640],
        [0.0634, 0.0615],
        [0.0646, 0.0604],
        [0.0603, 0.0647],
        [0.0634, 0.0615],
        [0.0614, 0.0635],
        [0.0614, 0.0635],
        [0.0588, 0.0663],
        [0.0581, 0.0671],
        [0.0676, 0.0577],
        [0.0625, 0.0624]], device='cuda:0')
 Batch: 4 of auxiliary classification Duration: 0:00:00.428092
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0012],
        [0.0003, 0.0005],
        [0.0008, 0.0011],
        [0.0008, 0.0012],
        [0.0006, 0.0015],
        [0.0003, 0.0006],
        [0.0005, 0.0010],
        [0.0006, 0.0012],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0006, 0.0009],
        [0.0003, 0.0004],
        [0.0005, 0.0011],
        [0.0005, 0.0013],
        [0.0005, 0.0007],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0635, 0.0614],
        [0.0626, 0.0623],
        [0.0664, 0.0587],
        [0.0654, 0.0596],
        [0.0575, 0.0678],
        [0.0610, 0.0640],
        [0.0604, 0.0645],
        [0.0626, 0.0623],
        [0.0607, 0.0642],
        [0.0624, 0.0625],
        [0.0641, 0.0609],
        [0.0661, 0.0590],
        [0.0602, 0.0647],
        [0.0578, 0.0674],
        [0.0653, 0.0597],
        [0.0641, 0.0609]], device='cuda:0')
 Batch: 5 of auxiliary classification Duration: 0:00:00.476873
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0012],
        [0.0005, 0.0013],
        [0.0004, 0.0007],
        [0.0009, 0.0013],
        [0.0007, 0.0010],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0009, 0.0015],
        [0.0003, 0.0006],
        [0.0006, 0.0012],
        [0.0004, 0.0009],
        [0.0005, 0.0011],
        [0.0004, 0.0006],
        [0.0006, 0.0011],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0580, 0.0672],
        [0.0586, 0.0666],
        [0.0654, 0.0596],
        [0.0655, 0.0595],
        [0.0673, 0.0579],
        [0.0634, 0.0615],
        [0.0643, 0.0606],
        [0.0610, 0.0639],
        [0.0642, 0.0607],
        [0.0631, 0.0618],
        [0.0624, 0.0625],
        [0.0613, 0.0636],
        [0.0615, 0.0634],
        [0.0641, 0.0608],
        [0.0618, 0.0631],
        [0.0579, 0.0673]], device='cuda:0')
 Batch: 6 of auxiliary classification Duration: 0:00:00.423183
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0016],
        [0.0006, 0.0011],
        [0.0005, 0.0009],
        [0.0006, 0.0011],
        [0.0005, 0.0009],
        [0.0005, 0.0011],
        [0.0005, 0.0012],
        [0.0003, 0.0009],
        [0.0005, 0.0011],
        [0.0006, 0.0013],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0010, 0.0017],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0012, 0.0018]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0581, 0.0671],
        [0.0633, 0.0616],
        [0.0634, 0.0615],
        [0.0651, 0.0599],
        [0.0640, 0.0609],
        [0.0622, 0.0627],
        [0.0608, 0.0641],
        [0.0561, 0.0696],
        [0.0611, 0.0638],
        [0.0606, 0.0644],
        [0.0649, 0.0600],
        [0.0628, 0.0621],
        [0.0642, 0.0607],
        [0.0632, 0.0617],
        [0.0637, 0.0612],
        [0.0665, 0.0586]], device='cuda:0')
 Batch: 7 of auxiliary classification Duration: 0:00:00.289955
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0008, 0.0013],
        [0.0005, 0.0008],
        [0.0004, 0.0006],
        [0.0009, 0.0014],
        [0.0006, 0.0011],
        [0.0009, 0.0017],
        [0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0007, 0.0011],
        [0.0005, 0.0011],
        [0.0002, 0.0005],
        [0.0004, 0.0009],
        [0.0010, 0.0014],
        [0.0007, 0.0011],
        [0.0002, 0.0004],
        [0.0006, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0639, 0.0611],
        [0.0626, 0.0623],
        [0.0640, 0.0610],
        [0.0648, 0.0602],
        [0.0627, 0.0622],
        [0.0623, 0.0626],
        [0.0610, 0.0640],
        [0.0622, 0.0628],
        [0.0639, 0.0611],
        [0.0595, 0.0656],
        [0.0597, 0.0654],
        [0.0585, 0.0667],
        [0.0675, 0.0578],
        [0.0642, 0.0607],
        [0.0618, 0.0631],
        [0.0615, 0.0634]], device='cuda:0')
 Batch: 8 of auxiliary classification Duration: 0:00:00.537054
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0014],
        [0.0005, 0.0009],
        [0.0006, 0.0010],
        [0.0004, 0.0004],
        [0.0006, 0.0014],
        [0.0004, 0.0009],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0005, 0.0010],
        [0.0005, 0.0010],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0006, 0.0010],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0582, 0.0670],
        [0.0628, 0.0621],
        [0.0637, 0.0612],
        [0.0724, 0.0538],
        [0.0580, 0.0671],
        [0.0607, 0.0642],
        [0.0624, 0.0624],
        [0.0582, 0.0669],
        [0.0609, 0.0640],
        [0.0612, 0.0636],
        [0.0634, 0.0614],
        [0.0641, 0.0607],
        [0.0626, 0.0622],
        [0.0640, 0.0609],
        [0.0637, 0.0612],
        [0.0636, 0.0613]], device='cuda:0')
 Batch: 9 of auxiliary classification Duration: 0:00:00.362505
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0005, 0.0007],
        [0.0005, 0.0009],
        [0.0004, 0.0005],
        [0.0004, 0.0006],
        [0.0004, 0.0008],
        [0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0004, 0.0013],
        [0.0005, 0.0012],
        [0.0003, 0.0008],
        [0.0005, 0.0010],
        [0.0005, 0.0010],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0592, 0.0658],
        [0.0672, 0.0579],
        [0.0627, 0.0621],
        [0.0683, 0.0571],
        [0.0644, 0.0605],
        [0.0603, 0.0646],
        [0.0644, 0.0605],
        [0.0616, 0.0633],
        [0.0561, 0.0695],
        [0.0594, 0.0655],
        [0.0592, 0.0658],
        [0.0605, 0.0643],
        [0.0613, 0.0636],
        [0.0635, 0.0614],
        [0.0650, 0.0599],
        [0.0669, 0.0583]], device='cuda:0')
 Batch: 10 of auxiliary classification Duration: 0:00:00.407049
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0006, 0.0012],
        [0.0006, 0.0010],
        [0.0005, 0.0011],
        [0.0006, 0.0010],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0002, 0.0007],
        [0.0006, 0.0008],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0006, 0.0015],
        [0.0005, 0.0011],
        [0.0007, 0.0013],
        [0.0007, 0.0011],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0650, 0.0599],
        [0.0624, 0.0625],
        [0.0648, 0.0602],
        [0.0600, 0.0650],
        [0.0632, 0.0617],
        [0.0618, 0.0630],
        [0.0627, 0.0622],
        [0.0562, 0.0694],
        [0.0663, 0.0588],
        [0.0661, 0.0589],
        [0.0648, 0.0602],
        [0.0593, 0.0657],
        [0.0594, 0.0656],
        [0.0631, 0.0618],
        [0.0648, 0.0602],
        [0.0601, 0.0649]], device='cuda:0')
 Batch: 11 of auxiliary classification Duration: 0:00:00.441212
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0007, 0.0014],
        [0.0005, 0.0010],
        [0.0003, 0.0008],
        [0.0007, 0.0014],
        [0.0008, 0.0015],
        [0.0002, 0.0004],
        [0.0005, 0.0012]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1249],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1209, 0.1291],
        [0.1291, 0.1209],
        [0.1276, 0.1224],
        [0.1176, 0.1327],
        [0.1280, 0.1219],
        [0.1305, 0.1196],
        [0.1241, 0.1258],
        [0.1223, 0.1277]], device='cuda:0')
 Batch: 12 of auxiliary classification Duration: 0:00:00.154165
acc:  0.54
Time taken to execute the en SA task with prompt type auxiliary, variation 9 and batchsize 16: 0:00:05.103841
path ['42', 'en', 'bloom-big', 'SA', 'auxiliary', 'prompt_id_9']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v73.pickle' as a pickle file.

prompt_type modal has 10 prompts in it
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([93, 2])
answers_probs just softmax dim 0: tensor([[0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108]], device='cuda:0')
tensor([[0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108],
        [0.0108, 0.0108]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA modal 0 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0009],
        [0.0004, 0.0005],
        [0.0002, 0.0003],
        [0.0005, 0.0009],
        [0.0005, 0.0006],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0005, 0.0004],
        [0.0005, 0.0007],
        [0.0004, 0.0005],
        [0.0006, 0.0006],
        [0.0006, 0.0006],
        [0.0006, 0.0008],
        [0.0007, 0.0008],
        [0.0004, 0.0005],
        [0.0006, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0622, 0.0627],
        [0.0626, 0.0623],
        [0.0628, 0.0621],
        [0.0569, 0.0685],
        [0.0633, 0.0616],
        [0.0610, 0.0639],
        [0.0600, 0.0650],
        [0.0673, 0.0579],
        [0.0627, 0.0622],
        [0.0621, 0.0628],
        [0.0666, 0.0586],
        [0.0648, 0.0602],
        [0.0620, 0.0630],
        [0.0635, 0.0614],
        [0.0615, 0.0634],
        [0.0608, 0.0642]], device='cuda:0')
 Batch: 0 of modal classification Duration: 0:00:00.371987
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0010],
        [0.0007, 0.0012],
        [0.0006, 0.0009],
        [0.0004, 0.0008],
        [0.0006, 0.0007],
        [0.0004, 0.0006],
        [0.0008, 0.0011],
        [0.0004, 0.0005],
        [0.0005, 0.0008],
        [0.0004, 0.0006],
        [0.0005, 0.0007],
        [0.0006, 0.0006],
        [0.0002, 0.0003],
        [0.0006, 0.0008],
        [0.0004, 0.0005],
        [0.0004, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0588, 0.0663],
        [0.0594, 0.0657],
        [0.0606, 0.0644],
        [0.0583, 0.0669],
        [0.0656, 0.0594],
        [0.0624, 0.0625],
        [0.0628, 0.0621],
        [0.0659, 0.0592],
        [0.0607, 0.0642],
        [0.0611, 0.0638],
        [0.0627, 0.0622],
        [0.0681, 0.0573],
        [0.0628, 0.0621],
        [0.0617, 0.0632],
        [0.0633, 0.0616],
        [0.0659, 0.0592]], device='cuda:0')
 Batch: 1 of modal classification Duration: 0:00:00.335462
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0004, 0.0006],
        [0.0005, 0.0005],
        [0.0005, 0.0008],
        [0.0007, 0.0019],
        [0.0004, 0.0006],
        [0.0004, 0.0008],
        [0.0005, 0.0005],
        [0.0006, 0.0011],
        [0.0005, 0.0005],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0007],
        [0.0004, 0.0005],
        [0.0004, 0.0009],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0559, 0.0695],
        [0.0648, 0.0601],
        [0.0677, 0.0575],
        [0.0619, 0.0628],
        [0.0557, 0.0699],
        [0.0639, 0.0609],
        [0.0599, 0.0649],
        [0.0686, 0.0567],
        [0.0598, 0.0650],
        [0.0700, 0.0556],
        [0.0626, 0.0621],
        [0.0625, 0.0623],
        [0.0621, 0.0626],
        [0.0659, 0.0590],
        [0.0574, 0.0678],
        [0.0614, 0.0633]], device='cuda:0')
 Batch: 2 of modal classification Duration: 0:00:00.422724
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0005, 0.0010],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0009, 0.0015],
        [0.0005, 0.0008],
        [0.0004, 0.0008],
        [0.0005, 0.0009],
        [0.0003, 0.0004],
        [0.0005, 0.0007],
        [0.0006, 0.0009],
        [0.0005, 0.0008],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0632, 0.0617],
        [0.0603, 0.0647],
        [0.0653, 0.0598],
        [0.0620, 0.0629],
        [0.0631, 0.0618],
        [0.0630, 0.0619],
        [0.0611, 0.0638],
        [0.0617, 0.0632],
        [0.0663, 0.0589],
        [0.0658, 0.0593],
        [0.0642, 0.0608],
        [0.0616, 0.0633],
        [0.0560, 0.0696],
        [0.0619, 0.0630],
        [0.0637, 0.0613],
        [0.0609, 0.0640]], device='cuda:0')
 Batch: 3 of modal classification Duration: 0:00:00.420234
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0005, 0.0005],
        [0.0005, 0.0007],
        [0.0005, 0.0005],
        [0.0006, 0.0006],
        [0.0005, 0.0006],
        [0.0002, 0.0004],
        [0.0008, 0.0008],
        [0.0005, 0.0008],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0007],
        [0.0006, 0.0006],
        [0.0003, 0.0004],
        [0.0007, 0.0008],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0609, 0.0640],
        [0.0650, 0.0599],
        [0.0612, 0.0636],
        [0.0655, 0.0594],
        [0.0645, 0.0604],
        [0.0656, 0.0593],
        [0.0593, 0.0657],
        [0.0664, 0.0586],
        [0.0579, 0.0672],
        [0.0617, 0.0631],
        [0.0619, 0.0629],
        [0.0535, 0.0728],
        [0.0677, 0.0575],
        [0.0642, 0.0606],
        [0.0635, 0.0613],
        [0.0612, 0.0636]], device='cuda:0')
 Batch: 4 of modal classification Duration: 0:00:00.357009
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0003],
        [0.0004, 0.0005],
        [0.0006, 0.0010],
        [0.0006, 0.0009],
        [0.0005, 0.0010],
        [0.0004, 0.0005],
        [0.0004, 0.0006],
        [0.0005, 0.0007],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0005, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0004],
        [0.0005, 0.0006],
        [0.0007, 0.0007],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0659, 0.0592],
        [0.0619, 0.0629],
        [0.0606, 0.0644],
        [0.0604, 0.0645],
        [0.0575, 0.0678],
        [0.0628, 0.0621],
        [0.0625, 0.0624],
        [0.0630, 0.0619],
        [0.0616, 0.0633],
        [0.0609, 0.0640],
        [0.0650, 0.0600],
        [0.0583, 0.0669],
        [0.0683, 0.0570],
        [0.0648, 0.0601],
        [0.0660, 0.0591],
        [0.0605, 0.0644]], device='cuda:0')
 Batch: 5 of modal classification Duration: 0:00:00.395796
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0009, 0.0012],
        [0.0005, 0.0009],
        [0.0005, 0.0006],
        [0.0005, 0.0007],
        [0.0004, 0.0005],
        [0.0005, 0.0007],
        [0.0006, 0.0010],
        [0.0005, 0.0006],
        [0.0010, 0.0015],
        [0.0005, 0.0007],
        [0.0006, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0007, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0634, 0.0616],
        [0.0582, 0.0670],
        [0.0640, 0.0610],
        [0.0615, 0.0635],
        [0.0652, 0.0599],
        [0.0622, 0.0628],
        [0.0614, 0.0636],
        [0.0637, 0.0612],
        [0.0617, 0.0632],
        [0.0637, 0.0612],
        [0.0633, 0.0616],
        [0.0618, 0.0631],
        [0.0619, 0.0630],
        [0.0605, 0.0646],
        [0.0610, 0.0640],
        [0.0665, 0.0587]], device='cuda:0')
 Batch: 6 of modal classification Duration: 0:00:00.253208
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0003],
        [0.0005, 0.0007],
        [0.0007, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0005],
        [0.0006, 0.0010],
        [0.0008, 0.0011],
        [0.0003, 0.0004],
        [0.0006, 0.0008],
        [0.0004, 0.0006],
        [0.0005, 0.0005],
        [0.0006, 0.0009],
        [0.0007, 0.0011],
        [0.0002, 0.0004],
        [0.0008, 0.0011],
        [0.0007, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0672, 0.0581],
        [0.0624, 0.0625],
        [0.0641, 0.0609],
        [0.0586, 0.0666],
        [0.0643, 0.0606],
        [0.0601, 0.0649],
        [0.0623, 0.0627],
        [0.0627, 0.0622],
        [0.0619, 0.0630],
        [0.0610, 0.0640],
        [0.0661, 0.0590],
        [0.0600, 0.0651],
        [0.0611, 0.0639],
        [0.0610, 0.0640],
        [0.0621, 0.0628],
        [0.0652, 0.0598]], device='cuda:0')
 Batch: 7 of modal classification Duration: 0:00:00.536632
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0013],
        [0.0005, 0.0010],
        [0.0005, 0.0008],
        [0.0005, 0.0006],
        [0.0006, 0.0008],
        [0.0002, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0009, 0.0013],
        [0.0004, 0.0006],
        [0.0006, 0.0007],
        [0.0007, 0.0009],
        [0.0005, 0.0009],
        [0.0006, 0.0010],
        [0.0004, 0.0006],
        [0.0003, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0598, 0.0651],
        [0.0587, 0.0663],
        [0.0626, 0.0622],
        [0.0666, 0.0585],
        [0.0642, 0.0606],
        [0.0550, 0.0708],
        [0.0608, 0.0640],
        [0.0602, 0.0647],
        [0.0637, 0.0611],
        [0.0642, 0.0607],
        [0.0680, 0.0572],
        [0.0638, 0.0610],
        [0.0588, 0.0662],
        [0.0625, 0.0623],
        [0.0621, 0.0627],
        [0.0688, 0.0566]], device='cuda:0')
 Batch: 8 of modal classification Duration: 0:00:00.452472
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0003, 0.0004],
        [0.0007, 0.0010],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0005, 0.0007],
        [0.0004, 0.0004],
        [0.0003, 0.0007],
        [0.0007, 0.0009],
        [0.0004, 0.0006],
        [0.0006, 0.0010],
        [0.0006, 0.0008],
        [0.0011, 0.0011],
        [0.0005, 0.0009],
        [0.0008, 0.0011],
        [0.0006, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0587, 0.0664],
        [0.0625, 0.0624],
        [0.0617, 0.0632],
        [0.0638, 0.0611],
        [0.0626, 0.0623],
        [0.0622, 0.0627],
        [0.0651, 0.0599],
        [0.0587, 0.0664],
        [0.0641, 0.0608],
        [0.0619, 0.0630],
        [0.0618, 0.0631],
        [0.0653, 0.0597],
        [0.0680, 0.0574],
        [0.0584, 0.0668],
        [0.0645, 0.0605],
        [0.0607, 0.0642]], device='cuda:0')
 Batch: 9 of modal classification Duration: 0:00:00.355772
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0002],
        [0.0003, 0.0006],
        [0.0006, 0.0008],
        [0.0004, 0.0011],
        [0.0005, 0.0006],
        [0.0005, 0.0009],
        [0.0008, 0.0012],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0005, 0.0007],
        [0.0004, 0.0006],
        [0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0726, 0.0537],
        [0.0612, 0.0637],
        [0.0631, 0.0617],
        [0.0558, 0.0697],
        [0.0643, 0.0605],
        [0.0604, 0.0645],
        [0.0622, 0.0626],
        [0.0611, 0.0638],
        [0.0604, 0.0645],
        [0.0640, 0.0609],
        [0.0631, 0.0617],
        [0.0637, 0.0611],
        [0.0578, 0.0674],
        [0.0604, 0.0645],
        [0.0631, 0.0617],
        [0.0668, 0.0582]], device='cuda:0')
 Batch: 10 of modal classification Duration: 0:00:00.425983
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0006, 0.0008],
        [0.0003, 0.0004],
        [0.0006, 0.0010],
        [0.0004, 0.0006],
        [0.0005, 0.0007],
        [0.0003, 0.0004],
        [0.0005, 0.0007],
        [0.0007, 0.0009],
        [0.0006, 0.0008],
        [0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0004, 0.0005],
        [0.0006, 0.0010],
        [0.0005, 0.0006],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0637, 0.0613],
        [0.0656, 0.0594],
        [0.0604, 0.0646],
        [0.0619, 0.0630],
        [0.0620, 0.0629],
        [0.0633, 0.0616],
        [0.0613, 0.0636],
        [0.0642, 0.0608],
        [0.0648, 0.0602],
        [0.0633, 0.0616],
        [0.0610, 0.0640],
        [0.0603, 0.0647],
        [0.0639, 0.0611],
        [0.0614, 0.0635],
        [0.0654, 0.0597],
        [0.0575, 0.0678]], device='cuda:0')
 Batch: 11 of modal classification Duration: 0:00:00.359877
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0007, 0.0009],
        [0.0007, 0.0012],
        [0.0004, 0.0008],
        [0.0005, 0.0005],
        [0.0003, 0.0004],
        [0.0005, 0.0006]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1225, 0.1272],
        [0.1216, 0.1282],
        [0.1300, 0.1199],
        [0.1212, 0.1287],
        [0.1150, 0.1356],
        [0.1346, 0.1158],
        [0.1261, 0.1237],
        [0.1290, 0.1209]], device='cuda:0')
 Batch: 12 of modal classification Duration: 0:00:00.180063
acc:  0.49
Time taken to execute the en SA task with prompt type modal, variation 0 and batchsize 16: 0:00:04.882996
path ['42', 'en', 'bloom-big', 'SA', 'modal', 'prompt_id_0']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([103, 2])
answers_probs just softmax dim 0: tensor([[0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097]], device='cuda:0')
tensor([[0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA modal 1 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0005, 0.0007],
        [0.0004, 0.0008],
        [0.0004, 0.0004],
        [0.0004, 0.0007],
        [0.0005, 0.0006],
        [0.0004, 0.0006],
        [0.0007, 0.0008],
        [0.0004, 0.0010],
        [0.0004, 0.0006],
        [0.0007, 0.0012],
        [0.0007, 0.0012],
        [0.0005, 0.0013],
        [0.0002, 0.0004],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0601, 0.0647],
        [0.0598, 0.0651],
        [0.0662, 0.0588],
        [0.0598, 0.0651],
        [0.0705, 0.0552],
        [0.0622, 0.0626],
        [0.0654, 0.0595],
        [0.0656, 0.0593],
        [0.0674, 0.0577],
        [0.0562, 0.0693],
        [0.0635, 0.0613],
        [0.0631, 0.0617],
        [0.0621, 0.0627],
        [0.0559, 0.0697],
        [0.0621, 0.0627],
        [0.0601, 0.0647]], device='cuda:0')
 Batch: 0 of modal classification Duration: 0:00:00.368231
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0005, 0.0008],
        [0.0004, 0.0005],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0004, 0.0005],
        [0.0005, 0.0010],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0651, 0.0598],
        [0.0624, 0.0625],
        [0.0670, 0.0582],
        [0.0646, 0.0603],
        [0.0605, 0.0644],
        [0.0673, 0.0579],
        [0.0589, 0.0662],
        [0.0605, 0.0644],
        [0.0624, 0.0625],
        [0.0620, 0.0628],
        [0.0588, 0.0663],
        [0.0567, 0.0688],
        [0.0628, 0.0620],
        [0.0617, 0.0632],
        [0.0666, 0.0585],
        [0.0626, 0.0622]], device='cuda:0')
 Batch: 1 of modal classification Duration: 0:00:00.421568
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0005, 0.0005],
        [0.0004, 0.0007],
        [0.0005, 0.0006],
        [0.0002, 0.0004],
        [0.0008, 0.0012],
        [0.0005, 0.0009],
        [0.0004, 0.0008],
        [0.0006, 0.0011],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0007, 0.0009],
        [0.0004, 0.0006],
        [0.0007, 0.0011],
        [0.0004, 0.0006],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0574, 0.0678],
        [0.0706, 0.0552],
        [0.0604, 0.0645],
        [0.0672, 0.0580],
        [0.0599, 0.0651],
        [0.0636, 0.0613],
        [0.0622, 0.0627],
        [0.0586, 0.0665],
        [0.0609, 0.0639],
        [0.0596, 0.0654],
        [0.0614, 0.0635],
        [0.0659, 0.0591],
        [0.0623, 0.0626],
        [0.0626, 0.0622],
        [0.0631, 0.0618],
        [0.0644, 0.0605]], device='cuda:0')
 Batch: 2 of modal classification Duration: 0:00:00.334310
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0008],
        [0.0005, 0.0009],
        [0.0004, 0.0006],
        [0.0003, 0.0008],
        [0.0004, 0.0005],
        [0.0005, 0.0009],
        [0.0002, 0.0005],
        [0.0005, 0.0005],
        [0.0003, 0.0004],
        [0.0005, 0.0009],
        [0.0005, 0.0007],
        [0.0003, 0.0006],
        [0.0006, 0.0007],
        [0.0006, 0.0010],
        [0.0010, 0.0011],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0647, 0.0602],
        [0.0598, 0.0651],
        [0.0626, 0.0622],
        [0.0545, 0.0715],
        [0.0659, 0.0591],
        [0.0598, 0.0651],
        [0.0584, 0.0667],
        [0.0689, 0.0565],
        [0.0645, 0.0603],
        [0.0595, 0.0654],
        [0.0644, 0.0604],
        [0.0601, 0.0647],
        [0.0645, 0.0603],
        [0.0605, 0.0644],
        [0.0684, 0.0569],
        [0.0636, 0.0612]], device='cuda:0')
 Batch: 3 of modal classification Duration: 0:00:00.545228
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0003, 0.0009],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0005, 0.0006],
        [0.0003, 0.0009],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0631, 0.0618],
        [0.0621, 0.0628],
        [0.0606, 0.0644],
        [0.0648, 0.0602],
        [0.0626, 0.0623],
        [0.0636, 0.0613],
        [0.0607, 0.0643],
        [0.0591, 0.0660],
        [0.0636, 0.0613],
        [0.0613, 0.0636],
        [0.0686, 0.0569],
        [0.0587, 0.0664],
        [0.0637, 0.0612],
        [0.0610, 0.0639],
        [0.0615, 0.0634],
        [0.0649, 0.0601]], device='cuda:0')
 Batch: 4 of modal classification Duration: 0:00:00.399214
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0006, 0.0009],
        [0.0005, 0.0007],
        [0.0006, 0.0009],
        [0.0006, 0.0008],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0007, 0.0007],
        [0.0004, 0.0006],
        [0.0003, 0.0004],
        [0.0004, 0.0008],
        [0.0004, 0.0006],
        [0.0006, 0.0010],
        [0.0004, 0.0005],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0572, 0.0682],
        [0.0626, 0.0623],
        [0.0617, 0.0632],
        [0.0631, 0.0618],
        [0.0634, 0.0616],
        [0.0628, 0.0622],
        [0.0616, 0.0633],
        [0.0615, 0.0635],
        [0.0677, 0.0577],
        [0.0618, 0.0631],
        [0.0631, 0.0618],
        [0.0599, 0.0651],
        [0.0631, 0.0618],
        [0.0619, 0.0630],
        [0.0637, 0.0612],
        [0.0647, 0.0603]], device='cuda:0')
 Batch: 5 of modal classification Duration: 0:00:00.396179
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0009],
        [0.0005, 0.0008],
        [0.0006, 0.0008],
        [0.0006, 0.0018],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0005, 0.0006],
        [0.0004, 0.0008],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0002, 0.0006],
        [0.0005, 0.0009],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0002, 0.0002],
        [0.0003, 0.0002]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0556, 0.0699],
        [0.0615, 0.0631],
        [0.0647, 0.0600],
        [0.0552, 0.0704],
        [0.0629, 0.0618],
        [0.0607, 0.0639],
        [0.0679, 0.0572],
        [0.0607, 0.0639],
        [0.0662, 0.0587],
        [0.0640, 0.0607],
        [0.0565, 0.0687],
        [0.0588, 0.0660],
        [0.0616, 0.0630],
        [0.0617, 0.0629],
        [0.0680, 0.0571],
        [0.0738, 0.0526]], device='cuda:0')
 Batch: 6 of modal classification Duration: 0:00:00.360676
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0003, 0.0004],
        [0.0004, 0.0008],
        [0.0006, 0.0009],
        [0.0009, 0.0014],
        [0.0006, 0.0009],
        [0.0004, 0.0005],
        [0.0004, 0.0006],
        [0.0005, 0.0006],
        [0.0003, 0.0006],
        [0.0005, 0.0007],
        [0.0004, 0.0005],
        [0.0005, 0.0013],
        [0.0003, 0.0004],
        [0.0008, 0.0013],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0611, 0.0638],
        [0.0651, 0.0599],
        [0.0579, 0.0674],
        [0.0618, 0.0631],
        [0.0631, 0.0617],
        [0.0628, 0.0621],
        [0.0687, 0.0567],
        [0.0613, 0.0636],
        [0.0641, 0.0608],
        [0.0576, 0.0677],
        [0.0656, 0.0594],
        [0.0655, 0.0595],
        [0.0572, 0.0681],
        [0.0642, 0.0607],
        [0.0614, 0.0634],
        [0.0627, 0.0622]], device='cuda:0')
 Batch: 7 of modal classification Duration: 0:00:00.338711
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0004, 0.0006],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0008],
        [0.0006, 0.0008],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0004, 0.0011],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0575, 0.0677],
        [0.0652, 0.0597],
        [0.0618, 0.0631],
        [0.0591, 0.0659],
        [0.0674, 0.0579],
        [0.0627, 0.0622],
        [0.0660, 0.0591],
        [0.0598, 0.0652],
        [0.0667, 0.0584],
        [0.0654, 0.0596],
        [0.0603, 0.0646],
        [0.0618, 0.0631],
        [0.0633, 0.0615],
        [0.0629, 0.0620],
        [0.0577, 0.0675],
        [0.0624, 0.0624]], device='cuda:0')
 Batch: 8 of modal classification Duration: 0:00:00.449188
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0008],
        [0.0003, 0.0010],
        [0.0003, 0.0005],
        [0.0005, 0.0009],
        [0.0005, 0.0007],
        [0.0005, 0.0011],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0676, 0.0576],
        [0.0562, 0.0693],
        [0.0624, 0.0625],
        [0.0627, 0.0621],
        [0.0683, 0.0571],
        [0.0597, 0.0653],
        [0.0614, 0.0634],
        [0.0622, 0.0627],
        [0.0668, 0.0583],
        [0.0610, 0.0639],
        [0.0622, 0.0627],
        [0.0638, 0.0611],
        [0.0624, 0.0624],
        [0.0624, 0.0625],
        [0.0634, 0.0614],
        [0.0577, 0.0676]], device='cuda:0')
 Batch: 9 of modal classification Duration: 0:00:00.400977
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0003, 0.0005],
        [0.0007, 0.0007],
        [0.0005, 0.0005],
        [0.0008, 0.0015],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0002, 0.0004],
        [0.0004, 0.0006],
        [0.0005, 0.0006],
        [0.0004, 0.0008],
        [0.0007, 0.0007],
        [0.0004, 0.0005],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0654, 0.0595],
        [0.0618, 0.0630],
        [0.0688, 0.0566],
        [0.0685, 0.0569],
        [0.0594, 0.0656],
        [0.0615, 0.0634],
        [0.0611, 0.0637],
        [0.0602, 0.0647],
        [0.0615, 0.0633],
        [0.0641, 0.0608],
        [0.0578, 0.0673],
        [0.0680, 0.0572],
        [0.0647, 0.0602],
        [0.0604, 0.0644],
        [0.0601, 0.0648],
        [0.0567, 0.0687]], device='cuda:0')
 Batch: 10 of modal classification Duration: 0:00:00.404402
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0008],
        [0.0003, 0.0004],
        [0.0003, 0.0008],
        [0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0003],
        [0.0003, 0.0006],
        [0.0005, 0.0006],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0578, 0.0673],
        [0.0621, 0.0627],
        [0.0665, 0.0585],
        [0.0688, 0.0566],
        [0.0610, 0.0639],
        [0.0625, 0.0623],
        [0.0581, 0.0670],
        [0.0650, 0.0599],
        [0.0621, 0.0627],
        [0.0614, 0.0634],
        [0.0565, 0.0690],
        [0.0620, 0.0629],
        [0.0668, 0.0583],
        [0.0597, 0.0652],
        [0.0667, 0.0584],
        [0.0631, 0.0617]], device='cuda:0')
 Batch: 11 of modal classification Duration: 0:00:00.357557
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0001, 0.0004],
        [0.0007, 0.0013],
        [0.0004, 0.0009],
        [0.0005, 0.0006],
        [0.0004, 0.0005],
        [0.0004, 0.0006],
        [0.0003, 0.0008]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1272, 0.1221],
        [0.1107, 0.1403],
        [0.1244, 0.1248],
        [0.1154, 0.1346],
        [0.1358, 0.1144],
        [0.1387, 0.1120],
        [0.1317, 0.1179],
        [0.1160, 0.1339]], device='cuda:0')
 Batch: 12 of modal classification Duration: 0:00:00.227197
acc:  0.465
Time taken to execute the en SA task with prompt type modal, variation 1 and batchsize 16: 0:00:05.018970
path ['42', 'en', 'bloom-big', 'SA', 'modal', 'prompt_id_1']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([109, 2])
answers_probs just softmax dim 0: tensor([[0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092]], device='cuda:0')
tensor([[0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA modal 2 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0004, 0.0009],
        [0.0005, 0.0013],
        [0.0004, 0.0011],
        [0.0003, 0.0007],
        [0.0007, 0.0016],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0002, 0.0003],
        [0.0005, 0.0013],
        [0.0003, 0.0006],
        [0.0004, 0.0014],
        [0.0001, 0.0003],
        [0.0004, 0.0010],
        [0.0006, 0.0012],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0636, 0.0613],
        [0.0618, 0.0631],
        [0.0599, 0.0651],
        [0.0614, 0.0635],
        [0.0610, 0.0639],
        [0.0636, 0.0613],
        [0.0614, 0.0635],
        [0.0636, 0.0613],
        [0.0703, 0.0555],
        [0.0609, 0.0640],
        [0.0635, 0.0614],
        [0.0588, 0.0663],
        [0.0625, 0.0624],
        [0.0620, 0.0629],
        [0.0645, 0.0605],
        [0.0610, 0.0639]], device='cuda:0')
 Batch: 0 of modal classification Duration: 0:00:00.427388
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0011],
        [0.0003, 0.0013],
        [0.0004, 0.0009],
        [0.0004, 0.0011],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0005, 0.0013],
        [0.0004, 0.0014],
        [0.0003, 0.0006],
        [0.0003, 0.0010],
        [0.0003, 0.0004],
        [0.0004, 0.0014],
        [0.0004, 0.0011],
        [0.0004, 0.0012],
        [0.0005, 0.0016],
        [0.0004, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0612, 0.0637],
        [0.0579, 0.0673],
        [0.0639, 0.0610],
        [0.0630, 0.0619],
        [0.0645, 0.0604],
        [0.0642, 0.0607],
        [0.0638, 0.0611],
        [0.0599, 0.0651],
        [0.0648, 0.0601],
        [0.0615, 0.0634],
        [0.0706, 0.0552],
        [0.0595, 0.0655],
        [0.0641, 0.0608],
        [0.0605, 0.0644],
        [0.0599, 0.0651],
        [0.0608, 0.0642]], device='cuda:0')
 Batch: 1 of modal classification Duration: 0:00:00.362841
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0015],
        [0.0004, 0.0006],
        [0.0002, 0.0005],
        [0.0004, 0.0011],
        [0.0005, 0.0014],
        [0.0003, 0.0008],
        [0.0004, 0.0018],
        [0.0007, 0.0022],
        [0.0005, 0.0016],
        [0.0007, 0.0017],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0009],
        [0.0004, 0.0011],
        [0.0004, 0.0010],
        [0.0005, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0638, 0.0612],
        [0.0686, 0.0569],
        [0.0633, 0.0617],
        [0.0625, 0.0624],
        [0.0614, 0.0636],
        [0.0627, 0.0622],
        [0.0575, 0.0679],
        [0.0602, 0.0648],
        [0.0609, 0.0640],
        [0.0646, 0.0604],
        [0.0635, 0.0615],
        [0.0618, 0.0631],
        [0.0608, 0.0641],
        [0.0622, 0.0627],
        [0.0622, 0.0627],
        [0.0642, 0.0608]], device='cuda:0')
 Batch: 2 of modal classification Duration: 0:00:00.406209
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0011],
        [0.0003, 0.0012],
        [0.0003, 0.0010],
        [0.0006, 0.0021],
        [0.0004, 0.0012],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0008],
        [0.0002, 0.0005],
        [0.0008, 0.0017],
        [0.0004, 0.0017],
        [0.0005, 0.0020],
        [0.0003, 0.0007],
        [0.0003, 0.0008],
        [0.0005, 0.0010],
        [0.0004, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0648, 0.0601],
        [0.0589, 0.0662],
        [0.0605, 0.0644],
        [0.0598, 0.0651],
        [0.0617, 0.0631],
        [0.0661, 0.0589],
        [0.0672, 0.0580],
        [0.0599, 0.0650],
        [0.0640, 0.0609],
        [0.0653, 0.0597],
        [0.0564, 0.0690],
        [0.0576, 0.0676],
        [0.0653, 0.0597],
        [0.0633, 0.0615],
        [0.0663, 0.0588],
        [0.0628, 0.0620]], device='cuda:0')
 Batch: 3 of modal classification Duration: 0:00:00.426344
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0002, 0.0008],
        [0.0005, 0.0013],
        [0.0002, 0.0003],
        [0.0004, 0.0009],
        [0.0008, 0.0013],
        [0.0003, 0.0008],
        [0.0003, 0.0011],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0007],
        [0.0005, 0.0010],
        [0.0004, 0.0012],
        [0.0005, 0.0013],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0655, 0.0595],
        [0.0577, 0.0676],
        [0.0619, 0.0629],
        [0.0666, 0.0585],
        [0.0624, 0.0625],
        [0.0692, 0.0563],
        [0.0617, 0.0632],
        [0.0572, 0.0681],
        [0.0655, 0.0595],
        [0.0634, 0.0614],
        [0.0645, 0.0604],
        [0.0604, 0.0645],
        [0.0631, 0.0617],
        [0.0591, 0.0659],
        [0.0621, 0.0627],
        [0.0598, 0.0652]], device='cuda:0')
 Batch: 4 of modal classification Duration: 0:00:00.448976
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0010],
        [0.0005, 0.0009],
        [0.0005, 0.0008],
        [0.0004, 0.0010],
        [0.0004, 0.0009],
        [0.0004, 0.0008],
        [0.0005, 0.0013],
        [0.0006, 0.0009],
        [0.0003, 0.0005],
        [0.0004, 0.0008],
        [0.0005, 0.0011],
        [0.0002, 0.0005],
        [0.0003, 0.0010],
        [0.0004, 0.0010],
        [0.0002, 0.0004],
        [0.0003, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0568, 0.0686],
        [0.0635, 0.0614],
        [0.0673, 0.0579],
        [0.0612, 0.0637],
        [0.0619, 0.0629],
        [0.0640, 0.0609],
        [0.0615, 0.0633],
        [0.0669, 0.0583],
        [0.0679, 0.0574],
        [0.0636, 0.0613],
        [0.0628, 0.0621],
        [0.0616, 0.0633],
        [0.0587, 0.0664],
        [0.0597, 0.0653],
        [0.0623, 0.0625],
        [0.0603, 0.0647]], device='cuda:0')
 Batch: 5 of modal classification Duration: 0:00:00.357669
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0015],
        [0.0003, 0.0009],
        [0.0004, 0.0008],
        [0.0002, 0.0008],
        [0.0005, 0.0009],
        [0.0006, 0.0015],
        [0.0005, 0.0011],
        [0.0004, 0.0011],
        [0.0004, 0.0007],
        [0.0003, 0.0009],
        [0.0006, 0.0020],
        [0.0005, 0.0013],
        [0.0006, 0.0021],
        [0.0004, 0.0012],
        [0.0003, 0.0008],
        [0.0005, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0619, 0.0630],
        [0.0610, 0.0640],
        [0.0661, 0.0590],
        [0.0595, 0.0656],
        [0.0661, 0.0590],
        [0.0617, 0.0632],
        [0.0650, 0.0600],
        [0.0631, 0.0619],
        [0.0660, 0.0591],
        [0.0615, 0.0634],
        [0.0592, 0.0658],
        [0.0632, 0.0618],
        [0.0599, 0.0651],
        [0.0611, 0.0639],
        [0.0611, 0.0638],
        [0.0637, 0.0612]], device='cuda:0')
 Batch: 6 of modal classification Duration: 0:00:00.365745
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0006],
        [0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0004, 0.0010],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0004, 0.0008],
        [0.0002, 0.0003],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0005, 0.0010],
        [0.0006, 0.0015],
        [0.0004, 0.0014],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0594, 0.0656],
        [0.0620, 0.0628],
        [0.0632, 0.0616],
        [0.0591, 0.0659],
        [0.0600, 0.0649],
        [0.0617, 0.0631],
        [0.0622, 0.0626],
        [0.0656, 0.0594],
        [0.0696, 0.0560],
        [0.0644, 0.0605],
        [0.0589, 0.0661],
        [0.0637, 0.0611],
        [0.0639, 0.0610],
        [0.0606, 0.0642],
        [0.0564, 0.0691],
        [0.0693, 0.0562]], device='cuda:0')
 Batch: 7 of modal classification Duration: 0:00:00.360897
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0004, 0.0009],
        [0.0004, 0.0009],
        [0.0003, 0.0005],
        [0.0006, 0.0014],
        [0.0003, 0.0010],
        [0.0002, 0.0007],
        [0.0003, 0.0006],
        [0.0005, 0.0016],
        [0.0003, 0.0004],
        [0.0005, 0.0011],
        [0.0003, 0.0010],
        [0.0005, 0.0012],
        [0.0004, 0.0014],
        [0.0003, 0.0008],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0607, 0.0642],
        [0.0633, 0.0616],
        [0.0646, 0.0604],
        [0.0668, 0.0583],
        [0.0632, 0.0617],
        [0.0572, 0.0681],
        [0.0609, 0.0640],
        [0.0664, 0.0587],
        [0.0607, 0.0642],
        [0.0683, 0.0570],
        [0.0635, 0.0614],
        [0.0592, 0.0658],
        [0.0633, 0.0616],
        [0.0578, 0.0674],
        [0.0613, 0.0636],
        [0.0628, 0.0621]], device='cuda:0')
 Batch: 8 of modal classification Duration: 0:00:00.328374
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0003, 0.0005],
        [0.0006, 0.0013],
        [0.0004, 0.0007],
        [0.0003, 0.0011],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0005, 0.0011],
        [0.0003, 0.0008],
        [0.0004, 0.0010],
        [0.0004, 0.0009],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0618, 0.0631],
        [0.0667, 0.0584],
        [0.0632, 0.0617],
        [0.0644, 0.0605],
        [0.0549, 0.0710],
        [0.0623, 0.0626],
        [0.0647, 0.0602],
        [0.0631, 0.0618],
        [0.0636, 0.0613],
        [0.0648, 0.0601],
        [0.0616, 0.0633],
        [0.0613, 0.0636],
        [0.0608, 0.0641],
        [0.0596, 0.0654],
        [0.0620, 0.0629],
        [0.0652, 0.0598]], device='cuda:0')
 Batch: 9 of modal classification Duration: 0:00:00.284882
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0012],
        [0.0004, 0.0012],
        [0.0007, 0.0019],
        [0.0004, 0.0010],
        [0.0003, 0.0009],
        [0.0005, 0.0014],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0004, 0.0008],
        [0.0005, 0.0015],
        [0.0006, 0.0016],
        [0.0004, 0.0010],
        [0.0006, 0.0016],
        [0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0005, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0676, 0.0577],
        [0.0596, 0.0654],
        [0.0608, 0.0641],
        [0.0612, 0.0637],
        [0.0604, 0.0645],
        [0.0595, 0.0655],
        [0.0659, 0.0591],
        [0.0590, 0.0660],
        [0.0663, 0.0588],
        [0.0611, 0.0638],
        [0.0602, 0.0647],
        [0.0611, 0.0638],
        [0.0623, 0.0625],
        [0.0683, 0.0570],
        [0.0648, 0.0602],
        [0.0618, 0.0630]], device='cuda:0')
 Batch: 10 of modal classification Duration: 0:00:00.425008
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0003, 0.0008],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0002, 0.0011],
        [0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0004, 0.0010],
        [0.0006, 0.0014],
        [0.0003, 0.0010],
        [0.0003, 0.0009],
        [0.0004, 0.0012],
        [0.0004, 0.0012],
        [0.0007, 0.0014],
        [0.0004, 0.0012],
        [0.0004, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0653, 0.0597],
        [0.0640, 0.0610],
        [0.0678, 0.0575],
        [0.0613, 0.0636],
        [0.0565, 0.0690],
        [0.0633, 0.0616],
        [0.0644, 0.0606],
        [0.0619, 0.0630],
        [0.0629, 0.0620],
        [0.0601, 0.0648],
        [0.0608, 0.0641],
        [0.0619, 0.0630],
        [0.0597, 0.0653],
        [0.0662, 0.0589],
        [0.0619, 0.0629],
        [0.0620, 0.0629]], device='cuda:0')
 Batch: 11 of modal classification Duration: 0:00:00.475190
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0005, 0.0012],
        [0.0003, 0.0008],
        [0.0006, 0.0013],
        [0.0005, 0.0014],
        [0.0003, 0.0004],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0001, 0.0002]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1251],
        [0.1250, 0.1249],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1249]], device='cuda:0')
tensor([[0.1215, 0.1280],
        [0.1170, 0.1330],
        [0.1217, 0.1278],
        [0.1152, 0.1350],
        [0.1400, 0.1111],
        [0.1308, 0.1190],
        [0.1192, 0.1305],
        [0.1347, 0.1155]], device='cuda:0')
 Batch: 12 of modal classification Duration: 0:00:00.296446
acc:  0.5
Time taken to execute the en SA task with prompt type modal, variation 2 and batchsize 16: 0:00:04.981805
path ['42', 'en', 'bloom-big', 'SA', 'modal', 'prompt_id_2']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([128, 2])
answers_probs just softmax dim 0: tensor([[0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078]], device='cuda:0')
tensor([[0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA modal 3 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0003, 0.0004],
        [0.0007, 0.0012],
        [0.0002, 0.0002],
        [0.0003, 0.0004],
        [0.0006, 0.0011],
        [0.0004, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0010],
        [0.0003, 0.0008],
        [0.0002, 0.0003],
        [0.0007, 0.0009],
        [0.0002, 0.0003],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0622, 0.0627],
        [0.0600, 0.0649],
        [0.0645, 0.0604],
        [0.0627, 0.0621],
        [0.0637, 0.0612],
        [0.0641, 0.0608],
        [0.0618, 0.0630],
        [0.0668, 0.0583],
        [0.0578, 0.0674],
        [0.0606, 0.0644],
        [0.0574, 0.0680],
        [0.0594, 0.0656],
        [0.0661, 0.0590],
        [0.0662, 0.0589],
        [0.0632, 0.0617],
        [0.0634, 0.0615]], device='cuda:0')
 Batch: 0 of modal classification Duration: 0:00:00.430754
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0011],
        [0.0006, 0.0011],
        [0.0004, 0.0005],
        [0.0003, 0.0004],
        [0.0004, 0.0005],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0005, 0.0008],
        [0.0002, 0.0004],
        [0.0002, 0.0002],
        [0.0003, 0.0003],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0006, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0618, 0.0631],
        [0.0604, 0.0646],
        [0.0645, 0.0604],
        [0.0647, 0.0602],
        [0.0632, 0.0617],
        [0.0634, 0.0615],
        [0.0603, 0.0647],
        [0.0604, 0.0646],
        [0.0629, 0.0619],
        [0.0616, 0.0633],
        [0.0640, 0.0609],
        [0.0706, 0.0552],
        [0.0659, 0.0592],
        [0.0576, 0.0676],
        [0.0582, 0.0669],
        [0.0606, 0.0643]], device='cuda:0')
 Batch: 1 of modal classification Duration: 0:00:00.399051
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0003, 0.0004],
        [0.0004, 0.0006],
        [0.0003, 0.0009],
        [0.0006, 0.0009],
        [0.0003, 0.0004],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0007, 0.0010],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0005, 0.0009],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0600, 0.0649],
        [0.0660, 0.0591],
        [0.0630, 0.0619],
        [0.0567, 0.0688],
        [0.0641, 0.0608],
        [0.0682, 0.0572],
        [0.0599, 0.0650],
        [0.0608, 0.0642],
        [0.0616, 0.0633],
        [0.0646, 0.0603],
        [0.0630, 0.0619],
        [0.0624, 0.0625],
        [0.0618, 0.0630],
        [0.0597, 0.0653],
        [0.0624, 0.0625],
        [0.0657, 0.0593]], device='cuda:0')
 Batch: 2 of modal classification Duration: 0:00:00.453057
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[4.4847e-04, 7.6866e-04],
        [9.8288e-05, 1.4877e-04],
        [4.8590e-04, 8.7976e-04],
        [3.2115e-04, 7.1812e-04],
        [4.2939e-04, 7.5960e-04],
        [2.6202e-04, 3.7837e-04],
        [3.8171e-04, 7.7724e-04],
        [2.0206e-04, 3.3832e-04],
        [3.5858e-04, 5.7316e-04],
        [2.5010e-04, 3.6407e-04],
        [2.7561e-04, 5.5695e-04],
        [3.3498e-04, 4.8733e-04],
        [5.6696e-04, 6.5279e-04],
        [4.2272e-04, 7.5388e-04],
        [4.1318e-04, 8.6117e-04],
        [3.2568e-04, 7.6962e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0625, 0.0624],
        [0.0644, 0.0606],
        [0.0617, 0.0632],
        [0.0589, 0.0662],
        [0.0620, 0.0628],
        [0.0651, 0.0599],
        [0.0601, 0.0649],
        [0.0628, 0.0620],
        [0.0635, 0.0614],
        [0.0650, 0.0600],
        [0.0602, 0.0648],
        [0.0650, 0.0600],
        [0.0688, 0.0567],
        [0.0619, 0.0630],
        [0.0598, 0.0652],
        [0.0582, 0.0670]], device='cuda:0')
 Batch: 3 of modal classification Duration: 0:00:00.407130
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0005],
        [0.0003, 0.0008],
        [0.0002, 0.0002],
        [0.0001, 0.0001],
        [0.0003, 0.0007],
        [0.0004, 0.0006],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0005, 0.0007],
        [0.0004, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0004, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0680, 0.0572],
        [0.0580, 0.0672],
        [0.0646, 0.0603],
        [0.0678, 0.0574],
        [0.0593, 0.0656],
        [0.0648, 0.0601],
        [0.0661, 0.0589],
        [0.0628, 0.0620],
        [0.0625, 0.0623],
        [0.0624, 0.0625],
        [0.0632, 0.0617],
        [0.0662, 0.0588],
        [0.0583, 0.0667],
        [0.0583, 0.0668],
        [0.0606, 0.0643],
        [0.0571, 0.0682]], device='cuda:0')
 Batch: 4 of modal classification Duration: 0:00:00.246969
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0006, 0.0008],
        [0.0002, 0.0004],
        [0.0005, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0005, 0.0008],
        [0.0003, 0.0003],
        [0.0002, 0.0003],
        [0.0004, 0.0004],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0614, 0.0635],
        [0.0617, 0.0632],
        [0.0583, 0.0669],
        [0.0653, 0.0597],
        [0.0635, 0.0614],
        [0.0624, 0.0625],
        [0.0636, 0.0613],
        [0.0573, 0.0681],
        [0.0649, 0.0600],
        [0.0596, 0.0654],
        [0.0617, 0.0632],
        [0.0618, 0.0631],
        [0.0661, 0.0590],
        [0.0615, 0.0634],
        [0.0680, 0.0573],
        [0.0630, 0.0619]], device='cuda:0')
 Batch: 5 of modal classification Duration: 0:00:00.403774
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0005],
        [0.0006, 0.0009],
        [0.0005, 0.0010],
        [0.0003, 0.0003],
        [0.0004, 0.0010],
        [0.0002, 0.0003],
        [0.0004, 0.0005],
        [0.0005, 0.0008],
        [0.0003, 0.0004],
        [0.0004, 0.0009],
        [0.0002, 0.0003],
        [0.0006, 0.0009],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0649, 0.0600],
        [0.0640, 0.0609],
        [0.0602, 0.0647],
        [0.0676, 0.0577],
        [0.0570, 0.0684],
        [0.0648, 0.0601],
        [0.0657, 0.0593],
        [0.0644, 0.0605],
        [0.0619, 0.0630],
        [0.0587, 0.0664],
        [0.0640, 0.0609],
        [0.0630, 0.0619],
        [0.0625, 0.0623],
        [0.0631, 0.0618],
        [0.0590, 0.0661],
        [0.0592, 0.0659]], device='cuda:0')
 Batch: 6 of modal classification Duration: 0:00:00.427660
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0005, 0.0010],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0002, 0.0002],
        [0.0003, 0.0004],
        [0.0001, 0.0004],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0011],
        [0.0003, 0.0008],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0607, 0.0641],
        [0.0622, 0.0626],
        [0.0632, 0.0616],
        [0.0650, 0.0599],
        [0.0594, 0.0656],
        [0.0668, 0.0583],
        [0.0648, 0.0601],
        [0.0630, 0.0618],
        [0.0693, 0.0562],
        [0.0659, 0.0591],
        [0.0576, 0.0676],
        [0.0602, 0.0646],
        [0.0643, 0.0606],
        [0.0557, 0.0699],
        [0.0583, 0.0668],
        [0.0637, 0.0611]], device='cuda:0')
 Batch: 7 of modal classification Duration: 0:00:00.358641
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0006, 0.0008],
        [0.0010, 0.0018],
        [0.0007, 0.0011],
        [0.0008, 0.0011],
        [0.0003, 0.0005],
        [0.0005, 0.0010],
        [0.0004, 0.0007],
        [0.0003, 0.0007],
        [0.0004, 0.0006],
        [0.0008, 0.0015],
        [0.0001, 0.0002],
        [0.0001, 0.0002],
        [0.0004, 0.0006],
        [0.0003, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0629, 0.0620],
        [0.0617, 0.0632],
        [0.0642, 0.0608],
        [0.0608, 0.0641],
        [0.0620, 0.0628],
        [0.0642, 0.0608],
        [0.0617, 0.0632],
        [0.0585, 0.0666],
        [0.0600, 0.0650],
        [0.0580, 0.0672],
        [0.0615, 0.0634],
        [0.0599, 0.0651],
        [0.0651, 0.0598],
        [0.0640, 0.0609],
        [0.0658, 0.0593],
        [0.0697, 0.0559]], device='cuda:0')
 Batch: 8 of modal classification Duration: 0:00:00.451096
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0002, 0.0004],
        [0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0003, 0.0007],
        [0.0004, 0.0004],
        [0.0010, 0.0015],
        [0.0004, 0.0007],
        [0.0002, 0.0003],
        [0.0003, 0.0009],
        [0.0004, 0.0005],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0655, 0.0594],
        [0.0616, 0.0632],
        [0.0591, 0.0659],
        [0.0591, 0.0659],
        [0.0597, 0.0652],
        [0.0657, 0.0593],
        [0.0636, 0.0612],
        [0.0679, 0.0574],
        [0.0597, 0.0652],
        [0.0682, 0.0571],
        [0.0643, 0.0605],
        [0.0621, 0.0627],
        [0.0612, 0.0636],
        [0.0547, 0.0712],
        [0.0641, 0.0608],
        [0.0635, 0.0613]], device='cuda:0')
 Batch: 9 of modal classification Duration: 0:00:00.448631
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0005],
        [0.0004, 0.0006],
        [0.0005, 0.0011],
        [0.0002, 0.0004],
        [0.0003, 0.0008],
        [0.0003, 0.0004],
        [0.0002, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0004],
        [0.0005, 0.0011],
        [0.0001, 0.0002],
        [0.0002, 0.0004],
        [0.0004, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0656, 0.0593],
        [0.0649, 0.0600],
        [0.0588, 0.0663],
        [0.0610, 0.0638],
        [0.0582, 0.0669],
        [0.0658, 0.0592],
        [0.0537, 0.0724],
        [0.0621, 0.0627],
        [0.0625, 0.0622],
        [0.0632, 0.0616],
        [0.0597, 0.0652],
        [0.0636, 0.0612],
        [0.0624, 0.0624],
        [0.0664, 0.0586],
        [0.0628, 0.0620],
        [0.0693, 0.0562]], device='cuda:0')
 Batch: 10 of modal classification Duration: 0:00:00.562651
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0002, 0.0003],
        [0.0003, 0.0009],
        [0.0006, 0.0011],
        [0.0002, 0.0003],
        [0.0003, 0.0004],
        [0.0004, 0.0010],
        [0.0006, 0.0013],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0006, 0.0009],
        [0.0002, 0.0003],
        [0.0005, 0.0011],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0007, 0.0014]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0590, 0.0660],
        [0.0613, 0.0635],
        [0.0565, 0.0689],
        [0.0627, 0.0621],
        [0.0664, 0.0587],
        [0.0669, 0.0582],
        [0.0580, 0.0672],
        [0.0615, 0.0633],
        [0.0601, 0.0649],
        [0.0641, 0.0608],
        [0.0653, 0.0597],
        [0.0679, 0.0573],
        [0.0601, 0.0648],
        [0.0646, 0.0603],
        [0.0643, 0.0606],
        [0.0613, 0.0635]], device='cuda:0')
 Batch: 11 of modal classification Duration: 0:00:00.495366
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0005, 0.0006],
        [0.0004, 0.0011],
        [0.0005, 0.0005],
        [0.0003, 0.0004],
        [0.0005, 0.0008],
        [0.0002, 0.0003],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1161, 0.1339],
        [0.1298, 0.1198],
        [0.1122, 0.1386],
        [0.1400, 0.1111],
        [0.1298, 0.1199],
        [0.1233, 0.1261],
        [0.1308, 0.1189],
        [0.1181, 0.1316]], device='cuda:0')
 Batch: 12 of modal classification Duration: 0:00:00.223590
acc:  0.42
Time taken to execute the en SA task with prompt type modal, variation 3 and batchsize 16: 0:00:05.324110
path ['42', 'en', 'bloom-big', 'SA', 'modal', 'prompt_id_3']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([119, 2])
answers_probs just softmax dim 0: tensor([[0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084]], device='cuda:0')
tensor([[0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084],
        [0.0084, 0.0084]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA modal 4 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0007, 0.0010],
        [0.0006, 0.0009],
        [0.0004, 0.0008],
        [0.0005, 0.0010],
        [0.0003, 0.0005],
        [0.0007, 0.0014],
        [0.0007, 0.0008],
        [0.0005, 0.0009],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0006, 0.0012],
        [0.0005, 0.0008],
        [0.0007, 0.0011],
        [0.0008, 0.0010],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0653, 0.0597],
        [0.0649, 0.0600],
        [0.0643, 0.0606],
        [0.0591, 0.0659],
        [0.0606, 0.0643],
        [0.0657, 0.0593],
        [0.0611, 0.0638],
        [0.0676, 0.0576],
        [0.0608, 0.0641],
        [0.0628, 0.0621],
        [0.0601, 0.0648],
        [0.0603, 0.0646],
        [0.0635, 0.0614],
        [0.0624, 0.0624],
        [0.0658, 0.0592],
        [0.0555, 0.0702]], device='cuda:0')
 Batch: 0 of modal classification Duration: 0:00:00.411458
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0006, 0.0009],
        [0.0005, 0.0012],
        [0.0004, 0.0008],
        [0.0008, 0.0011],
        [0.0005, 0.0007],
        [0.0006, 0.0012],
        [0.0008, 0.0008],
        [0.0008, 0.0013],
        [0.0004, 0.0004],
        [0.0005, 0.0009],
        [0.0004, 0.0007],
        [0.0004, 0.0005],
        [0.0008, 0.0018],
        [0.0007, 0.0020],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0608, 0.0640],
        [0.0642, 0.0606],
        [0.0576, 0.0676],
        [0.0584, 0.0666],
        [0.0649, 0.0599],
        [0.0651, 0.0597],
        [0.0612, 0.0636],
        [0.0711, 0.0547],
        [0.0633, 0.0614],
        [0.0692, 0.0562],
        [0.0623, 0.0624],
        [0.0608, 0.0640],
        [0.0662, 0.0588],
        [0.0580, 0.0670],
        [0.0557, 0.0698],
        [0.0613, 0.0635]], device='cuda:0')
 Batch: 1 of modal classification Duration: 0:00:00.485638
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0011, 0.0012],
        [0.0004, 0.0007],
        [0.0006, 0.0012],
        [0.0008, 0.0012],
        [0.0005, 0.0006],
        [0.0009, 0.0017],
        [0.0011, 0.0013],
        [0.0006, 0.0012],
        [0.0006, 0.0009],
        [0.0005, 0.0009],
        [0.0006, 0.0009],
        [0.0005, 0.0008],
        [0.0003, 0.0009],
        [0.0006, 0.0014],
        [0.0003, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0645, 0.0603],
        [0.0679, 0.0572],
        [0.0614, 0.0633],
        [0.0589, 0.0660],
        [0.0627, 0.0620],
        [0.0666, 0.0583],
        [0.0595, 0.0653],
        [0.0669, 0.0581],
        [0.0587, 0.0662],
        [0.0652, 0.0596],
        [0.0600, 0.0648],
        [0.0623, 0.0623],
        [0.0611, 0.0636],
        [0.0543, 0.0716],
        [0.0568, 0.0684],
        [0.0733, 0.0530]], device='cuda:0')
 Batch: 2 of modal classification Duration: 0:00:00.409276
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0010, 0.0012],
        [0.0005, 0.0008],
        [0.0006, 0.0010],
        [0.0004, 0.0008],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0010, 0.0011],
        [0.0006, 0.0010],
        [0.0006, 0.0009],
        [0.0004, 0.0010],
        [0.0009, 0.0013],
        [0.0007, 0.0011],
        [0.0011, 0.0015],
        [0.0004, 0.0011],
        [0.0006, 0.0014],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0669, 0.0582],
        [0.0612, 0.0637],
        [0.0627, 0.0621],
        [0.0599, 0.0651],
        [0.0632, 0.0617],
        [0.0605, 0.0644],
        [0.0690, 0.0565],
        [0.0624, 0.0624],
        [0.0649, 0.0600],
        [0.0591, 0.0660],
        [0.0641, 0.0607],
        [0.0637, 0.0612],
        [0.0654, 0.0596],
        [0.0552, 0.0706],
        [0.0593, 0.0657],
        [0.0627, 0.0621]], device='cuda:0')
 Batch: 3 of modal classification Duration: 0:00:00.319874
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0011],
        [0.0006, 0.0011],
        [0.0004, 0.0007],
        [0.0005, 0.0011],
        [0.0007, 0.0009],
        [0.0009, 0.0011],
        [0.0004, 0.0007],
        [0.0004, 0.0010],
        [0.0008, 0.0011],
        [0.0008, 0.0018],
        [0.0007, 0.0015],
        [0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0004, 0.0011],
        [0.0007, 0.0012],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0614, 0.0635],
        [0.0629, 0.0620],
        [0.0627, 0.0622],
        [0.0613, 0.0635],
        [0.0676, 0.0576],
        [0.0689, 0.0566],
        [0.0640, 0.0609],
        [0.0582, 0.0669],
        [0.0682, 0.0571],
        [0.0598, 0.0651],
        [0.0614, 0.0635],
        [0.0602, 0.0647],
        [0.0613, 0.0636],
        [0.0572, 0.0682],
        [0.0630, 0.0619],
        [0.0620, 0.0628]], device='cuda:0')
 Batch: 4 of modal classification Duration: 0:00:00.364899
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0009],
        [0.0004, 0.0009],
        [0.0007, 0.0015],
        [0.0008, 0.0012],
        [0.0004, 0.0007],
        [0.0006, 0.0013],
        [0.0004, 0.0010],
        [0.0006, 0.0014],
        [0.0004, 0.0008],
        [0.0006, 0.0009],
        [0.0003, 0.0006],
        [0.0008, 0.0013],
        [0.0006, 0.0010],
        [0.0005, 0.0010],
        [0.0005, 0.0011],
        [0.0006, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0647, 0.0603],
        [0.0608, 0.0642],
        [0.0613, 0.0637],
        [0.0652, 0.0599],
        [0.0641, 0.0609],
        [0.0592, 0.0659],
        [0.0592, 0.0659],
        [0.0603, 0.0647],
        [0.0611, 0.0639],
        [0.0661, 0.0590],
        [0.0610, 0.0640],
        [0.0638, 0.0611],
        [0.0649, 0.0601],
        [0.0628, 0.0621],
        [0.0609, 0.0641],
        [0.0648, 0.0602]], device='cuda:0')
 Batch: 5 of modal classification Duration: 0:00:00.313607
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0005, 0.0009],
        [0.0006, 0.0008],
        [0.0006, 0.0009],
        [0.0006, 0.0013],
        [0.0005, 0.0006],
        [0.0002, 0.0004],
        [0.0005, 0.0009],
        [0.0007, 0.0009],
        [0.0005, 0.0007],
        [0.0005, 0.0008],
        [0.0015, 0.0020],
        [0.0006, 0.0009],
        [0.0011, 0.0016],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0626, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0593, 0.0658],
        [0.0620, 0.0629],
        [0.0606, 0.0644],
        [0.0643, 0.0607],
        [0.0634, 0.0615],
        [0.0576, 0.0678],
        [0.0672, 0.0581],
        [0.0605, 0.0645],
        [0.0620, 0.0629],
        [0.0641, 0.0608],
        [0.0618, 0.0631],
        [0.0620, 0.0629],
        [0.0646, 0.0603],
        [0.0634, 0.0615],
        [0.0628, 0.0621],
        [0.0644, 0.0606]], device='cuda:0')
 Batch: 6 of modal classification Duration: 0:00:00.431605
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0015],
        [0.0010, 0.0017],
        [0.0004, 0.0007],
        [0.0006, 0.0012],
        [0.0004, 0.0007],
        [0.0006, 0.0013],
        [0.0006, 0.0010],
        [0.0003, 0.0005],
        [0.0005, 0.0009],
        [0.0009, 0.0014],
        [0.0007, 0.0013],
        [0.0005, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0006, 0.0009],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0576, 0.0677],
        [0.0641, 0.0608],
        [0.0646, 0.0604],
        [0.0611, 0.0638],
        [0.0622, 0.0627],
        [0.0599, 0.0652],
        [0.0623, 0.0626],
        [0.0643, 0.0607],
        [0.0626, 0.0623],
        [0.0644, 0.0606],
        [0.0620, 0.0629],
        [0.0670, 0.0582],
        [0.0623, 0.0626],
        [0.0607, 0.0643],
        [0.0654, 0.0597],
        [0.0596, 0.0655]], device='cuda:0')
 Batch: 7 of modal classification Duration: 0:00:00.333467
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0011, 0.0018],
        [0.0006, 0.0011],
        [0.0005, 0.0011],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0006, 0.0007],
        [0.0005, 0.0007],
        [0.0003, 0.0008],
        [0.0006, 0.0015],
        [0.0003, 0.0005],
        [0.0014, 0.0021],
        [0.0005, 0.0010],
        [0.0008, 0.0013],
        [0.0008, 0.0015],
        [0.0006, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0648, 0.0602],
        [0.0640, 0.0610],
        [0.0600, 0.0650],
        [0.0607, 0.0643],
        [0.0604, 0.0646],
        [0.0618, 0.0631],
        [0.0687, 0.0567],
        [0.0650, 0.0599],
        [0.0575, 0.0678],
        [0.0598, 0.0653],
        [0.0629, 0.0619],
        [0.0652, 0.0598],
        [0.0602, 0.0648],
        [0.0640, 0.0610],
        [0.0617, 0.0632],
        [0.0634, 0.0615]], device='cuda:0')
 Batch: 8 of modal classification Duration: 0:00:00.339613
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0010, 0.0012],
        [0.0005, 0.0010],
        [0.0005, 0.0009],
        [0.0006, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0005],
        [0.0006, 0.0010],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0006, 0.0010],
        [0.0007, 0.0009],
        [0.0003, 0.0005],
        [0.0006, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0614, 0.0636],
        [0.0599, 0.0652],
        [0.0587, 0.0664],
        [0.0671, 0.0582],
        [0.0609, 0.0640],
        [0.0618, 0.0631],
        [0.0664, 0.0587],
        [0.0616, 0.0633],
        [0.0663, 0.0589],
        [0.0614, 0.0636],
        [0.0618, 0.0631],
        [0.0612, 0.0638],
        [0.0624, 0.0625],
        [0.0646, 0.0603],
        [0.0602, 0.0648],
        [0.0644, 0.0606]], device='cuda:0')
 Batch: 9 of modal classification Duration: 0:00:00.446307
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0014],
        [0.0009, 0.0011],
        [0.0008, 0.0011],
        [0.0007, 0.0015],
        [0.0008, 0.0026],
        [0.0005, 0.0009],
        [0.0010, 0.0020],
        [0.0010, 0.0012],
        [0.0005, 0.0010],
        [0.0004, 0.0009],
        [0.0005, 0.0008],
        [0.0010, 0.0013],
        [0.0002, 0.0005],
        [0.0004, 0.0008],
        [0.0005, 0.0009],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0612, 0.0637],
        [0.0684, 0.0569],
        [0.0674, 0.0578],
        [0.0602, 0.0646],
        [0.0561, 0.0694],
        [0.0624, 0.0624],
        [0.0617, 0.0631],
        [0.0686, 0.0568],
        [0.0620, 0.0628],
        [0.0589, 0.0662],
        [0.0631, 0.0617],
        [0.0668, 0.0583],
        [0.0578, 0.0673],
        [0.0607, 0.0641],
        [0.0626, 0.0622],
        [0.0620, 0.0628]], device='cuda:0')
 Batch: 10 of modal classification Duration: 0:00:00.361470
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0006, 0.0007],
        [0.0004, 0.0014],
        [0.0006, 0.0010],
        [0.0004, 0.0007],
        [0.0007, 0.0011],
        [0.0011, 0.0015],
        [0.0006, 0.0011],
        [0.0008, 0.0011],
        [0.0005, 0.0010],
        [0.0005, 0.0007],
        [0.0003, 0.0005],
        [0.0007, 0.0012],
        [0.0004, 0.0010],
        [0.0005, 0.0009],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0637, 0.0612],
        [0.0683, 0.0571],
        [0.0555, 0.0703],
        [0.0633, 0.0615],
        [0.0607, 0.0643],
        [0.0627, 0.0621],
        [0.0666, 0.0585],
        [0.0615, 0.0634],
        [0.0652, 0.0597],
        [0.0614, 0.0635],
        [0.0651, 0.0599],
        [0.0625, 0.0623],
        [0.0626, 0.0622],
        [0.0586, 0.0665],
        [0.0614, 0.0635],
        [0.0608, 0.0641]], device='cuda:0')
 Batch: 11 of modal classification Duration: 0:00:00.447415
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0008, 0.0015],
        [0.0006, 0.0009],
        [0.0006, 0.0012],
        [0.0005, 0.0009],
        [0.0008, 0.0012],
        [0.0007, 0.0012],
        [0.0010, 0.0018]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251]], device='cuda:0')
tensor([[0.1254, 0.1245],
        [0.1231, 0.1268],
        [0.1312, 0.1190],
        [0.1189, 0.1314],
        [0.1266, 0.1234],
        [0.1275, 0.1225],
        [0.1258, 0.1241],
        [0.1216, 0.1284]], device='cuda:0')
 Batch: 12 of modal classification Duration: 0:00:00.294726
acc:  0.485
Time taken to execute the en SA task with prompt type modal, variation 4 and batchsize 16: 0:00:04.979366
path ['42', 'en', 'bloom-big', 'SA', 'modal', 'prompt_id_4']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([110, 2])
answers_probs just softmax dim 0: tensor([[0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091]], device='cuda:0')
tensor([[0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091],
        [0.0091, 0.0091]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA modal 5 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0006, 0.0008],
        [0.0003, 0.0005],
        [0.0007, 0.0010],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0002, 0.0003],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0616, 0.0633],
        [0.0590, 0.0661],
        [0.0581, 0.0671],
        [0.0654, 0.0596],
        [0.0638, 0.0612],
        [0.0651, 0.0600],
        [0.0641, 0.0609],
        [0.0635, 0.0614],
        [0.0631, 0.0619],
        [0.0634, 0.0615],
        [0.0614, 0.0636],
        [0.0620, 0.0629],
        [0.0607, 0.0643],
        [0.0646, 0.0604],
        [0.0636, 0.0613],
        [0.0605, 0.0645]], device='cuda:0')
 Batch: 0 of modal classification Duration: 0:00:00.412913
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0008, 0.0016],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0004, 0.0006],
        [0.0002, 0.0003],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0629, 0.0620],
        [0.0622, 0.0627],
        [0.0611, 0.0638],
        [0.0602, 0.0648],
        [0.0586, 0.0666],
        [0.0626, 0.0623],
        [0.0679, 0.0575],
        [0.0651, 0.0599],
        [0.0627, 0.0622],
        [0.0643, 0.0607],
        [0.0615, 0.0634],
        [0.0656, 0.0595],
        [0.0625, 0.0624],
        [0.0588, 0.0664],
        [0.0645, 0.0605],
        [0.0596, 0.0655]], device='cuda:0')
 Batch: 1 of modal classification Duration: 0:00:00.442941
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0007, 0.0008],
        [0.0004, 0.0006],
        [0.0001, 0.0003],
        [0.0003, 0.0006],
        [0.0006, 0.0011],
        [0.0003, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0614, 0.0635],
        [0.0630, 0.0619],
        [0.0661, 0.0589],
        [0.0631, 0.0618],
        [0.0613, 0.0636],
        [0.0640, 0.0609],
        [0.0614, 0.0635],
        [0.0669, 0.0583],
        [0.0600, 0.0649],
        [0.0614, 0.0635],
        [0.0687, 0.0567],
        [0.0653, 0.0597],
        [0.0598, 0.0651],
        [0.0586, 0.0665],
        [0.0613, 0.0636],
        [0.0574, 0.0679]], device='cuda:0')
 Batch: 2 of modal classification Duration: 0:00:00.431886
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0004, 0.0006],
        [0.0003, 0.0004],
        [0.0003, 0.0003],
        [0.0005, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0005, 0.0010],
        [0.0002, 0.0003],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0583, 0.0669],
        [0.0594, 0.0656],
        [0.0636, 0.0613],
        [0.0613, 0.0636],
        [0.0664, 0.0587],
        [0.0646, 0.0604],
        [0.0575, 0.0678],
        [0.0615, 0.0634],
        [0.0613, 0.0636],
        [0.0644, 0.0605],
        [0.0596, 0.0654],
        [0.0635, 0.0614],
        [0.0664, 0.0587],
        [0.0656, 0.0595],
        [0.0624, 0.0624],
        [0.0641, 0.0608]], device='cuda:0')
 Batch: 3 of modal classification Duration: 0:00:00.359803
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0007],
        [0.0004, 0.0005],
        [0.0003, 0.0009],
        [0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0002, 0.0007],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0635, 0.0614],
        [0.0633, 0.0615],
        [0.0638, 0.0611],
        [0.0620, 0.0629],
        [0.0663, 0.0588],
        [0.0631, 0.0618],
        [0.0652, 0.0598],
        [0.0660, 0.0591],
        [0.0582, 0.0670],
        [0.0587, 0.0665],
        [0.0646, 0.0603],
        [0.0625, 0.0624],
        [0.0608, 0.0641],
        [0.0621, 0.0628],
        [0.0566, 0.0688],
        [0.0631, 0.0618]], device='cuda:0')
 Batch: 4 of modal classification Duration: 0:00:00.289696
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0005, 0.0009],
        [0.0005, 0.0008],
        [0.0002, 0.0005],
        [0.0004, 0.0006],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0005, 0.0009],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0001, 0.0002],
        [0.0002, 0.0005],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0623, 0.0626],
        [0.0662, 0.0590],
        [0.0617, 0.0633],
        [0.0627, 0.0623],
        [0.0597, 0.0654],
        [0.0646, 0.0604],
        [0.0620, 0.0629],
        [0.0627, 0.0622],
        [0.0602, 0.0648],
        [0.0623, 0.0626],
        [0.0603, 0.0647],
        [0.0628, 0.0621],
        [0.0673, 0.0580],
        [0.0639, 0.0611],
        [0.0598, 0.0653],
        [0.0617, 0.0633]], device='cuda:0')
 Batch: 5 of modal classification Duration: 0:00:00.558142
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0002],
        [0.0002, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0666, 0.0584],
        [0.0608, 0.0640],
        [0.0642, 0.0606],
        [0.0721, 0.0540],
        [0.0576, 0.0676],
        [0.0630, 0.0618],
        [0.0650, 0.0599],
        [0.0673, 0.0579],
        [0.0614, 0.0634],
        [0.0618, 0.0630],
        [0.0627, 0.0621],
        [0.0588, 0.0661],
        [0.0558, 0.0698],
        [0.0623, 0.0624],
        [0.0605, 0.0643],
        [0.0601, 0.0647]], device='cuda:0')
 Batch: 6 of modal classification Duration: 0:00:00.367491
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0003, 0.0004],
        [0.0003, 0.0005],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0006],
        [0.0001, 0.0002],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0004, 0.0008],
        [0.0001, 0.0002]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0628, 0.0621],
        [0.0603, 0.0647],
        [0.0626, 0.0623],
        [0.0652, 0.0599],
        [0.0619, 0.0630],
        [0.0647, 0.0603],
        [0.0615, 0.0634],
        [0.0618, 0.0631],
        [0.0679, 0.0574],
        [0.0605, 0.0645],
        [0.0564, 0.0691],
        [0.0630, 0.0619],
        [0.0633, 0.0616],
        [0.0643, 0.0606],
        [0.0610, 0.0640],
        [0.0629, 0.0620]], device='cuda:0')
 Batch: 7 of modal classification Duration: 0:00:00.403827
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0014],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0627, 0.0622],
        [0.0602, 0.0647],
        [0.0640, 0.0608],
        [0.0637, 0.0612],
        [0.0700, 0.0557],
        [0.0619, 0.0629],
        [0.0678, 0.0574],
        [0.0634, 0.0614],
        [0.0623, 0.0625],
        [0.0597, 0.0652],
        [0.0611, 0.0637],
        [0.0561, 0.0694],
        [0.0595, 0.0654],
        [0.0592, 0.0658],
        [0.0617, 0.0632],
        [0.0666, 0.0585]], device='cuda:0')
 Batch: 8 of modal classification Duration: 0:00:00.421774
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0004, 0.0006],
        [0.0004, 0.0008],
        [0.0004, 0.0010],
        [0.0005, 0.0008],
        [0.0006, 0.0011],
        [0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0002, 0.0005],
        [0.0005, 0.0009],
        [0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0647, 0.0603],
        [0.0623, 0.0627],
        [0.0601, 0.0649],
        [0.0660, 0.0592],
        [0.0609, 0.0641],
        [0.0586, 0.0666],
        [0.0639, 0.0610],
        [0.0621, 0.0628],
        [0.0643, 0.0607],
        [0.0621, 0.0628],
        [0.0585, 0.0667],
        [0.0637, 0.0613],
        [0.0644, 0.0606],
        [0.0624, 0.0626],
        [0.0630, 0.0619],
        [0.0630, 0.0619]], device='cuda:0')
 Batch: 9 of modal classification Duration: 0:00:00.361954
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0003, 0.0003],
        [0.0002, 0.0004],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0615, 0.0635],
        [0.0652, 0.0598],
        [0.0606, 0.0644],
        [0.0620, 0.0629],
        [0.0621, 0.0628],
        [0.0654, 0.0596],
        [0.0603, 0.0647],
        [0.0615, 0.0635],
        [0.0624, 0.0626],
        [0.0621, 0.0628],
        [0.0618, 0.0631],
        [0.0647, 0.0603],
        [0.0605, 0.0645],
        [0.0687, 0.0568],
        [0.0588, 0.0664],
        [0.0624, 0.0625]], device='cuda:0')
 Batch: 10 of modal classification Duration: 0:00:00.422942
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0002, 0.0004],
        [0.0004, 0.0010],
        [0.0005, 0.0009],
        [0.0004, 0.0007],
        [0.0003, 0.0004],
        [0.0004, 0.0005],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0002, 0.0005],
        [0.0003, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0009],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0633, 0.0616],
        [0.0655, 0.0595],
        [0.0574, 0.0679],
        [0.0624, 0.0625],
        [0.0643, 0.0606],
        [0.0666, 0.0585],
        [0.0673, 0.0579],
        [0.0621, 0.0627],
        [0.0644, 0.0605],
        [0.0591, 0.0660],
        [0.0650, 0.0599],
        [0.0649, 0.0601],
        [0.0614, 0.0635],
        [0.0595, 0.0654],
        [0.0579, 0.0672],
        [0.0589, 0.0662]], device='cuda:0')
 Batch: 11 of modal classification Duration: 0:00:00.358841
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0003],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1187, 0.1315],
        [0.1240, 0.1259],
        [0.1249, 0.1250],
        [0.1292, 0.1208],
        [0.1227, 0.1272],
        [0.1197, 0.1304],
        [0.1314, 0.1188],
        [0.1295, 0.1206]], device='cuda:0')
 Batch: 12 of modal classification Duration: 0:00:00.156474
acc:  0.42
Time taken to execute the en SA task with prompt type modal, variation 5 and batchsize 16: 0:00:05.009658
path ['42', 'en', 'bloom-big', 'SA', 'modal', 'prompt_id_5']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003]], device='cuda:0') torch.Size([151, 2])
answers_probs just softmax dim 0: tensor([[0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066]], device='cuda:0')
tensor([[0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066],
        [0.0066, 0.0066]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA modal 6 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0006],
        [0.0003, 0.0006],
        [0.0004, 0.0004],
        [0.0004, 0.0006],
        [0.0005, 0.0006],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0006],
        [0.0007, 0.0010],
        [0.0002, 0.0003],
        [0.0007, 0.0008],
        [0.0006, 0.0008],
        [0.0005, 0.0006],
        [0.0003, 0.0004],
        [0.0003, 0.0005],
        [0.0006, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0637, 0.0612],
        [0.0592, 0.0659],
        [0.0657, 0.0594],
        [0.0609, 0.0641],
        [0.0625, 0.0624],
        [0.0637, 0.0612],
        [0.0623, 0.0627],
        [0.0604, 0.0646],
        [0.0609, 0.0641],
        [0.0652, 0.0598],
        [0.0652, 0.0598],
        [0.0619, 0.0630],
        [0.0647, 0.0603],
        [0.0608, 0.0642],
        [0.0599, 0.0652],
        [0.0629, 0.0621]], device='cuda:0')
 Batch: 0 of modal classification Duration: 0:00:00.482625
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0007],
        [0.0002, 0.0004],
        [0.0006, 0.0011],
        [0.0005, 0.0006],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0008, 0.0010],
        [0.0006, 0.0006],
        [0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0006, 0.0006],
        [0.0005, 0.0006],
        [0.0003, 0.0004],
        [0.0006, 0.0010],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0658, 0.0592],
        [0.0599, 0.0651],
        [0.0578, 0.0674],
        [0.0639, 0.0609],
        [0.0613, 0.0635],
        [0.0621, 0.0627],
        [0.0638, 0.0611],
        [0.0695, 0.0561],
        [0.0594, 0.0655],
        [0.0617, 0.0632],
        [0.0585, 0.0666],
        [0.0678, 0.0575],
        [0.0658, 0.0592],
        [0.0617, 0.0632],
        [0.0594, 0.0655],
        [0.0617, 0.0632]], device='cuda:0')
 Batch: 1 of modal classification Duration: 0:00:00.288491
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0004],
        [0.0004, 0.0006],
        [0.0005, 0.0008],
        [0.0005, 0.0006],
        [0.0005, 0.0008],
        [0.0005, 0.0007],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0006],
        [0.0007, 0.0009],
        [0.0003, 0.0004],
        [0.0005, 0.0007],
        [0.0006, 0.0007],
        [0.0004, 0.0007],
        [0.0005, 0.0010],
        [0.0007, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0699, 0.0558],
        [0.0625, 0.0624],
        [0.0626, 0.0623],
        [0.0634, 0.0615],
        [0.0606, 0.0643],
        [0.0641, 0.0609],
        [0.0610, 0.0639],
        [0.0615, 0.0634],
        [0.0646, 0.0604],
        [0.0643, 0.0606],
        [0.0624, 0.0625],
        [0.0631, 0.0618],
        [0.0636, 0.0613],
        [0.0592, 0.0658],
        [0.0566, 0.0689],
        [0.0607, 0.0642]], device='cuda:0')
 Batch: 2 of modal classification Duration: 0:00:00.491900
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0006],
        [0.0006, 0.0009],
        [0.0005, 0.0007],
        [0.0004, 0.0006],
        [0.0008, 0.0009],
        [0.0008, 0.0008],
        [0.0005, 0.0007],
        [0.0003, 0.0005],
        [0.0005, 0.0006],
        [0.0004, 0.0006],
        [0.0005, 0.0005],
        [0.0003, 0.0004],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0003, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0643, 0.0606],
        [0.0598, 0.0652],
        [0.0612, 0.0637],
        [0.0618, 0.0631],
        [0.0636, 0.0613],
        [0.0669, 0.0583],
        [0.0628, 0.0621],
        [0.0585, 0.0666],
        [0.0628, 0.0621],
        [0.0623, 0.0626],
        [0.0652, 0.0598],
        [0.0643, 0.0606],
        [0.0649, 0.0601],
        [0.0566, 0.0689],
        [0.0608, 0.0641],
        [0.0642, 0.0608]], device='cuda:0')
 Batch: 3 of modal classification Duration: 0:00:00.408928
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0004, 0.0005],
        [0.0006, 0.0007],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0007, 0.0008],
        [0.0004, 0.0005],
        [0.0005, 0.0007],
        [0.0004, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0003],
        [0.0007, 0.0009],
        [0.0012, 0.0015],
        [0.0003, 0.0006],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0627, 0.0622],
        [0.0633, 0.0616],
        [0.0621, 0.0628],
        [0.0642, 0.0607],
        [0.0580, 0.0672],
        [0.0599, 0.0651],
        [0.0652, 0.0598],
        [0.0641, 0.0608],
        [0.0637, 0.0612],
        [0.0596, 0.0654],
        [0.0590, 0.0660],
        [0.0640, 0.0609],
        [0.0635, 0.0614],
        [0.0650, 0.0600],
        [0.0587, 0.0664],
        [0.0670, 0.0582]], device='cuda:0')
 Batch: 4 of modal classification Duration: 0:00:00.446559
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0004, 0.0008],
        [0.0006, 0.0009],
        [0.0004, 0.0005],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0006, 0.0007],
        [0.0005, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0006, 0.0007],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0005, 0.0007],
        [0.0004, 0.0006],
        [0.0004, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0620, 0.0629],
        [0.0596, 0.0654],
        [0.0638, 0.0611],
        [0.0623, 0.0626],
        [0.0654, 0.0596],
        [0.0610, 0.0640],
        [0.0669, 0.0583],
        [0.0668, 0.0584],
        [0.0607, 0.0642],
        [0.0602, 0.0648],
        [0.0650, 0.0600],
        [0.0595, 0.0655],
        [0.0565, 0.0690],
        [0.0627, 0.0622],
        [0.0641, 0.0608],
        [0.0635, 0.0614]], device='cuda:0')
 Batch: 5 of modal classification Duration: 0:00:00.424733
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0008, 0.0011],
        [0.0006, 0.0009],
        [0.0005, 0.0005],
        [0.0007, 0.0010],
        [0.0005, 0.0011],
        [0.0002, 0.0003],
        [0.0006, 0.0007],
        [0.0006, 0.0008],
        [0.0003, 0.0004],
        [0.0005, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0006, 0.0006],
        [0.0003, 0.0003],
        [0.0004, 0.0006],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0621, 0.0628],
        [0.0595, 0.0655],
        [0.0675, 0.0578],
        [0.0613, 0.0636],
        [0.0564, 0.0691],
        [0.0633, 0.0616],
        [0.0654, 0.0596],
        [0.0629, 0.0619],
        [0.0642, 0.0608],
        [0.0640, 0.0609],
        [0.0591, 0.0659],
        [0.0609, 0.0640],
        [0.0678, 0.0575],
        [0.0643, 0.0606],
        [0.0612, 0.0637],
        [0.0602, 0.0647]], device='cuda:0')
 Batch: 6 of modal classification Duration: 0:00:00.405465
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0008],
        [0.0005, 0.0006],
        [0.0004, 0.0006],
        [0.0002, 0.0003],
        [0.0006, 0.0007],
        [0.0004, 0.0004],
        [0.0006, 0.0008],
        [0.0003, 0.0002],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0002, 0.0003],
        [0.0004, 0.0005],
        [0.0007, 0.0008],
        [0.0006, 0.0008],
        [0.0004, 0.0006],
        [0.0006, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0617, 0.0632],
        [0.0625, 0.0624],
        [0.0599, 0.0651],
        [0.0609, 0.0640],
        [0.0634, 0.0615],
        [0.0679, 0.0574],
        [0.0615, 0.0634],
        [0.0686, 0.0569],
        [0.0616, 0.0633],
        [0.0606, 0.0644],
        [0.0590, 0.0661],
        [0.0627, 0.0622],
        [0.0643, 0.0607],
        [0.0610, 0.0639],
        [0.0598, 0.0652],
        [0.0647, 0.0603]], device='cuda:0')
 Batch: 7 of modal classification Duration: 0:00:00.428277
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0005],
        [0.0004, 0.0006],
        [0.0009, 0.0012],
        [0.0005, 0.0006],
        [0.0006, 0.0009],
        [0.0004, 0.0005],
        [0.0005, 0.0007],
        [0.0005, 0.0006],
        [0.0003, 0.0004],
        [0.0005, 0.0006],
        [0.0004, 0.0005],
        [0.0005, 0.0007],
        [0.0002, 0.0003],
        [0.0004, 0.0005],
        [0.0007, 0.0008],
        [0.0003, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0635, 0.0615],
        [0.0579, 0.0674],
        [0.0628, 0.0622],
        [0.0655, 0.0596],
        [0.0606, 0.0643],
        [0.0628, 0.0622],
        [0.0635, 0.0615],
        [0.0623, 0.0627],
        [0.0590, 0.0661],
        [0.0641, 0.0609],
        [0.0628, 0.0622],
        [0.0610, 0.0640],
        [0.0623, 0.0626],
        [0.0628, 0.0622],
        [0.0640, 0.0610],
        [0.0652, 0.0598]], device='cuda:0')
 Batch: 8 of modal classification Duration: 0:00:00.453920
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0007, 0.0016],
        [0.0005, 0.0006],
        [0.0006, 0.0009],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0004, 0.0004],
        [0.0006, 0.0006],
        [0.0004, 0.0006],
        [0.0005, 0.0008],
        [0.0004, 0.0006],
        [0.0003, 0.0003],
        [0.0004, 0.0008],
        [0.0003, 0.0004],
        [0.0003, 0.0003],
        [0.0004, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0569, 0.0683],
        [0.0554, 0.0702],
        [0.0641, 0.0607],
        [0.0608, 0.0640],
        [0.0637, 0.0610],
        [0.0586, 0.0664],
        [0.0689, 0.0565],
        [0.0680, 0.0573],
        [0.0631, 0.0616],
        [0.0611, 0.0637],
        [0.0599, 0.0650],
        [0.0657, 0.0592],
        [0.0587, 0.0663],
        [0.0608, 0.0640],
        [0.0674, 0.0577],
        [0.0669, 0.0582]], device='cuda:0')
 Batch: 9 of modal classification Duration: 0:00:00.449590
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0006],
        [0.0004, 0.0003],
        [0.0005, 0.0006],
        [0.0005, 0.0009],
        [0.0006, 0.0010],
        [0.0006, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0005, 0.0007],
        [0.0004, 0.0004],
        [0.0003, 0.0006],
        [0.0004, 0.0004],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0005, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0664, 0.0587],
        [0.0697, 0.0559],
        [0.0619, 0.0629],
        [0.0592, 0.0658],
        [0.0587, 0.0664],
        [0.0645, 0.0604],
        [0.0575, 0.0677],
        [0.0626, 0.0622],
        [0.0616, 0.0633],
        [0.0648, 0.0601],
        [0.0595, 0.0654],
        [0.0652, 0.0597],
        [0.0618, 0.0630],
        [0.0599, 0.0651],
        [0.0608, 0.0641],
        [0.0660, 0.0590]], device='cuda:0')
 Batch: 10 of modal classification Duration: 0:00:00.593367
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0010],
        [0.0004, 0.0004],
        [0.0003, 0.0004],
        [0.0004, 0.0006],
        [0.0005, 0.0006],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0006, 0.0007],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0006, 0.0008],
        [0.0008, 0.0009],
        [0.0005, 0.0006],
        [0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0005, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0608, 0.0641],
        [0.0654, 0.0597],
        [0.0621, 0.0628],
        [0.0634, 0.0615],
        [0.0636, 0.0613],
        [0.0621, 0.0628],
        [0.0619, 0.0630],
        [0.0666, 0.0585],
        [0.0630, 0.0619],
        [0.0605, 0.0645],
        [0.0636, 0.0613],
        [0.0661, 0.0590],
        [0.0642, 0.0607],
        [0.0592, 0.0659],
        [0.0601, 0.0649],
        [0.0574, 0.0679]], device='cuda:0')
 Batch: 11 of modal classification Duration: 0:00:00.497751
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0004, 0.0004],
        [0.0005, 0.0006],
        [0.0002, 0.0003],
        [0.0007, 0.0008],
        [0.0004, 0.0007],
        [0.0007, 0.0009],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1245, 0.1254],
        [0.1279, 0.1220],
        [0.1276, 0.1223],
        [0.1271, 0.1228],
        [0.1286, 0.1214],
        [0.1138, 0.1371],
        [0.1271, 0.1228],
        [0.1235, 0.1263]], device='cuda:0')
 Batch: 12 of modal classification Duration: 0:00:00.152448
acc:  0.485
Time taken to execute the en SA task with prompt type modal, variation 6 and batchsize 16: 0:00:05.545046
path ['42', 'en', 'bloom-big', 'SA', 'modal', 'prompt_id_6']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([131, 2])
answers_probs just softmax dim 0: tensor([[0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076]], device='cuda:0')
tensor([[0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA modal 7 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0003, 0.0008],
        [0.0004, 0.0010],
        [0.0003, 0.0008],
        [0.0005, 0.0017],
        [0.0003, 0.0008],
        [0.0004, 0.0008],
        [0.0005, 0.0006],
        [0.0005, 0.0013],
        [0.0005, 0.0012],
        [0.0003, 0.0007],
        [0.0009, 0.0012],
        [0.0004, 0.0011],
        [0.0003, 0.0008],
        [0.0005, 0.0013],
        [0.0004, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0694, 0.0560],
        [0.0595, 0.0653],
        [0.0603, 0.0645],
        [0.0613, 0.0634],
        [0.0576, 0.0675],
        [0.0619, 0.0628],
        [0.0647, 0.0601],
        [0.0717, 0.0542],
        [0.0605, 0.0643],
        [0.0601, 0.0647],
        [0.0637, 0.0610],
        [0.0708, 0.0550],
        [0.0598, 0.0650],
        [0.0603, 0.0645],
        [0.0604, 0.0644],
        [0.0580, 0.0671]], device='cuda:0')
 Batch: 0 of modal classification Duration: 0:00:00.366287
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0008],
        [0.0004, 0.0009],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0004],
        [0.0002, 0.0008],
        [0.0005, 0.0013],
        [0.0003, 0.0007],
        [0.0003, 0.0009],
        [0.0005, 0.0012],
        [0.0004, 0.0010],
        [0.0006, 0.0012],
        [0.0006, 0.0018]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626]], device='cuda:0')
tensor([[0.0560, 0.0695],
        [0.0635, 0.0613],
        [0.0682, 0.0570],
        [0.0674, 0.0578],
        [0.0640, 0.0608],
        [0.0639, 0.0610],
        [0.0625, 0.0623],
        [0.0695, 0.0560],
        [0.0579, 0.0673],
        [0.0603, 0.0645],
        [0.0605, 0.0643],
        [0.0575, 0.0676],
        [0.0624, 0.0624],
        [0.0619, 0.0629],
        [0.0651, 0.0598],
        [0.0594, 0.0655]], device='cuda:0')
 Batch: 1 of modal classification Duration: 0:00:00.409530
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0004, 0.0010],
        [0.0003, 0.0005],
        [0.0005, 0.0011],
        [0.0003, 0.0008],
        [0.0002, 0.0003],
        [0.0003, 0.0007],
        [0.0004, 0.0010],
        [0.0005, 0.0016],
        [0.0003, 0.0011],
        [0.0003, 0.0005],
        [0.0005, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0743, 0.0523],
        [0.0610, 0.0637],
        [0.0634, 0.0614],
        [0.0625, 0.0622],
        [0.0597, 0.0652],
        [0.0688, 0.0565],
        [0.0613, 0.0634],
        [0.0590, 0.0659],
        [0.0579, 0.0672],
        [0.0569, 0.0683],
        [0.0669, 0.0582],
        [0.0631, 0.0616],
        [0.0591, 0.0659],
        [0.0610, 0.0637],
        [0.0634, 0.0614],
        [0.0615, 0.0632]], device='cuda:0')
 Batch: 2 of modal classification Duration: 0:00:00.566830
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0005, 0.0011],
        [0.0005, 0.0015],
        [0.0004, 0.0010],
        [0.0005, 0.0008],
        [0.0004, 0.0012],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0009],
        [0.0004, 0.0006],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0006, 0.0009],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0591, 0.0659],
        [0.0614, 0.0634],
        [0.0570, 0.0684],
        [0.0605, 0.0644],
        [0.0651, 0.0599],
        [0.0591, 0.0659],
        [0.0654, 0.0596],
        [0.0659, 0.0591],
        [0.0610, 0.0639],
        [0.0681, 0.0572],
        [0.0598, 0.0651],
        [0.0645, 0.0604],
        [0.0635, 0.0614],
        [0.0594, 0.0656],
        [0.0674, 0.0578],
        [0.0629, 0.0619]], device='cuda:0')
 Batch: 3 of modal classification Duration: 0:00:00.364655
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0016],
        [0.0005, 0.0013],
        [0.0003, 0.0007],
        [0.0004, 0.0011],
        [0.0006, 0.0014],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0002, 0.0006],
        [0.0008, 0.0017],
        [0.0004, 0.0006],
        [0.0004, 0.0011],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0014]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0585, 0.0665],
        [0.0605, 0.0643],
        [0.0611, 0.0637],
        [0.0610, 0.0638],
        [0.0613, 0.0635],
        [0.0659, 0.0591],
        [0.0632, 0.0616],
        [0.0578, 0.0673],
        [0.0633, 0.0615],
        [0.0663, 0.0587],
        [0.0599, 0.0650],
        [0.0631, 0.0617],
        [0.0745, 0.0522],
        [0.0606, 0.0642],
        [0.0645, 0.0603],
        [0.0586, 0.0664]], device='cuda:0')
 Batch: 4 of modal classification Duration: 0:00:00.322328
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0004, 0.0011],
        [0.0003, 0.0005],
        [0.0004, 0.0009],
        [0.0004, 0.0008],
        [0.0004, 0.0011],
        [0.0005, 0.0010],
        [0.0004, 0.0010],
        [0.0002, 0.0005],
        [0.0004, 0.0009],
        [0.0004, 0.0010],
        [0.0004, 0.0011],
        [0.0004, 0.0008],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0676, 0.0577],
        [0.0657, 0.0593],
        [0.0594, 0.0657],
        [0.0604, 0.0646],
        [0.0642, 0.0607],
        [0.0628, 0.0621],
        [0.0619, 0.0630],
        [0.0585, 0.0667],
        [0.0636, 0.0614],
        [0.0605, 0.0645],
        [0.0634, 0.0616],
        [0.0634, 0.0616],
        [0.0599, 0.0651],
        [0.0600, 0.0650],
        [0.0630, 0.0619],
        [0.0657, 0.0593]], device='cuda:0')
 Batch: 5 of modal classification Duration: 0:00:00.452093
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0005, 0.0014],
        [0.0006, 0.0011],
        [0.0004, 0.0011],
        [0.0003, 0.0010],
        [0.0005, 0.0013],
        [0.0002, 0.0005],
        [0.0008, 0.0013],
        [0.0006, 0.0015],
        [0.0004, 0.0010],
        [0.0004, 0.0009],
        [0.0003, 0.0010],
        [0.0002, 0.0003],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0004, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0600, 0.0650],
        [0.0601, 0.0648],
        [0.0647, 0.0602],
        [0.0591, 0.0659],
        [0.0591, 0.0659],
        [0.0602, 0.0647],
        [0.0622, 0.0626],
        [0.0683, 0.0571],
        [0.0620, 0.0628],
        [0.0599, 0.0651],
        [0.0642, 0.0607],
        [0.0583, 0.0668],
        [0.0692, 0.0563],
        [0.0638, 0.0611],
        [0.0662, 0.0589],
        [0.0626, 0.0622]], device='cuda:0')
 Batch: 6 of modal classification Duration: 0:00:00.406942
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0009],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0007, 0.0013],
        [0.0005, 0.0007],
        [0.0005, 0.0009],
        [0.0003, 0.0012],
        [0.0003, 0.0005],
        [0.0004, 0.0010],
        [0.0004, 0.0013],
        [0.0003, 0.0009],
        [0.0002, 0.0002],
        [0.0005, 0.0014],
        [0.0004, 0.0006],
        [0.0002, 0.0007],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0670, 0.0580],
        [0.0614, 0.0633],
        [0.0598, 0.0650],
        [0.0629, 0.0618],
        [0.0674, 0.0577],
        [0.0648, 0.0600],
        [0.0551, 0.0705],
        [0.0638, 0.0609],
        [0.0607, 0.0640],
        [0.0573, 0.0679],
        [0.0592, 0.0657],
        [0.0714, 0.0544],
        [0.0595, 0.0654],
        [0.0658, 0.0591],
        [0.0572, 0.0680],
        [0.0667, 0.0583]], device='cuda:0')
 Batch: 7 of modal classification Duration: 0:00:00.491005
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0005, 0.0013],
        [0.0004, 0.0012],
        [0.0003, 0.0010],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0006, 0.0015],
        [0.0001, 0.0004],
        [0.0003, 0.0008],
        [0.0004, 0.0006],
        [0.0005, 0.0011],
        [0.0005, 0.0009],
        [0.0004, 0.0008],
        [0.0002, 0.0006],
        [0.0002, 0.0006],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0653, 0.0597],
        [0.0604, 0.0645],
        [0.0584, 0.0668],
        [0.0588, 0.0662],
        [0.0639, 0.0610],
        [0.0670, 0.0582],
        [0.0627, 0.0621],
        [0.0614, 0.0634],
        [0.0588, 0.0663],
        [0.0675, 0.0578],
        [0.0647, 0.0603],
        [0.0650, 0.0600],
        [0.0623, 0.0625],
        [0.0603, 0.0646],
        [0.0614, 0.0634],
        [0.0618, 0.0631]], device='cuda:0')
 Batch: 8 of modal classification Duration: 0:00:00.320924
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0013],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0010],
        [0.0008, 0.0020],
        [0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0006, 0.0015],
        [0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0004, 0.0010],
        [0.0003, 0.0009],
        [0.0004, 0.0006],
        [0.0004, 0.0011],
        [0.0003, 0.0007],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0628, 0.0621],
        [0.0611, 0.0638],
        [0.0662, 0.0589],
        [0.0607, 0.0643],
        [0.0606, 0.0644],
        [0.0643, 0.0606],
        [0.0621, 0.0628],
        [0.0615, 0.0634],
        [0.0631, 0.0618],
        [0.0682, 0.0572],
        [0.0623, 0.0626],
        [0.0580, 0.0673],
        [0.0666, 0.0586],
        [0.0605, 0.0645],
        [0.0601, 0.0649],
        [0.0620, 0.0629]], device='cuda:0')
 Batch: 9 of modal classification Duration: 0:00:00.424968
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0004, 0.0005],
        [0.0004, 0.0010],
        [0.0005, 0.0011],
        [0.0003, 0.0007],
        [0.0004, 0.0012],
        [0.0004, 0.0010],
        [0.0003, 0.0007],
        [0.0003, 0.0010],
        [0.0002, 0.0005],
        [0.0005, 0.0010],
        [0.0007, 0.0017],
        [0.0003, 0.0006],
        [0.0003, 0.0009],
        [0.0002, 0.0003],
        [0.0006, 0.0015]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0657, 0.0593],
        [0.0722, 0.0540],
        [0.0605, 0.0644],
        [0.0637, 0.0612],
        [0.0597, 0.0652],
        [0.0606, 0.0643],
        [0.0622, 0.0626],
        [0.0607, 0.0642],
        [0.0566, 0.0688],
        [0.0644, 0.0604],
        [0.0649, 0.0600],
        [0.0620, 0.0628],
        [0.0634, 0.0614],
        [0.0570, 0.0683],
        [0.0649, 0.0600],
        [0.0616, 0.0632]], device='cuda:0')
 Batch: 10 of modal classification Duration: 0:00:00.400203
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0004, 0.0011],
        [0.0004, 0.0009],
        [0.0005, 0.0012],
        [0.0003, 0.0005],
        [0.0004, 0.0009],
        [0.0001, 0.0003],
        [0.0002, 0.0006],
        [0.0004, 0.0006],
        [0.0006, 0.0015],
        [0.0002, 0.0006],
        [0.0003, 0.0010],
        [0.0002, 0.0005],
        [0.0003, 0.0003],
        [0.0003, 0.0006],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0595, 0.0655],
        [0.0605, 0.0644],
        [0.0604, 0.0645],
        [0.0613, 0.0636],
        [0.0663, 0.0587],
        [0.0605, 0.0644],
        [0.0642, 0.0606],
        [0.0615, 0.0634],
        [0.0655, 0.0595],
        [0.0603, 0.0646],
        [0.0610, 0.0639],
        [0.0574, 0.0678],
        [0.0629, 0.0619],
        [0.0736, 0.0529],
        [0.0614, 0.0635],
        [0.0638, 0.0610]], device='cuda:0')
 Batch: 11 of modal classification Duration: 0:00:00.408250
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0002, 0.0006],
        [0.0005, 0.0011],
        [0.0004, 0.0013],
        [0.0004, 0.0008],
        [0.0001, 0.0001],
        [0.0006, 0.0017],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1249],
        [0.1250, 0.1251],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1306, 0.1187],
        [0.1163, 0.1333],
        [0.1217, 0.1274],
        [0.1123, 0.1380],
        [0.1238, 0.1253],
        [0.1500, 0.1034],
        [0.1144, 0.1355],
        [0.1308, 0.1185]], device='cuda:0')
 Batch: 12 of modal classification Duration: 0:00:00.232459
acc:  0.48
Time taken to execute the en SA task with prompt type modal, variation 7 and batchsize 16: 0:00:05.187388
path ['42', 'en', 'bloom-big', 'SA', 'modal', 'prompt_id_7']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([112, 2])
answers_probs just softmax dim 0: tensor([[0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089]], device='cuda:0')
tensor([[0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA modal 8 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0012],
        [0.0006, 0.0029],
        [0.0006, 0.0020],
        [0.0004, 0.0013],
        [0.0005, 0.0020],
        [0.0005, 0.0015],
        [0.0003, 0.0005],
        [0.0004, 0.0018],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0005, 0.0011],
        [0.0008, 0.0015],
        [0.0004, 0.0011],
        [0.0005, 0.0010],
        [0.0007, 0.0018],
        [0.0011, 0.0028]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0624],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0624],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626]], device='cuda:0')
tensor([[0.0646, 0.0603],
        [0.0569, 0.0684],
        [0.0596, 0.0654],
        [0.0608, 0.0641],
        [0.0589, 0.0662],
        [0.0605, 0.0644],
        [0.0666, 0.0585],
        [0.0572, 0.0681],
        [0.0639, 0.0610],
        [0.0648, 0.0601],
        [0.0646, 0.0603],
        [0.0672, 0.0580],
        [0.0628, 0.0620],
        [0.0668, 0.0583],
        [0.0619, 0.0630],
        [0.0628, 0.0620]], device='cuda:0')
 Batch: 0 of modal classification Duration: 0:00:00.479963
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0009],
        [0.0006, 0.0019],
        [0.0007, 0.0012],
        [0.0002, 0.0005],
        [0.0006, 0.0011],
        [0.0006, 0.0013],
        [0.0004, 0.0011],
        [0.0003, 0.0010],
        [0.0006, 0.0015],
        [0.0004, 0.0011],
        [0.0003, 0.0006],
        [0.0004, 0.0010],
        [0.0004, 0.0015],
        [0.0003, 0.0009],
        [0.0005, 0.0011],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0609, 0.0640],
        [0.0594, 0.0656],
        [0.0674, 0.0579],
        [0.0618, 0.0630],
        [0.0671, 0.0581],
        [0.0646, 0.0603],
        [0.0618, 0.0630],
        [0.0582, 0.0669],
        [0.0617, 0.0631],
        [0.0600, 0.0650],
        [0.0668, 0.0584],
        [0.0627, 0.0621],
        [0.0575, 0.0678],
        [0.0627, 0.0621],
        [0.0635, 0.0613],
        [0.0636, 0.0612]], device='cuda:0')
 Batch: 1 of modal classification Duration: 0:00:00.329473
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0021],
        [0.0005, 0.0008],
        [0.0006, 0.0013],
        [0.0004, 0.0008],
        [0.0003, 0.0012],
        [0.0002, 0.0007],
        [0.0008, 0.0017],
        [0.0006, 0.0021],
        [0.0004, 0.0016],
        [0.0003, 0.0005],
        [0.0006, 0.0012],
        [0.0005, 0.0014],
        [0.0010, 0.0030],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0006, 0.0014]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0586, 0.0665],
        [0.0687, 0.0567],
        [0.0628, 0.0621],
        [0.0631, 0.0618],
        [0.0581, 0.0670],
        [0.0588, 0.0662],
        [0.0645, 0.0603],
        [0.0580, 0.0672],
        [0.0582, 0.0669],
        [0.0676, 0.0576],
        [0.0663, 0.0588],
        [0.0619, 0.0630],
        [0.0599, 0.0650],
        [0.0660, 0.0590],
        [0.0643, 0.0605],
        [0.0633, 0.0616]], device='cuda:0')
 Batch: 2 of modal classification Duration: 0:00:00.405156
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0009, 0.0020],
        [0.0006, 0.0019],
        [0.0005, 0.0013],
        [0.0008, 0.0019],
        [0.0005, 0.0014],
        [0.0004, 0.0009],
        [0.0005, 0.0018],
        [0.0004, 0.0014],
        [0.0006, 0.0015],
        [0.0005, 0.0011],
        [0.0004, 0.0012],
        [0.0004, 0.0010],
        [0.0010, 0.0019],
        [0.0004, 0.0014],
        [0.0004, 0.0013],
        [0.0004, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0648, 0.0603],
        [0.0609, 0.0641],
        [0.0620, 0.0629],
        [0.0634, 0.0615],
        [0.0624, 0.0625],
        [0.0654, 0.0596],
        [0.0599, 0.0651],
        [0.0594, 0.0657],
        [0.0631, 0.0618],
        [0.0642, 0.0608],
        [0.0615, 0.0635],
        [0.0642, 0.0608],
        [0.0664, 0.0587],
        [0.0595, 0.0656],
        [0.0605, 0.0645],
        [0.0623, 0.0626]], device='cuda:0')
 Batch: 3 of modal classification Duration: 0:00:00.361671
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0014],
        [0.0010, 0.0016],
        [0.0007, 0.0014],
        [0.0004, 0.0013],
        [0.0003, 0.0008],
        [0.0005, 0.0013],
        [0.0004, 0.0012],
        [0.0007, 0.0012],
        [0.0005, 0.0012],
        [0.0005, 0.0015],
        [0.0002, 0.0005],
        [0.0007, 0.0019],
        [0.0005, 0.0008],
        [0.0011, 0.0030],
        [0.0004, 0.0020],
        [0.0004, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0624],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0606, 0.0643],
        [0.0681, 0.0571],
        [0.0655, 0.0595],
        [0.0585, 0.0665],
        [0.0598, 0.0651],
        [0.0607, 0.0642],
        [0.0613, 0.0635],
        [0.0684, 0.0569],
        [0.0632, 0.0616],
        [0.0611, 0.0637],
        [0.0654, 0.0595],
        [0.0608, 0.0640],
        [0.0688, 0.0566],
        [0.0615, 0.0633],
        [0.0557, 0.0699],
        [0.0606, 0.0643]], device='cuda:0')
 Batch: 4 of modal classification Duration: 0:00:00.565157
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0020],
        [0.0006, 0.0020],
        [0.0003, 0.0007],
        [0.0007, 0.0013],
        [0.0003, 0.0009],
        [0.0007, 0.0010],
        [0.0004, 0.0010],
        [0.0006, 0.0012],
        [0.0006, 0.0020],
        [0.0004, 0.0009],
        [0.0008, 0.0026],
        [0.0005, 0.0012],
        [0.0006, 0.0017],
        [0.0005, 0.0011],
        [0.0005, 0.0014],
        [0.0004, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0605, 0.0644],
        [0.0588, 0.0663],
        [0.0626, 0.0623],
        [0.0674, 0.0579],
        [0.0614, 0.0634],
        [0.0697, 0.0559],
        [0.0624, 0.0625],
        [0.0653, 0.0597],
        [0.0594, 0.0656],
        [0.0617, 0.0632],
        [0.0589, 0.0662],
        [0.0642, 0.0608],
        [0.0623, 0.0626],
        [0.0642, 0.0608],
        [0.0613, 0.0635],
        [0.0598, 0.0652]], device='cuda:0')
 Batch: 5 of modal classification Duration: 0:00:00.451467
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0013],
        [0.0006, 0.0022],
        [0.0006, 0.0014],
        [0.0004, 0.0009],
        [0.0006, 0.0009],
        [0.0005, 0.0010],
        [0.0003, 0.0007],
        [0.0003, 0.0008],
        [0.0005, 0.0008],
        [0.0004, 0.0010],
        [0.0007, 0.0017],
        [0.0003, 0.0010],
        [0.0003, 0.0007],
        [0.0007, 0.0020],
        [0.0006, 0.0012],
        [0.0010, 0.0020]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0631, 0.0618],
        [0.0575, 0.0678],
        [0.0614, 0.0635],
        [0.0633, 0.0616],
        [0.0687, 0.0567],
        [0.0653, 0.0597],
        [0.0613, 0.0636],
        [0.0605, 0.0644],
        [0.0675, 0.0578],
        [0.0602, 0.0648],
        [0.0609, 0.0640],
        [0.0593, 0.0658],
        [0.0627, 0.0622],
        [0.0601, 0.0649],
        [0.0642, 0.0607],
        [0.0642, 0.0607]], device='cuda:0')
 Batch: 6 of modal classification Duration: 0:00:00.358356
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0005, 0.0013],
        [0.0006, 0.0020],
        [0.0006, 0.0019],
        [0.0006, 0.0013],
        [0.0006, 0.0014],
        [0.0004, 0.0011],
        [0.0004, 0.0012],
        [0.0004, 0.0010],
        [0.0006, 0.0015],
        [0.0008, 0.0019],
        [0.0004, 0.0012],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0010, 0.0021]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626]], device='cuda:0')
tensor([[0.0670, 0.0582],
        [0.0605, 0.0645],
        [0.0594, 0.0656],
        [0.0593, 0.0658],
        [0.0644, 0.0606],
        [0.0633, 0.0616],
        [0.0620, 0.0629],
        [0.0614, 0.0635],
        [0.0614, 0.0635],
        [0.0613, 0.0636],
        [0.0621, 0.0628],
        [0.0598, 0.0653],
        [0.0676, 0.0577],
        [0.0639, 0.0610],
        [0.0628, 0.0621],
        [0.0640, 0.0609]], device='cuda:0')
 Batch: 7 of modal classification Duration: 0:00:00.362955
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0007, 0.0020],
        [0.0003, 0.0016],
        [0.0002, 0.0006],
        [0.0004, 0.0012],
        [0.0003, 0.0009],
        [0.0005, 0.0017],
        [0.0003, 0.0010],
        [0.0003, 0.0009],
        [0.0004, 0.0011],
        [0.0003, 0.0006],
        [0.0005, 0.0016],
        [0.0004, 0.0010],
        [0.0007, 0.0015],
        [0.0004, 0.0017],
        [0.0005, 0.0016]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0691, 0.0564],
        [0.0631, 0.0618],
        [0.0578, 0.0674],
        [0.0637, 0.0612],
        [0.0623, 0.0625],
        [0.0605, 0.0644],
        [0.0603, 0.0646],
        [0.0591, 0.0660],
        [0.0608, 0.0641],
        [0.0642, 0.0607],
        [0.0680, 0.0573],
        [0.0610, 0.0639],
        [0.0651, 0.0598],
        [0.0657, 0.0593],
        [0.0577, 0.0675],
        [0.0617, 0.0632]], device='cuda:0')
 Batch: 8 of modal classification Duration: 0:00:00.407842
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0011],
        [0.0003, 0.0007],
        [0.0006, 0.0014],
        [0.0006, 0.0010],
        [0.0005, 0.0018],
        [0.0005, 0.0015],
        [0.0006, 0.0019],
        [0.0001, 0.0002],
        [0.0003, 0.0005],
        [0.0004, 0.0018],
        [0.0003, 0.0010],
        [0.0008, 0.0018],
        [0.0005, 0.0007],
        [0.0008, 0.0019],
        [0.0005, 0.0020],
        [0.0005, 0.0018]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0624],
        [0.0625, 0.0624],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0574, 0.0677],
        [0.0653, 0.0595],
        [0.0620, 0.0626],
        [0.0670, 0.0580],
        [0.0597, 0.0651],
        [0.0596, 0.0652],
        [0.0598, 0.0649],
        [0.0711, 0.0547],
        [0.0674, 0.0577],
        [0.0565, 0.0688],
        [0.0587, 0.0662],
        [0.0648, 0.0599],
        [0.0715, 0.0543],
        [0.0625, 0.0622],
        [0.0581, 0.0668],
        [0.0586, 0.0663]], device='cuda:0')
 Batch: 9 of modal classification Duration: 0:00:00.406340
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0016],
        [0.0004, 0.0010],
        [0.0006, 0.0019],
        [0.0005, 0.0011],
        [0.0007, 0.0016],
        [0.0005, 0.0013],
        [0.0003, 0.0010],
        [0.0005, 0.0012],
        [0.0006, 0.0013],
        [0.0007, 0.0016],
        [0.0005, 0.0012],
        [0.0004, 0.0017],
        [0.0011, 0.0027],
        [0.0002, 0.0005],
        [0.0003, 0.0011],
        [0.0004, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0624],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0623, 0.0627],
        [0.0646, 0.0604],
        [0.0610, 0.0640],
        [0.0665, 0.0587],
        [0.0643, 0.0607],
        [0.0626, 0.0623],
        [0.0602, 0.0648],
        [0.0626, 0.0624],
        [0.0649, 0.0601],
        [0.0636, 0.0613],
        [0.0628, 0.0622],
        [0.0572, 0.0682],
        [0.0632, 0.0617],
        [0.0636, 0.0614],
        [0.0598, 0.0653],
        [0.0609, 0.0641]], device='cuda:0')
 Batch: 10 of modal classification Duration: 0:00:00.426064
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0003, 0.0013],
        [0.0005, 0.0012],
        [0.0005, 0.0014],
        [0.0006, 0.0021],
        [0.0005, 0.0010],
        [0.0003, 0.0011],
        [0.0005, 0.0013],
        [0.0006, 0.0020],
        [0.0005, 0.0009],
        [0.0003, 0.0010],
        [0.0006, 0.0014],
        [0.0002, 0.0005],
        [0.0008, 0.0016],
        [0.0006, 0.0019],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0628, 0.0621],
        [0.0573, 0.0680],
        [0.0658, 0.0593],
        [0.0616, 0.0633],
        [0.0587, 0.0664],
        [0.0653, 0.0597],
        [0.0606, 0.0643],
        [0.0626, 0.0623],
        [0.0597, 0.0653],
        [0.0671, 0.0581],
        [0.0614, 0.0635],
        [0.0637, 0.0612],
        [0.0621, 0.0628],
        [0.0660, 0.0591],
        [0.0604, 0.0645],
        [0.0648, 0.0602]], device='cuda:0')
 Batch: 11 of modal classification Duration: 0:00:00.421945
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0006, 0.0018],
        [0.0003, 0.0010],
        [0.0005, 0.0010],
        [0.0002, 0.0007],
        [0.0004, 0.0015],
        [0.0001, 0.0003],
        [0.0003, 0.0009],
        [0.0004, 0.0012]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1249],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1260, 0.1238],
        [0.1232, 0.1266],
        [0.1303, 0.1198],
        [0.1206, 0.1293],
        [0.1175, 0.1327],
        [0.1347, 0.1158],
        [0.1252, 0.1246],
        [0.1225, 0.1274]], device='cuda:0')
 Batch: 12 of modal classification Duration: 0:00:00.228980
acc:  0.49
Time taken to execute the en SA task with prompt type modal, variation 8 and batchsize 16: 0:00:05.225975
path ['42', 'en', 'bloom-big', 'SA', 'modal', 'prompt_id_8']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([115, 2])
answers_probs just softmax dim 0: tensor([[0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087]], device='cuda:0')
tensor([[0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087],
        [0.0087, 0.0087]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA modal 9 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0008],
        [0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0004, 0.0009],
        [0.0003, 0.0009],
        [0.0007, 0.0018],
        [0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0008],
        [0.0004, 0.0007],
        [0.0006, 0.0011],
        [0.0003, 0.0008],
        [0.0004, 0.0007],
        [0.0008, 0.0015],
        [0.0002, 0.0006],
        [0.0002, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0587, 0.0664],
        [0.0648, 0.0601],
        [0.0659, 0.0591],
        [0.0627, 0.0622],
        [0.0599, 0.0651],
        [0.0615, 0.0633],
        [0.0622, 0.0627],
        [0.0616, 0.0633],
        [0.0638, 0.0610],
        [0.0669, 0.0583],
        [0.0659, 0.0591],
        [0.0597, 0.0653],
        [0.0664, 0.0587],
        [0.0657, 0.0593],
        [0.0581, 0.0671],
        [0.0563, 0.0692]], device='cuda:0')
 Batch: 0 of modal classification Duration: 0:00:00.566999
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0014],
        [0.0003, 0.0005],
        [0.0006, 0.0010],
        [0.0004, 0.0011],
        [0.0007, 0.0027],
        [0.0006, 0.0017],
        [0.0005, 0.0013],
        [0.0005, 0.0015],
        [0.0004, 0.0010],
        [0.0008, 0.0015],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0005, 0.0017],
        [0.0005, 0.0011],
        [0.0010, 0.0018],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0645, 0.0604],
        [0.0643, 0.0606],
        [0.0670, 0.0582],
        [0.0621, 0.0627],
        [0.0570, 0.0684],
        [0.0603, 0.0646],
        [0.0602, 0.0647],
        [0.0597, 0.0653],
        [0.0618, 0.0630],
        [0.0650, 0.0600],
        [0.0616, 0.0632],
        [0.0664, 0.0587],
        [0.0577, 0.0676],
        [0.0620, 0.0628],
        [0.0658, 0.0593],
        [0.0647, 0.0602]], device='cuda:0')
 Batch: 1 of modal classification Duration: 0:00:00.366867
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0003, 0.0004],
        [0.0004, 0.0010],
        [0.0007, 0.0016],
        [0.0004, 0.0011],
        [0.0007, 0.0018],
        [0.0003, 0.0009],
        [0.0007, 0.0020],
        [0.0002, 0.0005],
        [0.0004, 0.0009],
        [0.0004, 0.0010],
        [0.0006, 0.0012],
        [0.0003, 0.0007],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0629, 0.0620],
        [0.0646, 0.0604],
        [0.0619, 0.0630],
        [0.0702, 0.0555],
        [0.0607, 0.0642],
        [0.0613, 0.0636],
        [0.0600, 0.0650],
        [0.0609, 0.0640],
        [0.0585, 0.0667],
        [0.0605, 0.0644],
        [0.0625, 0.0624],
        [0.0629, 0.0620],
        [0.0614, 0.0635],
        [0.0646, 0.0604],
        [0.0633, 0.0616],
        [0.0638, 0.0611]], device='cuda:0')
 Batch: 2 of modal classification Duration: 0:00:00.474734
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0004, 0.0014],
        [0.0005, 0.0014],
        [0.0006, 0.0012],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0005, 0.0010],
        [0.0003, 0.0008],
        [0.0004, 0.0008],
        [0.0002, 0.0006],
        [0.0003, 0.0011],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0631, 0.0618],
        [0.0570, 0.0685],
        [0.0596, 0.0654],
        [0.0642, 0.0607],
        [0.0613, 0.0637],
        [0.0633, 0.0616],
        [0.0634, 0.0615],
        [0.0658, 0.0592],
        [0.0632, 0.0617],
        [0.0644, 0.0606],
        [0.0615, 0.0634],
        [0.0570, 0.0685],
        [0.0629, 0.0619],
        [0.0643, 0.0606],
        [0.0649, 0.0601],
        [0.0642, 0.0607]], device='cuda:0')
 Batch: 3 of modal classification Duration: 0:00:00.403594
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0005, 0.0011],
        [0.0003, 0.0007],
        [0.0007, 0.0014],
        [0.0002, 0.0005],
        [0.0003, 0.0013],
        [0.0003, 0.0007],
        [0.0003, 0.0008],
        [0.0003, 0.0011],
        [0.0002, 0.0006],
        [0.0010, 0.0018],
        [0.0004, 0.0010],
        [0.0008, 0.0017],
        [0.0004, 0.0012],
        [0.0003, 0.0010],
        [0.0002, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0619, 0.0630],
        [0.0653, 0.0597],
        [0.0643, 0.0606],
        [0.0653, 0.0597],
        [0.0659, 0.0592],
        [0.0582, 0.0669],
        [0.0629, 0.0619],
        [0.0635, 0.0614],
        [0.0582, 0.0670],
        [0.0613, 0.0636],
        [0.0663, 0.0588],
        [0.0630, 0.0619],
        [0.0646, 0.0603],
        [0.0620, 0.0629],
        [0.0574, 0.0679],
        [0.0600, 0.0650]], device='cuda:0')
 Batch: 4 of modal classification Duration: 0:00:00.427409
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0003, 0.0007],
        [0.0007, 0.0010],
        [0.0003, 0.0003],
        [0.0004, 0.0010],
        [0.0007, 0.0010],
        [0.0003, 0.0008],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0005, 0.0013],
        [0.0006, 0.0012],
        [0.0004, 0.0009],
        [0.0007, 0.0016],
        [0.0006, 0.0009],
        [0.0004, 0.0007],
        [0.0004, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0597, 0.0652],
        [0.0603, 0.0646],
        [0.0673, 0.0578],
        [0.0724, 0.0537],
        [0.0584, 0.0667],
        [0.0668, 0.0583],
        [0.0605, 0.0644],
        [0.0630, 0.0618],
        [0.0613, 0.0635],
        [0.0595, 0.0654],
        [0.0629, 0.0619],
        [0.0598, 0.0651],
        [0.0597, 0.0652],
        [0.0666, 0.0585],
        [0.0631, 0.0617],
        [0.0587, 0.0663]], device='cuda:0')
 Batch: 5 of modal classification Duration: 0:00:00.362590
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0014],
        [0.0006, 0.0019],
        [0.0004, 0.0007],
        [0.0003, 0.0010],
        [0.0004, 0.0010],
        [0.0007, 0.0011],
        [0.0003, 0.0012],
        [0.0006, 0.0013],
        [0.0004, 0.0012],
        [0.0005, 0.0013],
        [0.0001, 0.0003],
        [0.0006, 0.0018],
        [0.0004, 0.0011],
        [0.0004, 0.0008],
        [0.0002, 0.0008],
        [0.0005, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0624],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0611, 0.0638],
        [0.0598, 0.0652],
        [0.0662, 0.0589],
        [0.0603, 0.0646],
        [0.0631, 0.0617],
        [0.0685, 0.0569],
        [0.0581, 0.0670],
        [0.0654, 0.0596],
        [0.0609, 0.0640],
        [0.0626, 0.0622],
        [0.0669, 0.0583],
        [0.0597, 0.0652],
        [0.0625, 0.0623],
        [0.0641, 0.0608],
        [0.0571, 0.0683],
        [0.0636, 0.0612]], device='cuda:0')
 Batch: 6 of modal classification Duration: 0:00:00.332071
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0008, 0.0014],
        [0.0010, 0.0015],
        [0.0002, 0.0006],
        [0.0004, 0.0013],
        [0.0002, 0.0005],
        [0.0002, 0.0008],
        [0.0002, 0.0007],
        [0.0007, 0.0017],
        [0.0002, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0006, 0.0013],
        [0.0003, 0.0005],
        [0.0007, 0.0011],
        [0.0003, 0.0010],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0671, 0.0580],
        [0.0694, 0.0561],
        [0.0609, 0.0638],
        [0.0594, 0.0655],
        [0.0612, 0.0635],
        [0.0580, 0.0671],
        [0.0584, 0.0666],
        [0.0625, 0.0623],
        [0.0555, 0.0701],
        [0.0611, 0.0636],
        [0.0606, 0.0641],
        [0.0638, 0.0610],
        [0.0681, 0.0571],
        [0.0683, 0.0569],
        [0.0590, 0.0659],
        [0.0665, 0.0585]], device='cuda:0')
 Batch: 7 of modal classification Duration: 0:00:00.429215
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0009],
        [0.0002, 0.0008],
        [0.0004, 0.0007],
        [0.0011, 0.0024],
        [0.0002, 0.0005],
        [0.0005, 0.0010],
        [0.0006, 0.0017],
        [0.0002, 0.0007],
        [0.0001, 0.0005],
        [0.0005, 0.0008],
        [0.0007, 0.0011],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0005, 0.0012],
        [0.0006, 0.0014]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0589, 0.0661],
        [0.0541, 0.0719],
        [0.0662, 0.0588],
        [0.0638, 0.0610],
        [0.0623, 0.0625],
        [0.0651, 0.0598],
        [0.0602, 0.0646],
        [0.0600, 0.0648],
        [0.0590, 0.0660],
        [0.0670, 0.0581],
        [0.0681, 0.0571],
        [0.0647, 0.0602],
        [0.0608, 0.0641],
        [0.0650, 0.0599],
        [0.0615, 0.0633],
        [0.0630, 0.0619]], device='cuda:0')
 Batch: 8 of modal classification Duration: 0:00:00.403887
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0002, 0.0006],
        [0.0009, 0.0018],
        [0.0005, 0.0011],
        [0.0005, 0.0014],
        [0.0003, 0.0011],
        [0.0002, 0.0006],
        [0.0003, 0.0008],
        [0.0006, 0.0013],
        [0.0002, 0.0007],
        [0.0002, 0.0008],
        [0.0005, 0.0010],
        [0.0005, 0.0009],
        [0.0009, 0.0013],
        [0.0003, 0.0006],
        [0.0005, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0617, 0.0632],
        [0.0626, 0.0623],
        [0.0649, 0.0600],
        [0.0636, 0.0613],
        [0.0602, 0.0648],
        [0.0563, 0.0692],
        [0.0601, 0.0649],
        [0.0616, 0.0633],
        [0.0649, 0.0601],
        [0.0607, 0.0642],
        [0.0584, 0.0667],
        [0.0642, 0.0607],
        [0.0661, 0.0590],
        [0.0691, 0.0564],
        [0.0632, 0.0617],
        [0.0626, 0.0623]], device='cuda:0')
 Batch: 9 of modal classification Duration: 0:00:00.421183
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0016],
        [0.0005, 0.0013],
        [0.0003, 0.0009],
        [0.0006, 0.0020],
        [0.0003, 0.0005],
        [0.0004, 0.0010],
        [0.0002, 0.0009],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0007, 0.0017],
        [0.0008, 0.0018],
        [0.0007, 0.0011],
        [0.0007, 0.0013],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0564, 0.0691],
        [0.0625, 0.0623],
        [0.0589, 0.0662],
        [0.0593, 0.0657],
        [0.0649, 0.0601],
        [0.0638, 0.0611],
        [0.0580, 0.0672],
        [0.0645, 0.0604],
        [0.0609, 0.0640],
        [0.0642, 0.0607],
        [0.0653, 0.0597],
        [0.0634, 0.0614],
        [0.0633, 0.0615],
        [0.0681, 0.0572],
        [0.0661, 0.0589],
        [0.0605, 0.0644]], device='cuda:0')
 Batch: 10 of modal classification Duration: 0:00:00.333860
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0010],
        [0.0002, 0.0004],
        [0.0007, 0.0015],
        [0.0005, 0.0015],
        [0.0003, 0.0009],
        [0.0003, 0.0008],
        [0.0003, 0.0010],
        [0.0006, 0.0010],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0004, 0.0009],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0591, 0.0659],
        [0.0604, 0.0645],
        [0.0644, 0.0606],
        [0.0676, 0.0576],
        [0.0599, 0.0651],
        [0.0643, 0.0607],
        [0.0647, 0.0603],
        [0.0600, 0.0650],
        [0.0588, 0.0663],
        [0.0607, 0.0642],
        [0.0597, 0.0653],
        [0.0671, 0.0581],
        [0.0614, 0.0635],
        [0.0611, 0.0638],
        [0.0651, 0.0598],
        [0.0657, 0.0593]], device='cuda:0')
 Batch: 11 of modal classification Duration: 0:00:00.448473
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0003, 0.0009],
        [0.0002, 0.0007],
        [0.0007, 0.0022],
        [0.0004, 0.0010],
        [0.0004, 0.0009],
        [0.0006, 0.0010],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1252],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1305, 0.1194],
        [0.1175, 0.1326],
        [0.1198, 0.1301],
        [0.1182, 0.1318],
        [0.1216, 0.1282],
        [0.1285, 0.1213],
        [0.1372, 0.1136],
        [0.1267, 0.1230]], device='cuda:0')
 Batch: 12 of modal classification Duration: 0:00:00.125170
acc:  0.49
Time taken to execute the en SA task with prompt type modal, variation 9 and batchsize 16: 0:00:05.112341
path ['42', 'en', 'bloom-big', 'SA', 'modal', 'prompt_id_9']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v73.pickle' as a pickle file.

prompt_type common has 7 prompts in it
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([106, 2])
answers_probs just softmax dim 0: tensor([[0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094]], device='cuda:0')
tensor([[0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094],
        [0.0094, 0.0094]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA common 0 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0005, 0.0007],
        [0.0002, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0005, 0.0011],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0004, 0.0015],
        [0.0003, 0.0006],
        [0.0002, 0.0007],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0001, 0.0003],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0688, 0.0566],
        [0.0676, 0.0576],
        [0.0585, 0.0666],
        [0.0663, 0.0588],
        [0.0589, 0.0661],
        [0.0611, 0.0638],
        [0.0641, 0.0607],
        [0.0589, 0.0661],
        [0.0606, 0.0643],
        [0.0565, 0.0689],
        [0.0643, 0.0606],
        [0.0587, 0.0663],
        [0.0659, 0.0591],
        [0.0654, 0.0595],
        [0.0629, 0.0619],
        [0.0617, 0.0631]], device='cuda:0')
 Batch: 0 of common classification Duration: 0:00:00.367442
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0009],
        [0.0003, 0.0006],
        [0.0003, 0.0012],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0010],
        [0.0001, 0.0003],
        [0.0002, 0.0007],
        [0.0002, 0.0003],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0004, 0.0014],
        [0.0004, 0.0006],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0582, 0.0669],
        [0.0652, 0.0597],
        [0.0557, 0.0699],
        [0.0644, 0.0604],
        [0.0665, 0.0585],
        [0.0641, 0.0608],
        [0.0612, 0.0636],
        [0.0615, 0.0633],
        [0.0587, 0.0663],
        [0.0669, 0.0582],
        [0.0662, 0.0588],
        [0.0635, 0.0613],
        [0.0605, 0.0643],
        [0.0582, 0.0669],
        [0.0684, 0.0569],
        [0.0608, 0.0640]], device='cuda:0')
 Batch: 1 of common classification Duration: 0:00:00.328394
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0002, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0004, 0.0007],
        [0.0003, 0.0010],
        [0.0003, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0635, 0.0614],
        [0.0612, 0.0637],
        [0.0625, 0.0624],
        [0.0640, 0.0610],
        [0.0592, 0.0658],
        [0.0622, 0.0627],
        [0.0662, 0.0589],
        [0.0617, 0.0632],
        [0.0611, 0.0638],
        [0.0662, 0.0589],
        [0.0591, 0.0659],
        [0.0662, 0.0589],
        [0.0593, 0.0657],
        [0.0595, 0.0655],
        [0.0664, 0.0587],
        [0.0616, 0.0633]], device='cuda:0')
 Batch: 2 of common classification Duration: 0:00:00.314893
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0006, 0.0015],
        [0.0004, 0.0013],
        [0.0002, 0.0003],
        [0.0002, 0.0012],
        [0.0004, 0.0008],
        [0.0004, 0.0007],
        [0.0002, 0.0007],
        [0.0005, 0.0012],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0612, 0.0636],
        [0.0631, 0.0617],
        [0.0622, 0.0626],
        [0.0624, 0.0624],
        [0.0702, 0.0554],
        [0.0657, 0.0593],
        [0.0640, 0.0608],
        [0.0613, 0.0635],
        [0.0592, 0.0658],
        [0.0665, 0.0585],
        [0.0544, 0.0715],
        [0.0633, 0.0615],
        [0.0651, 0.0598],
        [0.0557, 0.0699],
        [0.0624, 0.0624],
        [0.0634, 0.0614]], device='cuda:0')
 Batch: 3 of common classification Duration: 0:00:00.357333
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0006, 0.0012],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0008],
        [0.0006, 0.0013],
        [0.0002, 0.0005],
        [0.0002, 0.0007],
        [0.0002, 0.0008],
        [0.0003, 0.0010],
        [0.0002, 0.0006],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0663, 0.0587],
        [0.0611, 0.0638],
        [0.0623, 0.0625],
        [0.0655, 0.0595],
        [0.0634, 0.0614],
        [0.0667, 0.0584],
        [0.0599, 0.0651],
        [0.0641, 0.0608],
        [0.0661, 0.0589],
        [0.0578, 0.0674],
        [0.0587, 0.0664],
        [0.0596, 0.0654],
        [0.0617, 0.0631],
        [0.0672, 0.0580],
        [0.0598, 0.0652],
        [0.0597, 0.0653]], device='cuda:0')
 Batch: 4 of common classification Duration: 0:00:00.477891
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0006],
        [0.0006, 0.0012],
        [0.0002, 0.0006],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0002, 0.0006],
        [0.0004, 0.0008],
        [0.0002, 0.0005],
        [0.0005, 0.0009],
        [0.0002, 0.0005],
        [0.0002, 0.0006],
        [0.0003, 0.0009],
        [0.0002, 0.0003],
        [0.0004, 0.0007],
        [0.0002, 0.0006],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0594, 0.0656],
        [0.0640, 0.0609],
        [0.0597, 0.0653],
        [0.0618, 0.0631],
        [0.0622, 0.0627],
        [0.0617, 0.0632],
        [0.0637, 0.0613],
        [0.0589, 0.0662],
        [0.0660, 0.0591],
        [0.0651, 0.0599],
        [0.0609, 0.0640],
        [0.0603, 0.0647],
        [0.0660, 0.0591],
        [0.0650, 0.0600],
        [0.0609, 0.0640],
        [0.0644, 0.0606]], device='cuda:0')
 Batch: 5 of common classification Duration: 0:00:00.566607
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0010],
        [0.0005, 0.0011],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0006, 0.0008],
        [0.0002, 0.0006],
        [0.0002, 0.0004],
        [0.0007, 0.0017],
        [0.0002, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0004, 0.0005],
        [0.0003, 0.0009],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0571, 0.0681],
        [0.0632, 0.0616],
        [0.0632, 0.0616],
        [0.0617, 0.0630],
        [0.0657, 0.0592],
        [0.0692, 0.0562],
        [0.0576, 0.0675],
        [0.0615, 0.0632],
        [0.0608, 0.0640],
        [0.0569, 0.0684],
        [0.0642, 0.0606],
        [0.0600, 0.0648],
        [0.0612, 0.0635],
        [0.0709, 0.0548],
        [0.0573, 0.0678],
        [0.0697, 0.0558]], device='cuda:0')
 Batch: 6 of common classification Duration: 0:00:00.357454
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0001, 0.0003],
        [0.0002, 0.0004],
        [0.0004, 0.0008],
        [0.0002, 0.0006],
        [0.0003, 0.0007],
        [0.0002, 0.0006],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0006],
        [0.0004, 0.0008],
        [0.0002, 0.0005],
        [0.0004, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0599, 0.0651],
        [0.0639, 0.0611],
        [0.0630, 0.0619],
        [0.0629, 0.0620],
        [0.0608, 0.0642],
        [0.0625, 0.0625],
        [0.0598, 0.0652],
        [0.0606, 0.0644],
        [0.0612, 0.0638],
        [0.0622, 0.0628],
        [0.0620, 0.0630],
        [0.0645, 0.0605],
        [0.0634, 0.0615],
        [0.0658, 0.0593],
        [0.0622, 0.0628],
        [0.0652, 0.0599]], device='cuda:0')
 Batch: 7 of common classification Duration: 0:00:00.448145
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0002, 0.0002],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0006, 0.0013],
        [0.0004, 0.0010],
        [0.0002, 0.0005],
        [0.0001, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0619, 0.0629],
        [0.0756, 0.0515],
        [0.0618, 0.0630],
        [0.0656, 0.0593],
        [0.0619, 0.0629],
        [0.0601, 0.0648],
        [0.0623, 0.0624],
        [0.0610, 0.0638],
        [0.0652, 0.0597],
        [0.0619, 0.0629],
        [0.0625, 0.0622],
        [0.0583, 0.0668],
        [0.0622, 0.0626],
        [0.0588, 0.0662],
        [0.0626, 0.0622],
        [0.0583, 0.0668]], device='cuda:0')
 Batch: 8 of common classification Duration: 0:00:00.363532
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0001, 0.0004],
        [0.0003, 0.0007],
        [0.0004, 0.0009],
        [0.0003, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0007, 0.0009],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0004, 0.0009],
        [0.0003, 0.0008],
        [0.0004, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0599, 0.0651],
        [0.0612, 0.0637],
        [0.0639, 0.0610],
        [0.0582, 0.0670],
        [0.0663, 0.0588],
        [0.0655, 0.0595],
        [0.0605, 0.0644],
        [0.0704, 0.0553],
        [0.0624, 0.0625],
        [0.0601, 0.0649],
        [0.0633, 0.0616],
        [0.0608, 0.0641],
        [0.0637, 0.0612],
        [0.0635, 0.0614],
        [0.0600, 0.0650],
        [0.0604, 0.0645]], device='cuda:0')
 Batch: 9 of common classification Duration: 0:00:00.428809
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0003, 0.0009],
        [0.0003, 0.0007],
        [0.0002, 0.0007],
        [0.0002, 0.0004],
        [0.0007, 0.0010],
        [0.0002, 0.0005],
        [0.0002, 0.0007],
        [0.0004, 0.0009],
        [0.0003, 0.0007],
        [0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0629, 0.0621],
        [0.0643, 0.0606],
        [0.0602, 0.0647],
        [0.0620, 0.0629],
        [0.0592, 0.0659],
        [0.0639, 0.0610],
        [0.0597, 0.0653],
        [0.0624, 0.0625],
        [0.0698, 0.0559],
        [0.0638, 0.0611],
        [0.0606, 0.0644],
        [0.0629, 0.0621],
        [0.0611, 0.0639],
        [0.0618, 0.0631],
        [0.0621, 0.0628],
        [0.0632, 0.0618]], device='cuda:0')
 Batch: 10 of common classification Duration: 0:00:00.405537
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0002, 0.0006],
        [0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0003, 0.0007],
        [0.0008, 0.0011],
        [0.0001, 0.0004],
        [0.0003, 0.0011],
        [0.0002, 0.0005],
        [0.0005, 0.0009],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0596, 0.0654],
        [0.0592, 0.0658],
        [0.0619, 0.0629],
        [0.0624, 0.0624],
        [0.0576, 0.0676],
        [0.0647, 0.0602],
        [0.0629, 0.0619],
        [0.0661, 0.0589],
        [0.0687, 0.0567],
        [0.0629, 0.0619],
        [0.0699, 0.0557],
        [0.0599, 0.0650],
        [0.0573, 0.0680],
        [0.0612, 0.0636],
        [0.0650, 0.0599],
        [0.0606, 0.0643]], device='cuda:0')
 Batch: 11 of common classification Duration: 0:00:00.407107
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0002, 0.0006],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0010],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0004, 0.0004],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1210, 0.1285],
        [0.1208, 0.1287],
        [0.1140, 0.1364],
        [0.1173, 0.1325],
        [0.1324, 0.1175],
        [0.1288, 0.1207],
        [0.1430, 0.1087],
        [0.1226, 0.1269]], device='cuda:0')
 Batch: 12 of common classification Duration: 0:00:00.181830
acc:  0.555
Time taken to execute the en SA task with prompt type common, variation 0 and batchsize 16: 0:00:05.020727
path ['42', 'en', 'bloom-big', 'SA', 'common', 'prompt_id_0']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([100, 2])
answers_probs just softmax dim 0: tensor([[0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100]], device='cuda:0')
tensor([[0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100],
        [0.0100, 0.0100]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA common 1 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0011],
        [0.0002, 0.0004],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0003, 0.0009],
        [0.0003, 0.0010],
        [0.0001, 0.0002],
        [0.0005, 0.0012],
        [0.0003, 0.0007],
        [0.0004, 0.0011],
        [0.0003, 0.0007],
        [0.0001, 0.0002],
        [0.0002, 0.0003],
        [0.0004, 0.0011],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0628, 0.0621],
        [0.0644, 0.0605],
        [0.0597, 0.0653],
        [0.0645, 0.0604],
        [0.0656, 0.0594],
        [0.0595, 0.0655],
        [0.0573, 0.0681],
        [0.0647, 0.0603],
        [0.0621, 0.0627],
        [0.0604, 0.0645],
        [0.0607, 0.0642],
        [0.0609, 0.0640],
        [0.0645, 0.0604],
        [0.0663, 0.0588],
        [0.0587, 0.0664],
        [0.0678, 0.0575]], device='cuda:0')
 Batch: 0 of common classification Duration: 0:00:00.374557
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0010],
        [0.0003, 0.0007],
        [0.0006, 0.0011],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0013],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0627, 0.0621],
        [0.0621, 0.0628],
        [0.0565, 0.0690],
        [0.0615, 0.0634],
        [0.0634, 0.0615],
        [0.0649, 0.0601],
        [0.0635, 0.0614],
        [0.0628, 0.0621],
        [0.0607, 0.0642],
        [0.0649, 0.0601],
        [0.0621, 0.0628],
        [0.0603, 0.0646],
        [0.0653, 0.0597],
        [0.0675, 0.0578],
        [0.0587, 0.0664],
        [0.0630, 0.0619]], device='cuda:0')
 Batch: 1 of common classification Duration: 0:00:00.444998
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0004, 0.0008],
        [0.0004, 0.0012],
        [0.0002, 0.0007],
        [0.0003, 0.0009],
        [0.0003, 0.0004],
        [0.0003, 0.0009],
        [0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0004, 0.0005],
        [0.0001, 0.0002],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0625, 0.0622],
        [0.0634, 0.0614],
        [0.0615, 0.0633],
        [0.0678, 0.0574],
        [0.0605, 0.0643],
        [0.0639, 0.0610],
        [0.0591, 0.0658],
        [0.0567, 0.0686],
        [0.0581, 0.0669],
        [0.0686, 0.0568],
        [0.0601, 0.0647],
        [0.0595, 0.0654],
        [0.0604, 0.0644],
        [0.0694, 0.0561],
        [0.0676, 0.0576],
        [0.0609, 0.0639]], device='cuda:0')
 Batch: 2 of common classification Duration: 0:00:00.542088
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0004, 0.0011],
        [0.0004, 0.0008],
        [0.0001, 0.0003],
        [0.0005, 0.0012],
        [0.0002, 0.0008],
        [0.0003, 0.0004],
        [0.0004, 0.0009],
        [0.0003, 0.0004],
        [0.0003, 0.0008],
        [0.0003, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0006],
        [0.0002, 0.0002],
        [0.0007, 0.0018]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626]], device='cuda:0')
tensor([[0.0611, 0.0636],
        [0.0591, 0.0658],
        [0.0621, 0.0625],
        [0.0640, 0.0607],
        [0.0610, 0.0637],
        [0.0553, 0.0703],
        [0.0667, 0.0583],
        [0.0593, 0.0655],
        [0.0724, 0.0536],
        [0.0571, 0.0681],
        [0.0562, 0.0691],
        [0.0641, 0.0606],
        [0.0642, 0.0605],
        [0.0691, 0.0562],
        [0.0686, 0.0566],
        [0.0597, 0.0651]], device='cuda:0')
 Batch: 3 of common classification Duration: 0:00:00.358590
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0006, 0.0013],
        [0.0002, 0.0003],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0003, 0.0009],
        [0.0002, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0004],
        [0.0005, 0.0010],
        [0.0003, 0.0006],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0652, 0.0598],
        [0.0608, 0.0641],
        [0.0644, 0.0605],
        [0.0643, 0.0606],
        [0.0627, 0.0622],
        [0.0584, 0.0668],
        [0.0566, 0.0688],
        [0.0670, 0.0582],
        [0.0615, 0.0633],
        [0.0584, 0.0668],
        [0.0634, 0.0614],
        [0.0614, 0.0635],
        [0.0694, 0.0561],
        [0.0619, 0.0629],
        [0.0615, 0.0633],
        [0.0630, 0.0618]], device='cuda:0')
 Batch: 4 of common classification Duration: 0:00:00.364457
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0007],
        [0.0001, 0.0002],
        [0.0003, 0.0009],
        [0.0004, 0.0012],
        [0.0005, 0.0013],
        [0.0004, 0.0011],
        [0.0002, 0.0004],
        [0.0002, 0.0006],
        [0.0003, 0.0007],
        [0.0004, 0.0009],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0005, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0628, 0.0619],
        [0.0613, 0.0634],
        [0.0720, 0.0540],
        [0.0619, 0.0628],
        [0.0720, 0.0540],
        [0.0588, 0.0661],
        [0.0573, 0.0679],
        [0.0603, 0.0644],
        [0.0596, 0.0653],
        [0.0620, 0.0627],
        [0.0579, 0.0671],
        [0.0591, 0.0658],
        [0.0627, 0.0620],
        [0.0633, 0.0614],
        [0.0682, 0.0570],
        [0.0606, 0.0641]], device='cuda:0')
 Batch: 5 of common classification Duration: 0:00:00.402019
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0012],
        [0.0002, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0004],
        [0.0004, 0.0013],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0008],
        [0.0005, 0.0012],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0006, 0.0015],
        [0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0004, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0652, 0.0598],
        [0.0603, 0.0647],
        [0.0684, 0.0570],
        [0.0682, 0.0571],
        [0.0584, 0.0668],
        [0.0626, 0.0622],
        [0.0642, 0.0608],
        [0.0603, 0.0647],
        [0.0611, 0.0638],
        [0.0632, 0.0617],
        [0.0593, 0.0657],
        [0.0632, 0.0617],
        [0.0605, 0.0644],
        [0.0602, 0.0648],
        [0.0634, 0.0615],
        [0.0616, 0.0633]], device='cuda:0')
 Batch: 6 of common classification Duration: 0:00:00.431542
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0003, 0.0004],
        [0.0003, 0.0008],
        [0.0003, 0.0010],
        [0.0001, 0.0001],
        [0.0004, 0.0009],
        [0.0007, 0.0013],
        [0.0003, 0.0012],
        [0.0002, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0008, 0.0018],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0642, 0.0606],
        [0.0675, 0.0576],
        [0.0609, 0.0639],
        [0.0578, 0.0673],
        [0.0737, 0.0527],
        [0.0610, 0.0638],
        [0.0634, 0.0614],
        [0.0563, 0.0691],
        [0.0558, 0.0697],
        [0.0625, 0.0622],
        [0.0670, 0.0580],
        [0.0623, 0.0624],
        [0.0622, 0.0625],
        [0.0614, 0.0634],
        [0.0655, 0.0593],
        [0.0586, 0.0663]], device='cuda:0')
 Batch: 7 of common classification Duration: 0:00:00.404426
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0003, 0.0003],
        [0.0003, 0.0010],
        [0.0002, 0.0005],
        [0.0001, 0.0001],
        [0.0006, 0.0013],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0003, 0.0008],
        [0.0005, 0.0009],
        [0.0004, 0.0010],
        [0.0003, 0.0003],
        [0.0003, 0.0006],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0590, 0.0659],
        [0.0676, 0.0575],
        [0.0569, 0.0682],
        [0.0566, 0.0686],
        [0.0706, 0.0550],
        [0.0608, 0.0639],
        [0.0604, 0.0643],
        [0.0587, 0.0662],
        [0.0595, 0.0652],
        [0.0669, 0.0580],
        [0.0595, 0.0652],
        [0.0639, 0.0608],
        [0.0599, 0.0648],
        [0.0736, 0.0528],
        [0.0614, 0.0633],
        [0.0646, 0.0601]], device='cuda:0')
 Batch: 8 of common classification Duration: 0:00:00.407637
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0004, 0.0012],
        [0.0005, 0.0008],
        [0.0003, 0.0010],
        [0.0003, 0.0005],
        [0.0002, 0.0003],
        [0.0002, 0.0002],
        [0.0001, 0.0002],
        [0.0004, 0.0010],
        [0.0003, 0.0010],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0593, 0.0656],
        [0.0665, 0.0585],
        [0.0577, 0.0675],
        [0.0639, 0.0609],
        [0.0567, 0.0686],
        [0.0643, 0.0605],
        [0.0666, 0.0584],
        [0.0655, 0.0594],
        [0.0692, 0.0562],
        [0.0605, 0.0643],
        [0.0568, 0.0685],
        [0.0667, 0.0584],
        [0.0643, 0.0605],
        [0.0592, 0.0657],
        [0.0621, 0.0627],
        [0.0605, 0.0643]], device='cuda:0')
 Batch: 9 of common classification Duration: 0:00:00.359859
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0005, 0.0010],
        [0.0004, 0.0006],
        [0.0002, 0.0007],
        [0.0002, 0.0005],
        [0.0005, 0.0010],
        [0.0002, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0001, 0.0002],
        [0.0002, 0.0003],
        [0.0003, 0.0009],
        [0.0001, 0.0001],
        [0.0002, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0628, 0.0619],
        [0.0619, 0.0628],
        [0.0676, 0.0575],
        [0.0560, 0.0694],
        [0.0606, 0.0641],
        [0.0611, 0.0636],
        [0.0585, 0.0665],
        [0.0590, 0.0658],
        [0.0667, 0.0583],
        [0.0639, 0.0608],
        [0.0672, 0.0578],
        [0.0564, 0.0689],
        [0.0690, 0.0564],
        [0.0560, 0.0694],
        [0.0645, 0.0603],
        [0.0689, 0.0564]], device='cuda:0')
 Batch: 10 of common classification Duration: 0:00:00.478407
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0011],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0009],
        [0.0002, 0.0002],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0004, 0.0012],
        [0.0005, 0.0010],
        [0.0002, 0.0002],
        [0.0005, 0.0010],
        [0.0007, 0.0015],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0577, 0.0675],
        [0.0582, 0.0669],
        [0.0614, 0.0634],
        [0.0595, 0.0653],
        [0.0641, 0.0607],
        [0.0613, 0.0635],
        [0.0725, 0.0537],
        [0.0629, 0.0619],
        [0.0669, 0.0582],
        [0.0627, 0.0621],
        [0.0569, 0.0684],
        [0.0618, 0.0629],
        [0.0704, 0.0553],
        [0.0628, 0.0620],
        [0.0607, 0.0641],
        [0.0605, 0.0643]], device='cuda:0')
 Batch: 11 of common classification Duration: 0:00:00.321020
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0010],
        [0.0002, 0.0007],
        [0.0004, 0.0008],
        [0.0001, 0.0002],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0005, 0.0013],
        [0.0004, 0.0012]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1249],
        [0.1250, 0.1249],
        [0.1250, 0.1249],
        [0.1250, 0.1251],
        [0.1250, 0.1251]], device='cuda:0')
tensor([[0.1128, 0.1375],
        [0.1147, 0.1352],
        [0.1251, 0.1239],
        [0.1296, 0.1196],
        [0.1458, 0.1063],
        [0.1387, 0.1118],
        [0.1180, 0.1314],
        [0.1154, 0.1344]], device='cuda:0')
 Batch: 12 of common classification Duration: 0:00:00.178085
acc:  0.515
Time taken to execute the en SA task with prompt type common, variation 1 and batchsize 16: 0:00:05.083970
path ['42', 'en', 'bloom-big', 'SA', 'common', 'prompt_id_1']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([124, 2])
answers_probs just softmax dim 0: tensor([[0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081]], device='cuda:0')
tensor([[0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA common 2 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0002, 0.0006],
        [0.0004, 0.0005],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0001, 0.0004],
        [0.0004, 0.0010],
        [0.0003, 0.0013],
        [0.0003, 0.0006],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0640, 0.0608],
        [0.0624, 0.0624],
        [0.0704, 0.0553],
        [0.0591, 0.0658],
        [0.0700, 0.0556],
        [0.0614, 0.0634],
        [0.0632, 0.0616],
        [0.0605, 0.0644],
        [0.0604, 0.0645],
        [0.0626, 0.0622],
        [0.0617, 0.0631],
        [0.0591, 0.0658],
        [0.0603, 0.0645],
        [0.0555, 0.0702],
        [0.0636, 0.0612],
        [0.0658, 0.0591]], device='cuda:0')
 Batch: 0 of common classification Duration: 0:00:00.346042
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0005],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0005, 0.0008],
        [0.0003, 0.0008],
        [0.0004, 0.0009],
        [0.0002, 0.0003],
        [0.0002, 0.0004],
        [0.0002, 0.0002],
        [0.0003, 0.0010],
        [0.0004, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0001, 0.0003],
        [0.0002, 0.0005],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0676, 0.0575],
        [0.0614, 0.0633],
        [0.0592, 0.0656],
        [0.0636, 0.0611],
        [0.0573, 0.0678],
        [0.0609, 0.0639],
        [0.0621, 0.0626],
        [0.0633, 0.0614],
        [0.0761, 0.0511],
        [0.0559, 0.0696],
        [0.0623, 0.0624],
        [0.0584, 0.0666],
        [0.0655, 0.0593],
        [0.0619, 0.0628],
        [0.0590, 0.0658],
        [0.0655, 0.0593]], device='cuda:0')
 Batch: 1 of common classification Duration: 0:00:00.363263
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0002, 0.0003],
        [0.0001, 0.0004],
        [0.0001, 0.0002],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0002, 0.0006],
        [0.0003, 0.0005],
        [0.0006, 0.0016],
        [0.0002, 0.0009],
        [0.0005, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0606, 0.0642],
        [0.0579, 0.0672],
        [0.0688, 0.0566],
        [0.0594, 0.0655],
        [0.0726, 0.0536],
        [0.0639, 0.0609],
        [0.0621, 0.0627],
        [0.0655, 0.0594],
        [0.0619, 0.0629],
        [0.0623, 0.0624],
        [0.0601, 0.0647],
        [0.0606, 0.0642],
        [0.0670, 0.0581],
        [0.0596, 0.0652],
        [0.0557, 0.0699],
        [0.0621, 0.0627]], device='cuda:0')
 Batch: 2 of common classification Duration: 0:00:00.334644
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0002, 0.0003],
        [0.0005, 0.0008],
        [0.0002, 0.0005],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0005, 0.0009],
        [0.0003, 0.0005],
        [0.0004, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0610, 0.0639],
        [0.0615, 0.0633],
        [0.0630, 0.0618],
        [0.0607, 0.0642],
        [0.0631, 0.0617],
        [0.0597, 0.0652],
        [0.0591, 0.0660],
        [0.0702, 0.0555],
        [0.0649, 0.0601],
        [0.0587, 0.0664],
        [0.0669, 0.0582],
        [0.0598, 0.0651],
        [0.0622, 0.0627],
        [0.0641, 0.0608],
        [0.0649, 0.0601],
        [0.0600, 0.0649]], device='cuda:0')
 Batch: 3 of common classification Duration: 0:00:00.334019
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0004, 0.0010],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0002, 0.0003],
        [0.0005, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0006, 0.0012],
        [0.0002, 0.0007],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0598, 0.0651],
        [0.0602, 0.0647],
        [0.0618, 0.0631],
        [0.0617, 0.0632],
        [0.0641, 0.0608],
        [0.0640, 0.0609],
        [0.0622, 0.0626],
        [0.0671, 0.0580],
        [0.0724, 0.0538],
        [0.0617, 0.0632],
        [0.0642, 0.0607],
        [0.0628, 0.0620],
        [0.0571, 0.0682],
        [0.0619, 0.0629],
        [0.0581, 0.0671],
        [0.0609, 0.0639]], device='cuda:0')
 Batch: 4 of common classification Duration: 0:00:00.429461
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0002, 0.0010],
        [0.0003, 0.0007],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0007, 0.0015],
        [0.0004, 0.0005],
        [0.0002, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0002],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0009],
        [0.0004, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0694, 0.0559],
        [0.0542, 0.0716],
        [0.0601, 0.0645],
        [0.0685, 0.0566],
        [0.0657, 0.0590],
        [0.0586, 0.0662],
        [0.0626, 0.0620],
        [0.0675, 0.0575],
        [0.0577, 0.0673],
        [0.0611, 0.0635],
        [0.0752, 0.0516],
        [0.0611, 0.0635],
        [0.0612, 0.0634],
        [0.0598, 0.0649],
        [0.0581, 0.0668],
        [0.0591, 0.0657]], device='cuda:0')
 Batch: 5 of common classification Duration: 0:00:00.446019
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0002, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0002],
        [0.0002, 0.0004],
        [0.0002, 0.0006],
        [0.0006, 0.0011],
        [0.0006, 0.0015],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0003, 0.0008],
        [0.0002, 0.0007],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0627, 0.0620],
        [0.0647, 0.0602],
        [0.0608, 0.0641],
        [0.0653, 0.0596],
        [0.0584, 0.0666],
        [0.0582, 0.0668],
        [0.0738, 0.0528],
        [0.0621, 0.0627],
        [0.0603, 0.0646],
        [0.0645, 0.0604],
        [0.0591, 0.0658],
        [0.0630, 0.0618],
        [0.0662, 0.0587],
        [0.0597, 0.0652],
        [0.0571, 0.0681],
        [0.0642, 0.0606]], device='cuda:0')
 Batch: 6 of common classification Duration: 0:00:00.398404
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0008],
        [0.0004, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0002, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0609, 0.0639],
        [0.0646, 0.0602],
        [0.0656, 0.0594],
        [0.0588, 0.0662],
        [0.0646, 0.0602],
        [0.0590, 0.0660],
        [0.0625, 0.0623],
        [0.0550, 0.0708],
        [0.0616, 0.0632],
        [0.0595, 0.0654],
        [0.0651, 0.0598],
        [0.0673, 0.0578],
        [0.0657, 0.0592],
        [0.0668, 0.0583],
        [0.0651, 0.0598],
        [0.0577, 0.0674]], device='cuda:0')
 Batch: 7 of common classification Duration: 0:00:00.409694
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0004, 0.0007],
        [0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0002],
        [0.0001, 0.0004],
        [0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0002, 0.0006],
        [0.0003, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0626, 0.0622],
        [0.0628, 0.0620],
        [0.0600, 0.0649],
        [0.0642, 0.0606],
        [0.0590, 0.0661],
        [0.0605, 0.0644],
        [0.0707, 0.0551],
        [0.0618, 0.0630],
        [0.0620, 0.0628],
        [0.0618, 0.0631],
        [0.0618, 0.0631],
        [0.0650, 0.0599],
        [0.0687, 0.0567],
        [0.0618, 0.0631],
        [0.0577, 0.0675],
        [0.0594, 0.0656]], device='cuda:0')
 Batch: 8 of common classification Duration: 0:00:00.407724
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0006],
        [0.0004, 0.0009],
        [0.0003, 0.0009],
        [0.0004, 0.0008],
        [0.0002, 0.0003],
        [0.0003, 0.0008],
        [0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0008, 0.0017],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0003, 0.0009],
        [0.0003, 0.0009],
        [0.0002, 0.0005],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0615, 0.0634],
        [0.0640, 0.0609],
        [0.0578, 0.0674],
        [0.0632, 0.0616],
        [0.0707, 0.0551],
        [0.0597, 0.0653],
        [0.0627, 0.0621],
        [0.0591, 0.0659],
        [0.0629, 0.0619],
        [0.0640, 0.0609],
        [0.0626, 0.0623],
        [0.0701, 0.0556],
        [0.0606, 0.0643],
        [0.0599, 0.0650],
        [0.0622, 0.0627],
        [0.0592, 0.0657]], device='cuda:0')
 Batch: 9 of common classification Duration: 0:00:00.569137
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0001, 0.0002],
        [0.0002, 0.0003],
        [0.0002, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0010],
        [0.0005, 0.0013],
        [0.0005, 0.0009],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0001, 0.0004],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0006, 0.0012],
        [0.0001, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0690, 0.0565],
        [0.0662, 0.0589],
        [0.0632, 0.0617],
        [0.0604, 0.0646],
        [0.0640, 0.0609],
        [0.0585, 0.0667],
        [0.0589, 0.0661],
        [0.0651, 0.0599],
        [0.0636, 0.0614],
        [0.0638, 0.0611],
        [0.0595, 0.0655],
        [0.0629, 0.0620],
        [0.0602, 0.0648],
        [0.0621, 0.0628],
        [0.0612, 0.0637],
        [0.0616, 0.0633]], device='cuda:0')
 Batch: 10 of common classification Duration: 0:00:00.426270
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0004, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0011],
        [0.0002, 0.0003],
        [0.0004, 0.0009],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0006, 0.0009],
        [0.0004, 0.0007],
        [0.0004, 0.0010],
        [0.0002, 0.0005],
        [0.0004, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0583, 0.0667],
        [0.0609, 0.0639],
        [0.0659, 0.0591],
        [0.0652, 0.0597],
        [0.0609, 0.0639],
        [0.0579, 0.0672],
        [0.0658, 0.0592],
        [0.0609, 0.0639],
        [0.0661, 0.0589],
        [0.0586, 0.0664],
        [0.0624, 0.0624],
        [0.0690, 0.0564],
        [0.0676, 0.0576],
        [0.0592, 0.0658],
        [0.0626, 0.0622],
        [0.0585, 0.0665]], device='cuda:0')
 Batch: 11 of common classification Duration: 0:00:00.482803
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0006, 0.0020],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0002, 0.0006],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1252],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1249],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1295, 0.1203],
        [0.1213, 0.1284],
        [0.1153, 0.1351],
        [0.1366, 0.1141],
        [0.1176, 0.1324],
        [0.1316, 0.1184],
        [0.1219, 0.1278],
        [0.1262, 0.1235]], device='cuda:0')
 Batch: 12 of common classification Duration: 0:00:00.125511
acc:  0.545
Time taken to execute the en SA task with prompt type common, variation 2 and batchsize 16: 0:00:05.088750
path ['42', 'en', 'bloom-big', 'SA', 'common', 'prompt_id_2']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([155, 2])
answers_probs just softmax dim 0: tensor([[0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065]], device='cuda:0')
tensor([[0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065],
        [0.0065, 0.0065]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA common 3 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0005, 0.0013],
        [0.0006, 0.0009],
        [0.0005, 0.0009],
        [0.0004, 0.0009],
        [0.0006, 0.0010],
        [0.0006, 0.0012],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0005, 0.0009],
        [0.0006, 0.0009],
        [0.0006, 0.0012],
        [0.0006, 0.0011],
        [0.0003, 0.0004],
        [0.0004, 0.0006],
        [0.0006, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0603, 0.0647],
        [0.0583, 0.0670],
        [0.0656, 0.0595],
        [0.0625, 0.0624],
        [0.0593, 0.0659],
        [0.0629, 0.0620],
        [0.0619, 0.0631],
        [0.0639, 0.0610],
        [0.0618, 0.0632],
        [0.0632, 0.0617],
        [0.0651, 0.0599],
        [0.0613, 0.0636],
        [0.0630, 0.0619],
        [0.0653, 0.0598],
        [0.0642, 0.0608],
        [0.0614, 0.0635]], device='cuda:0')
 Batch: 0 of common classification Duration: 0:00:00.593418
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0006, 0.0008],
        [0.0003, 0.0006],
        [0.0006, 0.0011],
        [0.0008, 0.0015],
        [0.0006, 0.0012],
        [0.0004, 0.0008],
        [0.0006, 0.0007],
        [0.0007, 0.0010],
        [0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0005, 0.0008],
        [0.0008, 0.0015],
        [0.0005, 0.0009],
        [0.0003, 0.0005],
        [0.0007, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0683, 0.0571],
        [0.0648, 0.0603],
        [0.0621, 0.0629],
        [0.0614, 0.0636],
        [0.0611, 0.0639],
        [0.0605, 0.0645],
        [0.0608, 0.0641],
        [0.0664, 0.0588],
        [0.0645, 0.0605],
        [0.0613, 0.0637],
        [0.0623, 0.0626],
        [0.0613, 0.0637],
        [0.0613, 0.0637],
        [0.0615, 0.0634],
        [0.0616, 0.0633],
        [0.0609, 0.0640]], device='cuda:0')
 Batch: 1 of common classification Duration: 0:00:00.364876
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0004, 0.0005],
        [0.0007, 0.0010],
        [0.0008, 0.0013],
        [0.0005, 0.0009],
        [0.0004, 0.0007],
        [0.0006, 0.0008],
        [0.0005, 0.0008],
        [0.0006, 0.0009],
        [0.0005, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0007],
        [0.0007, 0.0010],
        [0.0004, 0.0007],
        [0.0005, 0.0005],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0650, 0.0601],
        [0.0634, 0.0616],
        [0.0643, 0.0607],
        [0.0617, 0.0632],
        [0.0610, 0.0639],
        [0.0595, 0.0656],
        [0.0640, 0.0610],
        [0.0618, 0.0631],
        [0.0638, 0.0611],
        [0.0637, 0.0612],
        [0.0610, 0.0639],
        [0.0618, 0.0631],
        [0.0626, 0.0623],
        [0.0588, 0.0664],
        [0.0660, 0.0592],
        [0.0614, 0.0636]], device='cuda:0')
 Batch: 2 of common classification Duration: 0:00:00.486532
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0006, 0.0013],
        [0.0004, 0.0006],
        [0.0006, 0.0008],
        [0.0003, 0.0004],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0004, 0.0005],
        [0.0004, 0.0008],
        [0.0004, 0.0006],
        [0.0007, 0.0012],
        [0.0005, 0.0009],
        [0.0005, 0.0008],
        [0.0007, 0.0009],
        [0.0005, 0.0010],
        [0.0006, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0666, 0.0585],
        [0.0582, 0.0670],
        [0.0656, 0.0594],
        [0.0657, 0.0593],
        [0.0662, 0.0589],
        [0.0582, 0.0670],
        [0.0599, 0.0651],
        [0.0651, 0.0599],
        [0.0601, 0.0648],
        [0.0624, 0.0624],
        [0.0607, 0.0642],
        [0.0613, 0.0636],
        [0.0617, 0.0631],
        [0.0665, 0.0586],
        [0.0585, 0.0667],
        [0.0635, 0.0614]], device='cuda:0')
 Batch: 3 of common classification Duration: 0:00:00.318166
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0004, 0.0006],
        [0.0003, 0.0006],
        [0.0006, 0.0013],
        [0.0005, 0.0008],
        [0.0006, 0.0009],
        [0.0004, 0.0006],
        [0.0004, 0.0005],
        [0.0005, 0.0007],
        [0.0004, 0.0008],
        [0.0007, 0.0011],
        [0.0005, 0.0010],
        [0.0006, 0.0009],
        [0.0003, 0.0004],
        [0.0003, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0601, 0.0648],
        [0.0620, 0.0629],
        [0.0653, 0.0597],
        [0.0604, 0.0645],
        [0.0586, 0.0665],
        [0.0643, 0.0606],
        [0.0639, 0.0610],
        [0.0632, 0.0617],
        [0.0662, 0.0589],
        [0.0657, 0.0594],
        [0.0605, 0.0644],
        [0.0634, 0.0615],
        [0.0604, 0.0645],
        [0.0643, 0.0606],
        [0.0655, 0.0595],
        [0.0561, 0.0695]], device='cuda:0')
 Batch: 4 of common classification Duration: 0:00:00.451803
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0006, 0.0007],
        [0.0006, 0.0012],
        [0.0002, 0.0003],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0005, 0.0008],
        [0.0006, 0.0008],
        [0.0005, 0.0010],
        [0.0004, 0.0006],
        [0.0005, 0.0009],
        [0.0003, 0.0005],
        [0.0006, 0.0016],
        [0.0006, 0.0010],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0610, 0.0638],
        [0.0610, 0.0638],
        [0.0677, 0.0576],
        [0.0591, 0.0659],
        [0.0644, 0.0605],
        [0.0604, 0.0645],
        [0.0585, 0.0666],
        [0.0618, 0.0630],
        [0.0672, 0.0580],
        [0.0606, 0.0643],
        [0.0661, 0.0589],
        [0.0610, 0.0638],
        [0.0650, 0.0599],
        [0.0565, 0.0690],
        [0.0624, 0.0625],
        [0.0672, 0.0580]], device='cuda:0')
 Batch: 5 of common classification Duration: 0:00:00.411046
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0003, 0.0003],
        [0.0007, 0.0010],
        [0.0005, 0.0008],
        [0.0006, 0.0010],
        [0.0007, 0.0017],
        [0.0004, 0.0008],
        [0.0004, 0.0007],
        [0.0011, 0.0015],
        [0.0004, 0.0004],
        [0.0006, 0.0008],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0005, 0.0008],
        [0.0006, 0.0008],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0622, 0.0627],
        [0.0703, 0.0554],
        [0.0639, 0.0609],
        [0.0609, 0.0639],
        [0.0612, 0.0637],
        [0.0569, 0.0685],
        [0.0581, 0.0670],
        [0.0628, 0.0621],
        [0.0652, 0.0598],
        [0.0663, 0.0587],
        [0.0631, 0.0617],
        [0.0630, 0.0618],
        [0.0601, 0.0649],
        [0.0601, 0.0649],
        [0.0653, 0.0597],
        [0.0606, 0.0643]], device='cuda:0')
 Batch: 6 of common classification Duration: 0:00:00.449680
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0005, 0.0006],
        [0.0004, 0.0006],
        [0.0006, 0.0013],
        [0.0002, 0.0003],
        [0.0004, 0.0008],
        [0.0003, 0.0003],
        [0.0004, 0.0007],
        [0.0007, 0.0012],
        [0.0003, 0.0006],
        [0.0006, 0.0013],
        [0.0006, 0.0012],
        [0.0007, 0.0012],
        [0.0006, 0.0010],
        [0.0006, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0611, 0.0638],
        [0.0577, 0.0675],
        [0.0681, 0.0572],
        [0.0622, 0.0627],
        [0.0590, 0.0661],
        [0.0639, 0.0609],
        [0.0613, 0.0636],
        [0.0703, 0.0554],
        [0.0626, 0.0622],
        [0.0618, 0.0630],
        [0.0595, 0.0655],
        [0.0593, 0.0657],
        [0.0605, 0.0644],
        [0.0625, 0.0623],
        [0.0624, 0.0624],
        [0.0680, 0.0573]], device='cuda:0')
 Batch: 7 of common classification Duration: 0:00:00.431628
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0014],
        [0.0004, 0.0008],
        [0.0005, 0.0014],
        [0.0004, 0.0008],
        [0.0004, 0.0006],
        [0.0006, 0.0009],
        [0.0005, 0.0011],
        [0.0004, 0.0008],
        [0.0005, 0.0008],
        [0.0006, 0.0010],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0005, 0.0008],
        [0.0005, 0.0009],
        [0.0004, 0.0006],
        [0.0005, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0576, 0.0676],
        [0.0606, 0.0643],
        [0.0571, 0.0682],
        [0.0618, 0.0630],
        [0.0623, 0.0625],
        [0.0638, 0.0610],
        [0.0588, 0.0662],
        [0.0593, 0.0656],
        [0.0624, 0.0624],
        [0.0638, 0.0610],
        [0.0690, 0.0564],
        [0.0705, 0.0552],
        [0.0642, 0.0607],
        [0.0633, 0.0615],
        [0.0655, 0.0594],
        [0.0599, 0.0650]], device='cuda:0')
 Batch: 8 of common classification Duration: 0:00:00.335372
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0013],
        [0.0005, 0.0006],
        [0.0006, 0.0008],
        [0.0004, 0.0007],
        [0.0005, 0.0006],
        [0.0004, 0.0005],
        [0.0004, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0008],
        [0.0006, 0.0007],
        [0.0005, 0.0009],
        [0.0005, 0.0007],
        [0.0005, 0.0007],
        [0.0005, 0.0007],
        [0.0006, 0.0016],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0574, 0.0679],
        [0.0680, 0.0573],
        [0.0641, 0.0608],
        [0.0622, 0.0627],
        [0.0665, 0.0585],
        [0.0655, 0.0594],
        [0.0600, 0.0649],
        [0.0602, 0.0647],
        [0.0636, 0.0613],
        [0.0659, 0.0591],
        [0.0603, 0.0646],
        [0.0642, 0.0607],
        [0.0631, 0.0617],
        [0.0639, 0.0609],
        [0.0564, 0.0691],
        [0.0588, 0.0663]], device='cuda:0')
 Batch: 9 of common classification Duration: 0:00:00.407606
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0008, 0.0010],
        [0.0004, 0.0007],
        [0.0005, 0.0009],
        [0.0009, 0.0015],
        [0.0005, 0.0006],
        [0.0003, 0.0004],
        [0.0007, 0.0011],
        [0.0006, 0.0010],
        [0.0003, 0.0006],
        [0.0002, 0.0002],
        [0.0005, 0.0007],
        [0.0004, 0.0007],
        [0.0007, 0.0020],
        [0.0006, 0.0010],
        [0.0004, 0.0007],
        [0.0007, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0664, 0.0587],
        [0.0624, 0.0625],
        [0.0605, 0.0644],
        [0.0625, 0.0624],
        [0.0660, 0.0590],
        [0.0642, 0.0607],
        [0.0624, 0.0625],
        [0.0626, 0.0622],
        [0.0585, 0.0666],
        [0.0692, 0.0563],
        [0.0648, 0.0602],
        [0.0602, 0.0648],
        [0.0558, 0.0698],
        [0.0623, 0.0626],
        [0.0614, 0.0635],
        [0.0610, 0.0639]], device='cuda:0')
 Batch: 10 of common classification Duration: 0:00:00.490124
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0005],
        [0.0006, 0.0009],
        [0.0008, 0.0010],
        [0.0006, 0.0008],
        [0.0005, 0.0009],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0006, 0.0011],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0003],
        [0.0003, 0.0005],
        [0.0005, 0.0009],
        [0.0006, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0633, 0.0616],
        [0.0619, 0.0630],
        [0.0660, 0.0591],
        [0.0645, 0.0604],
        [0.0608, 0.0642],
        [0.0621, 0.0628],
        [0.0588, 0.0663],
        [0.0630, 0.0619],
        [0.0622, 0.0626],
        [0.0592, 0.0659],
        [0.0590, 0.0660],
        [0.0628, 0.0621],
        [0.0703, 0.0555],
        [0.0625, 0.0624],
        [0.0601, 0.0649],
        [0.0634, 0.0615]], device='cuda:0')
 Batch: 11 of common classification Duration: 0:00:00.429094
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0009, 0.0011],
        [0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0006, 0.0009],
        [0.0006, 0.0010],
        [0.0005, 0.0005],
        [0.0004, 0.0008],
        [0.0006, 0.0010]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1309, 0.1191],
        [0.1175, 0.1327],
        [0.1221, 0.1277],
        [0.1265, 0.1233],
        [0.1226, 0.1272],
        [0.1363, 0.1144],
        [0.1217, 0.1281],
        [0.1224, 0.1274]], device='cuda:0')
 Batch: 12 of common classification Duration: 0:00:00.190033
acc:  0.545
Time taken to execute the en SA task with prompt type common, variation 3 and batchsize 16: 0:00:05.375188
path ['42', 'en', 'bloom-big', 'SA', 'common', 'prompt_id_3']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003]], device='cuda:0') torch.Size([128, 2])
answers_probs just softmax dim 0: tensor([[0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078]], device='cuda:0')
tensor([[0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078],
        [0.0078, 0.0078]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA common 4 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0007, 0.0009],
        [0.0009, 0.0012],
        [0.0007, 0.0013],
        [0.0005, 0.0008],
        [0.0003, 0.0008],
        [0.0005, 0.0008],
        [0.0004, 0.0005],
        [0.0005, 0.0007],
        [0.0006, 0.0011],
        [0.0002, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0005, 0.0006],
        [0.0004, 0.0004],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0639, 0.0609],
        [0.0646, 0.0602],
        [0.0655, 0.0594],
        [0.0603, 0.0646],
        [0.0618, 0.0630],
        [0.0568, 0.0685],
        [0.0618, 0.0630],
        [0.0654, 0.0595],
        [0.0639, 0.0609],
        [0.0593, 0.0656],
        [0.0541, 0.0719],
        [0.0631, 0.0617],
        [0.0593, 0.0656],
        [0.0668, 0.0583],
        [0.0694, 0.0560],
        [0.0639, 0.0609]], device='cuda:0')
 Batch: 0 of common classification Duration: 0:00:00.435274
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0006, 0.0008],
        [0.0004, 0.0011],
        [0.0003, 0.0005],
        [0.0003, 0.0004],
        [0.0006, 0.0012],
        [0.0004, 0.0008],
        [0.0002, 0.0002],
        [0.0007, 0.0010],
        [0.0003, 0.0004],
        [0.0008, 0.0013],
        [0.0008, 0.0008],
        [0.0009, 0.0013],
        [0.0004, 0.0010],
        [0.0003, 0.0006],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0638, 0.0610],
        [0.0652, 0.0598],
        [0.0558, 0.0698],
        [0.0642, 0.0607],
        [0.0638, 0.0610],
        [0.0593, 0.0657],
        [0.0590, 0.0660],
        [0.0657, 0.0593],
        [0.0637, 0.0611],
        [0.0644, 0.0604],
        [0.0629, 0.0619],
        [0.0700, 0.0556],
        [0.0639, 0.0609],
        [0.0570, 0.0683],
        [0.0611, 0.0637],
        [0.0602, 0.0647]], device='cuda:0')
 Batch: 1 of common classification Duration: 0:00:00.571623
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0005, 0.0010],
        [0.0005, 0.0012],
        [0.0003, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0007, 0.0009],
        [0.0005, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0009],
        [0.0004, 0.0006],
        [0.0006, 0.0009],
        [0.0004, 0.0006],
        [0.0004, 0.0009],
        [0.0006, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0616, 0.0633],
        [0.0593, 0.0657],
        [0.0578, 0.0675],
        [0.0622, 0.0626],
        [0.0687, 0.0567],
        [0.0618, 0.0631],
        [0.0600, 0.0650],
        [0.0655, 0.0595],
        [0.0672, 0.0580],
        [0.0595, 0.0655],
        [0.0605, 0.0644],
        [0.0628, 0.0620],
        [0.0648, 0.0601],
        [0.0636, 0.0612],
        [0.0592, 0.0658],
        [0.0655, 0.0595]], device='cuda:0')
 Batch: 2 of common classification Duration: 0:00:00.453316
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0006, 0.0010],
        [0.0003, 0.0004],
        [0.0005, 0.0009],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0005, 0.0009],
        [0.0011, 0.0019],
        [0.0004, 0.0006],
        [0.0004, 0.0005],
        [0.0006, 0.0008],
        [0.0002, 0.0003],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0618, 0.0632],
        [0.0613, 0.0636],
        [0.0632, 0.0618],
        [0.0601, 0.0649],
        [0.0654, 0.0597],
        [0.0616, 0.0634],
        [0.0604, 0.0646],
        [0.0613, 0.0636],
        [0.0628, 0.0621],
        [0.0662, 0.0589],
        [0.0642, 0.0607],
        [0.0635, 0.0614],
        [0.0598, 0.0653],
        [0.0610, 0.0640],
        [0.0652, 0.0598],
        [0.0621, 0.0628]], device='cuda:0')
 Batch: 3 of common classification Duration: 0:00:00.334759
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0011],
        [0.0004, 0.0006],
        [0.0004, 0.0005],
        [0.0002, 0.0005],
        [0.0004, 0.0005],
        [0.0003, 0.0004],
        [0.0006, 0.0011],
        [0.0002, 0.0003],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0005, 0.0007],
        [0.0003, 0.0004],
        [0.0007, 0.0014],
        [0.0002, 0.0004],
        [0.0006, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0635, 0.0614],
        [0.0630, 0.0619],
        [0.0648, 0.0601],
        [0.0582, 0.0669],
        [0.0646, 0.0604],
        [0.0645, 0.0605],
        [0.0589, 0.0661],
        [0.0652, 0.0598],
        [0.0605, 0.0644],
        [0.0606, 0.0643],
        [0.0585, 0.0666],
        [0.0652, 0.0598],
        [0.0640, 0.0609],
        [0.0597, 0.0653],
        [0.0620, 0.0629],
        [0.0666, 0.0585]], device='cuda:0')
 Batch: 4 of common classification Duration: 0:00:00.365622
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0010],
        [0.0003, 0.0004],
        [0.0002, 0.0003],
        [0.0008, 0.0011],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0005, 0.0010],
        [0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0006, 0.0012],
        [0.0007, 0.0012],
        [0.0007, 0.0009],
        [0.0005, 0.0013],
        [0.0004, 0.0005],
        [0.0005, 0.0008],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0639, 0.0610],
        [0.0629, 0.0620],
        [0.0650, 0.0600],
        [0.0658, 0.0593],
        [0.0637, 0.0612],
        [0.0599, 0.0651],
        [0.0606, 0.0644],
        [0.0617, 0.0632],
        [0.0596, 0.0655],
        [0.0604, 0.0646],
        [0.0622, 0.0627],
        [0.0659, 0.0592],
        [0.0587, 0.0665],
        [0.0672, 0.0581],
        [0.0641, 0.0609],
        [0.0587, 0.0665]], device='cuda:0')
 Batch: 5 of common classification Duration: 0:00:00.422648
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0006],
        [0.0003, 0.0008],
        [0.0005, 0.0009],
        [0.0003, 0.0003],
        [0.0005, 0.0007],
        [0.0005, 0.0008],
        [0.0008, 0.0013],
        [0.0004, 0.0005],
        [0.0003, 0.0004],
        [0.0003, 0.0009],
        [0.0003, 0.0007],
        [0.0005, 0.0012],
        [0.0006, 0.0009],
        [0.0003, 0.0006],
        [0.0006, 0.0011],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0666, 0.0585],
        [0.0568, 0.0685],
        [0.0602, 0.0647],
        [0.0679, 0.0574],
        [0.0657, 0.0593],
        [0.0626, 0.0622],
        [0.0645, 0.0604],
        [0.0692, 0.0563],
        [0.0633, 0.0615],
        [0.0570, 0.0683],
        [0.0605, 0.0644],
        [0.0573, 0.0680],
        [0.0651, 0.0598],
        [0.0614, 0.0634],
        [0.0618, 0.0630],
        [0.0604, 0.0645]], device='cuda:0')
 Batch: 6 of common classification Duration: 0:00:00.408021
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0006, 0.0009],
        [0.0003, 0.0004],
        [0.0005, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0002, 0.0003],
        [0.0007, 0.0011],
        [0.0006, 0.0011],
        [0.0004, 0.0011],
        [0.0007, 0.0008],
        [0.0004, 0.0010],
        [0.0005, 0.0009],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0637, 0.0611],
        [0.0605, 0.0643],
        [0.0627, 0.0621],
        [0.0648, 0.0600],
        [0.0634, 0.0614],
        [0.0618, 0.0630],
        [0.0635, 0.0613],
        [0.0598, 0.0651],
        [0.0637, 0.0611],
        [0.0637, 0.0611],
        [0.0603, 0.0645],
        [0.0568, 0.0686],
        [0.0701, 0.0556],
        [0.0554, 0.0703],
        [0.0608, 0.0641],
        [0.0690, 0.0564]], device='cuda:0')
 Batch: 7 of common classification Duration: 0:00:00.359418
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0006, 0.0010],
        [0.0005, 0.0008],
        [0.0004, 0.0008],
        [0.0005, 0.0007],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0009, 0.0012],
        [0.0004, 0.0004],
        [0.0005, 0.0008],
        [0.0004, 0.0005],
        [0.0003, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0625, 0.0624],
        [0.0602, 0.0647],
        [0.0622, 0.0627],
        [0.0582, 0.0670],
        [0.0631, 0.0618],
        [0.0652, 0.0598],
        [0.0615, 0.0634],
        [0.0577, 0.0676],
        [0.0580, 0.0671],
        [0.0661, 0.0590],
        [0.0647, 0.0603],
        [0.0637, 0.0612],
        [0.0657, 0.0593],
        [0.0597, 0.0653],
        [0.0639, 0.0610],
        [0.0678, 0.0575]], device='cuda:0')
 Batch: 8 of common classification Duration: 0:00:00.410357
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0004, 0.0005],
        [0.0007, 0.0014],
        [0.0008, 0.0013],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0003],
        [0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0005, 0.0010],
        [0.0002, 0.0004],
        [0.0008, 0.0013],
        [0.0003, 0.0004],
        [0.0005, 0.0006],
        [0.0007, 0.0015],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0667, 0.0584],
        [0.0677, 0.0575],
        [0.0586, 0.0664],
        [0.0619, 0.0628],
        [0.0597, 0.0652],
        [0.0578, 0.0674],
        [0.0715, 0.0544],
        [0.0629, 0.0619],
        [0.0617, 0.0631],
        [0.0596, 0.0654],
        [0.0589, 0.0660],
        [0.0626, 0.0621],
        [0.0640, 0.0608],
        [0.0676, 0.0576],
        [0.0591, 0.0658],
        [0.0597, 0.0652]], device='cuda:0')
 Batch: 9 of common classification Duration: 0:00:00.453463
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0006, 0.0009],
        [0.0005, 0.0007],
        [0.0004, 0.0008],
        [0.0005, 0.0007],
        [0.0004, 0.0008],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0006, 0.0007],
        [0.0003, 0.0007],
        [0.0001, 0.0002],
        [0.0013, 0.0017],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0626, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0640, 0.0609],
        [0.0638, 0.0612],
        [0.0647, 0.0602],
        [0.0605, 0.0645],
        [0.0662, 0.0589],
        [0.0597, 0.0653],
        [0.0640, 0.0609],
        [0.0625, 0.0624],
        [0.0657, 0.0593],
        [0.0593, 0.0658],
        [0.0633, 0.0616],
        [0.0649, 0.0601],
        [0.0636, 0.0613],
        [0.0606, 0.0644],
        [0.0594, 0.0657],
        [0.0579, 0.0674]], device='cuda:0')
 Batch: 10 of common classification Duration: 0:00:00.450061
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0004, 0.0010],
        [0.0002, 0.0003],
        [0.0004, 0.0006],
        [0.0003, 0.0004],
        [0.0007, 0.0012],
        [0.0005, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0006, 0.0007],
        [0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0005, 0.0006],
        [0.0004, 0.0006],
        [0.0001, 0.0002]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0600, 0.0650],
        [0.0600, 0.0650],
        [0.0572, 0.0681],
        [0.0617, 0.0632],
        [0.0640, 0.0609],
        [0.0663, 0.0589],
        [0.0614, 0.0635],
        [0.0634, 0.0615],
        [0.0631, 0.0618],
        [0.0605, 0.0645],
        [0.0672, 0.0581],
        [0.0609, 0.0640],
        [0.0601, 0.0648],
        [0.0654, 0.0597],
        [0.0636, 0.0613],
        [0.0652, 0.0598]], device='cuda:0')
 Batch: 11 of common classification Duration: 0:00:00.427448
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0005, 0.0007],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0005],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1192, 0.1310],
        [0.1220, 0.1280],
        [0.1236, 0.1263],
        [0.1303, 0.1198],
        [0.1245, 0.1254],
        [0.1202, 0.1298],
        [0.1315, 0.1186],
        [0.1288, 0.1212]], device='cuda:0')
 Batch: 12 of common classification Duration: 0:00:00.150581
acc:  0.4
Time taken to execute the en SA task with prompt type common, variation 4 and batchsize 16: 0:00:05.258669
path ['42', 'en', 'bloom-big', 'SA', 'common', 'prompt_id_4']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([101, 2])
answers_probs just softmax dim 0: tensor([[0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099]], device='cuda:0')
tensor([[0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099],
        [0.0099, 0.0099]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA common 5 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0007],
        [0.0006, 0.0016],
        [0.0004, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0008],
        [0.0002, 0.0006],
        [0.0006, 0.0010],
        [0.0004, 0.0009],
        [0.0003, 0.0007],
        [0.0008, 0.0017],
        [0.0003, 0.0010],
        [0.0003, 0.0010],
        [0.0003, 0.0007],
        [0.0003, 0.0010],
        [0.0001, 0.0004],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0593, 0.0657],
        [0.0621, 0.0627],
        [0.0648, 0.0601],
        [0.0661, 0.0590],
        [0.0608, 0.0641],
        [0.0627, 0.0621],
        [0.0678, 0.0575],
        [0.0647, 0.0602],
        [0.0629, 0.0619],
        [0.0640, 0.0609],
        [0.0594, 0.0656],
        [0.0578, 0.0674],
        [0.0648, 0.0601],
        [0.0602, 0.0647],
        [0.0566, 0.0688],
        [0.0658, 0.0592]], device='cuda:0')
 Batch: 0 of common classification Duration: 0:00:00.342855
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0001, 0.0004],
        [0.0003, 0.0013],
        [0.0003, 0.0008],
        [0.0004, 0.0013],
        [0.0003, 0.0010],
        [0.0005, 0.0010],
        [0.0003, 0.0010],
        [0.0005, 0.0010],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0005, 0.0020],
        [0.0003, 0.0005],
        [0.0006, 0.0010],
        [0.0005, 0.0007],
        [0.0004, 0.0009],
        [0.0003, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0601, 0.0648],
        [0.0574, 0.0678],
        [0.0640, 0.0609],
        [0.0595, 0.0654],
        [0.0603, 0.0646],
        [0.0649, 0.0600],
        [0.0590, 0.0660],
        [0.0649, 0.0600],
        [0.0614, 0.0635],
        [0.0631, 0.0617],
        [0.0582, 0.0669],
        [0.0654, 0.0595],
        [0.0686, 0.0567],
        [0.0703, 0.0554],
        [0.0631, 0.0617],
        [0.0596, 0.0653]], device='cuda:0')
 Batch: 1 of common classification Duration: 0:00:00.332988
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0008],
        [0.0002, 0.0006],
        [0.0002, 0.0007],
        [0.0003, 0.0007],
        [0.0005, 0.0006],
        [0.0005, 0.0009],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0002, 0.0007],
        [0.0001, 0.0003],
        [0.0005, 0.0008],
        [0.0003, 0.0008],
        [0.0005, 0.0012],
        [0.0004, 0.0008],
        [0.0006, 0.0015],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0590, 0.0660],
        [0.0628, 0.0620],
        [0.0580, 0.0672],
        [0.0607, 0.0641],
        [0.0709, 0.0550],
        [0.0656, 0.0594],
        [0.0669, 0.0582],
        [0.0595, 0.0655],
        [0.0604, 0.0645],
        [0.0597, 0.0652],
        [0.0666, 0.0584],
        [0.0611, 0.0637],
        [0.0622, 0.0626],
        [0.0640, 0.0609],
        [0.0620, 0.0628],
        [0.0606, 0.0643]], device='cuda:0')
 Batch: 2 of common classification Duration: 0:00:00.541866
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0011],
        [0.0002, 0.0007],
        [0.0001, 0.0005],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0014],
        [0.0001, 0.0003],
        [0.0003, 0.0007],
        [0.0004, 0.0009],
        [0.0002, 0.0007],
        [0.0006, 0.0012],
        [0.0003, 0.0006],
        [0.0005, 0.0011],
        [0.0003, 0.0007],
        [0.0002, 0.0006],
        [0.0003, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0702, 0.0555],
        [0.0577, 0.0675],
        [0.0581, 0.0670],
        [0.0634, 0.0614],
        [0.0646, 0.0603],
        [0.0559, 0.0696],
        [0.0639, 0.0609],
        [0.0611, 0.0637],
        [0.0621, 0.0627],
        [0.0615, 0.0633],
        [0.0660, 0.0590],
        [0.0647, 0.0602],
        [0.0648, 0.0601],
        [0.0651, 0.0598],
        [0.0586, 0.0665],
        [0.0623, 0.0625]], device='cuda:0')
 Batch: 3 of common classification Duration: 0:00:00.481253
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0003, 0.0010],
        [0.0003, 0.0014],
        [0.0004, 0.0009],
        [0.0003, 0.0011],
        [0.0001, 0.0005],
        [0.0003, 0.0012],
        [0.0004, 0.0013],
        [0.0003, 0.0009],
        [0.0003, 0.0014],
        [0.0002, 0.0006],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0002, 0.0006],
        [0.0003, 0.0006],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0632, 0.0616],
        [0.0597, 0.0653],
        [0.0582, 0.0669],
        [0.0675, 0.0577],
        [0.0591, 0.0659],
        [0.0609, 0.0640],
        [0.0606, 0.0643],
        [0.0621, 0.0627],
        [0.0627, 0.0621],
        [0.0589, 0.0662],
        [0.0603, 0.0646],
        [0.0649, 0.0600],
        [0.0630, 0.0619],
        [0.0614, 0.0635],
        [0.0649, 0.0600],
        [0.0727, 0.0536]], device='cuda:0')
 Batch: 4 of common classification Duration: 0:00:00.293517
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0011],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0010],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0007],
        [0.0003, 0.0010],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0005, 0.0011],
        [0.0003, 0.0008],
        [0.0004, 0.0014],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0677, 0.0576],
        [0.0633, 0.0616],
        [0.0601, 0.0649],
        [0.0601, 0.0648],
        [0.0614, 0.0635],
        [0.0620, 0.0629],
        [0.0604, 0.0645],
        [0.0588, 0.0663],
        [0.0632, 0.0617],
        [0.0627, 0.0622],
        [0.0633, 0.0616],
        [0.0630, 0.0619],
        [0.0590, 0.0661],
        [0.0624, 0.0625],
        [0.0632, 0.0617],
        [0.0694, 0.0562]], device='cuda:0')
 Batch: 5 of common classification Duration: 0:00:00.446552
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0005, 0.0014],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0012],
        [0.0002, 0.0007],
        [0.0003, 0.0009],
        [0.0004, 0.0012],
        [0.0004, 0.0009],
        [0.0003, 0.0013],
        [0.0004, 0.0010],
        [0.0004, 0.0016],
        [0.0005, 0.0009],
        [0.0002, 0.0008],
        [0.0004, 0.0007],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0646, 0.0603],
        [0.0628, 0.0620],
        [0.0658, 0.0591],
        [0.0671, 0.0580],
        [0.0579, 0.0671],
        [0.0590, 0.0659],
        [0.0626, 0.0622],
        [0.0594, 0.0655],
        [0.0635, 0.0613],
        [0.0556, 0.0700],
        [0.0635, 0.0613],
        [0.0591, 0.0658],
        [0.0666, 0.0584],
        [0.0566, 0.0688],
        [0.0684, 0.0569],
        [0.0677, 0.0575]], device='cuda:0')
 Batch: 6 of common classification Duration: 0:00:00.315613
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0005, 0.0014],
        [0.0003, 0.0009],
        [0.0003, 0.0007],
        [0.0002, 0.0008],
        [0.0002, 0.0006],
        [0.0003, 0.0009],
        [0.0002, 0.0007],
        [0.0004, 0.0010],
        [0.0002, 0.0005],
        [0.0005, 0.0012],
        [0.0004, 0.0010],
        [0.0003, 0.0008],
        [0.0003, 0.0003],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0636, 0.0612],
        [0.0617, 0.0631],
        [0.0619, 0.0629],
        [0.0610, 0.0637],
        [0.0624, 0.0624],
        [0.0554, 0.0702],
        [0.0609, 0.0638],
        [0.0616, 0.0632],
        [0.0592, 0.0657],
        [0.0640, 0.0608],
        [0.0612, 0.0636],
        [0.0638, 0.0610],
        [0.0607, 0.0641],
        [0.0614, 0.0634],
        [0.0768, 0.0506],
        [0.0645, 0.0603]], device='cuda:0')
 Batch: 7 of common classification Duration: 0:00:00.367117
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0014],
        [0.0003, 0.0010],
        [0.0002, 0.0006],
        [0.0004, 0.0010],
        [0.0005, 0.0012],
        [0.0003, 0.0008],
        [0.0004, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0014],
        [0.0006, 0.0013],
        [0.0005, 0.0012],
        [0.0003, 0.0010],
        [0.0002, 0.0007],
        [0.0011, 0.0013],
        [0.0003, 0.0012],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0560, 0.0695],
        [0.0603, 0.0645],
        [0.0620, 0.0627],
        [0.0620, 0.0627],
        [0.0635, 0.0613],
        [0.0630, 0.0618],
        [0.0657, 0.0592],
        [0.0642, 0.0606],
        [0.0564, 0.0689],
        [0.0639, 0.0609],
        [0.0626, 0.0622],
        [0.0606, 0.0642],
        [0.0594, 0.0655],
        [0.0737, 0.0527],
        [0.0590, 0.0659],
        [0.0677, 0.0575]], device='cuda:0')
 Batch: 8 of common classification Duration: 0:00:00.403050
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0011],
        [0.0004, 0.0010],
        [0.0002, 0.0007],
        [0.0003, 0.0008],
        [0.0002, 0.0008],
        [0.0002, 0.0006],
        [0.0003, 0.0010],
        [0.0003, 0.0011],
        [0.0003, 0.0008],
        [0.0006, 0.0015],
        [0.0006, 0.0015],
        [0.0003, 0.0011],
        [0.0007, 0.0019],
        [0.0004, 0.0009],
        [0.0002, 0.0006],
        [0.0003, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0667, 0.0585],
        [0.0630, 0.0619],
        [0.0621, 0.0628],
        [0.0643, 0.0607],
        [0.0597, 0.0653],
        [0.0617, 0.0633],
        [0.0610, 0.0640],
        [0.0618, 0.0632],
        [0.0639, 0.0611],
        [0.0644, 0.0606],
        [0.0636, 0.0614],
        [0.0607, 0.0643],
        [0.0625, 0.0624],
        [0.0652, 0.0598],
        [0.0594, 0.0657],
        [0.0600, 0.0651]], device='cuda:0')
 Batch: 9 of common classification Duration: 0:00:00.429542
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0012],
        [0.0002, 0.0006],
        [0.0003, 0.0008],
        [0.0002, 0.0009],
        [0.0006, 0.0015],
        [0.0003, 0.0008],
        [0.0003, 0.0013],
        [0.0001, 0.0005],
        [0.0003, 0.0008],
        [0.0002, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0008],
        [0.0008, 0.0012],
        [0.0003, 0.0009],
        [0.0005, 0.0010],
        [0.0003, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0630, 0.0619],
        [0.0598, 0.0651],
        [0.0617, 0.0631],
        [0.0589, 0.0661],
        [0.0632, 0.0617],
        [0.0646, 0.0603],
        [0.0589, 0.0661],
        [0.0596, 0.0654],
        [0.0614, 0.0635],
        [0.0577, 0.0675],
        [0.0680, 0.0573],
        [0.0615, 0.0633],
        [0.0709, 0.0549],
        [0.0620, 0.0628],
        [0.0662, 0.0588],
        [0.0626, 0.0623]], device='cuda:0')
 Batch: 10 of common classification Duration: 0:00:00.360439
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0003, 0.0008],
        [0.0004, 0.0010],
        [0.0004, 0.0008],
        [0.0005, 0.0012],
        [0.0003, 0.0007],
        [0.0002, 0.0007],
        [0.0002, 0.0007],
        [0.0002, 0.0007],
        [0.0003, 0.0011],
        [0.0003, 0.0006],
        [0.0002, 0.0008],
        [0.0003, 0.0010],
        [0.0003, 0.0011],
        [0.0005, 0.0013],
        [0.0003, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0719, 0.0542],
        [0.0625, 0.0623],
        [0.0615, 0.0633],
        [0.0669, 0.0582],
        [0.0644, 0.0604],
        [0.0645, 0.0603],
        [0.0618, 0.0630],
        [0.0588, 0.0662],
        [0.0588, 0.0662],
        [0.0595, 0.0654],
        [0.0674, 0.0578],
        [0.0589, 0.0661],
        [0.0595, 0.0654],
        [0.0599, 0.0650],
        [0.0640, 0.0608],
        [0.0597, 0.0653]], device='cuda:0')
 Batch: 11 of common classification Duration: 0:00:00.359740
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0006, 0.0014],
        [0.0002, 0.0004],
        [0.0005, 0.0013],
        [0.0003, 0.0007],
        [0.0004, 0.0012],
        [0.0002, 0.0006],
        [0.0004, 0.0011],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1251],
        [0.1250, 0.1249],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1266, 0.1232],
        [0.1359, 0.1148],
        [0.1201, 0.1298],
        [0.1225, 0.1272],
        [0.1216, 0.1283],
        [0.1185, 0.1316],
        [0.1217, 0.1281],
        [0.1332, 0.1171]], device='cuda:0')
 Batch: 12 of common classification Duration: 0:00:00.221357
acc:  0.52
Time taken to execute the en SA task with prompt type common, variation 5 and batchsize 16: 0:00:04.911402
path ['42', 'en', 'bloom-big', 'SA', 'common', 'prompt_id_5']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([109, 2])
answers_probs just softmax dim 0: tensor([[0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092]], device='cuda:0')
tensor([[0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092],
        [0.0092, 0.0092]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA common 6 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[3.5477e-04, 6.5756e-04],
        [9.2793e-04, 1.5182e-03],
        [2.8610e-04, 5.8699e-04],
        [2.8729e-04, 7.1096e-04],
        [1.5426e-04, 2.6250e-04],
        [2.6250e-04, 4.3941e-04],
        [3.1805e-04, 6.9475e-04],
        [1.3840e-04, 2.6679e-04],
        [2.4939e-04, 7.3290e-04],
        [2.0170e-04, 6.1655e-04],
        [3.4475e-04, 6.2418e-04],
        [2.3425e-04, 4.9973e-04],
        [8.3387e-05, 1.8072e-04],
        [3.0947e-04, 7.9012e-04],
        [3.1567e-04, 6.7902e-04],
        [2.3401e-04, 7.1001e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0645, 0.0604],
        [0.0664, 0.0587],
        [0.0631, 0.0618],
        [0.0606, 0.0643],
        [0.0658, 0.0593],
        [0.0661, 0.0590],
        [0.0622, 0.0627],
        [0.0640, 0.0610],
        [0.0586, 0.0666],
        [0.0582, 0.0670],
        [0.0649, 0.0601],
        [0.0625, 0.0624],
        [0.0623, 0.0626],
        [0.0602, 0.0647],
        [0.0624, 0.0625],
        [0.0582, 0.0670]], device='cuda:0')
 Batch: 0 of common classification Duration: 0:00:00.373090
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0002, 0.0003],
        [0.0002, 0.0006],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0009],
        [0.0003, 0.0005],
        [0.0004, 0.0008],
        [0.0002, 0.0005],
        [0.0004, 0.0009],
        [0.0004, 0.0009],
        [0.0001, 0.0004],
        [0.0005, 0.0009],
        [0.0003, 0.0011],
        [0.0002, 0.0003],
        [0.0005, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0598, 0.0651],
        [0.0678, 0.0575],
        [0.0598, 0.0652],
        [0.0631, 0.0617],
        [0.0627, 0.0622],
        [0.0596, 0.0654],
        [0.0640, 0.0609],
        [0.0635, 0.0614],
        [0.0623, 0.0626],
        [0.0623, 0.0626],
        [0.0626, 0.0623],
        [0.0603, 0.0646],
        [0.0648, 0.0601],
        [0.0567, 0.0688],
        [0.0689, 0.0566],
        [0.0619, 0.0630]], device='cuda:0')
 Batch: 1 of common classification Duration: 0:00:00.363565
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0002, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0005, 0.0007],
        [0.0004, 0.0009],
        [0.0005, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0608, 0.0642],
        [0.0597, 0.0653],
        [0.0619, 0.0630],
        [0.0582, 0.0670],
        [0.0602, 0.0648],
        [0.0618, 0.0631],
        [0.0682, 0.0572],
        [0.0616, 0.0633],
        [0.0673, 0.0580],
        [0.0609, 0.0641],
        [0.0623, 0.0626],
        [0.0616, 0.0633],
        [0.0619, 0.0630],
        [0.0632, 0.0617],
        [0.0648, 0.0602],
        [0.0659, 0.0592]], device='cuda:0')
 Batch: 2 of common classification Duration: 0:00:00.421823
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0005, 0.0008],
        [0.0001, 0.0003],
        [0.0004, 0.0013],
        [0.0001, 0.0003],
        [0.0002, 0.0005],
        [0.0002, 0.0003],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0618, 0.0631],
        [0.0603, 0.0647],
        [0.0653, 0.0597],
        [0.0640, 0.0610],
        [0.0619, 0.0630],
        [0.0608, 0.0642],
        [0.0661, 0.0591],
        [0.0594, 0.0657],
        [0.0578, 0.0675],
        [0.0627, 0.0623],
        [0.0618, 0.0631],
        [0.0636, 0.0613],
        [0.0635, 0.0614],
        [0.0634, 0.0615],
        [0.0634, 0.0615],
        [0.0641, 0.0609]], device='cuda:0')
 Batch: 3 of common classification Duration: 0:00:00.315003
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0003],
        [0.0003, 0.0007],
        [0.0001, 0.0002],
        [0.0001, 0.0003],
        [0.0002, 0.0004],
        [0.0002, 0.0007],
        [0.0002, 0.0002],
        [0.0001, 0.0003],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0002, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0005, 0.0013],
        [0.0002, 0.0005],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0737, 0.0528],
        [0.0603, 0.0645],
        [0.0644, 0.0604],
        [0.0598, 0.0650],
        [0.0658, 0.0591],
        [0.0579, 0.0672],
        [0.0683, 0.0570],
        [0.0615, 0.0633],
        [0.0643, 0.0605],
        [0.0610, 0.0638],
        [0.0579, 0.0672],
        [0.0618, 0.0630],
        [0.0610, 0.0638],
        [0.0612, 0.0636],
        [0.0592, 0.0657],
        [0.0618, 0.0630]], device='cuda:0')
 Batch: 4 of common classification Duration: 0:00:00.428639
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[1.5879e-04, 3.5501e-04],
        [4.2653e-04, 9.2459e-04],
        [5.3883e-04, 8.0872e-04],
        [1.4269e-04, 2.3162e-04],
        [3.0994e-04, 8.2970e-04],
        [3.1734e-04, 8.6927e-04],
        [1.7822e-04, 4.5133e-04],
        [4.5085e-04, 7.6103e-04],
        [1.4770e-04, 4.7660e-04],
        [1.7691e-04, 3.1543e-04],
        [2.6584e-04, 6.2275e-04],
        [8.7678e-05, 2.8419e-04],
        [2.3091e-04, 4.5562e-04],
        [2.0206e-04, 4.4489e-04],
        [2.6822e-04, 6.9046e-04],
        [3.8099e-04, 9.7322e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0624, 0.0624],
        [0.0629, 0.0620],
        [0.0684, 0.0570],
        [0.0671, 0.0581],
        [0.0602, 0.0648],
        [0.0599, 0.0651],
        [0.0608, 0.0641],
        [0.0665, 0.0586],
        [0.0581, 0.0671],
        [0.0657, 0.0594],
        [0.0618, 0.0630],
        [0.0580, 0.0672],
        [0.0642, 0.0607],
        [0.0626, 0.0622],
        [0.0606, 0.0643],
        [0.0607, 0.0642]], device='cuda:0')
 Batch: 5 of common classification Duration: 0:00:00.404460
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0004],
        [0.0006, 0.0008],
        [0.0002, 0.0003],
        [0.0005, 0.0011],
        [0.0004, 0.0007],
        [0.0006, 0.0011],
        [0.0002, 0.0006],
        [0.0003, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0588, 0.0662],
        [0.0691, 0.0563],
        [0.0622, 0.0626],
        [0.0570, 0.0683],
        [0.0588, 0.0662],
        [0.0638, 0.0610],
        [0.0628, 0.0619],
        [0.0616, 0.0632],
        [0.0642, 0.0607],
        [0.0689, 0.0565],
        [0.0681, 0.0572],
        [0.0605, 0.0644],
        [0.0628, 0.0619],
        [0.0646, 0.0602],
        [0.0587, 0.0663],
        [0.0581, 0.0670]], device='cuda:0')
 Batch: 6 of common classification Duration: 0:00:00.230853
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0013],
        [0.0001, 0.0002],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0003, 0.0004],
        [0.0003, 0.0007],
        [0.0003, 0.0011],
        [0.0003, 0.0005],
        [0.0004, 0.0015],
        [0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0625, 0.0624],
        [0.0631, 0.0617],
        [0.0628, 0.0620],
        [0.0620, 0.0629],
        [0.0709, 0.0550],
        [0.0612, 0.0636],
        [0.0572, 0.0682],
        [0.0662, 0.0588],
        [0.0569, 0.0684],
        [0.0635, 0.0614],
        [0.0605, 0.0644],
        [0.0620, 0.0629],
        [0.0621, 0.0628],
        [0.0645, 0.0605],
        [0.0641, 0.0608],
        [0.0607, 0.0642]], device='cuda:0')
 Batch: 7 of common classification Duration: 0:00:00.359251
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0013],
        [0.0005, 0.0011],
        [0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0004, 0.0012],
        [0.0003, 0.0010],
        [0.0001, 0.0003],
        [0.0004, 0.0008],
        [0.0001, 0.0002],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0611, 0.0638],
        [0.0629, 0.0620],
        [0.0615, 0.0633],
        [0.0701, 0.0556],
        [0.0589, 0.0662],
        [0.0561, 0.0694],
        [0.0615, 0.0633],
        [0.0634, 0.0615],
        [0.0627, 0.0622],
        [0.0594, 0.0656],
        [0.0608, 0.0641],
        [0.0607, 0.0642],
        [0.0657, 0.0593],
        [0.0657, 0.0593],
        [0.0655, 0.0595],
        [0.0641, 0.0608]], device='cuda:0')
 Batch: 8 of common classification Duration: 0:00:00.428524
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[1.6451e-04, 3.3474e-04],
        [1.6487e-04, 2.5940e-04],
        [1.5557e-04, 3.2926e-04],
        [2.3127e-04, 5.5933e-04],
        [2.8586e-04, 4.6754e-04],
        [2.7037e-04, 5.5027e-04],
        [2.1732e-04, 4.0913e-04],
        [3.1877e-04, 6.9618e-04],
        [2.0158e-04, 4.4370e-04],
        [2.1219e-04, 3.5810e-04],
        [9.3579e-05, 1.8036e-04],
        [1.8942e-04, 5.5647e-04],
        [2.7227e-04, 5.6267e-04],
        [2.0993e-04, 4.5848e-04],
        [2.0289e-04, 4.4322e-04],
        [2.5678e-04, 5.8317e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0626, 0.0623],
        [0.0664, 0.0588],
        [0.0620, 0.0629],
        [0.0603, 0.0647],
        [0.0658, 0.0593],
        [0.0626, 0.0623],
        [0.0637, 0.0613],
        [0.0616, 0.0633],
        [0.0615, 0.0634],
        [0.0653, 0.0597],
        [0.0633, 0.0616],
        [0.0580, 0.0672],
        [0.0624, 0.0626],
        [0.0616, 0.0633],
        [0.0616, 0.0633],
        [0.0611, 0.0638]], device='cuda:0')
 Batch: 9 of common classification Duration: 0:00:00.452470
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0001, 0.0002],
        [0.0003, 0.0005],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0001, 0.0003],
        [0.0003, 0.0006],
        [0.0001, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0001, 0.0003],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0660, 0.0591],
        [0.0654, 0.0597],
        [0.0624, 0.0625],
        [0.0653, 0.0598],
        [0.0632, 0.0617],
        [0.0611, 0.0639],
        [0.0619, 0.0630],
        [0.0566, 0.0690],
        [0.0607, 0.0643],
        [0.0620, 0.0629],
        [0.0631, 0.0618],
        [0.0623, 0.0626],
        [0.0617, 0.0632],
        [0.0616, 0.0633],
        [0.0640, 0.0610],
        [0.0627, 0.0623]], device='cuda:0')
 Batch: 10 of common classification Duration: 0:00:00.480905
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0001, 0.0003],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0001, 0.0003],
        [0.0006, 0.0012],
        [0.0004, 0.0009],
        [0.0004, 0.0010],
        [0.0001, 0.0003],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0002, 0.0003],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0610, 0.0639],
        [0.0612, 0.0637],
        [0.0596, 0.0655],
        [0.0616, 0.0633],
        [0.0600, 0.0650],
        [0.0656, 0.0595],
        [0.0627, 0.0622],
        [0.0623, 0.0626],
        [0.0635, 0.0614],
        [0.0612, 0.0637],
        [0.0618, 0.0631],
        [0.0586, 0.0666],
        [0.0668, 0.0584],
        [0.0656, 0.0595],
        [0.0639, 0.0611],
        [0.0644, 0.0605]], device='cuda:0')
 Batch: 11 of common classification Duration: 0:00:00.564848
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0004, 0.0010],
        [0.0002, 0.0007]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1261, 0.1238],
        [0.1261, 0.1238],
        [0.1276, 0.1224],
        [0.1240, 0.1259],
        [0.1298, 0.1203],
        [0.1244, 0.1255],
        [0.1250, 0.1249],
        [0.1169, 0.1335]], device='cuda:0')
 Batch: 12 of common classification Duration: 0:00:00.183098
acc:  0.535
Time taken to execute the en SA task with prompt type common, variation 6 and batchsize 16: 0:00:05.022268
path ['42', 'en', 'bloom-big', 'SA', 'common', 'prompt_id_6']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v73.pickle' as a pickle file.

prompt_type rare_synonyms has 7 prompts in it
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0004]], device='cuda:0') torch.Size([107, 2])
answers_probs just softmax dim 0: tensor([[0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093]], device='cuda:0')
tensor([[0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA rare_synonyms 0 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0008, 0.0011],
        [0.0004, 0.0006],
        [0.0005, 0.0006],
        [0.0005, 0.0007],
        [0.0006, 0.0008],
        [0.0006, 0.0008],
        [0.0004, 0.0006],
        [0.0007, 0.0009],
        [0.0005, 0.0007],
        [0.0007, 0.0008],
        [0.0008, 0.0010],
        [0.0003, 0.0004],
        [0.0006, 0.0015],
        [0.0005, 0.0006],
        [0.0008, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0595, 0.0655],
        [0.0627, 0.0621],
        [0.0629, 0.0620],
        [0.0641, 0.0609],
        [0.0627, 0.0622],
        [0.0640, 0.0610],
        [0.0625, 0.0624],
        [0.0622, 0.0627],
        [0.0638, 0.0611],
        [0.0646, 0.0604],
        [0.0661, 0.0590],
        [0.0646, 0.0604],
        [0.0608, 0.0642],
        [0.0554, 0.0704],
        [0.0643, 0.0606],
        [0.0599, 0.0651]], device='cuda:0')
 Batch: 0 of rare_synonyms classification Duration: 0:00:00.255096
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0007],
        [0.0004, 0.0006],
        [0.0003, 0.0003],
        [0.0005, 0.0005],
        [0.0005, 0.0008],
        [0.0008, 0.0010],
        [0.0006, 0.0009],
        [0.0006, 0.0007],
        [0.0009, 0.0009],
        [0.0005, 0.0006],
        [0.0005, 0.0011],
        [0.0004, 0.0005],
        [0.0005, 0.0009],
        [0.0008, 0.0012],
        [0.0009, 0.0011],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0652, 0.0597],
        [0.0595, 0.0654],
        [0.0661, 0.0589],
        [0.0697, 0.0559],
        [0.0589, 0.0662],
        [0.0634, 0.0615],
        [0.0619, 0.0629],
        [0.0630, 0.0618],
        [0.0663, 0.0588],
        [0.0630, 0.0618],
        [0.0562, 0.0693],
        [0.0633, 0.0616],
        [0.0592, 0.0658],
        [0.0600, 0.0649],
        [0.0631, 0.0617],
        [0.0611, 0.0637]], device='cuda:0')
 Batch: 1 of rare_synonyms classification Duration: 0:00:00.356576
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0009, 0.0011],
        [0.0007, 0.0010],
        [0.0005, 0.0009],
        [0.0004, 0.0006],
        [0.0005, 0.0008],
        [0.0005, 0.0005],
        [0.0009, 0.0011],
        [0.0005, 0.0013],
        [0.0008, 0.0009],
        [0.0006, 0.0009],
        [0.0007, 0.0008],
        [0.0005, 0.0006],
        [0.0009, 0.0013],
        [0.0006, 0.0007],
        [0.0007, 0.0008],
        [0.0007, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0649, 0.0600],
        [0.0626, 0.0622],
        [0.0584, 0.0666],
        [0.0620, 0.0628],
        [0.0596, 0.0653],
        [0.0682, 0.0571],
        [0.0634, 0.0614],
        [0.0537, 0.0726],
        [0.0648, 0.0601],
        [0.0610, 0.0639],
        [0.0645, 0.0603],
        [0.0624, 0.0625],
        [0.0615, 0.0633],
        [0.0654, 0.0595],
        [0.0645, 0.0603],
        [0.0629, 0.0619]], device='cuda:0')
 Batch: 2 of rare_synonyms classification Duration: 0:00:00.448469
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0006],
        [0.0007, 0.0013],
        [0.0006, 0.0010],
        [0.0006, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0007, 0.0007],
        [0.0013, 0.0013],
        [0.0006, 0.0006],
        [0.0004, 0.0005],
        [0.0005, 0.0006],
        [0.0013, 0.0014],
        [0.0008, 0.0007],
        [0.0007, 0.0008],
        [0.0008, 0.0010],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0619, 0.0629],
        [0.0572, 0.0681],
        [0.0582, 0.0669],
        [0.0615, 0.0634],
        [0.0589, 0.0662],
        [0.0559, 0.0697],
        [0.0655, 0.0594],
        [0.0655, 0.0594],
        [0.0654, 0.0595],
        [0.0638, 0.0611],
        [0.0640, 0.0609],
        [0.0653, 0.0597],
        [0.0676, 0.0576],
        [0.0650, 0.0599],
        [0.0622, 0.0626],
        [0.0622, 0.0626]], device='cuda:0')
 Batch: 3 of rare_synonyms classification Duration: 0:00:00.363748
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0007],
        [0.0005, 0.0009],
        [0.0009, 0.0008],
        [0.0006, 0.0009],
        [0.0007, 0.0009],
        [0.0005, 0.0006],
        [0.0005, 0.0007],
        [0.0006, 0.0007],
        [0.0004, 0.0004],
        [0.0003, 0.0005],
        [0.0006, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0004],
        [0.0007, 0.0010],
        [0.0009, 0.0013],
        [0.0006, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0631, 0.0617],
        [0.0571, 0.0682],
        [0.0688, 0.0566],
        [0.0598, 0.0652],
        [0.0630, 0.0618],
        [0.0630, 0.0618],
        [0.0631, 0.0617],
        [0.0663, 0.0588],
        [0.0651, 0.0598],
        [0.0593, 0.0657],
        [0.0611, 0.0637],
        [0.0560, 0.0696],
        [0.0639, 0.0610],
        [0.0619, 0.0629],
        [0.0618, 0.0630],
        [0.0667, 0.0584]], device='cuda:0')
 Batch: 4 of rare_synonyms classification Duration: 0:00:00.403486
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0005, 0.0008],
        [0.0005, 0.0006],
        [0.0008, 0.0009],
        [0.0010, 0.0014],
        [0.0005, 0.0006],
        [0.0007, 0.0009],
        [0.0005, 0.0007],
        [0.0005, 0.0008],
        [0.0010, 0.0017],
        [0.0006, 0.0008],
        [0.0006, 0.0011],
        [0.0005, 0.0008],
        [0.0003, 0.0002],
        [0.0008, 0.0008],
        [0.0007, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0551, 0.0706],
        [0.0592, 0.0658],
        [0.0634, 0.0613],
        [0.0643, 0.0605],
        [0.0624, 0.0624],
        [0.0641, 0.0607],
        [0.0638, 0.0610],
        [0.0624, 0.0624],
        [0.0600, 0.0649],
        [0.0592, 0.0657],
        [0.0646, 0.0603],
        [0.0579, 0.0672],
        [0.0614, 0.0634],
        [0.0736, 0.0528],
        [0.0657, 0.0592],
        [0.0630, 0.0618]], device='cuda:0')
 Batch: 5 of rare_synonyms classification Duration: 0:00:00.562227
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0009, 0.0010],
        [0.0003, 0.0005],
        [0.0006, 0.0009],
        [0.0004, 0.0004],
        [0.0005, 0.0008],
        [0.0006, 0.0008],
        [0.0006, 0.0009],
        [0.0010, 0.0010],
        [0.0005, 0.0007],
        [0.0008, 0.0010],
        [0.0006, 0.0008],
        [0.0006, 0.0005],
        [0.0007, 0.0011],
        [0.0004, 0.0005],
        [0.0006, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0578, 0.0674],
        [0.0642, 0.0607],
        [0.0617, 0.0632],
        [0.0618, 0.0631],
        [0.0674, 0.0578],
        [0.0592, 0.0659],
        [0.0624, 0.0625],
        [0.0592, 0.0659],
        [0.0668, 0.0584],
        [0.0631, 0.0618],
        [0.0624, 0.0625],
        [0.0632, 0.0617],
        [0.0674, 0.0578],
        [0.0594, 0.0656],
        [0.0638, 0.0611],
        [0.0602, 0.0648]], device='cuda:0')
 Batch: 6 of rare_synonyms classification Duration: 0:00:00.333909
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0009, 0.0012],
        [0.0009, 0.0011],
        [0.0005, 0.0007],
        [0.0006, 0.0009],
        [0.0003, 0.0004],
        [0.0005, 0.0009],
        [0.0005, 0.0007],
        [0.0009, 0.0014],
        [0.0007, 0.0007],
        [0.0011, 0.0014],
        [0.0003, 0.0006],
        [0.0006, 0.0009],
        [0.0008, 0.0012],
        [0.0006, 0.0013],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0635, 0.0614],
        [0.0633, 0.0616],
        [0.0645, 0.0604],
        [0.0620, 0.0629],
        [0.0614, 0.0635],
        [0.0643, 0.0607],
        [0.0591, 0.0660],
        [0.0632, 0.0618],
        [0.0620, 0.0629],
        [0.0684, 0.0570],
        [0.0646, 0.0603],
        [0.0603, 0.0647],
        [0.0622, 0.0627],
        [0.0616, 0.0633],
        [0.0574, 0.0679],
        [0.0622, 0.0627]], device='cuda:0')
 Batch: 7 of rare_synonyms classification Duration: 0:00:00.432786
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0004],
        [0.0005, 0.0007],
        [0.0005, 0.0007],
        [0.0006, 0.0005],
        [0.0007, 0.0015],
        [0.0006, 0.0012],
        [0.0007, 0.0016],
        [0.0005, 0.0007],
        [0.0004, 0.0008],
        [0.0009, 0.0012],
        [0.0005, 0.0006],
        [0.0005, 0.0006],
        [0.0006, 0.0008],
        [0.0006, 0.0007],
        [0.0007, 0.0012],
        [0.0011, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0692, 0.0562],
        [0.0614, 0.0633],
        [0.0629, 0.0618],
        [0.0706, 0.0551],
        [0.0572, 0.0680],
        [0.0574, 0.0677],
        [0.0547, 0.0711],
        [0.0639, 0.0608],
        [0.0590, 0.0660],
        [0.0627, 0.0620],
        [0.0644, 0.0604],
        [0.0635, 0.0612],
        [0.0614, 0.0633],
        [0.0654, 0.0595],
        [0.0596, 0.0653],
        [0.0667, 0.0583]], device='cuda:0')
 Batch: 8 of rare_synonyms classification Duration: 0:00:00.423403
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0006],
        [0.0006, 0.0009],
        [0.0009, 0.0008],
        [0.0004, 0.0005],
        [0.0003, 0.0003],
        [0.0007, 0.0007],
        [0.0008, 0.0010],
        [0.0008, 0.0007],
        [0.0012, 0.0017],
        [0.0006, 0.0010],
        [0.0006, 0.0009],
        [0.0006, 0.0006],
        [0.0009, 0.0009],
        [0.0007, 0.0018],
        [0.0003, 0.0004],
        [0.0009, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0623, 0.0624],
        [0.0599, 0.0649],
        [0.0672, 0.0578],
        [0.0628, 0.0619],
        [0.0634, 0.0613],
        [0.0652, 0.0597],
        [0.0627, 0.0620],
        [0.0696, 0.0559],
        [0.0605, 0.0642],
        [0.0571, 0.0681],
        [0.0585, 0.0664],
        [0.0662, 0.0587],
        [0.0657, 0.0592],
        [0.0525, 0.0741],
        [0.0610, 0.0637],
        [0.0654, 0.0594]], device='cuda:0')
 Batch: 9 of rare_synonyms classification Duration: 0:00:00.420428
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0004, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0003],
        [0.0006, 0.0008],
        [0.0005, 0.0006],
        [0.0008, 0.0011],
        [0.0004, 0.0006],
        [0.0003, 0.0008],
        [0.0006, 0.0010],
        [0.0004, 0.0006],
        [0.0006, 0.0006],
        [0.0006, 0.0008],
        [0.0004, 0.0007],
        [0.0005, 0.0008],
        [0.0011, 0.0018]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626]], device='cuda:0')
tensor([[0.0645, 0.0604],
        [0.0664, 0.0587],
        [0.0595, 0.0654],
        [0.0674, 0.0577],
        [0.0623, 0.0625],
        [0.0641, 0.0607],
        [0.0633, 0.0616],
        [0.0603, 0.0646],
        [0.0533, 0.0731],
        [0.0614, 0.0634],
        [0.0640, 0.0608],
        [0.0687, 0.0566],
        [0.0620, 0.0628],
        [0.0600, 0.0648],
        [0.0623, 0.0625],
        [0.0606, 0.0642]], device='cuda:0')
 Batch: 10 of rare_synonyms classification Duration: 0:00:00.233734
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0007],
        [0.0005, 0.0007],
        [0.0003, 0.0003],
        [0.0007, 0.0011],
        [0.0008, 0.0009],
        [0.0006, 0.0008],
        [0.0006, 0.0005],
        [0.0007, 0.0010],
        [0.0005, 0.0008],
        [0.0004, 0.0006],
        [0.0005, 0.0005],
        [0.0008, 0.0009],
        [0.0004, 0.0008],
        [0.0005, 0.0006],
        [0.0010, 0.0009],
        [0.0006, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0646, 0.0603],
        [0.0599, 0.0651],
        [0.0641, 0.0608],
        [0.0600, 0.0650],
        [0.0645, 0.0604],
        [0.0599, 0.0651],
        [0.0671, 0.0581],
        [0.0605, 0.0644],
        [0.0593, 0.0657],
        [0.0593, 0.0657],
        [0.0647, 0.0602],
        [0.0639, 0.0610],
        [0.0579, 0.0673],
        [0.0621, 0.0628],
        [0.0672, 0.0580],
        [0.0651, 0.0598]], device='cuda:0')
 Batch: 11 of rare_synonyms classification Duration: 0:00:00.488152
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0006, 0.0008],
        [0.0007, 0.0014],
        [0.0008, 0.0011],
        [0.0005, 0.0006],
        [0.0007, 0.0010],
        [0.0003, 0.0003],
        [0.0006, 0.0006],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1249],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1280, 0.1218],
        [0.1153, 0.1352],
        [0.1218, 0.1280],
        [0.1300, 0.1199],
        [0.1241, 0.1256],
        [0.1315, 0.1186],
        [0.1315, 0.1186],
        [0.1178, 0.1323]], device='cuda:0')
 Batch: 12 of rare_synonyms classification Duration: 0:00:00.216473
acc:  0.455
Time taken to execute the en SA task with prompt type rare_synonyms, variation 0 and batchsize 16: 0:00:04.954379
path ['42', 'en', 'bloom-big', 'SA', 'rare_synonyms', 'prompt_id_0']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0003, 0.0003]], device='cuda:0') torch.Size([107, 2])
answers_probs just softmax dim 0: tensor([[0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093]], device='cuda:0')
tensor([[0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093],
        [0.0093, 0.0093]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA rare_synonyms 1 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0012],
        [0.0006, 0.0016],
        [0.0004, 0.0008],
        [0.0002, 0.0005],
        [0.0005, 0.0008],
        [0.0006, 0.0011],
        [0.0005, 0.0010],
        [0.0005, 0.0012],
        [0.0004, 0.0008],
        [0.0008, 0.0024],
        [0.0005, 0.0011],
        [0.0003, 0.0006],
        [0.0004, 0.0011],
        [0.0003, 0.0012],
        [0.0006, 0.0012],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0625, 0.0624],
        [0.0604, 0.0646],
        [0.0635, 0.0614],
        [0.0626, 0.0623],
        [0.0663, 0.0588],
        [0.0645, 0.0605],
        [0.0622, 0.0627],
        [0.0616, 0.0633],
        [0.0633, 0.0616],
        [0.0588, 0.0663],
        [0.0613, 0.0636],
        [0.0647, 0.0602],
        [0.0601, 0.0649],
        [0.0567, 0.0688],
        [0.0638, 0.0611],
        [0.0678, 0.0576]], device='cuda:0')
 Batch: 0 of rare_synonyms classification Duration: 0:00:00.363303
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0013],
        [0.0004, 0.0004],
        [0.0005, 0.0007],
        [0.0005, 0.0015],
        [0.0004, 0.0010],
        [0.0003, 0.0008],
        [0.0005, 0.0013],
        [0.0004, 0.0009],
        [0.0004, 0.0012],
        [0.0003, 0.0007],
        [0.0004, 0.0012],
        [0.0005, 0.0009],
        [0.0009, 0.0019],
        [0.0005, 0.0013],
        [0.0004, 0.0009],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0603, 0.0646],
        [0.0732, 0.0532],
        [0.0671, 0.0581],
        [0.0593, 0.0657],
        [0.0597, 0.0653],
        [0.0612, 0.0637],
        [0.0608, 0.0641],
        [0.0633, 0.0616],
        [0.0585, 0.0665],
        [0.0617, 0.0631],
        [0.0595, 0.0655],
        [0.0637, 0.0611],
        [0.0637, 0.0611],
        [0.0615, 0.0633],
        [0.0613, 0.0635],
        [0.0653, 0.0597]], device='cuda:0')
 Batch: 1 of rare_synonyms classification Duration: 0:00:00.361039
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0014],
        [0.0004, 0.0013],
        [0.0004, 0.0011],
        [0.0005, 0.0012],
        [0.0006, 0.0011],
        [0.0005, 0.0013],
        [0.0004, 0.0008],
        [0.0004, 0.0010],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0005, 0.0016],
        [0.0004, 0.0010],
        [0.0006, 0.0011],
        [0.0007, 0.0021],
        [0.0005, 0.0010],
        [0.0007, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0607, 0.0642],
        [0.0585, 0.0666],
        [0.0608, 0.0641],
        [0.0619, 0.0630],
        [0.0656, 0.0594],
        [0.0600, 0.0649],
        [0.0639, 0.0610],
        [0.0616, 0.0633],
        [0.0687, 0.0567],
        [0.0637, 0.0612],
        [0.0591, 0.0659],
        [0.0602, 0.0647],
        [0.0655, 0.0595],
        [0.0588, 0.0663],
        [0.0643, 0.0606],
        [0.0664, 0.0587]], device='cuda:0')
 Batch: 2 of rare_synonyms classification Duration: 0:00:00.339591
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0010, 0.0022],
        [0.0005, 0.0011],
        [0.0004, 0.0007],
        [0.0005, 0.0015],
        [0.0008, 0.0018],
        [0.0004, 0.0011],
        [0.0004, 0.0014],
        [0.0003, 0.0005],
        [0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0004, 0.0009],
        [0.0007, 0.0015],
        [0.0003, 0.0004],
        [0.0005, 0.0008],
        [0.0006, 0.0011],
        [0.0007, 0.0016]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0620, 0.0629],
        [0.0624, 0.0625],
        [0.0655, 0.0595],
        [0.0586, 0.0666],
        [0.0624, 0.0625],
        [0.0593, 0.0658],
        [0.0575, 0.0678],
        [0.0644, 0.0605],
        [0.0631, 0.0618],
        [0.0605, 0.0645],
        [0.0626, 0.0623],
        [0.0622, 0.0627],
        [0.0664, 0.0587],
        [0.0666, 0.0586],
        [0.0655, 0.0595],
        [0.0612, 0.0637]], device='cuda:0')
 Batch: 3 of rare_synonyms classification Duration: 0:00:00.367576
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0003, 0.0008],
        [0.0009, 0.0020],
        [0.0005, 0.0016],
        [0.0003, 0.0009],
        [0.0005, 0.0009],
        [0.0004, 0.0009],
        [0.0004, 0.0010],
        [0.0004, 0.0012],
        [0.0006, 0.0009],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0004, 0.0009],
        [0.0005, 0.0012],
        [0.0007, 0.0017],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0653, 0.0597],
        [0.0600, 0.0649],
        [0.0616, 0.0633],
        [0.0577, 0.0675],
        [0.0590, 0.0661],
        [0.0660, 0.0591],
        [0.0638, 0.0611],
        [0.0620, 0.0629],
        [0.0596, 0.0654],
        [0.0691, 0.0564],
        [0.0680, 0.0573],
        [0.0613, 0.0636],
        [0.0620, 0.0629],
        [0.0623, 0.0626],
        [0.0619, 0.0630],
        [0.0606, 0.0643]], device='cuda:0')
 Batch: 4 of rare_synonyms classification Duration: 0:00:00.313257
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0013],
        [0.0004, 0.0006],
        [0.0004, 0.0009],
        [0.0007, 0.0015],
        [0.0007, 0.0014],
        [0.0004, 0.0009],
        [0.0004, 0.0006],
        [0.0005, 0.0009],
        [0.0004, 0.0013],
        [0.0006, 0.0016],
        [0.0004, 0.0015],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0005, 0.0010],
        [0.0007, 0.0011],
        [0.0007, 0.0018]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0564, 0.0690],
        [0.0676, 0.0576],
        [0.0627, 0.0622],
        [0.0615, 0.0633],
        [0.0629, 0.0620],
        [0.0630, 0.0618],
        [0.0676, 0.0576],
        [0.0652, 0.0597],
        [0.0585, 0.0666],
        [0.0601, 0.0648],
        [0.0570, 0.0683],
        [0.0654, 0.0596],
        [0.0631, 0.0617],
        [0.0628, 0.0621],
        [0.0668, 0.0583],
        [0.0596, 0.0654]], device='cuda:0')
 Batch: 5 of rare_synonyms classification Duration: 0:00:00.445596
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0008, 0.0011],
        [0.0004, 0.0006],
        [0.0004, 0.0011],
        [0.0005, 0.0012],
        [0.0002, 0.0006],
        [0.0004, 0.0011],
        [0.0007, 0.0015],
        [0.0002, 0.0002],
        [0.0005, 0.0013],
        [0.0003, 0.0008],
        [0.0005, 0.0011],
        [0.0004, 0.0008],
        [0.0005, 0.0010],
        [0.0003, 0.0008],
        [0.0007, 0.0016],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0683, 0.0570],
        [0.0669, 0.0582],
        [0.0587, 0.0664],
        [0.0613, 0.0635],
        [0.0610, 0.0638],
        [0.0589, 0.0661],
        [0.0618, 0.0630],
        [0.0733, 0.0531],
        [0.0599, 0.0650],
        [0.0584, 0.0667],
        [0.0621, 0.0627],
        [0.0621, 0.0627],
        [0.0649, 0.0600],
        [0.0610, 0.0638],
        [0.0616, 0.0632],
        [0.0599, 0.0650]], device='cuda:0')
 Batch: 6 of rare_synonyms classification Duration: 0:00:00.360883
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0012],
        [0.0004, 0.0013],
        [0.0004, 0.0010],
        [0.0004, 0.0013],
        [0.0006, 0.0023],
        [0.0004, 0.0007],
        [0.0007, 0.0014],
        [0.0005, 0.0009],
        [0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0004, 0.0012],
        [0.0004, 0.0008],
        [0.0004, 0.0014],
        [0.0004, 0.0006],
        [0.0003, 0.0004],
        [0.0010, 0.0022]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626]], device='cuda:0')
tensor([[0.0609, 0.0640],
        [0.0592, 0.0658],
        [0.0626, 0.0623],
        [0.0591, 0.0660],
        [0.0566, 0.0688],
        [0.0640, 0.0609],
        [0.0642, 0.0607],
        [0.0649, 0.0601],
        [0.0643, 0.0606],
        [0.0641, 0.0608],
        [0.0597, 0.0653],
        [0.0656, 0.0594],
        [0.0575, 0.0677],
        [0.0679, 0.0574],
        [0.0675, 0.0577],
        [0.0622, 0.0627]], device='cuda:0')
 Batch: 7 of rare_synonyms classification Duration: 0:00:00.407102
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0012],
        [0.0002, 0.0004],
        [0.0009, 0.0016],
        [0.0007, 0.0013],
        [0.0002, 0.0002],
        [0.0006, 0.0015],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0006, 0.0013],
        [0.0003, 0.0006],
        [0.0007, 0.0017],
        [0.0005, 0.0015],
        [0.0004, 0.0011],
        [0.0005, 0.0016],
        [0.0007, 0.0017],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0624],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0601, 0.0648],
        [0.0654, 0.0596],
        [0.0653, 0.0597],
        [0.0651, 0.0599],
        [0.0717, 0.0543],
        [0.0613, 0.0636],
        [0.0625, 0.0623],
        [0.0630, 0.0618],
        [0.0633, 0.0616],
        [0.0622, 0.0626],
        [0.0606, 0.0643],
        [0.0577, 0.0676],
        [0.0592, 0.0658],
        [0.0583, 0.0668],
        [0.0606, 0.0643],
        [0.0637, 0.0612]], device='cuda:0')
 Batch: 8 of rare_synonyms classification Duration: 0:00:00.488322
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0012],
        [0.0005, 0.0009],
        [0.0004, 0.0010],
        [0.0004, 0.0012],
        [0.0003, 0.0005],
        [0.0004, 0.0014],
        [0.0004, 0.0011],
        [0.0003, 0.0010],
        [0.0004, 0.0008],
        [0.0005, 0.0017],
        [0.0005, 0.0011],
        [0.0004, 0.0009],
        [0.0004, 0.0008],
        [0.0005, 0.0006],
        [0.0003, 0.0008],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0609, 0.0639],
        [0.0646, 0.0602],
        [0.0621, 0.0626],
        [0.0594, 0.0655],
        [0.0669, 0.0581],
        [0.0574, 0.0678],
        [0.0603, 0.0646],
        [0.0577, 0.0674],
        [0.0636, 0.0612],
        [0.0570, 0.0683],
        [0.0638, 0.0610],
        [0.0626, 0.0621],
        [0.0647, 0.0602],
        [0.0730, 0.0533],
        [0.0606, 0.0643],
        [0.0654, 0.0595]], device='cuda:0')
 Batch: 9 of rare_synonyms classification Duration: 0:00:00.370640
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0006, 0.0008],
        [0.0003, 0.0009],
        [0.0006, 0.0012],
        [0.0003, 0.0005],
        [0.0006, 0.0013],
        [0.0005, 0.0014],
        [0.0002, 0.0004],
        [0.0006, 0.0020],
        [0.0004, 0.0011],
        [0.0003, 0.0009],
        [0.0006, 0.0012],
        [0.0004, 0.0012],
        [0.0008, 0.0018],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0634, 0.0615],
        [0.0635, 0.0614],
        [0.0690, 0.0565],
        [0.0603, 0.0647],
        [0.0638, 0.0611],
        [0.0669, 0.0583],
        [0.0629, 0.0620],
        [0.0607, 0.0643],
        [0.0626, 0.0623],
        [0.0588, 0.0663],
        [0.0604, 0.0646],
        [0.0605, 0.0645],
        [0.0637, 0.0612],
        [0.0582, 0.0670],
        [0.0623, 0.0626],
        [0.0632, 0.0617]], device='cuda:0')
 Batch: 10 of rare_synonyms classification Duration: 0:00:00.562050
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0012],
        [0.0005, 0.0020],
        [0.0005, 0.0010],
        [0.0005, 0.0007],
        [0.0006, 0.0014],
        [0.0002, 0.0005],
        [0.0011, 0.0029],
        [0.0004, 0.0010],
        [0.0005, 0.0006],
        [0.0005, 0.0010],
        [0.0008, 0.0024],
        [0.0005, 0.0011],
        [0.0004, 0.0011],
        [0.0005, 0.0016],
        [0.0006, 0.0014],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0624]], device='cuda:0')
tensor([[0.0603, 0.0646],
        [0.0561, 0.0693],
        [0.0635, 0.0612],
        [0.0696, 0.0559],
        [0.0619, 0.0628],
        [0.0635, 0.0612],
        [0.0598, 0.0651],
        [0.0613, 0.0634],
        [0.0717, 0.0543],
        [0.0649, 0.0599],
        [0.0587, 0.0663],
        [0.0629, 0.0619],
        [0.0603, 0.0646],
        [0.0577, 0.0674],
        [0.0621, 0.0626],
        [0.0655, 0.0594]], device='cuda:0')
 Batch: 11 of rare_synonyms classification Duration: 0:00:00.402988
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0006, 0.0013],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0004, 0.0009],
        [0.0004, 0.0011],
        [0.0005, 0.0008],
        [0.0005, 0.0012]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1271, 0.1228],
        [0.1252, 0.1247],
        [0.1254, 0.1245],
        [0.1221, 0.1278],
        [0.1233, 0.1266],
        [0.1184, 0.1318],
        [0.1344, 0.1162],
        [0.1241, 0.1257]], device='cuda:0')
 Batch: 12 of rare_synonyms classification Duration: 0:00:00.217348
acc:  0.505
Time taken to execute the en SA task with prompt type rare_synonyms, variation 1 and batchsize 16: 0:00:05.015251
path ['42', 'en', 'bloom-big', 'SA', 'rare_synonyms', 'prompt_id_1']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([132, 2])
answers_probs just softmax dim 0: tensor([[0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076]], device='cuda:0')
tensor([[0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076],
        [0.0076, 0.0076]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA rare_synonyms 2 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0003, 0.0009],
        [0.0004, 0.0015],
        [0.0003, 0.0004],
        [0.0003, 0.0007],
        [0.0003, 0.0013],
        [0.0005, 0.0011],
        [0.0002, 0.0009],
        [0.0004, 0.0015],
        [0.0005, 0.0010],
        [0.0004, 0.0006],
        [0.0004, 0.0015],
        [0.0006, 0.0015],
        [0.0004, 0.0014],
        [0.0003, 0.0006],
        [0.0005, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0711, 0.0546],
        [0.0599, 0.0648],
        [0.0572, 0.0678],
        [0.0726, 0.0535],
        [0.0624, 0.0622],
        [0.0577, 0.0672],
        [0.0635, 0.0611],
        [0.0571, 0.0680],
        [0.0570, 0.0681],
        [0.0648, 0.0599],
        [0.0688, 0.0565],
        [0.0586, 0.0663],
        [0.0615, 0.0631],
        [0.0573, 0.0678],
        [0.0679, 0.0572],
        [0.0626, 0.0620]], device='cuda:0')
 Batch: 0 of rare_synonyms classification Duration: 0:00:00.411967
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0014],
        [0.0003, 0.0005],
        [0.0006, 0.0014],
        [0.0004, 0.0009],
        [0.0005, 0.0015],
        [0.0004, 0.0012],
        [0.0003, 0.0009],
        [0.0002, 0.0008],
        [0.0002, 0.0009],
        [0.0004, 0.0011],
        [0.0002, 0.0005],
        [0.0002, 0.0011],
        [0.0002, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0011],
        [0.0006, 0.0018]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0591, 0.0659],
        [0.0683, 0.0571],
        [0.0652, 0.0598],
        [0.0639, 0.0610],
        [0.0614, 0.0635],
        [0.0632, 0.0617],
        [0.0611, 0.0638],
        [0.0618, 0.0631],
        [0.0588, 0.0662],
        [0.0627, 0.0621],
        [0.0631, 0.0618],
        [0.0568, 0.0687],
        [0.0617, 0.0632],
        [0.0673, 0.0579],
        [0.0632, 0.0617],
        [0.0622, 0.0627]], device='cuda:0')
 Batch: 1 of rare_synonyms classification Duration: 0:00:00.411512
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0017],
        [0.0004, 0.0006],
        [0.0002, 0.0009],
        [0.0007, 0.0010],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0005, 0.0011],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0011],
        [0.0008, 0.0023],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0010],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0602, 0.0647],
        [0.0672, 0.0580],
        [0.0560, 0.0695],
        [0.0677, 0.0575],
        [0.0637, 0.0612],
        [0.0659, 0.0591],
        [0.0647, 0.0602],
        [0.0618, 0.0631],
        [0.0662, 0.0588],
        [0.0614, 0.0635],
        [0.0584, 0.0666],
        [0.0594, 0.0656],
        [0.0631, 0.0617],
        [0.0641, 0.0607],
        [0.0578, 0.0674],
        [0.0624, 0.0624]], device='cuda:0')
 Batch: 2 of rare_synonyms classification Duration: 0:00:00.369442
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0003, 0.0007],
        [0.0005, 0.0012],
        [0.0003, 0.0011],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0004, 0.0009],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0010],
        [0.0003, 0.0008],
        [0.0002, 0.0011],
        [0.0002, 0.0004],
        [0.0005, 0.0016],
        [0.0003, 0.0004],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0597, 0.0651],
        [0.0632, 0.0615],
        [0.0616, 0.0631],
        [0.0589, 0.0660],
        [0.0711, 0.0547],
        [0.0602, 0.0646],
        [0.0635, 0.0612],
        [0.0636, 0.0611],
        [0.0635, 0.0612],
        [0.0572, 0.0679],
        [0.0607, 0.0641],
        [0.0551, 0.0705],
        [0.0643, 0.0605],
        [0.0585, 0.0665],
        [0.0699, 0.0557],
        [0.0691, 0.0563]], device='cuda:0')
 Batch: 3 of rare_synonyms classification Duration: 0:00:00.445298
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0005, 0.0008],
        [0.0006, 0.0014],
        [0.0003, 0.0010],
        [0.0003, 0.0009],
        [0.0002, 0.0006],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0007, 0.0017],
        [0.0003, 0.0007],
        [0.0004, 0.0006],
        [0.0006, 0.0012],
        [0.0005, 0.0013],
        [0.0003, 0.0010],
        [0.0003, 0.0011],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0589, 0.0661],
        [0.0667, 0.0584],
        [0.0632, 0.0616],
        [0.0579, 0.0672],
        [0.0599, 0.0650],
        [0.0622, 0.0626],
        [0.0628, 0.0620],
        [0.0628, 0.0620],
        [0.0616, 0.0632],
        [0.0619, 0.0629],
        [0.0693, 0.0561],
        [0.0663, 0.0587],
        [0.0603, 0.0645],
        [0.0580, 0.0672],
        [0.0582, 0.0669],
        [0.0701, 0.0555]], device='cuda:0')
 Batch: 4 of rare_synonyms classification Duration: 0:00:00.319411
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0010],
        [0.0005, 0.0009],
        [0.0003, 0.0005],
        [0.0007, 0.0012],
        [0.0002, 0.0007],
        [0.0003, 0.0015],
        [0.0005, 0.0016],
        [0.0002, 0.0006],
        [0.0002, 0.0007],
        [0.0002, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0011],
        [0.0003, 0.0008],
        [0.0004, 0.0013],
        [0.0003, 0.0009],
        [0.0004, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0608, 0.0640],
        [0.0677, 0.0574],
        [0.0702, 0.0554],
        [0.0687, 0.0566],
        [0.0583, 0.0667],
        [0.0565, 0.0688],
        [0.0607, 0.0641],
        [0.0601, 0.0647],
        [0.0592, 0.0658],
        [0.0622, 0.0626],
        [0.0680, 0.0572],
        [0.0592, 0.0658],
        [0.0637, 0.0610],
        [0.0603, 0.0645],
        [0.0620, 0.0628],
        [0.0623, 0.0625]], device='cuda:0')
 Batch: 5 of rare_synonyms classification Duration: 0:00:00.456483
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0010, 0.0018],
        [0.0007, 0.0018],
        [0.0003, 0.0008],
        [0.0005, 0.0011],
        [0.0002, 0.0003],
        [0.0003, 0.0012],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0003, 0.0003],
        [0.0005, 0.0015],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0004, 0.0007],
        [0.0003, 0.0009],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0626],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0654, 0.0595],
        [0.0596, 0.0652],
        [0.0612, 0.0636],
        [0.0615, 0.0633],
        [0.0642, 0.0606],
        [0.0569, 0.0683],
        [0.0612, 0.0636],
        [0.0647, 0.0601],
        [0.0745, 0.0522],
        [0.0576, 0.0675],
        [0.0663, 0.0587],
        [0.0612, 0.0636],
        [0.0597, 0.0651],
        [0.0664, 0.0586],
        [0.0602, 0.0646],
        [0.0594, 0.0654]], device='cuda:0')
 Batch: 6 of rare_synonyms classification Duration: 0:00:00.364921
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0012],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0005, 0.0013],
        [0.0002, 0.0002],
        [0.0005, 0.0010],
        [0.0004, 0.0011],
        [0.0003, 0.0005],
        [0.0005, 0.0007],
        [0.0005, 0.0017],
        [0.0005, 0.0008],
        [0.0003, 0.0007],
        [0.0002, 0.0009],
        [0.0002, 0.0002],
        [0.0003, 0.0013],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0613, 0.0634],
        [0.0646, 0.0601],
        [0.0643, 0.0605],
        [0.0601, 0.0646],
        [0.0702, 0.0554],
        [0.0617, 0.0629],
        [0.0603, 0.0644],
        [0.0636, 0.0611],
        [0.0668, 0.0582],
        [0.0565, 0.0687],
        [0.0657, 0.0592],
        [0.0607, 0.0640],
        [0.0558, 0.0697],
        [0.0727, 0.0535],
        [0.0552, 0.0704],
        [0.0606, 0.0641]], device='cuda:0')
 Batch: 7 of rare_synonyms classification Duration: 0:00:00.571579
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0011],
        [0.0004, 0.0010],
        [0.0003, 0.0010],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0003, 0.0010],
        [0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0002, 0.0008],
        [0.0002, 0.0008],
        [0.0002, 0.0007],
        [0.0004, 0.0009],
        [0.0002, 0.0003],
        [0.0003, 0.0010],
        [0.0005, 0.0011],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0579, 0.0673],
        [0.0607, 0.0642],
        [0.0601, 0.0648],
        [0.0671, 0.0581],
        [0.0648, 0.0601],
        [0.0591, 0.0659],
        [0.0685, 0.0568],
        [0.0651, 0.0598],
        [0.0592, 0.0658],
        [0.0596, 0.0653],
        [0.0596, 0.0653],
        [0.0648, 0.0601],
        [0.0677, 0.0575],
        [0.0574, 0.0678],
        [0.0638, 0.0610],
        [0.0647, 0.0602]], device='cuda:0')
 Batch: 8 of rare_synonyms classification Duration: 0:00:00.430861
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0005, 0.0009],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0002, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0010],
        [0.0004, 0.0010],
        [0.0005, 0.0008],
        [0.0002, 0.0009],
        [0.0003, 0.0003],
        [0.0002, 0.0008],
        [0.0005, 0.0015],
        [0.0005, 0.0014],
        [0.0004, 0.0009],
        [0.0004, 0.0019]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626]], device='cuda:0')
tensor([[0.0625, 0.0621],
        [0.0641, 0.0604],
        [0.0685, 0.0566],
        [0.0589, 0.0658],
        [0.0584, 0.0664],
        [0.0704, 0.0551],
        [0.0581, 0.0667],
        [0.0610, 0.0636],
        [0.0687, 0.0565],
        [0.0560, 0.0693],
        [0.0768, 0.0505],
        [0.0582, 0.0666],
        [0.0605, 0.0640],
        [0.0606, 0.0639],
        [0.0625, 0.0621],
        [0.0549, 0.0706]], device='cuda:0')
 Batch: 9 of rare_synonyms classification Duration: 0:00:00.424402
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0010],
        [0.0004, 0.0011],
        [0.0006, 0.0011],
        [0.0002, 0.0008],
        [0.0009, 0.0024],
        [0.0003, 0.0007],
        [0.0004, 0.0009],
        [0.0004, 0.0009],
        [0.0004, 0.0006],
        [0.0003, 0.0009],
        [0.0004, 0.0010],
        [0.0007, 0.0025],
        [0.0009, 0.0025],
        [0.0005, 0.0007],
        [0.0005, 0.0008],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0570, 0.0683],
        [0.0606, 0.0643],
        [0.0671, 0.0580],
        [0.0591, 0.0659],
        [0.0610, 0.0638],
        [0.0607, 0.0641],
        [0.0633, 0.0615],
        [0.0634, 0.0614],
        [0.0698, 0.0558],
        [0.0587, 0.0663],
        [0.0606, 0.0642],
        [0.0583, 0.0668],
        [0.0605, 0.0643],
        [0.0689, 0.0565],
        [0.0665, 0.0585],
        [0.0645, 0.0604]], device='cuda:0')
 Batch: 10 of rare_synonyms classification Duration: 0:00:00.367071
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0010],
        [0.0003, 0.0013],
        [0.0003, 0.0007],
        [0.0006, 0.0012],
        [0.0008, 0.0018],
        [0.0003, 0.0008],
        [0.0003, 0.0012],
        [0.0004, 0.0007],
        [0.0006, 0.0008],
        [0.0004, 0.0013],
        [0.0004, 0.0012],
        [0.0007, 0.0011],
        [0.0004, 0.0011],
        [0.0004, 0.0010],
        [0.0004, 0.0013],
        [0.0003, 0.0015]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0601, 0.0647],
        [0.0582, 0.0668],
        [0.0641, 0.0607],
        [0.0666, 0.0584],
        [0.0639, 0.0609],
        [0.0645, 0.0603],
        [0.0586, 0.0663],
        [0.0680, 0.0572],
        [0.0715, 0.0543],
        [0.0593, 0.0655],
        [0.0613, 0.0635],
        [0.0683, 0.0570],
        [0.0598, 0.0650],
        [0.0615, 0.0632],
        [0.0598, 0.0651],
        [0.0546, 0.0712]], device='cuda:0')
 Batch: 11 of rare_synonyms classification Duration: 0:00:00.365251
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0004, 0.0014],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0002, 0.0007],
        [0.0004, 0.0011],
        [0.0002, 0.0005],
        [0.0006, 0.0012]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1249],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1210, 0.1290],
        [0.1228, 0.1271],
        [0.1301, 0.1200],
        [0.1286, 0.1214],
        [0.1209, 0.1292],
        [0.1205, 0.1295],
        [0.1263, 0.1236],
        [0.1297, 0.1204]], device='cuda:0')
 Batch: 12 of rare_synonyms classification Duration: 0:00:00.253418
acc:  0.56
Time taken to execute the en SA task with prompt type rare_synonyms, variation 2 and batchsize 16: 0:00:05.207852
path ['42', 'en', 'bloom-big', 'SA', 'rare_synonyms', 'prompt_id_2']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0008]], device='cuda:0') torch.Size([165, 2])
answers_probs just softmax dim 0: tensor([[0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061]], device='cuda:0')
tensor([[0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061],
        [0.0061, 0.0061]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA rare_synonyms 3 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0004, 0.0006],
        [0.0005, 0.0006],
        [0.0005, 0.0006],
        [0.0003, 0.0005],
        [0.0006, 0.0006],
        [0.0004, 0.0008],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0007, 0.0008],
        [0.0003, 0.0004],
        [0.0006, 0.0005],
        [0.0003, 0.0003],
        [0.0008, 0.0013],
        [0.0003, 0.0006],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0622, 0.0626],
        [0.0591, 0.0659],
        [0.0647, 0.0602],
        [0.0644, 0.0604],
        [0.0594, 0.0656],
        [0.0663, 0.0587],
        [0.0573, 0.0680],
        [0.0632, 0.0616],
        [0.0621, 0.0627],
        [0.0668, 0.0583],
        [0.0604, 0.0645],
        [0.0698, 0.0558],
        [0.0665, 0.0586],
        [0.0608, 0.0640],
        [0.0578, 0.0674],
        [0.0592, 0.0658]], device='cuda:0')
 Batch: 0 of rare_synonyms classification Duration: 0:00:00.457227
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0011],
        [0.0004, 0.0004],
        [0.0003, 0.0003],
        [0.0003, 0.0004],
        [0.0007, 0.0009],
        [0.0006, 0.0010],
        [0.0005, 0.0004],
        [0.0005, 0.0006],
        [0.0008, 0.0007],
        [0.0005, 0.0004],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0006, 0.0008],
        [0.0002, 0.0003],
        [0.0002, 0.0002],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0558, 0.0698],
        [0.0668, 0.0584],
        [0.0634, 0.0614],
        [0.0619, 0.0630],
        [0.0625, 0.0624],
        [0.0577, 0.0675],
        [0.0675, 0.0577],
        [0.0632, 0.0616],
        [0.0665, 0.0586],
        [0.0658, 0.0592],
        [0.0628, 0.0620],
        [0.0630, 0.0619],
        [0.0616, 0.0632],
        [0.0590, 0.0660],
        [0.0622, 0.0626],
        [0.0601, 0.0648]], device='cuda:0')
 Batch: 1 of rare_synonyms classification Duration: 0:00:00.495412
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0006],
        [0.0002, 0.0002],
        [0.0003, 0.0003],
        [0.0012, 0.0027],
        [0.0004, 0.0005],
        [0.0011, 0.0011],
        [0.0003, 0.0007],
        [0.0004, 0.0003],
        [0.0004, 0.0005],
        [0.0006, 0.0010],
        [0.0004, 0.0003],
        [0.0005, 0.0005],
        [0.0004, 0.0005],
        [0.0003, 0.0004],
        [0.0001, 0.0002],
        [0.0004, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0609, 0.0638],
        [0.0623, 0.0624],
        [0.0656, 0.0593],
        [0.0537, 0.0724],
        [0.0631, 0.0617],
        [0.0651, 0.0598],
        [0.0556, 0.0699],
        [0.0698, 0.0557],
        [0.0619, 0.0628],
        [0.0591, 0.0658],
        [0.0703, 0.0553],
        [0.0642, 0.0606],
        [0.0595, 0.0653],
        [0.0641, 0.0607],
        [0.0620, 0.0627],
        [0.0628, 0.0619]], device='cuda:0')
 Batch: 2 of rare_synonyms classification Duration: 0:00:00.429630
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0006],
        [0.0006, 0.0008],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0006, 0.0004],
        [0.0003, 0.0003],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0005],
        [0.0003, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0005, 0.0006],
        [0.0003, 0.0005],
        [0.0007, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0628, 0.0620],
        [0.0621, 0.0628],
        [0.0631, 0.0618],
        [0.0633, 0.0616],
        [0.0700, 0.0556],
        [0.0626, 0.0623],
        [0.0549, 0.0710],
        [0.0602, 0.0647],
        [0.0626, 0.0623],
        [0.0638, 0.0611],
        [0.0599, 0.0651],
        [0.0635, 0.0613],
        [0.0659, 0.0591],
        [0.0624, 0.0624],
        [0.0594, 0.0656],
        [0.0635, 0.0613]], device='cuda:0')
 Batch: 3 of rare_synonyms classification Duration: 0:00:00.546496
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0004],
        [0.0003, 0.0004],
        [0.0004, 0.0004],
        [0.0004, 0.0006],
        [0.0005, 0.0006],
        [0.0003, 0.0004],
        [0.0008, 0.0008],
        [0.0001, 0.0002],
        [0.0006, 0.0007],
        [0.0005, 0.0006],
        [0.0006, 0.0006],
        [0.0003, 0.0004],
        [0.0006, 0.0007],
        [0.0004, 0.0005],
        [0.0003, 0.0004],
        [0.0003, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0674, 0.0579],
        [0.0651, 0.0600],
        [0.0648, 0.0602],
        [0.0576, 0.0677],
        [0.0608, 0.0642],
        [0.0608, 0.0642],
        [0.0643, 0.0607],
        [0.0596, 0.0654],
        [0.0637, 0.0613],
        [0.0618, 0.0631],
        [0.0648, 0.0602],
        [0.0640, 0.0609],
        [0.0629, 0.0620],
        [0.0603, 0.0647],
        [0.0603, 0.0647],
        [0.0617, 0.0632]], device='cuda:0')
 Batch: 4 of rare_synonyms classification Duration: 0:00:00.496014
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0003],
        [0.0004, 0.0005],
        [0.0003, 0.0004],
        [0.0005, 0.0007],
        [0.0001, 0.0001],
        [0.0005, 0.0004],
        [0.0002, 0.0002],
        [0.0003, 0.0003],
        [0.0006, 0.0006],
        [0.0007, 0.0012],
        [0.0004, 0.0005],
        [0.0002, 0.0004],
        [0.0004, 0.0005],
        [0.0001, 0.0001],
        [0.0004, 0.0008],
        [0.0005, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0666, 0.0585],
        [0.0622, 0.0626],
        [0.0615, 0.0633],
        [0.0599, 0.0651],
        [0.0648, 0.0601],
        [0.0661, 0.0589],
        [0.0662, 0.0588],
        [0.0649, 0.0600],
        [0.0637, 0.0612],
        [0.0574, 0.0679],
        [0.0639, 0.0609],
        [0.0598, 0.0652],
        [0.0609, 0.0639],
        [0.0639, 0.0610],
        [0.0548, 0.0711],
        [0.0634, 0.0614]], device='cuda:0')
 Batch: 5 of rare_synonyms classification Duration: 0:00:00.496694
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[5.6124e-04, 6.2132e-04],
        [2.7895e-04, 4.5633e-04],
        [2.5010e-04, 2.4438e-04],
        [8.1348e-04, 7.9489e-04],
        [2.7132e-04, 2.9564e-04],
        [2.7800e-04, 3.3283e-04],
        [4.6039e-04, 4.4966e-04],
        [2.4331e-04, 2.2149e-04],
        [2.8324e-04, 3.0160e-04],
        [4.5896e-04, 4.5896e-04],
        [4.1604e-04, 7.0763e-04],
        [3.1519e-04, 5.1165e-04],
        [9.2387e-05, 9.6858e-05],
        [4.6420e-04, 6.2943e-04],
        [3.3593e-04, 6.7329e-04],
        [3.5810e-04, 6.5851e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0641, 0.0607],
        [0.0583, 0.0668],
        [0.0661, 0.0589],
        [0.0661, 0.0589],
        [0.0643, 0.0605],
        [0.0629, 0.0619],
        [0.0661, 0.0588],
        [0.0673, 0.0578],
        [0.0647, 0.0601],
        [0.0657, 0.0592],
        [0.0577, 0.0674],
        [0.0584, 0.0667],
        [0.0650, 0.0599],
        [0.0610, 0.0638],
        [0.0556, 0.0700],
        [0.0567, 0.0686]], device='cuda:0')
 Batch: 6 of rare_synonyms classification Duration: 0:00:00.366545
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[4.7112e-04, 4.9400e-04],
        [2.9969e-04, 2.9516e-04],
        [1.7452e-04, 1.2863e-04],
        [4.7255e-04, 7.0953e-04],
        [3.3879e-04, 5.3692e-04],
        [7.0453e-05, 6.1452e-05],
        [6.2752e-04, 9.3460e-04],
        [4.2176e-04, 7.0620e-04],
        [2.0206e-04, 1.7560e-04],
        [4.0126e-04, 6.2656e-04],
        [8.6355e-04, 1.0262e-03],
        [6.0272e-04, 6.0272e-04],
        [5.6410e-04, 6.9666e-04],
        [3.7766e-04, 5.2404e-04],
        [3.2473e-04, 4.3011e-04],
        [2.9802e-04, 3.0017e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0642, 0.0606],
        [0.0653, 0.0596],
        [0.0701, 0.0555],
        [0.0588, 0.0662],
        [0.0581, 0.0670],
        [0.0673, 0.0579],
        [0.0589, 0.0661],
        [0.0573, 0.0679],
        [0.0673, 0.0578],
        [0.0583, 0.0668],
        [0.0623, 0.0625],
        [0.0650, 0.0599],
        [0.0617, 0.0631],
        [0.0599, 0.0649],
        [0.0606, 0.0642],
        [0.0649, 0.0600]], device='cuda:0')
 Batch: 7 of rare_synonyms classification Duration: 0:00:00.458626
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0007],
        [0.0010, 0.0011],
        [0.0005, 0.0005],
        [0.0004, 0.0003],
        [0.0004, 0.0005],
        [0.0003, 0.0003],
        [0.0001, 0.0001],
        [0.0006, 0.0008],
        [0.0003, 0.0005],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0009, 0.0012],
        [0.0007, 0.0009],
        [0.0003, 0.0003],
        [0.0003, 0.0004],
        [0.0004, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0619, 0.0630],
        [0.0648, 0.0601],
        [0.0638, 0.0610],
        [0.0685, 0.0569],
        [0.0618, 0.0631],
        [0.0670, 0.0581],
        [0.0659, 0.0591],
        [0.0598, 0.0652],
        [0.0575, 0.0678],
        [0.0586, 0.0665],
        [0.0610, 0.0639],
        [0.0600, 0.0649],
        [0.0613, 0.0636],
        [0.0635, 0.0614],
        [0.0627, 0.0621],
        [0.0618, 0.0631]], device='cuda:0')
 Batch: 8 of rare_synonyms classification Duration: 0:00:00.455399
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0005, 0.0008],
        [0.0007, 0.0009],
        [0.0006, 0.0008],
        [0.0001, 0.0002],
        [0.0005, 0.0008],
        [0.0002, 0.0004],
        [0.0004, 0.0006],
        [0.0006, 0.0007],
        [0.0005, 0.0011],
        [0.0003, 0.0004],
        [0.0005, 0.0008],
        [0.0003, 0.0004],
        [0.0006, 0.0013],
        [0.0003, 0.0004],
        [0.0007, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0629, 0.0620],
        [0.0623, 0.0626],
        [0.0646, 0.0604],
        [0.0647, 0.0603],
        [0.0632, 0.0617],
        [0.0613, 0.0637],
        [0.0599, 0.0651],
        [0.0623, 0.0626],
        [0.0663, 0.0588],
        [0.0584, 0.0668],
        [0.0668, 0.0584],
        [0.0610, 0.0639],
        [0.0622, 0.0627],
        [0.0570, 0.0684],
        [0.0641, 0.0609],
        [0.0631, 0.0618]], device='cuda:0')
 Batch: 9 of rare_synonyms classification Duration: 0:00:00.424222
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[6.6423e-04, 7.2908e-04],
        [6.6459e-05, 4.8041e-05],
        [6.6853e-04, 5.4169e-04],
        [5.6362e-04, 5.8603e-04],
        [3.3379e-04, 4.5967e-04],
        [2.3878e-04, 2.9016e-04],
        [6.9904e-04, 8.0442e-04],
        [3.6430e-04, 6.0558e-04],
        [3.8624e-04, 6.0272e-04],
        [9.0504e-04, 9.7084e-04],
        [3.3522e-04, 4.2057e-04],
        [3.9530e-04, 5.1165e-04],
        [5.8508e-04, 8.6498e-04],
        [3.0756e-04, 3.4046e-04],
        [3.0923e-04, 3.6716e-04],
        [2.7776e-04, 3.0255e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0634, 0.0615],
        [0.0703, 0.0554],
        [0.0684, 0.0570],
        [0.0643, 0.0606],
        [0.0599, 0.0650],
        [0.0618, 0.0630],
        [0.0627, 0.0622],
        [0.0573, 0.0680],
        [0.0582, 0.0670],
        [0.0638, 0.0611],
        [0.0613, 0.0635],
        [0.0609, 0.0640],
        [0.0589, 0.0661],
        [0.0633, 0.0616],
        [0.0622, 0.0627],
        [0.0635, 0.0613]], device='cuda:0')
 Batch: 10 of rare_synonyms classification Duration: 0:00:00.414511
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0006],
        [0.0006, 0.0006],
        [0.0004, 0.0005],
        [0.0001, 0.0001],
        [0.0002, 0.0001],
        [0.0002, 0.0003],
        [0.0006, 0.0005],
        [0.0002, 0.0003],
        [0.0004, 0.0005],
        [0.0007, 0.0012],
        [0.0006, 0.0007],
        [0.0004, 0.0005],
        [0.0003, 0.0003],
        [0.0003, 0.0003],
        [0.0005, 0.0008],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0611, 0.0638],
        [0.0635, 0.0614],
        [0.0600, 0.0649],
        [0.0667, 0.0584],
        [0.0695, 0.0561],
        [0.0625, 0.0623],
        [0.0687, 0.0567],
        [0.0608, 0.0640],
        [0.0610, 0.0639],
        [0.0576, 0.0676],
        [0.0630, 0.0619],
        [0.0632, 0.0616],
        [0.0618, 0.0631],
        [0.0636, 0.0612],
        [0.0568, 0.0686],
        [0.0603, 0.0646]], device='cuda:0')
 Batch: 11 of rare_synonyms classification Duration: 0:00:00.597391
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[7.6485e-04, 1.0786e-03],
        [4.3535e-04, 5.0926e-04],
        [3.0994e-04, 4.2701e-04],
        [5.7364e-04, 9.7561e-04],
        [3.6645e-04, 5.3310e-04],
        [7.0143e-04, 7.8869e-04],
        [1.1569e-04, 9.9003e-05],
        [3.2949e-04, 3.5620e-04]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1249],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1211, 0.1287],
        [0.1268, 0.1229],
        [0.1218, 0.1280],
        [0.1158, 0.1346],
        [0.1202, 0.1297],
        [0.1280, 0.1217],
        [0.1371, 0.1137],
        [0.1293, 0.1206]], device='cuda:0')
 Batch: 12 of rare_synonyms classification Duration: 0:00:00.233784
acc:  0.55
Time taken to execute the en SA task with prompt type rare_synonyms, variation 3 and batchsize 16: 0:00:05.892842
path ['42', 'en', 'bloom-big', 'SA', 'rare_synonyms', 'prompt_id_3']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([130, 2])
answers_probs just softmax dim 0: tensor([[0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077]], device='cuda:0')
tensor([[0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077],
        [0.0077, 0.0077]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA rare_synonyms 4 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0010, 0.0016],
        [0.0009, 0.0019],
        [0.0006, 0.0009],
        [0.0007, 0.0015],
        [0.0007, 0.0012],
        [0.0010, 0.0016],
        [0.0006, 0.0009],
        [0.0005, 0.0011],
        [0.0010, 0.0016],
        [0.0005, 0.0009],
        [0.0008, 0.0015],
        [0.0009, 0.0016],
        [0.0008, 0.0013],
        [0.0009, 0.0021],
        [0.0009, 0.0016]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0657, 0.0594],
        [0.0641, 0.0609],
        [0.0602, 0.0648],
        [0.0637, 0.0612],
        [0.0593, 0.0658],
        [0.0639, 0.0611],
        [0.0640, 0.0610],
        [0.0649, 0.0601],
        [0.0597, 0.0654],
        [0.0641, 0.0609],
        [0.0615, 0.0635],
        [0.0614, 0.0636],
        [0.0628, 0.0621],
        [0.0627, 0.0622],
        [0.0593, 0.0658],
        [0.0627, 0.0622]], device='cuda:0')
 Batch: 0 of rare_synonyms classification Duration: 0:00:00.580883
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0012],
        [0.0010, 0.0014],
        [0.0007, 0.0012],
        [0.0009, 0.0016],
        [0.0008, 0.0011],
        [0.0003, 0.0005],
        [0.0011, 0.0018],
        [0.0009, 0.0015],
        [0.0008, 0.0013],
        [0.0006, 0.0011],
        [0.0006, 0.0014],
        [0.0005, 0.0006],
        [0.0004, 0.0008],
        [0.0007, 0.0013],
        [0.0012, 0.0023],
        [0.0008, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0592, 0.0659],
        [0.0652, 0.0599],
        [0.0627, 0.0623],
        [0.0616, 0.0634],
        [0.0654, 0.0596],
        [0.0627, 0.0623],
        [0.0634, 0.0616],
        [0.0627, 0.0623],
        [0.0631, 0.0618],
        [0.0623, 0.0626],
        [0.0583, 0.0670],
        [0.0663, 0.0589],
        [0.0618, 0.0632],
        [0.0616, 0.0634],
        [0.0610, 0.0640],
        [0.0628, 0.0621]], device='cuda:0')
 Batch: 1 of rare_synonyms classification Duration: 0:00:00.436117
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0016],
        [0.0007, 0.0013],
        [0.0009, 0.0015],
        [0.0009, 0.0017],
        [0.0004, 0.0006],
        [0.0006, 0.0012],
        [0.0009, 0.0014],
        [0.0007, 0.0015],
        [0.0007, 0.0011],
        [0.0007, 0.0015],
        [0.0006, 0.0010],
        [0.0010, 0.0018],
        [0.0009, 0.0015],
        [0.0008, 0.0018],
        [0.0005, 0.0015],
        [0.0007, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0624],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0593, 0.0657],
        [0.0630, 0.0619],
        [0.0640, 0.0609],
        [0.0618, 0.0631],
        [0.0658, 0.0592],
        [0.0615, 0.0635],
        [0.0649, 0.0601],
        [0.0615, 0.0635],
        [0.0643, 0.0607],
        [0.0607, 0.0642],
        [0.0650, 0.0600],
        [0.0625, 0.0624],
        [0.0651, 0.0599],
        [0.0594, 0.0656],
        [0.0577, 0.0676],
        [0.0634, 0.0615]], device='cuda:0')
 Batch: 2 of rare_synonyms classification Duration: 0:00:00.251526
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0014],
        [0.0008, 0.0011],
        [0.0005, 0.0008],
        [0.0008, 0.0020],
        [0.0006, 0.0013],
        [0.0007, 0.0013],
        [0.0009, 0.0012],
        [0.0006, 0.0007],
        [0.0006, 0.0011],
        [0.0008, 0.0012],
        [0.0008, 0.0013],
        [0.0008, 0.0018],
        [0.0019, 0.0037],
        [0.0018, 0.0033],
        [0.0008, 0.0015],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0624],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0626, 0.0626],
        [0.0626, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0624]], device='cuda:0')
tensor([[0.0603, 0.0647],
        [0.0670, 0.0582],
        [0.0625, 0.0623],
        [0.0579, 0.0674],
        [0.0606, 0.0643],
        [0.0633, 0.0616],
        [0.0662, 0.0589],
        [0.0676, 0.0577],
        [0.0615, 0.0634],
        [0.0645, 0.0604],
        [0.0629, 0.0620],
        [0.0595, 0.0656],
        [0.0617, 0.0632],
        [0.0622, 0.0627],
        [0.0607, 0.0642],
        [0.0614, 0.0635]], device='cuda:0')
 Batch: 3 of rare_synonyms classification Duration: 0:00:00.331110
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0004, 0.0005],
        [0.0005, 0.0011],
        [0.0016, 0.0025],
        [0.0006, 0.0011],
        [0.0011, 0.0013],
        [0.0007, 0.0014],
        [0.0012, 0.0024],
        [0.0009, 0.0016],
        [0.0005, 0.0009],
        [0.0003, 0.0005],
        [0.0008, 0.0011],
        [0.0006, 0.0013],
        [0.0006, 0.0010],
        [0.0012, 0.0018],
        [0.0007, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0626, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0607, 0.0642],
        [0.0644, 0.0606],
        [0.0584, 0.0668],
        [0.0631, 0.0619],
        [0.0607, 0.0642],
        [0.0676, 0.0577],
        [0.0605, 0.0645],
        [0.0602, 0.0648],
        [0.0612, 0.0637],
        [0.0627, 0.0622],
        [0.0627, 0.0622],
        [0.0660, 0.0591],
        [0.0586, 0.0666],
        [0.0642, 0.0607],
        [0.0639, 0.0610],
        [0.0652, 0.0598]], device='cuda:0')
 Batch: 4 of rare_synonyms classification Duration: 0:00:00.450672
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0008, 0.0011],
        [0.0006, 0.0013],
        [0.0010, 0.0014],
        [0.0009, 0.0012],
        [0.0012, 0.0020],
        [0.0008, 0.0016],
        [0.0007, 0.0014],
        [0.0008, 0.0013],
        [0.0010, 0.0017],
        [0.0008, 0.0012],
        [0.0007, 0.0011],
        [0.0007, 0.0011],
        [0.0009, 0.0020],
        [0.0004, 0.0006],
        [0.0007, 0.0013],
        [0.0007, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0659, 0.0592],
        [0.0592, 0.0659],
        [0.0645, 0.0605],
        [0.0643, 0.0607],
        [0.0625, 0.0624],
        [0.0606, 0.0644],
        [0.0603, 0.0647],
        [0.0627, 0.0622],
        [0.0620, 0.0629],
        [0.0627, 0.0622],
        [0.0635, 0.0614],
        [0.0621, 0.0628],
        [0.0584, 0.0668],
        [0.0640, 0.0609],
        [0.0611, 0.0638],
        [0.0660, 0.0591]], device='cuda:0')
 Batch: 5 of rare_synonyms classification Duration: 0:00:00.492708
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0011, 0.0014],
        [0.0008, 0.0011],
        [0.0006, 0.0008],
        [0.0011, 0.0016],
        [0.0007, 0.0015],
        [0.0008, 0.0013],
        [0.0005, 0.0009],
        [0.0004, 0.0006],
        [0.0007, 0.0010],
        [0.0007, 0.0011],
        [0.0012, 0.0021],
        [0.0005, 0.0009],
        [0.0007, 0.0011],
        [0.0006, 0.0013],
        [0.0007, 0.0014],
        [0.0009, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0654, 0.0596],
        [0.0641, 0.0609],
        [0.0662, 0.0589],
        [0.0634, 0.0616],
        [0.0585, 0.0667],
        [0.0621, 0.0628],
        [0.0614, 0.0635],
        [0.0620, 0.0630],
        [0.0644, 0.0605],
        [0.0622, 0.0627],
        [0.0615, 0.0634],
        [0.0612, 0.0638],
        [0.0635, 0.0615],
        [0.0594, 0.0657],
        [0.0603, 0.0647],
        [0.0645, 0.0605]], device='cuda:0')
 Batch: 6 of rare_synonyms classification Duration: 0:00:00.319117
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0011],
        [0.0008, 0.0013],
        [0.0006, 0.0009],
        [0.0005, 0.0012],
        [0.0008, 0.0014],
        [0.0007, 0.0013],
        [0.0006, 0.0012],
        [0.0008, 0.0013],
        [0.0007, 0.0010],
        [0.0009, 0.0019],
        [0.0011, 0.0016],
        [0.0007, 0.0011],
        [0.0007, 0.0010],
        [0.0010, 0.0030],
        [0.0008, 0.0016],
        [0.0007, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0622, 0.0626],
        [0.0635, 0.0614],
        [0.0646, 0.0604],
        [0.0593, 0.0657],
        [0.0636, 0.0613],
        [0.0618, 0.0631],
        [0.0608, 0.0641],
        [0.0634, 0.0615],
        [0.0657, 0.0594],
        [0.0602, 0.0648],
        [0.0656, 0.0595],
        [0.0657, 0.0594],
        [0.0657, 0.0594],
        [0.0556, 0.0701],
        [0.0604, 0.0645],
        [0.0619, 0.0630]], device='cuda:0')
 Batch: 7 of rare_synonyms classification Duration: 0:00:00.434254
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0012],
        [0.0008, 0.0025],
        [0.0008, 0.0016],
        [0.0008, 0.0014],
        [0.0012, 0.0022],
        [0.0007, 0.0014],
        [0.0006, 0.0010],
        [0.0014, 0.0024],
        [0.0010, 0.0015],
        [0.0003, 0.0004],
        [0.0010, 0.0017],
        [0.0010, 0.0019],
        [0.0006, 0.0011],
        [0.0005, 0.0009],
        [0.0005, 0.0007],
        [0.0006, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0624],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0620, 0.0629],
        [0.0556, 0.0701],
        [0.0612, 0.0637],
        [0.0631, 0.0618],
        [0.0618, 0.0631],
        [0.0604, 0.0646],
        [0.0631, 0.0618],
        [0.0630, 0.0619],
        [0.0642, 0.0608],
        [0.0664, 0.0588],
        [0.0635, 0.0615],
        [0.0622, 0.0627],
        [0.0618, 0.0631],
        [0.0630, 0.0619],
        [0.0653, 0.0598],
        [0.0635, 0.0615]], device='cuda:0')
 Batch: 8 of rare_synonyms classification Duration: 0:00:00.365542
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0010, 0.0019],
        [0.0004, 0.0007],
        [0.0006, 0.0009],
        [0.0011, 0.0018],
        [0.0012, 0.0021],
        [0.0008, 0.0016],
        [0.0011, 0.0017],
        [0.0008, 0.0015],
        [0.0009, 0.0016],
        [0.0007, 0.0011],
        [0.0006, 0.0013],
        [0.0007, 0.0012],
        [0.0010, 0.0015],
        [0.0007, 0.0013],
        [0.0009, 0.0014],
        [0.0007, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0614, 0.0636],
        [0.0634, 0.0616],
        [0.0643, 0.0607],
        [0.0632, 0.0617],
        [0.0622, 0.0628],
        [0.0602, 0.0648],
        [0.0630, 0.0620],
        [0.0602, 0.0648],
        [0.0620, 0.0630],
        [0.0631, 0.0619],
        [0.0597, 0.0654],
        [0.0638, 0.0612],
        [0.0643, 0.0607],
        [0.0619, 0.0631],
        [0.0648, 0.0603],
        [0.0624, 0.0625]], device='cuda:0')
 Batch: 9 of rare_synonyms classification Duration: 0:00:00.484982
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0009, 0.0013],
        [0.0014, 0.0024],
        [0.0010, 0.0017],
        [0.0010, 0.0017],
        [0.0005, 0.0006],
        [0.0009, 0.0021],
        [0.0008, 0.0018],
        [0.0008, 0.0012],
        [0.0007, 0.0014],
        [0.0006, 0.0009],
        [0.0006, 0.0009],
        [0.0007, 0.0014],
        [0.0009, 0.0015],
        [0.0009, 0.0011],
        [0.0010, 0.0014],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0644, 0.0605],
        [0.0625, 0.0624],
        [0.0619, 0.0630],
        [0.0631, 0.0618],
        [0.0675, 0.0578],
        [0.0585, 0.0667],
        [0.0587, 0.0664],
        [0.0635, 0.0614],
        [0.0589, 0.0662],
        [0.0624, 0.0625],
        [0.0648, 0.0602],
        [0.0594, 0.0657],
        [0.0630, 0.0619],
        [0.0660, 0.0590],
        [0.0645, 0.0604],
        [0.0609, 0.0641]], device='cuda:0')
 Batch: 10 of rare_synonyms classification Duration: 0:00:00.337685
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0013],
        [0.0005, 0.0008],
        [0.0008, 0.0017],
        [0.0005, 0.0006],
        [0.0014, 0.0018],
        [0.0007, 0.0010],
        [0.0007, 0.0012],
        [0.0006, 0.0009],
        [0.0007, 0.0012],
        [0.0007, 0.0014],
        [0.0012, 0.0019],
        [0.0008, 0.0015],
        [0.0005, 0.0008],
        [0.0009, 0.0013],
        [0.0013, 0.0018],
        [0.0011, 0.0017]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0607, 0.0643],
        [0.0642, 0.0608],
        [0.0593, 0.0658],
        [0.0651, 0.0599],
        [0.0654, 0.0597],
        [0.0645, 0.0605],
        [0.0606, 0.0644],
        [0.0630, 0.0620],
        [0.0616, 0.0634],
        [0.0592, 0.0659],
        [0.0618, 0.0631],
        [0.0612, 0.0637],
        [0.0618, 0.0631],
        [0.0643, 0.0607],
        [0.0650, 0.0600],
        [0.0624, 0.0626]], device='cuda:0')
 Batch: 11 of rare_synonyms classification Duration: 0:00:00.454928
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0012, 0.0020],
        [0.0015, 0.0027],
        [0.0007, 0.0016],
        [0.0002, 0.0004],
        [0.0010, 0.0018],
        [0.0005, 0.0012],
        [0.0011, 0.0018],
        [0.0007, 0.0012]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1251],
        [0.1251, 0.1251],
        [0.1250, 0.1250],
        [0.1249, 0.1248],
        [0.1250, 0.1250],
        [0.1250, 0.1249],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1274, 0.1225],
        [0.1261, 0.1238],
        [0.1200, 0.1302],
        [0.1232, 0.1267],
        [0.1266, 0.1234],
        [0.1202, 0.1299],
        [0.1293, 0.1207],
        [0.1272, 0.1227]], device='cuda:0')
 Batch: 12 of rare_synonyms classification Duration: 0:00:00.218854
acc:  0.46
Time taken to execute the en SA task with prompt type rare_synonyms, variation 4 and batchsize 16: 0:00:05.179471
path ['42', 'en', 'bloom-big', 'SA', 'rare_synonyms', 'prompt_id_4']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([124, 2])
answers_probs just softmax dim 0: tensor([[0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081]], device='cuda:0')
tensor([[0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081],
        [0.0081, 0.0081]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA rare_synonyms 5 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0011],
        [0.0006, 0.0009],
        [0.0008, 0.0025],
        [0.0008, 0.0012],
        [0.0006, 0.0009],
        [0.0005, 0.0009],
        [0.0009, 0.0015],
        [0.0006, 0.0012],
        [0.0007, 0.0015],
        [0.0005, 0.0009],
        [0.0006, 0.0010],
        [0.0009, 0.0013],
        [0.0007, 0.0011],
        [0.0006, 0.0009],
        [0.0005, 0.0009],
        [0.0006, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0627, 0.0622],
        [0.0658, 0.0592],
        [0.0555, 0.0702],
        [0.0643, 0.0606],
        [0.0636, 0.0613],
        [0.0630, 0.0618],
        [0.0634, 0.0615],
        [0.0600, 0.0650],
        [0.0596, 0.0655],
        [0.0603, 0.0647],
        [0.0630, 0.0618],
        [0.0655, 0.0595],
        [0.0651, 0.0599],
        [0.0656, 0.0595],
        [0.0629, 0.0620],
        [0.0597, 0.0653]], device='cuda:0')
 Batch: 0 of rare_synonyms classification Duration: 0:00:00.372513
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0007, 0.0013],
        [0.0006, 0.0011],
        [0.0006, 0.0010],
        [0.0007, 0.0012],
        [0.0005, 0.0008],
        [0.0008, 0.0015],
        [0.0006, 0.0012],
        [0.0006, 0.0013],
        [0.0006, 0.0008],
        [0.0008, 0.0012],
        [0.0007, 0.0015],
        [0.0006, 0.0007],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0640, 0.0609],
        [0.0601, 0.0650],
        [0.0606, 0.0644],
        [0.0617, 0.0632],
        [0.0611, 0.0638],
        [0.0623, 0.0626],
        [0.0630, 0.0619],
        [0.0641, 0.0608],
        [0.0609, 0.0641],
        [0.0599, 0.0651],
        [0.0605, 0.0645],
        [0.0665, 0.0587],
        [0.0655, 0.0596],
        [0.0589, 0.0663],
        [0.0666, 0.0586],
        [0.0644, 0.0606]], device='cuda:0')
 Batch: 1 of rare_synonyms classification Duration: 0:00:00.574576
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0008],
        [0.0008, 0.0012],
        [0.0005, 0.0010],
        [0.0004, 0.0005],
        [0.0004, 0.0006],
        [0.0004, 0.0010],
        [0.0007, 0.0011],
        [0.0006, 0.0009],
        [0.0006, 0.0008],
        [0.0005, 0.0016],
        [0.0007, 0.0011],
        [0.0008, 0.0013],
        [0.0008, 0.0011],
        [0.0005, 0.0007],
        [0.0004, 0.0007],
        [0.0005, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0657, 0.0592],
        [0.0641, 0.0607],
        [0.0590, 0.0660],
        [0.0685, 0.0569],
        [0.0652, 0.0597],
        [0.0568, 0.0686],
        [0.0639, 0.0609],
        [0.0639, 0.0609],
        [0.0646, 0.0602],
        [0.0537, 0.0725],
        [0.0612, 0.0636],
        [0.0626, 0.0622],
        [0.0649, 0.0600],
        [0.0631, 0.0617],
        [0.0638, 0.0610],
        [0.0591, 0.0659]], device='cuda:0')
 Batch: 2 of rare_synonyms classification Duration: 0:00:00.340617
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0005, 0.0007],
        [0.0006, 0.0010],
        [0.0011, 0.0015],
        [0.0008, 0.0012],
        [0.0007, 0.0010],
        [0.0007, 0.0010],
        [0.0007, 0.0014],
        [0.0006, 0.0007],
        [0.0005, 0.0009],
        [0.0006, 0.0009],
        [0.0005, 0.0009],
        [0.0004, 0.0007],
        [0.0006, 0.0009],
        [0.0006, 0.0011],
        [0.0013, 0.0019]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626]], device='cuda:0')
tensor([[0.0632, 0.0618],
        [0.0648, 0.0603],
        [0.0605, 0.0645],
        [0.0641, 0.0608],
        [0.0629, 0.0620],
        [0.0634, 0.0615],
        [0.0636, 0.0613],
        [0.0595, 0.0656],
        [0.0659, 0.0592],
        [0.0609, 0.0641],
        [0.0639, 0.0611],
        [0.0592, 0.0660],
        [0.0611, 0.0639],
        [0.0639, 0.0611],
        [0.0598, 0.0653],
        [0.0633, 0.0616]], device='cuda:0')
 Batch: 3 of rare_synonyms classification Duration: 0:00:00.341600
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0008, 0.0013],
        [0.0008, 0.0015],
        [0.0004, 0.0008],
        [0.0004, 0.0009],
        [0.0003, 0.0009],
        [0.0009, 0.0014],
        [0.0008, 0.0012],
        [0.0004, 0.0007],
        [0.0005, 0.0008],
        [0.0007, 0.0011],
        [0.0005, 0.0010],
        [0.0004, 0.0007],
        [0.0004, 0.0004],
        [0.0003, 0.0005],
        [0.0006, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0611, 0.0637],
        [0.0639, 0.0610],
        [0.0615, 0.0634],
        [0.0610, 0.0638],
        [0.0586, 0.0664],
        [0.0547, 0.0712],
        [0.0636, 0.0612],
        [0.0654, 0.0595],
        [0.0616, 0.0632],
        [0.0637, 0.0611],
        [0.0630, 0.0618],
        [0.0605, 0.0644],
        [0.0620, 0.0628],
        [0.0725, 0.0537],
        [0.0653, 0.0596],
        [0.0615, 0.0634]], device='cuda:0')
 Batch: 4 of rare_synonyms classification Duration: 0:00:00.427099
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0010, 0.0015],
        [0.0006, 0.0014],
        [0.0005, 0.0008],
        [0.0007, 0.0010],
        [0.0006, 0.0012],
        [0.0003, 0.0006],
        [0.0013, 0.0021],
        [0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0008, 0.0013],
        [0.0005, 0.0012],
        [0.0004, 0.0010],
        [0.0004, 0.0009],
        [0.0008, 0.0011],
        [0.0005, 0.0007],
        [0.0004, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0642, 0.0608],
        [0.0590, 0.0660],
        [0.0633, 0.0616],
        [0.0640, 0.0609],
        [0.0613, 0.0636],
        [0.0620, 0.0629],
        [0.0641, 0.0608],
        [0.0643, 0.0607],
        [0.0599, 0.0650],
        [0.0633, 0.0616],
        [0.0568, 0.0686],
        [0.0596, 0.0654],
        [0.0600, 0.0649],
        [0.0656, 0.0594],
        [0.0660, 0.0591],
        [0.0664, 0.0588]], device='cuda:0')
 Batch: 5 of rare_synonyms classification Duration: 0:00:00.434016
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0012],
        [0.0006, 0.0009],
        [0.0006, 0.0008],
        [0.0008, 0.0014],
        [0.0005, 0.0009],
        [0.0007, 0.0015],
        [0.0009, 0.0014],
        [0.0007, 0.0010],
        [0.0005, 0.0010],
        [0.0005, 0.0007],
        [0.0008, 0.0015],
        [0.0007, 0.0010],
        [0.0006, 0.0010],
        [0.0008, 0.0012],
        [0.0006, 0.0010],
        [0.0007, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0598, 0.0652],
        [0.0641, 0.0609],
        [0.0647, 0.0603],
        [0.0613, 0.0636],
        [0.0619, 0.0630],
        [0.0593, 0.0658],
        [0.0630, 0.0619],
        [0.0647, 0.0603],
        [0.0594, 0.0656],
        [0.0658, 0.0593],
        [0.0609, 0.0641],
        [0.0640, 0.0610],
        [0.0636, 0.0613],
        [0.0642, 0.0607],
        [0.0629, 0.0620],
        [0.0600, 0.0651]], device='cuda:0')
 Batch: 6 of rare_synonyms classification Duration: 0:00:00.457529
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0010, 0.0017],
        [0.0004, 0.0007],
        [0.0005, 0.0007],
        [0.0006, 0.0010],
        [0.0006, 0.0009],
        [0.0006, 0.0012],
        [0.0005, 0.0008],
        [0.0007, 0.0011],
        [0.0008, 0.0012],
        [0.0007, 0.0014],
        [0.0004, 0.0012],
        [0.0008, 0.0012],
        [0.0011, 0.0017],
        [0.0006, 0.0009],
        [0.0003, 0.0004],
        [0.0006, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0621, 0.0628],
        [0.0624, 0.0625],
        [0.0630, 0.0619],
        [0.0628, 0.0621],
        [0.0639, 0.0610],
        [0.0587, 0.0665],
        [0.0624, 0.0625],
        [0.0629, 0.0620],
        [0.0642, 0.0608],
        [0.0594, 0.0657],
        [0.0553, 0.0705],
        [0.0633, 0.0616],
        [0.0636, 0.0613],
        [0.0650, 0.0600],
        [0.0655, 0.0595],
        [0.0655, 0.0595]], device='cuda:0')
 Batch: 7 of rare_synonyms classification Duration: 0:00:00.450343
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0008],
        [0.0007, 0.0011],
        [0.0008, 0.0011],
        [0.0004, 0.0008],
        [0.0006, 0.0010],
        [0.0006, 0.0008],
        [0.0005, 0.0010],
        [0.0007, 0.0013],
        [0.0003, 0.0005],
        [0.0011, 0.0017],
        [0.0007, 0.0014],
        [0.0004, 0.0007],
        [0.0005, 0.0009],
        [0.0007, 0.0015],
        [0.0008, 0.0017],
        [0.0006, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0648, 0.0602],
        [0.0619, 0.0630],
        [0.0653, 0.0598],
        [0.0616, 0.0633],
        [0.0618, 0.0631],
        [0.0668, 0.0584],
        [0.0599, 0.0651],
        [0.0614, 0.0635],
        [0.0642, 0.0608],
        [0.0634, 0.0615],
        [0.0602, 0.0648],
        [0.0618, 0.0631],
        [0.0611, 0.0639],
        [0.0597, 0.0653],
        [0.0591, 0.0660],
        [0.0669, 0.0583]], device='cuda:0')
 Batch: 8 of rare_synonyms classification Duration: 0:00:00.368424
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0009, 0.0015],
        [0.0006, 0.0008],
        [0.0006, 0.0011],
        [0.0006, 0.0014],
        [0.0008, 0.0011],
        [0.0003, 0.0006],
        [0.0005, 0.0009],
        [0.0003, 0.0004],
        [0.0006, 0.0008],
        [0.0007, 0.0012],
        [0.0008, 0.0009],
        [0.0005, 0.0010],
        [0.0009, 0.0013],
        [0.0008, 0.0019],
        [0.0006, 0.0008],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0621, 0.0627],
        [0.0656, 0.0594],
        [0.0610, 0.0639],
        [0.0582, 0.0670],
        [0.0655, 0.0595],
        [0.0611, 0.0638],
        [0.0597, 0.0653],
        [0.0652, 0.0597],
        [0.0659, 0.0592],
        [0.0612, 0.0637],
        [0.0675, 0.0577],
        [0.0593, 0.0657],
        [0.0641, 0.0608],
        [0.0568, 0.0686],
        [0.0650, 0.0600],
        [0.0618, 0.0631]], device='cuda:0')
 Batch: 9 of rare_synonyms classification Duration: 0:00:00.402202
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0011],
        [0.0005, 0.0010],
        [0.0009, 0.0018],
        [0.0008, 0.0012],
        [0.0004, 0.0010],
        [0.0004, 0.0007],
        [0.0008, 0.0012],
        [0.0011, 0.0019],
        [0.0004, 0.0006],
        [0.0009, 0.0014],
        [0.0005, 0.0009],
        [0.0006, 0.0012],
        [0.0010, 0.0017],
        [0.0007, 0.0010],
        [0.0006, 0.0011],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0632, 0.0617],
        [0.0608, 0.0642],
        [0.0603, 0.0647],
        [0.0648, 0.0602],
        [0.0584, 0.0669],
        [0.0608, 0.0642],
        [0.0649, 0.0601],
        [0.0620, 0.0630],
        [0.0663, 0.0589],
        [0.0647, 0.0604],
        [0.0612, 0.0637],
        [0.0619, 0.0631],
        [0.0621, 0.0628],
        [0.0647, 0.0603],
        [0.0621, 0.0628],
        [0.0620, 0.0630]], device='cuda:0')
 Batch: 10 of rare_synonyms classification Duration: 0:00:00.325158
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0010],
        [0.0007, 0.0015],
        [0.0005, 0.0008],
        [0.0006, 0.0012],
        [0.0005, 0.0007],
        [0.0007, 0.0009],
        [0.0009, 0.0014],
        [0.0005, 0.0010],
        [0.0008, 0.0013],
        [0.0009, 0.0012],
        [0.0005, 0.0011],
        [0.0005, 0.0009],
        [0.0010, 0.0012],
        [0.0003, 0.0004],
        [0.0006, 0.0009],
        [0.0009, 0.0019]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0603, 0.0646],
        [0.0584, 0.0667],
        [0.0637, 0.0612],
        [0.0596, 0.0654],
        [0.0647, 0.0603],
        [0.0662, 0.0589],
        [0.0632, 0.0616],
        [0.0619, 0.0630],
        [0.0619, 0.0630],
        [0.0672, 0.0580],
        [0.0583, 0.0668],
        [0.0616, 0.0632],
        [0.0677, 0.0576],
        [0.0635, 0.0614],
        [0.0631, 0.0618],
        [0.0587, 0.0664]], device='cuda:0')
 Batch: 11 of rare_synonyms classification Duration: 0:00:00.484517
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0006, 0.0010],
        [0.0005, 0.0007],
        [0.0008, 0.0013],
        [0.0005, 0.0009],
        [0.0006, 0.0012],
        [0.0005, 0.0010],
        [0.0007, 0.0015],
        [0.0007, 0.0010]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1284, 0.1216],
        [0.1286, 0.1214],
        [0.1258, 0.1241],
        [0.1235, 0.1264],
        [0.1235, 0.1264],
        [0.1213, 0.1287],
        [0.1189, 0.1313],
        [0.1301, 0.1200]], device='cuda:0')
 Batch: 12 of rare_synonyms classification Duration: 0:00:00.157891
acc:  0.375
Time taken to execute the en SA task with prompt type rare_synonyms, variation 5 and batchsize 16: 0:00:05.158008
path ['42', 'en', 'bloom-big', 'SA', 'rare_synonyms', 'prompt_id_5']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([112, 2])
answers_probs just softmax dim 0: tensor([[0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089]], device='cuda:0')
tensor([[0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089],
        [0.0089, 0.0089]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA rare_synonyms 6 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0010],
        [0.0007, 0.0012],
        [0.0003, 0.0005],
        [0.0005, 0.0007],
        [0.0006, 0.0009],
        [0.0004, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0006, 0.0011],
        [0.0005, 0.0008],
        [0.0010, 0.0020],
        [0.0003, 0.0005],
        [0.0009, 0.0014],
        [0.0003, 0.0005],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0618, 0.0631],
        [0.0602, 0.0648],
        [0.0624, 0.0625],
        [0.0655, 0.0596],
        [0.0639, 0.0610],
        [0.0653, 0.0598],
        [0.0626, 0.0623],
        [0.0650, 0.0600],
        [0.0600, 0.0651],
        [0.0607, 0.0643],
        [0.0637, 0.0613],
        [0.0602, 0.0648],
        [0.0614, 0.0636],
        [0.0629, 0.0621],
        [0.0615, 0.0635],
        [0.0628, 0.0622]], device='cuda:0')
 Batch: 0 of rare_synonyms classification Duration: 0:00:00.414813
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0005],
        [0.0005, 0.0004],
        [0.0008, 0.0015],
        [0.0005, 0.0010],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0004, 0.0009],
        [0.0005, 0.0007],
        [0.0003, 0.0006],
        [0.0006, 0.0008],
        [0.0003, 0.0004],
        [0.0004, 0.0004],
        [0.0008, 0.0019],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0646, 0.0602],
        [0.0719, 0.0541],
        [0.0596, 0.0653],
        [0.0570, 0.0683],
        [0.0629, 0.0618],
        [0.0590, 0.0659],
        [0.0647, 0.0601],
        [0.0626, 0.0622],
        [0.0586, 0.0663],
        [0.0621, 0.0626],
        [0.0577, 0.0674],
        [0.0632, 0.0616],
        [0.0656, 0.0593],
        [0.0677, 0.0575],
        [0.0568, 0.0685],
        [0.0659, 0.0590]], device='cuda:0')
 Batch: 1 of rare_synonyms classification Duration: 0:00:00.333128
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0015],
        [0.0003, 0.0005],
        [0.0007, 0.0010],
        [0.0004, 0.0006],
        [0.0005, 0.0007],
        [0.0004, 0.0007],
        [0.0006, 0.0008],
        [0.0007, 0.0009],
        [0.0006, 0.0008],
        [0.0002, 0.0005],
        [0.0004, 0.0006],
        [0.0003, 0.0004],
        [0.0007, 0.0010],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0576, 0.0677],
        [0.0621, 0.0627],
        [0.0641, 0.0608],
        [0.0628, 0.0620],
        [0.0660, 0.0590],
        [0.0609, 0.0640],
        [0.0651, 0.0598],
        [0.0669, 0.0583],
        [0.0644, 0.0605],
        [0.0592, 0.0658],
        [0.0629, 0.0619],
        [0.0650, 0.0600],
        [0.0647, 0.0602],
        [0.0632, 0.0617],
        [0.0553, 0.0705],
        [0.0597, 0.0652]], device='cuda:0')
 Batch: 2 of rare_synonyms classification Duration: 0:00:00.289371
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0006, 0.0009],
        [0.0007, 0.0017],
        [0.0007, 0.0009],
        [0.0004, 0.0010],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0005, 0.0006],
        [0.0006, 0.0011],
        [0.0003, 0.0002],
        [0.0002, 0.0005],
        [0.0005, 0.0008],
        [0.0006, 0.0008],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0629, 0.0618],
        [0.0620, 0.0627],
        [0.0572, 0.0680],
        [0.0653, 0.0595],
        [0.0573, 0.0678],
        [0.0615, 0.0632],
        [0.0612, 0.0635],
        [0.0591, 0.0657],
        [0.0630, 0.0617],
        [0.0650, 0.0598],
        [0.0611, 0.0637],
        [0.0767, 0.0507],
        [0.0571, 0.0681],
        [0.0620, 0.0627],
        [0.0638, 0.0610],
        [0.0649, 0.0599]], device='cuda:0')
 Batch: 3 of rare_synonyms classification Duration: 0:00:00.367272
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0004, 0.0006],
        [0.0008, 0.0013],
        [0.0003, 0.0004],
        [0.0004, 0.0005],
        [0.0004, 0.0004],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0006],
        [0.0005, 0.0006],
        [0.0006, 0.0014],
        [0.0013, 0.0024],
        [0.0006, 0.0008],
        [0.0008, 0.0025],
        [0.0004, 0.0006],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0626, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0595, 0.0655],
        [0.0608, 0.0641],
        [0.0613, 0.0635],
        [0.0653, 0.0596],
        [0.0649, 0.0600],
        [0.0693, 0.0562],
        [0.0656, 0.0593],
        [0.0637, 0.0611],
        [0.0621, 0.0627],
        [0.0661, 0.0589],
        [0.0568, 0.0685],
        [0.0604, 0.0644],
        [0.0640, 0.0608],
        [0.0541, 0.0720],
        [0.0633, 0.0615],
        [0.0629, 0.0619]], device='cuda:0')
 Batch: 4 of rare_synonyms classification Duration: 0:00:00.568011
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0011],
        [0.0006, 0.0008],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0003, 0.0004],
        [0.0005, 0.0016],
        [0.0003, 0.0004],
        [0.0004, 0.0006],
        [0.0004, 0.0005],
        [0.0007, 0.0019],
        [0.0010, 0.0018],
        [0.0004, 0.0006],
        [0.0006, 0.0014],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0005, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0638, 0.0610],
        [0.0660, 0.0590],
        [0.0638, 0.0610],
        [0.0605, 0.0643],
        [0.0692, 0.0563],
        [0.0548, 0.0710],
        [0.0636, 0.0612],
        [0.0652, 0.0597],
        [0.0648, 0.0601],
        [0.0560, 0.0695],
        [0.0612, 0.0636],
        [0.0629, 0.0619],
        [0.0579, 0.0673],
        [0.0616, 0.0632],
        [0.0625, 0.0623],
        [0.0664, 0.0586]], device='cuda:0')
 Batch: 5 of rare_synonyms classification Duration: 0:00:00.238203
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0008, 0.0009],
        [0.0003, 0.0004],
        [0.0011, 0.0023],
        [0.0005, 0.0006],
        [0.0004, 0.0006],
        [0.0006, 0.0016],
        [0.0005, 0.0007],
        [0.0006, 0.0006],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0004, 0.0005],
        [0.0005, 0.0008],
        [0.0003, 0.0004],
        [0.0006, 0.0007],
        [0.0011, 0.0015],
        [0.0005, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0668, 0.0583],
        [0.0623, 0.0625],
        [0.0575, 0.0677],
        [0.0642, 0.0607],
        [0.0612, 0.0636],
        [0.0546, 0.0713],
        [0.0630, 0.0618],
        [0.0680, 0.0573],
        [0.0637, 0.0612],
        [0.0585, 0.0665],
        [0.0629, 0.0620],
        [0.0613, 0.0635],
        [0.0616, 0.0633],
        [0.0664, 0.0586],
        [0.0634, 0.0614],
        [0.0646, 0.0603]], device='cuda:0')
 Batch: 6 of rare_synonyms classification Duration: 0:00:00.451094
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0005, 0.0005],
        [0.0003, 0.0004],
        [0.0004, 0.0006],
        [0.0005, 0.0009],
        [0.0008, 0.0014],
        [0.0005, 0.0008],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0002, 0.0004],
        [0.0005, 0.0012],
        [0.0004, 0.0005],
        [0.0005, 0.0008],
        [0.0007, 0.0012],
        [0.0006, 0.0008],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0569, 0.0685],
        [0.0684, 0.0570],
        [0.0637, 0.0612],
        [0.0638, 0.0611],
        [0.0606, 0.0643],
        [0.0605, 0.0644],
        [0.0623, 0.0626],
        [0.0619, 0.0629],
        [0.0623, 0.0626],
        [0.0603, 0.0647],
        [0.0580, 0.0672],
        [0.0668, 0.0583],
        [0.0642, 0.0607],
        [0.0606, 0.0643],
        [0.0645, 0.0604],
        [0.0650, 0.0599]], device='cuda:0')
 Batch: 7 of rare_synonyms classification Duration: 0:00:00.426037
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0009],
        [0.0003, 0.0004],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0005, 0.0008],
        [0.0006, 0.0008],
        [0.0006, 0.0010],
        [0.0003, 0.0003],
        [0.0003, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0004],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0618, 0.0631],
        [0.0658, 0.0592],
        [0.0610, 0.0639],
        [0.0608, 0.0641],
        [0.0608, 0.0641],
        [0.0594, 0.0656],
        [0.0604, 0.0646],
        [0.0631, 0.0618],
        [0.0607, 0.0642],
        [0.0675, 0.0578],
        [0.0684, 0.0570],
        [0.0643, 0.0606],
        [0.0592, 0.0658],
        [0.0589, 0.0662],
        [0.0636, 0.0613],
        [0.0642, 0.0607]], device='cuda:0')
 Batch: 8 of rare_synonyms classification Duration: 0:00:00.413074
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0010, 0.0011],
        [0.0009, 0.0014],
        [0.0005, 0.0009],
        [0.0002, 0.0003],
        [0.0004, 0.0008],
        [0.0006, 0.0007],
        [0.0009, 0.0015],
        [0.0004, 0.0010],
        [0.0002, 0.0003],
        [0.0004, 0.0004],
        [0.0004, 0.0004],
        [0.0007, 0.0012],
        [0.0005, 0.0012],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0006, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0676, 0.0576],
        [0.0620, 0.0628],
        [0.0610, 0.0638],
        [0.0627, 0.0621],
        [0.0588, 0.0662],
        [0.0654, 0.0595],
        [0.0609, 0.0640],
        [0.0566, 0.0688],
        [0.0633, 0.0615],
        [0.0673, 0.0578],
        [0.0680, 0.0573],
        [0.0609, 0.0640],
        [0.0564, 0.0690],
        [0.0603, 0.0645],
        [0.0632, 0.0616],
        [0.0655, 0.0594]], device='cuda:0')
 Batch: 9 of rare_synonyms classification Duration: 0:00:00.406073
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0008, 0.0009],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0005, 0.0006],
        [0.0005, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0011, 0.0013],
        [0.0004, 0.0005],
        [0.0002, 0.0004],
        [0.0006, 0.0007],
        [0.0005, 0.0008],
        [0.0010, 0.0012],
        [0.0004, 0.0008],
        [0.0004, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0664, 0.0586],
        [0.0585, 0.0665],
        [0.0588, 0.0663],
        [0.0666, 0.0585],
        [0.0642, 0.0607],
        [0.0595, 0.0655],
        [0.0579, 0.0672],
        [0.0613, 0.0635],
        [0.0653, 0.0597],
        [0.0655, 0.0594],
        [0.0605, 0.0644],
        [0.0659, 0.0591],
        [0.0612, 0.0637],
        [0.0638, 0.0611],
        [0.0572, 0.0681],
        [0.0674, 0.0578]], device='cuda:0')
 Batch: 10 of rare_synonyms classification Duration: 0:00:00.359044
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0008, 0.0010],
        [0.0012, 0.0012],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0008],
        [0.0004, 0.0009],
        [0.0006, 0.0010],
        [0.0007, 0.0011],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0009, 0.0011],
        [0.0005, 0.0007],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0657, 0.0594],
        [0.0690, 0.0565],
        [0.0648, 0.0602],
        [0.0616, 0.0633],
        [0.0608, 0.0641],
        [0.0585, 0.0667],
        [0.0605, 0.0645],
        [0.0620, 0.0628],
        [0.0598, 0.0652],
        [0.0638, 0.0611],
        [0.0636, 0.0613],
        [0.0606, 0.0644],
        [0.0592, 0.0659],
        [0.0647, 0.0603],
        [0.0653, 0.0597],
        [0.0602, 0.0647]], device='cuda:0')
 Batch: 11 of rare_synonyms classification Duration: 0:00:00.431094
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0006, 0.0009],
        [0.0007, 0.0012],
        [0.0003, 0.0003],
        [0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0003, 0.0003],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1201, 0.1299],
        [0.1277, 0.1222],
        [0.1197, 0.1303],
        [0.1350, 0.1156],
        [0.1232, 0.1266],
        [0.1201, 0.1299],
        [0.1304, 0.1197],
        [0.1239, 0.1259]], device='cuda:0')
 Batch: 12 of rare_synonyms classification Duration: 0:00:00.250410
acc:  0.48
Time taken to execute the en SA task with prompt type rare_synonyms, variation 6 and batchsize 16: 0:00:04.968424
path ['42', 'en', 'bloom-big', 'SA', 'rare_synonyms', 'prompt_id_6']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v73.pickle' as a pickle file.

prompt_type identical_modal has 10 prompts in it
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([102, 2])
answers_probs just softmax dim 0: tensor([[0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098]], device='cuda:0')
tensor([[0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA identical_modal 0 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0006, 0.0010],
        [0.0005, 0.0008],
        [0.0008, 0.0014],
        [0.0004, 0.0011],
        [0.0004, 0.0004],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0005, 0.0007],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0599, 0.0650],
        [0.0602, 0.0648],
        [0.0687, 0.0567],
        [0.0638, 0.0611],
        [0.0621, 0.0628],
        [0.0625, 0.0623],
        [0.0625, 0.0623],
        [0.0574, 0.0679],
        [0.0694, 0.0561],
        [0.0586, 0.0666],
        [0.0611, 0.0638],
        [0.0631, 0.0618],
        [0.0621, 0.0628],
        [0.0618, 0.0631],
        [0.0637, 0.0612],
        [0.0630, 0.0619]], device='cuda:0')
 Batch: 0 of identical_modal classification Duration: 0:00:00.414313
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0006, 0.0009],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0008, 0.0016],
        [0.0001, 0.0006],
        [0.0002, 0.0005],
        [0.0005, 0.0011],
        [0.0005, 0.0013],
        [0.0003, 0.0009],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0702, 0.0555],
        [0.0649, 0.0600],
        [0.0641, 0.0608],
        [0.0618, 0.0630],
        [0.0634, 0.0614],
        [0.0659, 0.0591],
        [0.0635, 0.0613],
        [0.0611, 0.0637],
        [0.0586, 0.0665],
        [0.0639, 0.0610],
        [0.0546, 0.0713],
        [0.0605, 0.0644],
        [0.0631, 0.0617],
        [0.0610, 0.0638],
        [0.0596, 0.0654],
        [0.0638, 0.0611]], device='cuda:0')
 Batch: 1 of identical_modal classification Duration: 0:00:00.447196
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0005, 0.0012],
        [0.0005, 0.0013],
        [0.0003, 0.0002],
        [0.0005, 0.0007],
        [0.0005, 0.0009],
        [0.0007, 0.0022],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0005, 0.0010],
        [0.0005, 0.0013],
        [0.0005, 0.0008],
        [0.0005, 0.0009],
        [0.0008, 0.0015],
        [0.0005, 0.0012],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0621, 0.0627],
        [0.0615, 0.0633],
        [0.0584, 0.0667],
        [0.0746, 0.0522],
        [0.0675, 0.0576],
        [0.0622, 0.0625],
        [0.0574, 0.0678],
        [0.0597, 0.0652],
        [0.0639, 0.0609],
        [0.0610, 0.0638],
        [0.0592, 0.0657],
        [0.0644, 0.0605],
        [0.0628, 0.0620],
        [0.0631, 0.0617],
        [0.0594, 0.0655],
        [0.0629, 0.0619]], device='cuda:0')
 Batch: 2 of identical_modal classification Duration: 0:00:00.427913
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0011],
        [0.0006, 0.0009],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0006, 0.0007],
        [0.0007, 0.0014],
        [0.0006, 0.0012],
        [0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0004, 0.0010],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0006, 0.0009],
        [0.0003, 0.0006],
        [0.0006, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0609, 0.0640],
        [0.0667, 0.0585],
        [0.0612, 0.0637],
        [0.0616, 0.0632],
        [0.0670, 0.0581],
        [0.0686, 0.0568],
        [0.0608, 0.0641],
        [0.0617, 0.0631],
        [0.0631, 0.0618],
        [0.0591, 0.0660],
        [0.0589, 0.0662],
        [0.0585, 0.0666],
        [0.0596, 0.0654],
        [0.0654, 0.0596],
        [0.0617, 0.0631],
        [0.0652, 0.0598]], device='cuda:0')
 Batch: 3 of identical_modal classification Duration: 0:00:00.359091
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0006, 0.0013],
        [0.0003, 0.0006],
        [0.0007, 0.0011],
        [0.0003, 0.0006],
        [0.0004, 0.0010],
        [0.0003, 0.0008],
        [0.0005, 0.0011],
        [0.0003, 0.0005],
        [0.0008, 0.0014],
        [0.0005, 0.0012],
        [0.0005, 0.0011],
        [0.0005, 0.0008],
        [0.0007, 0.0014],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0638, 0.0612],
        [0.0610, 0.0640],
        [0.0621, 0.0628],
        [0.0609, 0.0641],
        [0.0673, 0.0580],
        [0.0638, 0.0612],
        [0.0601, 0.0650],
        [0.0606, 0.0644],
        [0.0609, 0.0641],
        [0.0641, 0.0609],
        [0.0636, 0.0614],
        [0.0615, 0.0635],
        [0.0617, 0.0633],
        [0.0647, 0.0603],
        [0.0633, 0.0616],
        [0.0609, 0.0641]], device='cuda:0')
 Batch: 4 of identical_modal classification Duration: 0:00:00.360536
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0011],
        [0.0003, 0.0007],
        [0.0003, 0.0004],
        [0.0004, 0.0005],
        [0.0005, 0.0007],
        [0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0009],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0005, 0.0014],
        [0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0008],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0579, 0.0673],
        [0.0611, 0.0638],
        [0.0664, 0.0587],
        [0.0670, 0.0582],
        [0.0655, 0.0595],
        [0.0608, 0.0641],
        [0.0622, 0.0627],
        [0.0660, 0.0591],
        [0.0640, 0.0609],
        [0.0617, 0.0631],
        [0.0602, 0.0648],
        [0.0578, 0.0674],
        [0.0658, 0.0593],
        [0.0633, 0.0616],
        [0.0598, 0.0652],
        [0.0605, 0.0644]], device='cuda:0')
 Batch: 5 of identical_modal classification Duration: 0:00:00.410760
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0005, 0.0008],
        [0.0003, 0.0007],
        [0.0008, 0.0011],
        [0.0006, 0.0011],
        [0.0004, 0.0009],
        [0.0004, 0.0006],
        [0.0003, 0.0010],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0003, 0.0005],
        [0.0004, 0.0008],
        [0.0003, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0604, 0.0645],
        [0.0650, 0.0599],
        [0.0639, 0.0610],
        [0.0594, 0.0656],
        [0.0653, 0.0597],
        [0.0601, 0.0648],
        [0.0664, 0.0587],
        [0.0622, 0.0626],
        [0.0613, 0.0635],
        [0.0680, 0.0573],
        [0.0568, 0.0686],
        [0.0631, 0.0618],
        [0.0634, 0.0614],
        [0.0638, 0.0611],
        [0.0642, 0.0607],
        [0.0566, 0.0689]], device='cuda:0')
 Batch: 6 of identical_modal classification Duration: 0:00:00.334398
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0011],
        [0.0003, 0.0007],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0007, 0.0013],
        [0.0001, 0.0004],
        [0.0002, 0.0004],
        [0.0005, 0.0009],
        [0.0007, 0.0011],
        [0.0004, 0.0011],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0005, 0.0009],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0648, 0.0601],
        [0.0622, 0.0626],
        [0.0659, 0.0591],
        [0.0668, 0.0583],
        [0.0623, 0.0625],
        [0.0547, 0.0712],
        [0.0623, 0.0625],
        [0.0618, 0.0631],
        [0.0654, 0.0596],
        [0.0581, 0.0671],
        [0.0638, 0.0611],
        [0.0607, 0.0643],
        [0.0638, 0.0611],
        [0.0609, 0.0640],
        [0.0638, 0.0611],
        [0.0627, 0.0622]], device='cuda:0')
 Batch: 7 of identical_modal classification Duration: 0:00:00.402737
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0012],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0005, 0.0010],
        [0.0004, 0.0006],
        [0.0004, 0.0005],
        [0.0005, 0.0008],
        [0.0008, 0.0015],
        [0.0006, 0.0010],
        [0.0004, 0.0009],
        [0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0014],
        [0.0004, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0575, 0.0677],
        [0.0648, 0.0601],
        [0.0675, 0.0576],
        [0.0665, 0.0585],
        [0.0611, 0.0636],
        [0.0657, 0.0592],
        [0.0679, 0.0573],
        [0.0640, 0.0607],
        [0.0612, 0.0635],
        [0.0635, 0.0613],
        [0.0595, 0.0654],
        [0.0643, 0.0605],
        [0.0619, 0.0629],
        [0.0651, 0.0597],
        [0.0551, 0.0705],
        [0.0544, 0.0715]], device='cuda:0')
 Batch: 8 of identical_modal classification Duration: 0:00:00.552628
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0005, 0.0007],
        [0.0002, 0.0005],
        [0.0005, 0.0009],
        [0.0005, 0.0008],
        [0.0002, 0.0004],
        [0.0006, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0003, 0.0010],
        [0.0004, 0.0009],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0681, 0.0572],
        [0.0636, 0.0613],
        [0.0628, 0.0621],
        [0.0685, 0.0569],
        [0.0618, 0.0631],
        [0.0633, 0.0615],
        [0.0648, 0.0601],
        [0.0596, 0.0654],
        [0.0659, 0.0591],
        [0.0600, 0.0649],
        [0.0623, 0.0625],
        [0.0626, 0.0622],
        [0.0606, 0.0643],
        [0.0557, 0.0700],
        [0.0606, 0.0643],
        [0.0598, 0.0651]], device='cuda:0')
 Batch: 9 of identical_modal classification Duration: 0:00:00.408637
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0004, 0.0008],
        [0.0007, 0.0009],
        [0.0005, 0.0007],
        [0.0003, 0.0005],
        [0.0006, 0.0012],
        [0.0004, 0.0009],
        [0.0005, 0.0011],
        [0.0004, 0.0010],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0578, 0.0674],
        [0.0619, 0.0630],
        [0.0611, 0.0639],
        [0.0630, 0.0619],
        [0.0628, 0.0621],
        [0.0632, 0.0617],
        [0.0646, 0.0603],
        [0.0637, 0.0612],
        [0.0689, 0.0566],
        [0.0652, 0.0598],
        [0.0659, 0.0592],
        [0.0602, 0.0647],
        [0.0595, 0.0655],
        [0.0614, 0.0635],
        [0.0605, 0.0644],
        [0.0601, 0.0649]], device='cuda:0')
 Batch: 10 of identical_modal classification Duration: 0:00:00.365226
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0005, 0.0012],
        [0.0002, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0006, 0.0010],
        [0.0003, 0.0008],
        [0.0005, 0.0008],
        [0.0002, 0.0004],
        [0.0004, 0.0008],
        [0.0005, 0.0009],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0674, 0.0579],
        [0.0593, 0.0658],
        [0.0591, 0.0660],
        [0.0619, 0.0630],
        [0.0602, 0.0648],
        [0.0663, 0.0588],
        [0.0653, 0.0597],
        [0.0610, 0.0639],
        [0.0641, 0.0608],
        [0.0629, 0.0620],
        [0.0595, 0.0656],
        [0.0643, 0.0607],
        [0.0616, 0.0634],
        [0.0625, 0.0624],
        [0.0614, 0.0635],
        [0.0631, 0.0618]], device='cuda:0')
 Batch: 11 of identical_modal classification Duration: 0:00:00.456934
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0004, 0.0005],
        [0.0010, 0.0014],
        [0.0004, 0.0010],
        [0.0003, 0.0006],
        [0.0002, 0.0008],
        [0.0006, 0.0010],
        [0.0003, 0.0010]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1251, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1231, 0.1262],
        [0.1354, 0.1148],
        [0.1364, 0.1139],
        [0.1197, 0.1298],
        [0.1299, 0.1196],
        [0.1100, 0.1412],
        [0.1311, 0.1185],
        [0.1144, 0.1358]], device='cuda:0')
 Batch: 12 of identical_modal classification Duration: 0:00:00.220802
acc:  0.49
Time taken to execute the en SA task with prompt type identical_modal, variation 0 and batchsize 16: 0:00:05.181590
path ['42', 'en', 'bloom-big', 'SA', 'identical_modal', 'prompt_id_0']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([104, 2])
answers_probs just softmax dim 0: tensor([[0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096]], device='cuda:0')
tensor([[0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA identical_modal 1 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0007, 0.0009],
        [0.0005, 0.0011],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0004, 0.0005],
        [0.0009, 0.0014],
        [0.0005, 0.0008],
        [0.0006, 0.0011],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0575, 0.0677],
        [0.0641, 0.0607],
        [0.0628, 0.0620],
        [0.0580, 0.0671],
        [0.0612, 0.0636],
        [0.0587, 0.0664],
        [0.0573, 0.0679],
        [0.0673, 0.0578],
        [0.0616, 0.0632],
        [0.0635, 0.0613],
        [0.0649, 0.0600],
        [0.0707, 0.0551],
        [0.0648, 0.0601],
        [0.0632, 0.0616],
        [0.0622, 0.0626],
        [0.0621, 0.0628]], device='cuda:0')
 Batch: 0 of identical_modal classification Duration: 0:00:00.347297
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0008],
        [0.0003, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0012],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0007, 0.0009],
        [0.0003, 0.0006],
        [0.0003, 0.0009],
        [0.0003, 0.0004],
        [0.0005, 0.0007],
        [0.0006, 0.0009],
        [0.0002, 0.0005],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0660, 0.0590],
        [0.0574, 0.0677],
        [0.0631, 0.0617],
        [0.0594, 0.0655],
        [0.0618, 0.0629],
        [0.0670, 0.0581],
        [0.0603, 0.0645],
        [0.0589, 0.0661],
        [0.0684, 0.0569],
        [0.0596, 0.0652],
        [0.0546, 0.0712],
        [0.0680, 0.0572],
        [0.0656, 0.0593],
        [0.0650, 0.0599],
        [0.0616, 0.0631],
        [0.0632, 0.0616]], device='cuda:0')
 Batch: 1 of identical_modal classification Duration: 0:00:00.363492
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0005, 0.0008],
        [0.0004, 0.0008],
        [0.0007, 0.0011],
        [0.0004, 0.0009],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0004, 0.0005],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0006, 0.0014],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0638, 0.0611],
        [0.0638, 0.0611],
        [0.0629, 0.0620],
        [0.0630, 0.0619],
        [0.0613, 0.0636],
        [0.0643, 0.0607],
        [0.0605, 0.0645],
        [0.0628, 0.0621],
        [0.0628, 0.0621],
        [0.0606, 0.0644],
        [0.0680, 0.0573],
        [0.0600, 0.0650],
        [0.0640, 0.0609],
        [0.0598, 0.0653],
        [0.0591, 0.0660],
        [0.0632, 0.0617]], device='cuda:0')
 Batch: 2 of identical_modal classification Duration: 0:00:00.340730
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0004, 0.0007],
        [0.0007, 0.0011],
        [0.0003, 0.0007],
        [0.0005, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0008, 0.0014],
        [0.0004, 0.0007],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0004],
        [0.0006, 0.0009],
        [0.0005, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0633, 0.0615],
        [0.0623, 0.0626],
        [0.0633, 0.0615],
        [0.0580, 0.0672],
        [0.0665, 0.0586],
        [0.0591, 0.0659],
        [0.0594, 0.0656],
        [0.0593, 0.0657],
        [0.0623, 0.0626],
        [0.0616, 0.0632],
        [0.0625, 0.0623],
        [0.0649, 0.0601],
        [0.0654, 0.0596],
        [0.0690, 0.0565],
        [0.0638, 0.0611],
        [0.0590, 0.0660]], device='cuda:0')
 Batch: 3 of identical_modal classification Duration: 0:00:00.429630
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0003],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0005, 0.0005],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0003, 0.0006],
        [0.0006, 0.0009],
        [0.0006, 0.0007],
        [0.0003, 0.0003],
        [0.0004, 0.0008],
        [0.0008, 0.0014]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0644, 0.0606],
        [0.0634, 0.0615],
        [0.0616, 0.0633],
        [0.0596, 0.0654],
        [0.0653, 0.0598],
        [0.0593, 0.0658],
        [0.0617, 0.0632],
        [0.0670, 0.0582],
        [0.0595, 0.0655],
        [0.0633, 0.0616],
        [0.0608, 0.0642],
        [0.0638, 0.0611],
        [0.0654, 0.0596],
        [0.0664, 0.0587],
        [0.0577, 0.0676],
        [0.0610, 0.0639]], device='cuda:0')
 Batch: 4 of identical_modal classification Duration: 0:00:00.415257
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0011],
        [0.0005, 0.0007],
        [0.0004, 0.0006],
        [0.0005, 0.0008],
        [0.0007, 0.0010],
        [0.0003, 0.0006],
        [0.0003, 0.0009],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0006, 0.0010],
        [0.0005, 0.0009],
        [0.0005, 0.0009],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0005, 0.0006],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0617, 0.0633],
        [0.0647, 0.0603],
        [0.0642, 0.0608],
        [0.0626, 0.0624],
        [0.0647, 0.0603],
        [0.0626, 0.0623],
        [0.0578, 0.0675],
        [0.0621, 0.0628],
        [0.0605, 0.0645],
        [0.0618, 0.0631],
        [0.0630, 0.0619],
        [0.0617, 0.0633],
        [0.0599, 0.0651],
        [0.0613, 0.0637],
        [0.0670, 0.0582],
        [0.0645, 0.0604]], device='cuda:0')
 Batch: 5 of identical_modal classification Duration: 0:00:00.552655
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0008, 0.0012],
        [0.0009, 0.0011],
        [0.0007, 0.0011],
        [0.0003, 0.0007],
        [0.0004, 0.0009],
        [0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0006, 0.0008],
        [0.0005, 0.0007],
        [0.0005, 0.0006],
        [0.0005, 0.0011],
        [0.0006, 0.0007],
        [0.0007, 0.0012],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0569, 0.0685],
        [0.0622, 0.0626],
        [0.0638, 0.0610],
        [0.0675, 0.0578],
        [0.0624, 0.0624],
        [0.0579, 0.0673],
        [0.0596, 0.0654],
        [0.0630, 0.0618],
        [0.0614, 0.0635],
        [0.0658, 0.0592],
        [0.0637, 0.0612],
        [0.0684, 0.0570],
        [0.0590, 0.0661],
        [0.0664, 0.0587],
        [0.0614, 0.0634],
        [0.0607, 0.0641]], device='cuda:0')
 Batch: 6 of identical_modal classification Duration: 0:00:00.335970
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0004, 0.0012],
        [0.0007, 0.0020],
        [0.0006, 0.0009],
        [0.0005, 0.0009],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0005, 0.0011],
        [0.0003, 0.0009],
        [0.0006, 0.0010],
        [0.0005, 0.0009],
        [0.0003, 0.0003],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0627, 0.0620],
        [0.0566, 0.0687],
        [0.0577, 0.0674],
        [0.0660, 0.0589],
        [0.0645, 0.0603],
        [0.0607, 0.0641],
        [0.0646, 0.0601],
        [0.0619, 0.0628],
        [0.0570, 0.0682],
        [0.0639, 0.0608],
        [0.0623, 0.0625],
        [0.0752, 0.0517],
        [0.0637, 0.0610],
        [0.0605, 0.0643],
        [0.0644, 0.0604],
        [0.0582, 0.0669]], device='cuda:0')
 Batch: 7 of identical_modal classification Duration: 0:00:00.454542
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0008, 0.0014],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0004, 0.0010],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0005, 0.0009],
        [0.0003, 0.0011],
        [0.0003, 0.0003],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0004, 0.0010],
        [0.0006, 0.0010],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0631, 0.0617],
        [0.0638, 0.0610],
        [0.0654, 0.0596],
        [0.0588, 0.0662],
        [0.0651, 0.0598],
        [0.0608, 0.0641],
        [0.0645, 0.0603],
        [0.0551, 0.0706],
        [0.0684, 0.0569],
        [0.0642, 0.0607],
        [0.0557, 0.0698],
        [0.0639, 0.0609],
        [0.0620, 0.0628],
        [0.0590, 0.0660],
        [0.0636, 0.0612],
        [0.0665, 0.0586]], device='cuda:0')
 Batch: 8 of identical_modal classification Duration: 0:00:00.427029
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0007],
        [0.0006, 0.0010],
        [0.0005, 0.0010],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0006, 0.0010],
        [0.0004, 0.0005],
        [0.0005, 0.0010],
        [0.0005, 0.0006],
        [0.0004, 0.0005],
        [0.0004, 0.0007],
        [0.0005, 0.0009],
        [0.0003, 0.0005],
        [0.0001, 0.0005],
        [0.0005, 0.0008],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0672, 0.0579],
        [0.0629, 0.0619],
        [0.0598, 0.0651],
        [0.0630, 0.0618],
        [0.0600, 0.0649],
        [0.0612, 0.0636],
        [0.0667, 0.0584],
        [0.0594, 0.0656],
        [0.0654, 0.0595],
        [0.0671, 0.0581],
        [0.0632, 0.0616],
        [0.0620, 0.0628],
        [0.0653, 0.0597],
        [0.0539, 0.0723],
        [0.0627, 0.0622],
        [0.0602, 0.0647]], device='cuda:0')
 Batch: 9 of identical_modal classification Duration: 0:00:00.365343
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0007, 0.0012],
        [0.0004, 0.0010],
        [0.0003, 0.0005],
        [0.0005, 0.0007],
        [0.0004, 0.0010],
        [0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0004, 0.0010],
        [0.0004, 0.0005],
        [0.0003, 0.0004],
        [0.0004, 0.0008],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0609, 0.0640],
        [0.0644, 0.0606],
        [0.0620, 0.0629],
        [0.0592, 0.0659],
        [0.0615, 0.0635],
        [0.0646, 0.0604],
        [0.0596, 0.0654],
        [0.0637, 0.0612],
        [0.0650, 0.0600],
        [0.0611, 0.0638],
        [0.0630, 0.0619],
        [0.0585, 0.0667],
        [0.0657, 0.0594],
        [0.0657, 0.0593],
        [0.0627, 0.0623],
        [0.0622, 0.0627]], device='cuda:0')
 Batch: 10 of identical_modal classification Duration: 0:00:00.287907
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0005, 0.0008],
        [0.0005, 0.0007],
        [0.0002, 0.0005],
        [0.0004, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0004, 0.0006],
        [0.0004, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0636, 0.0613],
        [0.0630, 0.0619],
        [0.0611, 0.0638],
        [0.0636, 0.0613],
        [0.0589, 0.0662],
        [0.0621, 0.0628],
        [0.0643, 0.0606],
        [0.0634, 0.0615],
        [0.0647, 0.0603],
        [0.0648, 0.0602],
        [0.0605, 0.0645],
        [0.0658, 0.0593],
        [0.0593, 0.0658],
        [0.0609, 0.0640],
        [0.0673, 0.0579],
        [0.0569, 0.0685]], device='cuda:0')
 Batch: 11 of identical_modal classification Duration: 0:00:00.447932
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0006, 0.0011],
        [0.0005, 0.0010],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0007, 0.0012]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1316, 0.1186],
        [0.1251, 0.1249],
        [0.1264, 0.1235],
        [0.1253, 0.1247],
        [0.1239, 0.1260],
        [0.1218, 0.1282],
        [0.1204, 0.1297],
        [0.1255, 0.1244]], device='cuda:0')
 Batch: 12 of identical_modal classification Duration: 0:00:00.179962
acc:  0.53
Time taken to execute the en SA task with prompt type identical_modal, variation 1 and batchsize 16: 0:00:04.968924
path ['42', 'en', 'bloom-big', 'SA', 'identical_modal', 'prompt_id_1']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([102, 2])
answers_probs just softmax dim 0: tensor([[0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098]], device='cuda:0')
tensor([[0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098],
        [0.0098, 0.0098]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA identical_modal 2 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0006, 0.0008],
        [0.0005, 0.0012],
        [0.0006, 0.0008],
        [0.0004, 0.0005],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0007, 0.0009],
        [0.0005, 0.0007],
        [0.0004, 0.0006],
        [0.0007, 0.0009],
        [0.0005, 0.0011],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0598, 0.0651],
        [0.0673, 0.0578],
        [0.0565, 0.0690],
        [0.0656, 0.0594],
        [0.0672, 0.0580],
        [0.0620, 0.0628],
        [0.0591, 0.0659],
        [0.0609, 0.0640],
        [0.0610, 0.0639],
        [0.0607, 0.0642],
        [0.0662, 0.0588],
        [0.0655, 0.0594],
        [0.0624, 0.0624],
        [0.0677, 0.0575],
        [0.0592, 0.0658],
        [0.0590, 0.0660]], device='cuda:0')
 Batch: 0 of identical_modal classification Duration: 0:00:00.367419
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0008, 0.0011],
        [0.0008, 0.0016],
        [0.0003, 0.0005],
        [0.0005, 0.0007],
        [0.0005, 0.0010],
        [0.0002, 0.0006],
        [0.0002, 0.0005],
        [0.0004, 0.0008],
        [0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0006, 0.0008],
        [0.0006, 0.0009],
        [0.0005, 0.0008],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0664, 0.0587],
        [0.0607, 0.0642],
        [0.0650, 0.0599],
        [0.0664, 0.0587],
        [0.0608, 0.0641],
        [0.0552, 0.0706],
        [0.0591, 0.0660],
        [0.0622, 0.0626],
        [0.0620, 0.0629],
        [0.0611, 0.0638],
        [0.0656, 0.0594],
        [0.0654, 0.0596],
        [0.0630, 0.0619],
        [0.0662, 0.0588],
        [0.0602, 0.0648],
        [0.0609, 0.0640]], device='cuda:0')
 Batch: 1 of identical_modal classification Duration: 0:00:00.320789
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0005, 0.0007],
        [0.0005, 0.0009],
        [0.0002, 0.0005],
        [0.0007, 0.0008],
        [0.0002, 0.0007],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0003, 0.0007],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0003],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0640, 0.0609],
        [0.0642, 0.0606],
        [0.0624, 0.0624],
        [0.0613, 0.0635],
        [0.0686, 0.0568],
        [0.0554, 0.0704],
        [0.0650, 0.0600],
        [0.0619, 0.0630],
        [0.0598, 0.0652],
        [0.0640, 0.0609],
        [0.0602, 0.0647],
        [0.0623, 0.0625],
        [0.0689, 0.0565],
        [0.0603, 0.0646],
        [0.0610, 0.0639],
        [0.0608, 0.0641]], device='cuda:0')
 Batch: 2 of identical_modal classification Duration: 0:00:00.451415
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0005, 0.0007],
        [0.0004, 0.0006],
        [0.0004, 0.0009],
        [0.0004, 0.0009],
        [0.0006, 0.0009],
        [0.0004, 0.0009],
        [0.0003, 0.0002],
        [0.0004, 0.0008],
        [0.0004, 0.0010],
        [0.0008, 0.0019],
        [0.0006, 0.0009],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0002, 0.0007],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0608, 0.0639],
        [0.0646, 0.0602],
        [0.0647, 0.0601],
        [0.0601, 0.0647],
        [0.0587, 0.0663],
        [0.0646, 0.0602],
        [0.0595, 0.0654],
        [0.0734, 0.0530],
        [0.0620, 0.0627],
        [0.0583, 0.0667],
        [0.0579, 0.0671],
        [0.0638, 0.0610],
        [0.0645, 0.0603],
        [0.0638, 0.0610],
        [0.0560, 0.0695],
        [0.0672, 0.0579]], device='cuda:0')
 Batch: 3 of identical_modal classification Duration: 0:00:00.553301
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0013],
        [0.0004, 0.0010],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0007, 0.0010],
        [0.0010, 0.0013],
        [0.0003, 0.0008],
        [0.0005, 0.0005],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0005, 0.0011],
        [0.0004, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0011],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0592, 0.0657],
        [0.0587, 0.0664],
        [0.0617, 0.0631],
        [0.0626, 0.0622],
        [0.0651, 0.0598],
        [0.0668, 0.0583],
        [0.0562, 0.0693],
        [0.0708, 0.0550],
        [0.0634, 0.0614],
        [0.0659, 0.0591],
        [0.0612, 0.0636],
        [0.0614, 0.0634],
        [0.0616, 0.0632],
        [0.0620, 0.0628],
        [0.0579, 0.0672],
        [0.0654, 0.0595]], device='cuda:0')
 Batch: 4 of identical_modal classification Duration: 0:00:00.335817
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0005],
        [0.0005, 0.0009],
        [0.0004, 0.0007],
        [0.0005, 0.0008],
        [0.0002, 0.0005],
        [0.0004, 0.0010],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0005],
        [0.0007, 0.0011],
        [0.0003, 0.0009],
        [0.0002, 0.0004],
        [0.0004, 0.0008],
        [0.0008, 0.0010],
        [0.0003, 0.0005],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0669, 0.0582],
        [0.0638, 0.0610],
        [0.0620, 0.0628],
        [0.0648, 0.0601],
        [0.0576, 0.0676],
        [0.0587, 0.0663],
        [0.0633, 0.0615],
        [0.0626, 0.0622],
        [0.0673, 0.0578],
        [0.0646, 0.0603],
        [0.0565, 0.0689],
        [0.0583, 0.0668],
        [0.0617, 0.0631],
        [0.0685, 0.0568],
        [0.0653, 0.0596],
        [0.0582, 0.0669]], device='cuda:0')
 Batch: 5 of identical_modal classification Duration: 0:00:00.453502
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0005, 0.0011],
        [0.0005, 0.0008],
        [0.0010, 0.0017],
        [0.0008, 0.0010],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0003, 0.0010],
        [0.0003, 0.0007],
        [0.0013, 0.0019],
        [0.0003, 0.0005],
        [0.0007, 0.0011],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0006, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0682, 0.0571],
        [0.0599, 0.0650],
        [0.0631, 0.0618],
        [0.0624, 0.0624],
        [0.0661, 0.0589],
        [0.0608, 0.0641],
        [0.0640, 0.0609],
        [0.0645, 0.0604],
        [0.0559, 0.0697],
        [0.0585, 0.0666],
        [0.0642, 0.0607],
        [0.0627, 0.0621],
        [0.0645, 0.0604],
        [0.0642, 0.0607],
        [0.0611, 0.0638],
        [0.0598, 0.0652]], device='cuda:0')
 Batch: 6 of identical_modal classification Duration: 0:00:00.408527
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[4.6134e-04, 6.0654e-04],
        [4.3774e-04, 9.3412e-04],
        [2.6941e-04, 4.6182e-04],
        [4.1056e-04, 7.9155e-04],
        [5.3358e-04, 9.4414e-04],
        [6.1607e-04, 1.3351e-03],
        [3.9077e-04, 9.0837e-04],
        [5.1689e-04, 9.5797e-04],
        [1.9622e-04, 2.8563e-04],
        [7.1228e-05, 1.9443e-04],
        [7.1955e-04, 8.1539e-04],
        [5.0831e-04, 1.4477e-03],
        [4.3035e-04, 1.2751e-03],
        [2.6488e-04, 5.3930e-04],
        [1.8096e-04, 3.5167e-04],
        [5.1165e-04, 1.0996e-03]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0684, 0.0569],
        [0.0611, 0.0637],
        [0.0642, 0.0606],
        [0.0625, 0.0623],
        [0.0638, 0.0611],
        [0.0609, 0.0639],
        [0.0600, 0.0649],
        [0.0631, 0.0617],
        [0.0668, 0.0583],
        [0.0581, 0.0670],
        [0.0710, 0.0548],
        [0.0576, 0.0676],
        [0.0572, 0.0681],
        [0.0618, 0.0630],
        [0.0624, 0.0624],
        [0.0610, 0.0638]], device='cuda:0')
 Batch: 7 of identical_modal classification Duration: 0:00:00.402182
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0011],
        [0.0006, 0.0011],
        [0.0004, 0.0010],
        [0.0004, 0.0009],
        [0.0006, 0.0012],
        [0.0005, 0.0007],
        [0.0007, 0.0008],
        [0.0006, 0.0008],
        [0.0002, 0.0003],
        [0.0005, 0.0010],
        [0.0004, 0.0007],
        [0.0003, 0.0004],
        [0.0003, 0.0010],
        [0.0003, 0.0006],
        [0.0006, 0.0010],
        [0.0008, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0621, 0.0628],
        [0.0624, 0.0624],
        [0.0590, 0.0660],
        [0.0597, 0.0652],
        [0.0612, 0.0637],
        [0.0651, 0.0598],
        [0.0691, 0.0564],
        [0.0669, 0.0582],
        [0.0638, 0.0611],
        [0.0602, 0.0647],
        [0.0638, 0.0611],
        [0.0631, 0.0617],
        [0.0553, 0.0705],
        [0.0611, 0.0638],
        [0.0625, 0.0623],
        [0.0645, 0.0604]], device='cuda:0')
 Batch: 8 of identical_modal classification Duration: 0:00:00.340369
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0003],
        [0.0002, 0.0005],
        [0.0004, 0.0008],
        [0.0005, 0.0010],
        [0.0004, 0.0009],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0005, 0.0013],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0004, 0.0010],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0693, 0.0563],
        [0.0606, 0.0643],
        [0.0621, 0.0628],
        [0.0617, 0.0632],
        [0.0609, 0.0640],
        [0.0657, 0.0593],
        [0.0624, 0.0625],
        [0.0574, 0.0680],
        [0.0636, 0.0613],
        [0.0606, 0.0643],
        [0.0640, 0.0609],
        [0.0613, 0.0636],
        [0.0596, 0.0654],
        [0.0627, 0.0621],
        [0.0667, 0.0585],
        [0.0614, 0.0635]], device='cuda:0')
 Batch: 9 of identical_modal classification Duration: 0:00:00.401328
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0003, 0.0009],
        [0.0005, 0.0009],
        [0.0004, 0.0007],
        [0.0001, 0.0005],
        [0.0003, 0.0003],
        [0.0004, 0.0006],
        [0.0006, 0.0010],
        [0.0004, 0.0010],
        [0.0003, 0.0006],
        [0.0005, 0.0008],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0634, 0.0614],
        [0.0608, 0.0640],
        [0.0608, 0.0640],
        [0.0588, 0.0661],
        [0.0639, 0.0608],
        [0.0638, 0.0609],
        [0.0548, 0.0709],
        [0.0751, 0.0518],
        [0.0631, 0.0616],
        [0.0654, 0.0595],
        [0.0569, 0.0683],
        [0.0603, 0.0644],
        [0.0647, 0.0601],
        [0.0630, 0.0617],
        [0.0604, 0.0644],
        [0.0648, 0.0600]], device='cuda:0')
 Batch: 10 of identical_modal classification Duration: 0:00:00.359581
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0005, 0.0012],
        [0.0005, 0.0009],
        [0.0005, 0.0008],
        [0.0003, 0.0004],
        [0.0009, 0.0016],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0011, 0.0015],
        [0.0005, 0.0009],
        [0.0003, 0.0006],
        [0.0003, 0.0009],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0006, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0667, 0.0584],
        [0.0591, 0.0659],
        [0.0607, 0.0641],
        [0.0623, 0.0626],
        [0.0697, 0.0559],
        [0.0625, 0.0624],
        [0.0597, 0.0653],
        [0.0611, 0.0638],
        [0.0665, 0.0586],
        [0.0607, 0.0641],
        [0.0625, 0.0624],
        [0.0558, 0.0698],
        [0.0650, 0.0600],
        [0.0626, 0.0622],
        [0.0606, 0.0643],
        [0.0646, 0.0603]], device='cuda:0')
 Batch: 11 of identical_modal classification Duration: 0:00:00.427225
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0007, 0.0013],
        [0.0004, 0.0007],
        [0.0007, 0.0009]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1182, 0.1319],
        [0.1261, 0.1237],
        [0.1217, 0.1282],
        [0.1229, 0.1269],
        [0.1195, 0.1304],
        [0.1279, 0.1219],
        [0.1254, 0.1243],
        [0.1383, 0.1128]], device='cuda:0')
 Batch: 12 of identical_modal classification Duration: 0:00:00.100895
acc:  0.5
Time taken to execute the en SA task with prompt type identical_modal, variation 2 and batchsize 16: 0:00:04.943195
path ['42', 'en', 'bloom-big', 'SA', 'identical_modal', 'prompt_id_2']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([104, 2])
answers_probs just softmax dim 0: tensor([[0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096]], device='cuda:0')
tensor([[0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA identical_modal 3 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0010],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0004, 0.0008],
        [0.0001, 0.0005],
        [0.0002, 0.0006],
        [0.0006, 0.0009],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0002, 0.0007],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0631, 0.0616],
        [0.0652, 0.0597],
        [0.0642, 0.0607],
        [0.0653, 0.0596],
        [0.0585, 0.0665],
        [0.0615, 0.0633],
        [0.0640, 0.0608],
        [0.0661, 0.0589],
        [0.0613, 0.0635],
        [0.0543, 0.0716],
        [0.0594, 0.0655],
        [0.0681, 0.0571],
        [0.0622, 0.0625],
        [0.0650, 0.0599],
        [0.0555, 0.0701],
        [0.0662, 0.0588]], device='cuda:0')
 Batch: 0 of identical_modal classification Duration: 0:00:00.439039
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0004, 0.0009],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0006, 0.0009],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0626, 0.0623],
        [0.0642, 0.0608],
        [0.0638, 0.0611],
        [0.0632, 0.0618],
        [0.0607, 0.0643],
        [0.0641, 0.0609],
        [0.0656, 0.0594],
        [0.0617, 0.0632],
        [0.0658, 0.0593],
        [0.0574, 0.0679],
        [0.0608, 0.0642],
        [0.0608, 0.0642],
        [0.0651, 0.0599],
        [0.0625, 0.0624],
        [0.0595, 0.0656],
        [0.0623, 0.0627]], device='cuda:0')
 Batch: 1 of identical_modal classification Duration: 0:00:00.447971
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[3.1948e-04, 6.1131e-04],
        [2.6464e-04, 5.7840e-04],
        [2.3472e-04, 5.0449e-04],
        [2.9349e-04, 6.5088e-04],
        [2.9778e-04, 4.2653e-04],
        [7.4506e-05, 2.6417e-04],
        [3.0518e-04, 5.4407e-04],
        [2.9898e-04, 4.2510e-04],
        [3.2020e-04, 5.2786e-04],
        [3.0541e-04, 5.1165e-04],
        [2.9349e-04, 7.5531e-04],
        [3.9864e-04, 7.3910e-04],
        [3.7551e-04, 6.0034e-04],
        [3.9434e-04, 7.2527e-04],
        [2.8157e-04, 5.7745e-04],
        [2.4056e-04, 5.3787e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0626, 0.0622],
        [0.0608, 0.0641],
        [0.0610, 0.0639],
        [0.0606, 0.0643],
        [0.0670, 0.0582],
        [0.0554, 0.0704],
        [0.0636, 0.0612],
        [0.0671, 0.0581],
        [0.0648, 0.0601],
        [0.0646, 0.0604],
        [0.0588, 0.0663],
        [0.0631, 0.0618],
        [0.0653, 0.0597],
        [0.0632, 0.0617],
        [0.0617, 0.0632],
        [0.0605, 0.0644]], device='cuda:0')
 Batch: 2 of identical_modal classification Duration: 0:00:00.412781
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0005],
        [0.0005, 0.0009],
        [0.0002, 0.0002],
        [0.0005, 0.0007],
        [0.0003, 0.0005],
        [0.0010, 0.0017],
        [0.0004, 0.0007],
        [0.0006, 0.0010],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0006, 0.0018],
        [0.0002, 0.0004],
        [0.0006, 0.0010],
        [0.0004, 0.0006],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0660, 0.0590],
        [0.0612, 0.0637],
        [0.0679, 0.0574],
        [0.0650, 0.0599],
        [0.0629, 0.0620],
        [0.0635, 0.0614],
        [0.0614, 0.0635],
        [0.0641, 0.0608],
        [0.0601, 0.0648],
        [0.0608, 0.0641],
        [0.0621, 0.0627],
        [0.0567, 0.0687],
        [0.0624, 0.0625],
        [0.0641, 0.0608],
        [0.0640, 0.0610],
        [0.0577, 0.0675]], device='cuda:0')
 Batch: 3 of identical_modal classification Duration: 0:00:00.406038
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0005, 0.0008],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0003],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0005, 0.0007],
        [0.0004, 0.0009],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0618, 0.0631],
        [0.0613, 0.0637],
        [0.0583, 0.0669],
        [0.0616, 0.0633],
        [0.0632, 0.0618],
        [0.0625, 0.0624],
        [0.0651, 0.0599],
        [0.0617, 0.0632],
        [0.0591, 0.0660],
        [0.0691, 0.0565],
        [0.0607, 0.0642],
        [0.0646, 0.0604],
        [0.0624, 0.0625],
        [0.0646, 0.0604],
        [0.0602, 0.0648],
        [0.0642, 0.0607]], device='cuda:0')
 Batch: 4 of identical_modal classification Duration: 0:00:00.546566
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0002, 0.0008],
        [0.0004, 0.0007],
        [0.0002, 0.0001],
        [0.0005, 0.0006],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0005, 0.0010],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0586, 0.0663],
        [0.0603, 0.0644],
        [0.0610, 0.0637],
        [0.0637, 0.0610],
        [0.0531, 0.0732],
        [0.0628, 0.0618],
        [0.0736, 0.0528],
        [0.0674, 0.0577],
        [0.0640, 0.0607],
        [0.0636, 0.0611],
        [0.0651, 0.0597],
        [0.0684, 0.0568],
        [0.0598, 0.0650],
        [0.0600, 0.0647],
        [0.0594, 0.0654],
        [0.0592, 0.0656]], device='cuda:0')
 Batch: 5 of identical_modal classification Duration: 0:00:00.368032
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0008, 0.0010],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0004],
        [0.0003, 0.0004],
        [0.0002, 0.0008],
        [0.0003, 0.0008],
        [0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0002, 0.0006],
        [0.0003, 0.0004],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0677, 0.0574],
        [0.0636, 0.0611],
        [0.0596, 0.0652],
        [0.0617, 0.0630],
        [0.0631, 0.0617],
        [0.0708, 0.0549],
        [0.0664, 0.0585],
        [0.0553, 0.0703],
        [0.0584, 0.0666],
        [0.0613, 0.0635],
        [0.0573, 0.0679],
        [0.0594, 0.0654],
        [0.0690, 0.0563],
        [0.0601, 0.0647],
        [0.0615, 0.0632],
        [0.0647, 0.0601]], device='cuda:0')
 Batch: 6 of identical_modal classification Duration: 0:00:00.234218
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0002, 0.0004],
        [0.0004, 0.0010],
        [0.0005, 0.0009],
        [0.0003, 0.0004],
        [0.0004, 0.0007],
        [0.0005, 0.0009],
        [0.0003, 0.0004],
        [0.0003, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0002, 0.0003],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0614, 0.0635],
        [0.0593, 0.0658],
        [0.0631, 0.0618],
        [0.0640, 0.0609],
        [0.0621, 0.0628],
        [0.0593, 0.0658],
        [0.0610, 0.0639],
        [0.0654, 0.0597],
        [0.0632, 0.0617],
        [0.0632, 0.0617],
        [0.0639, 0.0610],
        [0.0591, 0.0660],
        [0.0588, 0.0664],
        [0.0678, 0.0575],
        [0.0667, 0.0584],
        [0.0618, 0.0631]], device='cuda:0')
 Batch: 7 of identical_modal classification Duration: 0:00:00.368215
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0005, 0.0010],
        [0.0004, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0002, 0.0005],
        [0.0002, 0.0002],
        [0.0003, 0.0007],
        [0.0003, 0.0009],
        [0.0003, 0.0005],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0635, 0.0614],
        [0.0591, 0.0659],
        [0.0624, 0.0625],
        [0.0650, 0.0600],
        [0.0596, 0.0654],
        [0.0604, 0.0646],
        [0.0623, 0.0626],
        [0.0670, 0.0582],
        [0.0625, 0.0624],
        [0.0627, 0.0622],
        [0.0628, 0.0621],
        [0.0688, 0.0567],
        [0.0595, 0.0655],
        [0.0572, 0.0681],
        [0.0633, 0.0616],
        [0.0641, 0.0609]], device='cuda:0')
 Batch: 8 of identical_modal classification Duration: 0:00:00.338722
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0007, 0.0011],
        [0.0002, 0.0003],
        [0.0004, 0.0007],
        [0.0005, 0.0007],
        [0.0006, 0.0009],
        [0.0004, 0.0005],
        [0.0005, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0004],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0005, 0.0007],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0616, 0.0633],
        [0.0613, 0.0636],
        [0.0627, 0.0622],
        [0.0623, 0.0626],
        [0.0658, 0.0593],
        [0.0598, 0.0652],
        [0.0630, 0.0619],
        [0.0629, 0.0620],
        [0.0644, 0.0605],
        [0.0644, 0.0605],
        [0.0642, 0.0608],
        [0.0651, 0.0600],
        [0.0583, 0.0669],
        [0.0574, 0.0679],
        [0.0646, 0.0604],
        [0.0621, 0.0628]], device='cuda:0')
 Batch: 9 of identical_modal classification Duration: 0:00:00.482963
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0006, 0.0012],
        [0.0002, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0005, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0640, 0.0610],
        [0.0604, 0.0646],
        [0.0639, 0.0611],
        [0.0613, 0.0637],
        [0.0647, 0.0603],
        [0.0627, 0.0622],
        [0.0600, 0.0650],
        [0.0638, 0.0612],
        [0.0609, 0.0641],
        [0.0612, 0.0638],
        [0.0616, 0.0634],
        [0.0622, 0.0627],
        [0.0688, 0.0567],
        [0.0635, 0.0614],
        [0.0617, 0.0632],
        [0.0596, 0.0655]], device='cuda:0')
 Batch: 10 of identical_modal classification Duration: 0:00:00.432846
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0005, 0.0012],
        [0.0003, 0.0004],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0006, 0.0011],
        [0.0003, 0.0006],
        [0.0006, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0587, 0.0664],
        [0.0607, 0.0643],
        [0.0658, 0.0592],
        [0.0627, 0.0622],
        [0.0594, 0.0657],
        [0.0630, 0.0619],
        [0.0638, 0.0611],
        [0.0602, 0.0647],
        [0.0706, 0.0552],
        [0.0622, 0.0627],
        [0.0619, 0.0630],
        [0.0595, 0.0656],
        [0.0616, 0.0633],
        [0.0641, 0.0608],
        [0.0614, 0.0635],
        [0.0644, 0.0606]], device='cuda:0')
 Batch: 11 of identical_modal classification Duration: 0:00:00.361462
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0004, 0.0006],
        [0.0004, 0.0006],
        [0.0006, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0002, 0.0004],
        [0.0005, 0.0010],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1266, 0.1232],
        [0.1301, 0.1199],
        [0.1349, 0.1157],
        [0.1179, 0.1323],
        [0.1209, 0.1290],
        [0.1239, 0.1259],
        [0.1220, 0.1279],
        [0.1237, 0.1261]], device='cuda:0')
 Batch: 12 of identical_modal classification Duration: 0:00:00.157464
acc:  0.41
Time taken to execute the en SA task with prompt type identical_modal, variation 3 and batchsize 16: 0:00:05.017050
path ['42', 'en', 'bloom-big', 'SA', 'identical_modal', 'prompt_id_3']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([104, 2])
answers_probs just softmax dim 0: tensor([[0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096]], device='cuda:0')
tensor([[0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA identical_modal 4 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0009],
        [0.0005, 0.0016],
        [0.0003, 0.0006],
        [0.0005, 0.0011],
        [0.0004, 0.0011],
        [0.0007, 0.0010],
        [0.0004, 0.0009],
        [0.0003, 0.0007],
        [0.0005, 0.0007],
        [0.0002, 0.0008],
        [0.0004, 0.0009],
        [0.0005, 0.0011],
        [0.0005, 0.0008],
        [0.0003, 0.0009],
        [0.0006, 0.0009],
        [0.0007, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0682, 0.0570],
        [0.0561, 0.0693],
        [0.0628, 0.0619],
        [0.0626, 0.0621],
        [0.0595, 0.0653],
        [0.0661, 0.0589],
        [0.0617, 0.0631],
        [0.0604, 0.0644],
        [0.0673, 0.0578],
        [0.0563, 0.0691],
        [0.0606, 0.0642],
        [0.0623, 0.0625],
        [0.0636, 0.0612],
        [0.0569, 0.0684],
        [0.0672, 0.0579],
        [0.0682, 0.0570]], device='cuda:0')
 Batch: 0 of identical_modal classification Duration: 0:00:00.454778
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0009, 0.0014],
        [0.0002, 0.0004],
        [0.0004, 0.0012],
        [0.0012, 0.0015],
        [0.0006, 0.0012],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0004, 0.0011],
        [0.0008, 0.0014],
        [0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0004, 0.0008],
        [0.0004, 0.0010],
        [0.0003, 0.0004],
        [0.0007, 0.0011],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0655, 0.0595],
        [0.0587, 0.0664],
        [0.0580, 0.0671],
        [0.0699, 0.0558],
        [0.0614, 0.0634],
        [0.0642, 0.0607],
        [0.0614, 0.0634],
        [0.0564, 0.0690],
        [0.0638, 0.0610],
        [0.0614, 0.0634],
        [0.0616, 0.0632],
        [0.0634, 0.0615],
        [0.0600, 0.0649],
        [0.0649, 0.0600],
        [0.0654, 0.0596],
        [0.0640, 0.0609]], device='cuda:0')
 Batch: 1 of identical_modal classification Duration: 0:00:00.407226
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0003, 0.0009],
        [0.0003, 0.0007],
        [0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0005, 0.0012],
        [0.0003, 0.0008],
        [0.0005, 0.0009],
        [0.0002, 0.0004],
        [0.0005, 0.0015],
        [0.0003, 0.0007],
        [0.0002, 0.0004],
        [0.0004, 0.0008],
        [0.0007, 0.0011],
        [0.0003, 0.0009],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0627, 0.0621],
        [0.0580, 0.0672],
        [0.0603, 0.0647],
        [0.0673, 0.0579],
        [0.0655, 0.0595],
        [0.0606, 0.0643],
        [0.0605, 0.0644],
        [0.0657, 0.0593],
        [0.0662, 0.0589],
        [0.0585, 0.0666],
        [0.0609, 0.0640],
        [0.0660, 0.0591],
        [0.0621, 0.0627],
        [0.0674, 0.0578],
        [0.0582, 0.0669],
        [0.0603, 0.0646]], device='cuda:0')
 Batch: 2 of identical_modal classification Duration: 0:00:00.358989
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0015],
        [0.0004, 0.0011],
        [0.0005, 0.0009],
        [0.0003, 0.0006],
        [0.0002, 0.0007],
        [0.0005, 0.0010],
        [0.0005, 0.0010],
        [0.0003, 0.0007],
        [0.0004, 0.0006],
        [0.0006, 0.0014],
        [0.0004, 0.0007],
        [0.0006, 0.0010],
        [0.0005, 0.0009],
        [0.0004, 0.0008],
        [0.0005, 0.0009],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0598, 0.0652],
        [0.0591, 0.0661],
        [0.0650, 0.0600],
        [0.0627, 0.0623],
        [0.0586, 0.0666],
        [0.0623, 0.0626],
        [0.0623, 0.0626],
        [0.0618, 0.0631],
        [0.0647, 0.0603],
        [0.0603, 0.0647],
        [0.0633, 0.0616],
        [0.0647, 0.0603],
        [0.0645, 0.0605],
        [0.0636, 0.0613],
        [0.0631, 0.0619],
        [0.0642, 0.0608]], device='cuda:0')
 Batch: 3 of identical_modal classification Duration: 0:00:00.316664
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0012],
        [0.0003, 0.0006],
        [0.0005, 0.0008],
        [0.0004, 0.0007],
        [0.0005, 0.0008],
        [0.0005, 0.0010],
        [0.0006, 0.0011],
        [0.0003, 0.0006],
        [0.0006, 0.0008],
        [0.0004, 0.0008],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0004, 0.0010],
        [0.0003, 0.0005],
        [0.0004, 0.0008],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0620, 0.0629],
        [0.0610, 0.0639],
        [0.0653, 0.0597],
        [0.0631, 0.0618],
        [0.0670, 0.0582],
        [0.0622, 0.0627],
        [0.0623, 0.0626],
        [0.0592, 0.0658],
        [0.0684, 0.0570],
        [0.0629, 0.0619],
        [0.0624, 0.0625],
        [0.0593, 0.0657],
        [0.0583, 0.0669],
        [0.0641, 0.0609],
        [0.0611, 0.0638],
        [0.0613, 0.0636]], device='cuda:0')
 Batch: 4 of identical_modal classification Duration: 0:00:00.543783
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0015],
        [0.0003, 0.0006],
        [0.0005, 0.0012],
        [0.0003, 0.0006],
        [0.0005, 0.0010],
        [0.0004, 0.0004],
        [0.0003, 0.0006],
        [0.0005, 0.0010],
        [0.0004, 0.0005],
        [0.0005, 0.0008],
        [0.0003, 0.0009],
        [0.0005, 0.0009],
        [0.0004, 0.0008],
        [0.0004, 0.0011],
        [0.0006, 0.0012],
        [0.0005, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0601, 0.0647],
        [0.0602, 0.0646],
        [0.0600, 0.0648],
        [0.0607, 0.0641],
        [0.0628, 0.0619],
        [0.0728, 0.0534],
        [0.0610, 0.0637],
        [0.0610, 0.0637],
        [0.0694, 0.0560],
        [0.0654, 0.0594],
        [0.0554, 0.0701],
        [0.0623, 0.0624],
        [0.0607, 0.0641],
        [0.0570, 0.0682],
        [0.0614, 0.0633],
        [0.0699, 0.0556]], device='cuda:0')
 Batch: 5 of identical_modal classification Duration: 0:00:00.410207
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0011],
        [0.0002, 0.0006],
        [0.0007, 0.0010],
        [0.0003, 0.0005],
        [0.0005, 0.0009],
        [0.0005, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0005, 0.0013],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0003, 0.0007],
        [0.0009, 0.0018],
        [0.0004, 0.0009],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0578, 0.0674],
        [0.0611, 0.0638],
        [0.0673, 0.0579],
        [0.0680, 0.0573],
        [0.0666, 0.0585],
        [0.0649, 0.0601],
        [0.0630, 0.0619],
        [0.0635, 0.0614],
        [0.0634, 0.0615],
        [0.0590, 0.0661],
        [0.0581, 0.0671],
        [0.0625, 0.0623],
        [0.0593, 0.0657],
        [0.0629, 0.0620],
        [0.0610, 0.0639],
        [0.0618, 0.0631]], device='cuda:0')
 Batch: 6 of identical_modal classification Duration: 0:00:00.484394
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0010],
        [0.0004, 0.0009],
        [0.0005, 0.0012],
        [0.0003, 0.0010],
        [0.0007, 0.0013],
        [0.0003, 0.0008],
        [0.0003, 0.0010],
        [0.0004, 0.0011],
        [0.0004, 0.0012],
        [0.0004, 0.0007],
        [0.0005, 0.0008],
        [0.0005, 0.0007],
        [0.0004, 0.0007],
        [0.0006, 0.0007],
        [0.0004, 0.0007],
        [0.0002, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0592, 0.0656],
        [0.0629, 0.0618],
        [0.0602, 0.0646],
        [0.0566, 0.0686],
        [0.0660, 0.0589],
        [0.0609, 0.0638],
        [0.0562, 0.0691],
        [0.0585, 0.0664],
        [0.0572, 0.0679],
        [0.0647, 0.0601],
        [0.0658, 0.0590],
        [0.0668, 0.0582],
        [0.0671, 0.0579],
        [0.0720, 0.0540],
        [0.0671, 0.0580],
        [0.0588, 0.0661]], device='cuda:0')
 Batch: 7 of identical_modal classification Duration: 0:00:00.294507
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0011],
        [0.0005, 0.0009],
        [0.0004, 0.0008],
        [0.0004, 0.0007],
        [0.0004, 0.0013],
        [0.0008, 0.0017],
        [0.0006, 0.0008],
        [0.0007, 0.0011],
        [0.0005, 0.0009],
        [0.0007, 0.0017],
        [0.0005, 0.0011],
        [0.0003, 0.0006],
        [0.0005, 0.0011],
        [0.0004, 0.0012],
        [0.0004, 0.0005],
        [0.0009, 0.0016]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0622, 0.0627],
        [0.0627, 0.0621],
        [0.0612, 0.0636],
        [0.0655, 0.0595],
        [0.0557, 0.0699],
        [0.0614, 0.0634],
        [0.0662, 0.0588],
        [0.0667, 0.0584],
        [0.0642, 0.0607],
        [0.0598, 0.0651],
        [0.0605, 0.0644],
        [0.0602, 0.0647],
        [0.0614, 0.0634],
        [0.0588, 0.0663],
        [0.0691, 0.0564],
        [0.0644, 0.0605]], device='cuda:0')
 Batch: 8 of identical_modal classification Duration: 0:00:00.430805
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0001, 0.0005],
        [0.0004, 0.0006],
        [0.0004, 0.0011],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0005],
        [0.0005, 0.0007],
        [0.0002, 0.0003],
        [0.0003, 0.0010],
        [0.0006, 0.0012],
        [0.0003, 0.0007],
        [0.0005, 0.0011],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0556, 0.0701],
        [0.0671, 0.0580],
        [0.0606, 0.0642],
        [0.0616, 0.0631],
        [0.0614, 0.0633],
        [0.0617, 0.0631],
        [0.0661, 0.0589],
        [0.0682, 0.0570],
        [0.0689, 0.0565],
        [0.0558, 0.0697],
        [0.0624, 0.0624],
        [0.0630, 0.0618],
        [0.0631, 0.0617],
        [0.0631, 0.0617],
        [0.0609, 0.0639],
        [0.0603, 0.0646]], device='cuda:0')
 Batch: 9 of identical_modal classification Duration: 0:00:00.411405
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0008, 0.0023],
        [0.0006, 0.0011],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0002, 0.0005],
        [0.0005, 0.0008],
        [0.0002, 0.0003],
        [0.0003, 0.0007],
        [0.0006, 0.0009],
        [0.0006, 0.0009],
        [0.0006, 0.0010],
        [0.0006, 0.0010],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0622, 0.0627],
        [0.0624, 0.0625],
        [0.0579, 0.0674],
        [0.0631, 0.0618],
        [0.0602, 0.0648],
        [0.0614, 0.0635],
        [0.0647, 0.0603],
        [0.0594, 0.0656],
        [0.0649, 0.0601],
        [0.0615, 0.0634],
        [0.0597, 0.0653],
        [0.0656, 0.0594],
        [0.0679, 0.0574],
        [0.0650, 0.0600],
        [0.0634, 0.0615],
        [0.0606, 0.0643]], device='cuda:0')
 Batch: 10 of identical_modal classification Duration: 0:00:00.432353
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0003, 0.0003],
        [0.0006, 0.0014],
        [0.0003, 0.0007],
        [0.0003, 0.0008],
        [0.0005, 0.0015],
        [0.0003, 0.0009],
        [0.0004, 0.0007],
        [0.0005, 0.0010],
        [0.0005, 0.0010],
        [0.0005, 0.0011],
        [0.0003, 0.0005],
        [0.0005, 0.0011],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0585, 0.0665],
        [0.0617, 0.0630],
        [0.0615, 0.0632],
        [0.0757, 0.0514],
        [0.0605, 0.0643],
        [0.0613, 0.0635],
        [0.0601, 0.0647],
        [0.0585, 0.0665],
        [0.0590, 0.0660],
        [0.0646, 0.0602],
        [0.0612, 0.0635],
        [0.0639, 0.0609],
        [0.0622, 0.0626],
        [0.0664, 0.0586],
        [0.0606, 0.0642],
        [0.0638, 0.0610]], device='cuda:0')
 Batch: 11 of identical_modal classification Duration: 0:00:00.368681
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0007, 0.0013],
        [0.0002, 0.0005],
        [0.0005, 0.0009],
        [0.0003, 0.0007],
        [0.0003, 0.0010],
        [0.0006, 0.0009],
        [0.0004, 0.0008],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1251],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1268, 0.1228],
        [0.1198, 0.1300],
        [0.1278, 0.1219],
        [0.1225, 0.1271],
        [0.1111, 0.1401],
        [0.1360, 0.1145],
        [0.1251, 0.1245],
        [0.1308, 0.1191]], device='cuda:0')
 Batch: 12 of identical_modal classification Duration: 0:00:00.213178
acc:  0.495
Time taken to execute the en SA task with prompt type identical_modal, variation 4 and batchsize 16: 0:00:05.147806
path ['42', 'en', 'bloom-big', 'SA', 'identical_modal', 'prompt_id_4']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([105, 2])
answers_probs just softmax dim 0: tensor([[0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095]], device='cuda:0')
tensor([[0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095],
        [0.0095, 0.0095]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA identical_modal 5 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0002, 0.0005],
        [0.0001, 0.0003],
        [0.0003, 0.0005],
        [0.0002, 0.0002],
        [0.0007, 0.0014],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0001, 0.0004],
        [0.0004, 0.0009],
        [0.0002, 0.0005],
        [0.0004, 0.0009],
        [0.0002, 0.0004],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0638, 0.0611],
        [0.0623, 0.0626],
        [0.0618, 0.0631],
        [0.0691, 0.0564],
        [0.0666, 0.0586],
        [0.0623, 0.0626],
        [0.0602, 0.0648],
        [0.0650, 0.0600],
        [0.0604, 0.0646],
        [0.0613, 0.0636],
        [0.0577, 0.0676],
        [0.0627, 0.0621],
        [0.0594, 0.0656],
        [0.0625, 0.0624],
        [0.0627, 0.0621],
        [0.0621, 0.0628]], device='cuda:0')
 Batch: 0 of identical_modal classification Duration: 0:00:00.555204
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0004, 0.0014],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0010],
        [0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0006, 0.0010],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0001, 0.0004],
        [0.0004, 0.0007],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0606, 0.0644],
        [0.0640, 0.0609],
        [0.0575, 0.0678],
        [0.0625, 0.0624],
        [0.0603, 0.0647],
        [0.0665, 0.0586],
        [0.0589, 0.0662],
        [0.0662, 0.0589],
        [0.0599, 0.0651],
        [0.0629, 0.0619],
        [0.0668, 0.0584],
        [0.0657, 0.0594],
        [0.0615, 0.0634],
        [0.0590, 0.0661],
        [0.0648, 0.0601],
        [0.0629, 0.0619]], device='cuda:0')
 Batch: 1 of identical_modal classification Duration: 0:00:00.415036
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0005, 0.0009],
        [0.0007, 0.0010],
        [0.0003, 0.0011],
        [0.0003, 0.0008],
        [0.0004, 0.0010],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0006, 0.0010],
        [0.0001, 0.0003],
        [0.0002, 0.0005],
        [0.0004, 0.0006],
        [0.0002, 0.0005],
        [0.0005, 0.0009],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0645, 0.0604],
        [0.0654, 0.0595],
        [0.0683, 0.0570],
        [0.0564, 0.0690],
        [0.0596, 0.0654],
        [0.0598, 0.0651],
        [0.0652, 0.0598],
        [0.0587, 0.0663],
        [0.0658, 0.0592],
        [0.0643, 0.0605],
        [0.0595, 0.0655],
        [0.0633, 0.0615],
        [0.0649, 0.0600],
        [0.0567, 0.0687],
        [0.0640, 0.0608],
        [0.0637, 0.0612]], device='cuda:0')
 Batch: 2 of identical_modal classification Duration: 0:00:00.340030
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0002, 0.0007],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0002, 0.0006],
        [0.0004, 0.0006],
        [0.0002, 0.0006],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0003, 0.0007],
        [0.0004, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0008],
        [0.0001, 0.0004],
        [0.0002, 0.0005],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0633, 0.0615],
        [0.0567, 0.0688],
        [0.0678, 0.0575],
        [0.0651, 0.0598],
        [0.0614, 0.0635],
        [0.0663, 0.0588],
        [0.0586, 0.0665],
        [0.0637, 0.0612],
        [0.0679, 0.0574],
        [0.0630, 0.0618],
        [0.0637, 0.0612],
        [0.0618, 0.0631],
        [0.0594, 0.0655],
        [0.0589, 0.0661],
        [0.0603, 0.0646],
        [0.0621, 0.0628]], device='cuda:0')
 Batch: 3 of identical_modal classification Duration: 0:00:00.332297
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0002, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0001, 0.0003],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0004],
        [0.0002, 0.0005],
        [0.0002, 0.0006],
        [0.0002, 0.0004],
        [0.0003, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0647, 0.0603],
        [0.0577, 0.0676],
        [0.0630, 0.0619],
        [0.0606, 0.0643],
        [0.0623, 0.0626],
        [0.0633, 0.0616],
        [0.0644, 0.0605],
        [0.0686, 0.0568],
        [0.0612, 0.0637],
        [0.0600, 0.0649],
        [0.0598, 0.0652],
        [0.0613, 0.0636],
        [0.0625, 0.0624],
        [0.0638, 0.0611],
        [0.0603, 0.0646],
        [0.0665, 0.0587]], device='cuda:0')
 Batch: 4 of identical_modal classification Duration: 0:00:00.453953
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0002, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0002, 0.0007],
        [0.0004, 0.0010],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0600, 0.0650],
        [0.0599, 0.0651],
        [0.0617, 0.0632],
        [0.0685, 0.0569],
        [0.0608, 0.0642],
        [0.0633, 0.0615],
        [0.0611, 0.0639],
        [0.0616, 0.0633],
        [0.0605, 0.0645],
        [0.0686, 0.0568],
        [0.0610, 0.0639],
        [0.0644, 0.0606],
        [0.0642, 0.0607],
        [0.0583, 0.0669],
        [0.0613, 0.0636],
        [0.0650, 0.0599]], device='cuda:0')
 Batch: 5 of identical_modal classification Duration: 0:00:00.365742
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0008],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0005, 0.0013],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0002, 0.0006],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0001, 0.0004],
        [0.0004, 0.0008],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0614, 0.0635],
        [0.0610, 0.0640],
        [0.0630, 0.0620],
        [0.0611, 0.0639],
        [0.0624, 0.0626],
        [0.0663, 0.0589],
        [0.0609, 0.0641],
        [0.0626, 0.0624],
        [0.0601, 0.0649],
        [0.0626, 0.0624],
        [0.0636, 0.0613],
        [0.0586, 0.0666],
        [0.0645, 0.0605],
        [0.0658, 0.0593],
        [0.0650, 0.0601],
        [0.0614, 0.0636]], device='cuda:0')
 Batch: 6 of identical_modal classification Duration: 0:00:00.450274
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[1.7440e-04, 3.1328e-04],
        [1.8644e-04, 3.5381e-04],
        [7.4565e-05, 3.5572e-04],
        [3.2449e-04, 7.2575e-04],
        [2.0909e-04, 4.0317e-04],
        [2.4724e-04, 4.5824e-04],
        [5.1355e-04, 6.7520e-04],
        [2.2626e-04, 2.9969e-04],
        [1.6117e-04, 3.8981e-04],
        [3.4213e-04, 7.8917e-04],
        [2.0182e-04, 3.7122e-04],
        [2.3401e-04, 8.1015e-04],
        [6.1846e-04, 1.0443e-03],
        [1.6654e-04, 4.6706e-04],
        [2.3639e-04, 6.8951e-04],
        [3.4237e-04, 6.5994e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0647, 0.0601],
        [0.0639, 0.0609],
        [0.0538, 0.0723],
        [0.0616, 0.0631],
        [0.0636, 0.0611],
        [0.0642, 0.0606],
        [0.0697, 0.0558],
        [0.0695, 0.0559],
        [0.0606, 0.0642],
        [0.0612, 0.0636],
        [0.0643, 0.0605],
        [0.0566, 0.0687],
        [0.0656, 0.0593],
        [0.0588, 0.0661],
        [0.0584, 0.0666],
        [0.0636, 0.0611]], device='cuda:0')
 Batch: 7 of identical_modal classification Duration: 0:00:00.430757
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0008],
        [0.0001, 0.0006],
        [0.0003, 0.0008],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0619, 0.0629],
        [0.0616, 0.0632],
        [0.0592, 0.0658],
        [0.0544, 0.0716],
        [0.0597, 0.0652],
        [0.0621, 0.0627],
        [0.0659, 0.0591],
        [0.0649, 0.0600],
        [0.0637, 0.0612],
        [0.0646, 0.0603],
        [0.0648, 0.0601],
        [0.0592, 0.0658],
        [0.0629, 0.0619],
        [0.0629, 0.0619],
        [0.0621, 0.0627],
        [0.0701, 0.0555]], device='cuda:0')
 Batch: 8 of identical_modal classification Duration: 0:00:00.321291
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0011],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0002, 0.0006],
        [0.0003, 0.0005],
        [0.0001, 0.0003],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0004, 0.0007],
        [0.0002, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0003],
        [0.0003, 0.0006],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0566, 0.0687],
        [0.0660, 0.0589],
        [0.0604, 0.0644],
        [0.0574, 0.0677],
        [0.0633, 0.0614],
        [0.0596, 0.0652],
        [0.0599, 0.0649],
        [0.0611, 0.0637],
        [0.0642, 0.0606],
        [0.0556, 0.0700],
        [0.0649, 0.0599],
        [0.0666, 0.0584],
        [0.0642, 0.0606],
        [0.0712, 0.0546],
        [0.0612, 0.0636],
        [0.0679, 0.0573]], device='cuda:0')
 Batch: 9 of identical_modal classification Duration: 0:00:00.403171
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0004, 0.0005],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0001, 0.0004],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0004, 0.0010],
        [0.0002, 0.0006],
        [0.0004, 0.0005],
        [0.0003, 0.0006],
        [0.0006, 0.0010],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0629, 0.0620],
        [0.0641, 0.0608],
        [0.0608, 0.0641],
        [0.0683, 0.0571],
        [0.0609, 0.0640],
        [0.0631, 0.0618],
        [0.0577, 0.0676],
        [0.0629, 0.0620],
        [0.0633, 0.0615],
        [0.0643, 0.0606],
        [0.0594, 0.0656],
        [0.0567, 0.0687],
        [0.0660, 0.0591],
        [0.0607, 0.0642],
        [0.0631, 0.0618],
        [0.0658, 0.0592]], device='cuda:0')
 Batch: 10 of identical_modal classification Duration: 0:00:00.315335
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0003, 0.0009],
        [0.0002, 0.0002],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0004, 0.0009],
        [0.0004, 0.0005],
        [0.0002, 0.0007],
        [0.0003, 0.0008],
        [0.0002, 0.0005],
        [0.0003, 0.0009],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0689, 0.0563],
        [0.0605, 0.0642],
        [0.0613, 0.0634],
        [0.0614, 0.0633],
        [0.0666, 0.0583],
        [0.0576, 0.0675],
        [0.0755, 0.0514],
        [0.0621, 0.0625],
        [0.0585, 0.0664],
        [0.0620, 0.0626],
        [0.0684, 0.0568],
        [0.0567, 0.0685],
        [0.0605, 0.0642],
        [0.0618, 0.0628],
        [0.0570, 0.0682],
        [0.0612, 0.0635]], device='cuda:0')
 Batch: 11 of identical_modal classification Duration: 0:00:00.363568
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0002, 0.0006],
        [0.0002, 0.0007],
        [0.0004, 0.0006],
        [0.0003, 0.0004],
        [0.0002, 0.0005],
        [0.0004, 0.0009],
        [0.0004, 0.0006],
        [0.0005, 0.0010]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1183, 0.1317],
        [0.1156, 0.1348],
        [0.1321, 0.1180],
        [0.1354, 0.1151],
        [0.1185, 0.1315],
        [0.1247, 0.1249],
        [0.1288, 0.1210],
        [0.1267, 0.1230]], device='cuda:0')
 Batch: 12 of identical_modal classification Duration: 0:00:00.160809
acc:  0.425
Time taken to execute the en SA task with prompt type identical_modal, variation 5 and batchsize 16: 0:00:04.928298
path ['42', 'en', 'bloom-big', 'SA', 'identical_modal', 'prompt_id_5']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([103, 2])
answers_probs just softmax dim 0: tensor([[0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097]], device='cuda:0')
tensor([[0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA identical_modal 6 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0006, 0.0007],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0004, 0.0008],
        [0.0005, 0.0010],
        [0.0003, 0.0005],
        [0.0004, 0.0005],
        [0.0003, 0.0007],
        [0.0004, 0.0009],
        [0.0004, 0.0009],
        [0.0002, 0.0006],
        [0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0006, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0631, 0.0618],
        [0.0632, 0.0617],
        [0.0671, 0.0582],
        [0.0618, 0.0631],
        [0.0599, 0.0651],
        [0.0626, 0.0623],
        [0.0626, 0.0623],
        [0.0621, 0.0629],
        [0.0675, 0.0578],
        [0.0609, 0.0641],
        [0.0611, 0.0639],
        [0.0613, 0.0636],
        [0.0580, 0.0672],
        [0.0619, 0.0630],
        [0.0609, 0.0641],
        [0.0662, 0.0589]], device='cuda:0')
 Batch: 0 of identical_modal classification Duration: 0:00:00.558434
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0005],
        [0.0002, 0.0005],
        [0.0005, 0.0007],
        [0.0003, 0.0005],
        [0.0005, 0.0009],
        [0.0007, 0.0013],
        [0.0004, 0.0007],
        [0.0006, 0.0012],
        [0.0005, 0.0012],
        [0.0004, 0.0011],
        [0.0006, 0.0016],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0006, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0688, 0.0566],
        [0.0613, 0.0636],
        [0.0678, 0.0575],
        [0.0638, 0.0611],
        [0.0637, 0.0612],
        [0.0623, 0.0626],
        [0.0631, 0.0618],
        [0.0619, 0.0630],
        [0.0597, 0.0653],
        [0.0597, 0.0653],
        [0.0587, 0.0664],
        [0.0623, 0.0626],
        [0.0613, 0.0636],
        [0.0599, 0.0651],
        [0.0639, 0.0610],
        [0.0619, 0.0630]], device='cuda:0')
 Batch: 1 of identical_modal classification Duration: 0:00:00.409540
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0003, 0.0004],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0005, 0.0009],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0005, 0.0007],
        [0.0009, 0.0015],
        [0.0005, 0.0007],
        [0.0007, 0.0012],
        [0.0004, 0.0006],
        [0.0006, 0.0009],
        [0.0006, 0.0013],
        [0.0008, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0587, 0.0665],
        [0.0666, 0.0585],
        [0.0610, 0.0639],
        [0.0639, 0.0610],
        [0.0601, 0.0649],
        [0.0622, 0.0627],
        [0.0611, 0.0638],
        [0.0587, 0.0665],
        [0.0659, 0.0592],
        [0.0635, 0.0614],
        [0.0650, 0.0600],
        [0.0630, 0.0619],
        [0.0624, 0.0625],
        [0.0649, 0.0601],
        [0.0589, 0.0662],
        [0.0641, 0.0609]], device='cuda:0')
 Batch: 2 of identical_modal classification Duration: 0:00:00.403660
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0012],
        [0.0004, 0.0008],
        [0.0005, 0.0008],
        [0.0004, 0.0011],
        [0.0003, 0.0006],
        [0.0006, 0.0009],
        [0.0004, 0.0008],
        [0.0007, 0.0014],
        [0.0003, 0.0008],
        [0.0006, 0.0006],
        [0.0004, 0.0007],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0005, 0.0015],
        [0.0004, 0.0006],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0617, 0.0631],
        [0.0619, 0.0629],
        [0.0639, 0.0609],
        [0.0572, 0.0680],
        [0.0620, 0.0628],
        [0.0667, 0.0584],
        [0.0615, 0.0633],
        [0.0609, 0.0639],
        [0.0595, 0.0654],
        [0.0710, 0.0549],
        [0.0640, 0.0608],
        [0.0588, 0.0663],
        [0.0628, 0.0620],
        [0.0561, 0.0694],
        [0.0665, 0.0586],
        [0.0656, 0.0594]], device='cuda:0')
 Batch: 3 of identical_modal classification Duration: 0:00:00.427083
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0009],
        [0.0011, 0.0021],
        [0.0004, 0.0007],
        [0.0007, 0.0008],
        [0.0004, 0.0006],
        [0.0005, 0.0014],
        [0.0004, 0.0007],
        [0.0005, 0.0009],
        [0.0004, 0.0011],
        [0.0003, 0.0007],
        [0.0009, 0.0011],
        [0.0004, 0.0007],
        [0.0009, 0.0026],
        [0.0006, 0.0010],
        [0.0007, 0.0012],
        [0.0008, 0.0014]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0651, 0.0598],
        [0.0620, 0.0628],
        [0.0640, 0.0608],
        [0.0699, 0.0557],
        [0.0633, 0.0615],
        [0.0560, 0.0695],
        [0.0620, 0.0628],
        [0.0624, 0.0624],
        [0.0568, 0.0685],
        [0.0611, 0.0637],
        [0.0685, 0.0568],
        [0.0630, 0.0618],
        [0.0567, 0.0686],
        [0.0625, 0.0622],
        [0.0637, 0.0611],
        [0.0629, 0.0619]], device='cuda:0')
 Batch: 4 of identical_modal classification Duration: 0:00:00.359669
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0011, 0.0013],
        [0.0003, 0.0005],
        [0.0004, 0.0010],
        [0.0005, 0.0006],
        [0.0006, 0.0011],
        [0.0006, 0.0009],
        [0.0006, 0.0013],
        [0.0003, 0.0004],
        [0.0006, 0.0015],
        [0.0008, 0.0012],
        [0.0006, 0.0014],
        [0.0005, 0.0008],
        [0.0004, 0.0006],
        [0.0005, 0.0009],
        [0.0006, 0.0011],
        [0.0004, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0692, 0.0563],
        [0.0616, 0.0632],
        [0.0582, 0.0669],
        [0.0673, 0.0579],
        [0.0617, 0.0631],
        [0.0656, 0.0594],
        [0.0584, 0.0667],
        [0.0669, 0.0582],
        [0.0587, 0.0663],
        [0.0644, 0.0605],
        [0.0582, 0.0669],
        [0.0626, 0.0622],
        [0.0645, 0.0604],
        [0.0609, 0.0640],
        [0.0623, 0.0625],
        [0.0594, 0.0655]], device='cuda:0')
 Batch: 5 of identical_modal classification Duration: 0:00:00.364875
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0006, 0.0011],
        [0.0004, 0.0009],
        [0.0005, 0.0005],
        [0.0004, 0.0005],
        [0.0005, 0.0007],
        [0.0006, 0.0013],
        [0.0004, 0.0006],
        [0.0007, 0.0014],
        [0.0004, 0.0007],
        [0.0006, 0.0008],
        [0.0005, 0.0009],
        [0.0003, 0.0006],
        [0.0006, 0.0009],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0610, 0.0638],
        [0.0634, 0.0614],
        [0.0610, 0.0638],
        [0.0575, 0.0677],
        [0.0699, 0.0557],
        [0.0657, 0.0593],
        [0.0659, 0.0591],
        [0.0594, 0.0656],
        [0.0675, 0.0577],
        [0.0601, 0.0648],
        [0.0601, 0.0648],
        [0.0662, 0.0589],
        [0.0614, 0.0634],
        [0.0580, 0.0671],
        [0.0641, 0.0608],
        [0.0590, 0.0660]], device='cuda:0')
 Batch: 6 of identical_modal classification Duration: 0:00:00.321424
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0010],
        [0.0004, 0.0005],
        [0.0004, 0.0007],
        [0.0006, 0.0008],
        [0.0008, 0.0014],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0010, 0.0018],
        [0.0005, 0.0012],
        [0.0005, 0.0007],
        [0.0004, 0.0007],
        [0.0006, 0.0008],
        [0.0007, 0.0014],
        [0.0001, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0634, 0.0614],
        [0.0693, 0.0562],
        [0.0611, 0.0637],
        [0.0654, 0.0595],
        [0.0614, 0.0634],
        [0.0634, 0.0614],
        [0.0601, 0.0648],
        [0.0610, 0.0638],
        [0.0642, 0.0607],
        [0.0624, 0.0623],
        [0.0594, 0.0656],
        [0.0674, 0.0577],
        [0.0630, 0.0618],
        [0.0653, 0.0596],
        [0.0599, 0.0650],
        [0.0533, 0.0730]], device='cuda:0')
 Batch: 7 of identical_modal classification Duration: 0:00:00.320844
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0003, 0.0009],
        [0.0003, 0.0006],
        [0.0006, 0.0011],
        [0.0004, 0.0008],
        [0.0005, 0.0007],
        [0.0006, 0.0011],
        [0.0006, 0.0010],
        [0.0002, 0.0006],
        [0.0003, 0.0011],
        [0.0006, 0.0011],
        [0.0006, 0.0012],
        [0.0006, 0.0009],
        [0.0004, 0.0008],
        [0.0005, 0.0009],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0624, 0.0625],
        [0.0576, 0.0677],
        [0.0605, 0.0644],
        [0.0638, 0.0610],
        [0.0618, 0.0630],
        [0.0660, 0.0590],
        [0.0637, 0.0612],
        [0.0634, 0.0615],
        [0.0583, 0.0669],
        [0.0562, 0.0694],
        [0.0647, 0.0603],
        [0.0620, 0.0628],
        [0.0667, 0.0584],
        [0.0638, 0.0610],
        [0.0619, 0.0629],
        [0.0672, 0.0580]], device='cuda:0')
 Batch: 8 of identical_modal classification Duration: 0:00:00.412701
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0008],
        [0.0005, 0.0012],
        [0.0005, 0.0007],
        [0.0005, 0.0008],
        [0.0004, 0.0007],
        [0.0006, 0.0011],
        [0.0005, 0.0009],
        [0.0006, 0.0007],
        [0.0005, 0.0008],
        [0.0005, 0.0008],
        [0.0004, 0.0006],
        [0.0003, 0.0008],
        [0.0005, 0.0007],
        [0.0005, 0.0011],
        [0.0005, 0.0008],
        [0.0004, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0623, 0.0625],
        [0.0590, 0.0661],
        [0.0653, 0.0597],
        [0.0642, 0.0607],
        [0.0617, 0.0632],
        [0.0617, 0.0632],
        [0.0611, 0.0638],
        [0.0690, 0.0565],
        [0.0622, 0.0627],
        [0.0629, 0.0620],
        [0.0629, 0.0620],
        [0.0591, 0.0660],
        [0.0650, 0.0600],
        [0.0592, 0.0659],
        [0.0643, 0.0606],
        [0.0600, 0.0650]], device='cuda:0')
 Batch: 9 of identical_modal classification Duration: 0:00:00.336249
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0004, 0.0009],
        [0.0006, 0.0009],
        [0.0004, 0.0011],
        [0.0003, 0.0007],
        [0.0006, 0.0010],
        [0.0004, 0.0008],
        [0.0004, 0.0006],
        [0.0008, 0.0010],
        [0.0002, 0.0005],
        [0.0003, 0.0009],
        [0.0005, 0.0008],
        [0.0003, 0.0003],
        [0.0005, 0.0008],
        [0.0004, 0.0007],
        [0.0006, 0.0013]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0608, 0.0640],
        [0.0614, 0.0633],
        [0.0641, 0.0607],
        [0.0568, 0.0685],
        [0.0603, 0.0644],
        [0.0622, 0.0625],
        [0.0618, 0.0629],
        [0.0651, 0.0598],
        [0.0688, 0.0566],
        [0.0582, 0.0668],
        [0.0582, 0.0668],
        [0.0646, 0.0602],
        [0.0754, 0.0516],
        [0.0628, 0.0619],
        [0.0605, 0.0643],
        [0.0592, 0.0657]], device='cuda:0')
 Batch: 10 of identical_modal classification Duration: 0:00:00.429527
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0007, 0.0010],
        [0.0004, 0.0011],
        [0.0004, 0.0006],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0006, 0.0011],
        [0.0007, 0.0010],
        [0.0004, 0.0006],
        [0.0004, 0.0008],
        [0.0004, 0.0009],
        [0.0003, 0.0004],
        [0.0003, 0.0008],
        [0.0006, 0.0009],
        [0.0002, 0.0007],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0651, 0.0598],
        [0.0577, 0.0674],
        [0.0652, 0.0597],
        [0.0687, 0.0567],
        [0.0632, 0.0616],
        [0.0596, 0.0653],
        [0.0611, 0.0637],
        [0.0662, 0.0588],
        [0.0675, 0.0577],
        [0.0602, 0.0647],
        [0.0608, 0.0640],
        [0.0633, 0.0615],
        [0.0594, 0.0655],
        [0.0659, 0.0591],
        [0.0555, 0.0701],
        [0.0603, 0.0646]], device='cuda:0')
 Batch: 11 of identical_modal classification Duration: 0:00:00.448971
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0007, 0.0010],
        [0.0005, 0.0009],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0002, 0.0005],
        [0.0004, 0.0009],
        [0.0007, 0.0010]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1220, 0.1279],
        [0.1296, 0.1204],
        [0.1262, 0.1236],
        [0.1237, 0.1261],
        [0.1313, 0.1188],
        [0.1190, 0.1310],
        [0.1174, 0.1328],
        [0.1308, 0.1193]], device='cuda:0')
 Batch: 12 of identical_modal classification Duration: 0:00:00.211048
acc:  0.45
Time taken to execute the en SA task with prompt type identical_modal, variation 6 and batchsize 16: 0:00:05.024833
path ['42', 'en', 'bloom-big', 'SA', 'identical_modal', 'prompt_id_6']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003],
        [0.0002, 0.0003]], device='cuda:0') torch.Size([104, 2])
answers_probs just softmax dim 0: tensor([[0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096]], device='cuda:0')
tensor([[0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA identical_modal 7 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0003, 0.0004],
        [0.0005, 0.0006],
        [0.0006, 0.0010],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0007],
        [0.0009, 0.0010],
        [0.0005, 0.0011],
        [0.0003, 0.0005],
        [0.0006, 0.0011],
        [0.0002, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0004],
        [0.0005, 0.0006],
        [0.0006, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0594, 0.0656],
        [0.0652, 0.0597],
        [0.0665, 0.0586],
        [0.0618, 0.0630],
        [0.0598, 0.0652],
        [0.0602, 0.0647],
        [0.0585, 0.0666],
        [0.0682, 0.0571],
        [0.0580, 0.0672],
        [0.0652, 0.0597],
        [0.0613, 0.0636],
        [0.0577, 0.0675],
        [0.0623, 0.0626],
        [0.0649, 0.0600],
        [0.0661, 0.0589],
        [0.0650, 0.0599]], device='cuda:0')
 Batch: 0 of identical_modal classification Duration: 0:00:00.232035
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0004, 0.0007],
        [0.0004, 0.0005],
        [0.0006, 0.0007],
        [0.0007, 0.0022],
        [0.0007, 0.0009],
        [0.0004, 0.0009],
        [0.0005, 0.0006],
        [0.0005, 0.0008],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0005, 0.0008],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0008, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0595, 0.0655],
        [0.0614, 0.0634],
        [0.0656, 0.0594],
        [0.0692, 0.0563],
        [0.0554, 0.0703],
        [0.0667, 0.0584],
        [0.0588, 0.0662],
        [0.0664, 0.0587],
        [0.0623, 0.0625],
        [0.0596, 0.0653],
        [0.0612, 0.0637],
        [0.0632, 0.0616],
        [0.0641, 0.0607],
        [0.0628, 0.0620],
        [0.0596, 0.0653],
        [0.0641, 0.0607]], device='cuda:0')
 Batch: 1 of identical_modal classification Duration: 0:00:00.363929
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0006],
        [0.0002, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0009],
        [0.0003, 0.0009],
        [0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0005, 0.0006],
        [0.0004, 0.0011],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0004, 0.0009],
        [0.0005, 0.0006],
        [0.0003, 0.0010],
        [0.0005, 0.0009],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0677, 0.0574],
        [0.0573, 0.0678],
        [0.0665, 0.0584],
        [0.0582, 0.0668],
        [0.0564, 0.0689],
        [0.0655, 0.0593],
        [0.0618, 0.0629],
        [0.0673, 0.0578],
        [0.0572, 0.0680],
        [0.0618, 0.0629],
        [0.0675, 0.0576],
        [0.0604, 0.0644],
        [0.0679, 0.0572],
        [0.0562, 0.0692],
        [0.0628, 0.0619],
        [0.0654, 0.0594]], device='cuda:0')
 Batch: 2 of identical_modal classification Duration: 0:00:00.314308
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0005, 0.0007],
        [0.0005, 0.0008],
        [0.0003, 0.0007],
        [0.0004, 0.0012],
        [0.0003, 0.0005],
        [0.0004, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0002, 0.0006],
        [0.0002, 0.0006],
        [0.0003, 0.0007],
        [0.0004, 0.0013],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0601, 0.0648],
        [0.0676, 0.0576],
        [0.0645, 0.0603],
        [0.0621, 0.0627],
        [0.0575, 0.0677],
        [0.0625, 0.0623],
        [0.0720, 0.0540],
        [0.0636, 0.0612],
        [0.0640, 0.0609],
        [0.0572, 0.0680],
        [0.0589, 0.0661],
        [0.0614, 0.0634],
        [0.0581, 0.0670],
        [0.0644, 0.0604],
        [0.0617, 0.0630],
        [0.0644, 0.0604]], device='cuda:0')
 Batch: 3 of identical_modal classification Duration: 0:00:00.553061
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0004, 0.0005],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0005, 0.0009],
        [0.0004, 0.0008],
        [0.0005, 0.0008],
        [0.0009, 0.0015],
        [0.0003, 0.0007],
        [0.0005, 0.0008],
        [0.0006, 0.0014]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0594, 0.0657],
        [0.0614, 0.0635],
        [0.0651, 0.0600],
        [0.0595, 0.0655],
        [0.0620, 0.0629],
        [0.0664, 0.0587],
        [0.0638, 0.0612],
        [0.0622, 0.0627],
        [0.0606, 0.0644],
        [0.0624, 0.0625],
        [0.0626, 0.0623],
        [0.0669, 0.0583],
        [0.0640, 0.0610],
        [0.0594, 0.0656],
        [0.0640, 0.0610],
        [0.0602, 0.0648]], device='cuda:0')
 Batch: 4 of identical_modal classification Duration: 0:00:00.449199
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0009],
        [0.0003, 0.0007],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0006, 0.0009],
        [0.0004, 0.0008],
        [0.0003, 0.0002],
        [0.0002, 0.0004],
        [0.0007, 0.0012],
        [0.0003, 0.0009],
        [0.0004, 0.0007],
        [0.0008, 0.0013],
        [0.0002, 0.0005],
        [0.0001, 0.0005],
        [0.0003, 0.0003],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0570, 0.0680],
        [0.0611, 0.0635],
        [0.0634, 0.0612],
        [0.0622, 0.0624],
        [0.0654, 0.0593],
        [0.0624, 0.0622],
        [0.0767, 0.0506],
        [0.0591, 0.0657],
        [0.0623, 0.0623],
        [0.0581, 0.0668],
        [0.0654, 0.0593],
        [0.0645, 0.0602],
        [0.0605, 0.0641],
        [0.0533, 0.0728],
        [0.0688, 0.0564],
        [0.0596, 0.0651]], device='cuda:0')
 Batch: 5 of identical_modal classification Duration: 0:00:00.363608
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0007, 0.0011],
        [0.0004, 0.0010],
        [0.0007, 0.0011],
        [0.0005, 0.0007],
        [0.0003, 0.0008],
        [0.0004, 0.0010],
        [0.0005, 0.0008],
        [0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0645, 0.0604],
        [0.0608, 0.0641],
        [0.0621, 0.0628],
        [0.0652, 0.0597],
        [0.0583, 0.0669],
        [0.0642, 0.0607],
        [0.0671, 0.0581],
        [0.0571, 0.0682],
        [0.0582, 0.0670],
        [0.0643, 0.0606],
        [0.0645, 0.0604],
        [0.0614, 0.0635],
        [0.0629, 0.0620],
        [0.0632, 0.0616],
        [0.0596, 0.0654],
        [0.0666, 0.0585]], device='cuda:0')
 Batch: 6 of identical_modal classification Duration: 0:00:00.364263
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0009],
        [0.0005, 0.0009],
        [0.0002, 0.0005],
        [0.0005, 0.0010],
        [0.0002, 0.0004],
        [0.0003, 0.0007],
        [0.0005, 0.0012],
        [0.0004, 0.0007],
        [0.0005, 0.0009],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0004, 0.0009],
        [0.0002, 0.0005],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0622, 0.0627],
        [0.0601, 0.0649],
        [0.0593, 0.0658],
        [0.0650, 0.0600],
        [0.0618, 0.0631],
        [0.0637, 0.0612],
        [0.0628, 0.0621],
        [0.0617, 0.0633],
        [0.0603, 0.0647],
        [0.0635, 0.0614],
        [0.0640, 0.0610],
        [0.0645, 0.0604],
        [0.0602, 0.0648],
        [0.0619, 0.0630],
        [0.0598, 0.0653],
        [0.0693, 0.0563]], device='cuda:0')
 Batch: 7 of identical_modal classification Duration: 0:00:00.343171
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0005, 0.0006],
        [0.0004, 0.0004],
        [0.0004, 0.0007],
        [0.0004, 0.0011],
        [0.0004, 0.0008],
        [0.0003, 0.0006],
        [0.0005, 0.0008],
        [0.0004, 0.0006],
        [0.0002, 0.0005],
        [0.0004, 0.0005],
        [0.0002, 0.0004],
        [0.0005, 0.0009],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0003, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0598, 0.0651],
        [0.0678, 0.0575],
        [0.0694, 0.0561],
        [0.0613, 0.0636],
        [0.0561, 0.0694],
        [0.0616, 0.0632],
        [0.0609, 0.0639],
        [0.0643, 0.0606],
        [0.0655, 0.0595],
        [0.0582, 0.0669],
        [0.0661, 0.0589],
        [0.0623, 0.0626],
        [0.0601, 0.0648],
        [0.0634, 0.0614],
        [0.0604, 0.0645],
        [0.0629, 0.0619]], device='cuda:0')
 Batch: 8 of identical_modal classification Duration: 0:00:00.457956
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0002, 0.0005],
        [0.0004, 0.0009],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0005, 0.0005],
        [0.0004, 0.0008],
        [0.0005, 0.0008],
        [0.0005, 0.0009],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0002, 0.0003],
        [0.0004, 0.0013],
        [0.0005, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0592, 0.0658],
        [0.0572, 0.0681],
        [0.0603, 0.0646],
        [0.0630, 0.0618],
        [0.0646, 0.0603],
        [0.0627, 0.0621],
        [0.0616, 0.0632],
        [0.0708, 0.0550],
        [0.0617, 0.0631],
        [0.0635, 0.0613],
        [0.0636, 0.0612],
        [0.0628, 0.0620],
        [0.0619, 0.0629],
        [0.0675, 0.0577],
        [0.0549, 0.0709],
        [0.0646, 0.0603]], device='cuda:0')
 Batch: 9 of identical_modal classification Duration: 0:00:00.322962
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0011],
        [0.0002, 0.0005],
        [0.0006, 0.0011],
        [0.0004, 0.0007],
        [0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0005, 0.0011],
        [0.0004, 0.0006],
        [0.0005, 0.0006],
        [0.0007, 0.0012],
        [0.0007, 0.0011],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0003, 0.0010],
        [0.0002, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0596, 0.0653],
        [0.0559, 0.0696],
        [0.0614, 0.0634],
        [0.0625, 0.0623],
        [0.0638, 0.0611],
        [0.0641, 0.0607],
        [0.0641, 0.0607],
        [0.0610, 0.0639],
        [0.0668, 0.0583],
        [0.0675, 0.0577],
        [0.0646, 0.0603],
        [0.0647, 0.0602],
        [0.0651, 0.0598],
        [0.0646, 0.0603],
        [0.0558, 0.0698],
        [0.0587, 0.0664]], device='cuda:0')
 Batch: 10 of identical_modal classification Duration: 0:00:00.428550
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0009, 0.0017],
        [0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0003, 0.0008],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0004, 0.0010],
        [0.0003, 0.0008],
        [0.0003, 0.0008],
        [0.0006, 0.0010],
        [0.0002, 0.0004],
        [0.0005, 0.0011],
        [0.0003, 0.0008],
        [0.0002, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0642, 0.0608],
        [0.0629, 0.0619],
        [0.0621, 0.0628],
        [0.0647, 0.0602],
        [0.0583, 0.0669],
        [0.0677, 0.0575],
        [0.0645, 0.0604],
        [0.0658, 0.0593],
        [0.0618, 0.0631],
        [0.0612, 0.0637],
        [0.0616, 0.0633],
        [0.0654, 0.0596],
        [0.0612, 0.0637],
        [0.0636, 0.0613],
        [0.0587, 0.0664],
        [0.0563, 0.0692]], device='cuda:0')
 Batch: 11 of identical_modal classification Duration: 0:00:00.360824
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0005, 0.0009],
        [0.0002, 0.0005],
        [0.0003, 0.0004],
        [0.0002, 0.0004],
        [0.0003, 0.0008]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1252, 0.1247],
        [0.1279, 0.1221],
        [0.1233, 0.1266],
        [0.1254, 0.1245],
        [0.1191, 0.1311],
        [0.1296, 0.1205],
        [0.1291, 0.1209],
        [0.1204, 0.1296]], device='cuda:0')
 Batch: 12 of identical_modal classification Duration: 0:00:00.216643
acc:  0.405
Time taken to execute the en SA task with prompt type identical_modal, variation 7 and batchsize 16: 0:00:04.792398
path ['42', 'en', 'bloom-big', 'SA', 'identical_modal', 'prompt_id_7']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([103, 2])
answers_probs just softmax dim 0: tensor([[0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097]], device='cuda:0')
tensor([[0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097],
        [0.0097, 0.0097]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA identical_modal 8 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0011],
        [0.0005, 0.0007],
        [0.0003, 0.0005],
        [0.0005, 0.0006],
        [0.0010, 0.0018],
        [0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0002, 0.0008],
        [0.0005, 0.0008],
        [0.0004, 0.0007],
        [0.0006, 0.0008],
        [0.0005, 0.0007],
        [0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0008, 0.0009],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0597, 0.0653],
        [0.0631, 0.0617],
        [0.0649, 0.0600],
        [0.0664, 0.0586],
        [0.0618, 0.0630],
        [0.0609, 0.0639],
        [0.0610, 0.0638],
        [0.0539, 0.0723],
        [0.0633, 0.0615],
        [0.0600, 0.0649],
        [0.0670, 0.0581],
        [0.0664, 0.0586],
        [0.0599, 0.0650],
        [0.0608, 0.0640],
        [0.0681, 0.0572],
        [0.0627, 0.0621]], device='cuda:0')
 Batch: 0 of identical_modal classification Duration: 0:00:00.368417
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0004, 0.0010],
        [0.0004, 0.0016],
        [0.0008, 0.0011],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0004, 0.0006],
        [0.0005, 0.0009],
        [0.0003, 0.0008],
        [0.0006, 0.0008],
        [0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0004, 0.0008],
        [0.0004, 0.0010]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0621, 0.0627],
        [0.0599, 0.0650],
        [0.0548, 0.0710],
        [0.0676, 0.0576],
        [0.0637, 0.0612],
        [0.0655, 0.0595],
        [0.0628, 0.0621],
        [0.0613, 0.0636],
        [0.0650, 0.0600],
        [0.0639, 0.0609],
        [0.0593, 0.0657],
        [0.0672, 0.0580],
        [0.0619, 0.0629],
        [0.0631, 0.0617],
        [0.0617, 0.0632],
        [0.0602, 0.0648]], device='cuda:0')
 Batch: 1 of identical_modal classification Duration: 0:00:00.363661
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0009],
        [0.0005, 0.0009],
        [0.0005, 0.0010],
        [0.0006, 0.0008],
        [0.0005, 0.0011],
        [0.0005, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0006],
        [0.0004, 0.0009],
        [0.0006, 0.0008],
        [0.0005, 0.0010],
        [0.0009, 0.0024],
        [0.0006, 0.0013],
        [0.0006, 0.0009],
        [0.0009, 0.0016],
        [0.0002, 0.0002]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0598, 0.0651],
        [0.0612, 0.0636],
        [0.0602, 0.0648],
        [0.0659, 0.0591],
        [0.0596, 0.0653],
        [0.0669, 0.0582],
        [0.0633, 0.0615],
        [0.0661, 0.0589],
        [0.0596, 0.0653],
        [0.0664, 0.0587],
        [0.0611, 0.0637],
        [0.0563, 0.0692],
        [0.0599, 0.0650],
        [0.0643, 0.0606],
        [0.0610, 0.0639],
        [0.0683, 0.0570]], device='cuda:0')
 Batch: 2 of identical_modal classification Duration: 0:00:00.363893
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0010],
        [0.0006, 0.0014],
        [0.0003, 0.0005],
        [0.0004, 0.0009],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0006, 0.0010],
        [0.0005, 0.0005],
        [0.0008, 0.0016],
        [0.0003, 0.0007],
        [0.0005, 0.0006],
        [0.0006, 0.0007],
        [0.0006, 0.0008],
        [0.0006, 0.0011],
        [0.0004, 0.0008],
        [0.0006, 0.0008]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0622, 0.0626],
        [0.0585, 0.0666],
        [0.0622, 0.0626],
        [0.0588, 0.0663],
        [0.0595, 0.0655],
        [0.0618, 0.0631],
        [0.0622, 0.0626],
        [0.0683, 0.0571],
        [0.0606, 0.0643],
        [0.0592, 0.0658],
        [0.0671, 0.0581],
        [0.0676, 0.0576],
        [0.0642, 0.0607],
        [0.0612, 0.0637],
        [0.0621, 0.0628],
        [0.0642, 0.0607]], device='cuda:0')
 Batch: 3 of identical_modal classification Duration: 0:00:00.449198
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0005, 0.0010],
        [0.0006, 0.0015],
        [0.0003, 0.0010],
        [0.0005, 0.0010],
        [0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0004, 0.0008],
        [0.0005, 0.0008],
        [0.0006, 0.0010],
        [0.0007, 0.0013],
        [0.0006, 0.0009],
        [0.0003, 0.0005],
        [0.0005, 0.0008],
        [0.0004, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0632, 0.0617],
        [0.0646, 0.0604],
        [0.0612, 0.0637],
        [0.0585, 0.0667],
        [0.0558, 0.0699],
        [0.0621, 0.0628],
        [0.0620, 0.0629],
        [0.0632, 0.0617],
        [0.0602, 0.0648],
        [0.0648, 0.0601],
        [0.0633, 0.0616],
        [0.0618, 0.0631],
        [0.0632, 0.0617],
        [0.0658, 0.0592],
        [0.0655, 0.0596],
        [0.0648, 0.0601]], device='cuda:0')
 Batch: 4 of identical_modal classification Duration: 0:00:00.411814
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0011, 0.0017],
        [0.0002, 0.0003],
        [0.0005, 0.0009],
        [0.0006, 0.0012],
        [0.0005, 0.0010],
        [0.0003, 0.0005],
        [0.0006, 0.0010],
        [0.0005, 0.0010],
        [0.0004, 0.0006],
        [0.0003, 0.0008],
        [0.0002, 0.0003],
        [0.0004, 0.0006],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0617, 0.0632],
        [0.0630, 0.0620],
        [0.0602, 0.0648],
        [0.0651, 0.0599],
        [0.0642, 0.0607],
        [0.0641, 0.0608],
        [0.0612, 0.0638],
        [0.0610, 0.0640],
        [0.0623, 0.0626],
        [0.0646, 0.0604],
        [0.0597, 0.0653],
        [0.0621, 0.0629],
        [0.0579, 0.0674],
        [0.0657, 0.0594],
        [0.0653, 0.0597],
        [0.0618, 0.0631]], device='cuda:0')
 Batch: 5 of identical_modal classification Duration: 0:00:00.457859
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0004, 0.0007],
        [0.0004, 0.0008],
        [0.0007, 0.0009],
        [0.0005, 0.0008],
        [0.0006, 0.0009],
        [0.0004, 0.0007],
        [0.0004, 0.0007],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0008],
        [0.0004, 0.0010],
        [0.0004, 0.0005],
        [0.0006, 0.0011],
        [0.0005, 0.0011],
        [0.0006, 0.0011]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0622, 0.0627],
        [0.0635, 0.0614],
        [0.0590, 0.0661],
        [0.0686, 0.0569],
        [0.0643, 0.0607],
        [0.0655, 0.0595],
        [0.0618, 0.0631],
        [0.0615, 0.0634],
        [0.0626, 0.0622],
        [0.0640, 0.0609],
        [0.0600, 0.0650],
        [0.0585, 0.0667],
        [0.0660, 0.0591],
        [0.0622, 0.0627],
        [0.0585, 0.0667],
        [0.0619, 0.0630]], device='cuda:0')
 Batch: 6 of identical_modal classification Duration: 0:00:00.362806
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0007],
        [0.0008, 0.0012],
        [0.0003, 0.0007],
        [0.0002, 0.0005],
        [0.0005, 0.0009],
        [0.0004, 0.0007],
        [0.0007, 0.0010],
        [0.0003, 0.0005],
        [0.0006, 0.0010],
        [0.0003, 0.0006],
        [0.0005, 0.0008],
        [0.0004, 0.0007],
        [0.0003, 0.0004],
        [0.0010, 0.0017],
        [0.0004, 0.0009],
        [0.0005, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0634, 0.0615],
        [0.0653, 0.0598],
        [0.0580, 0.0672],
        [0.0592, 0.0659],
        [0.0621, 0.0628],
        [0.0614, 0.0636],
        [0.0663, 0.0589],
        [0.0643, 0.0606],
        [0.0629, 0.0620],
        [0.0593, 0.0657],
        [0.0644, 0.0605],
        [0.0639, 0.0610],
        [0.0663, 0.0589],
        [0.0635, 0.0614],
        [0.0612, 0.0638],
        [0.0586, 0.0665]], device='cuda:0')
 Batch: 7 of identical_modal classification Duration: 0:00:00.336866
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0004, 0.0009],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0003, 0.0005],
        [0.0009, 0.0012],
        [0.0004, 0.0005],
        [0.0004, 0.0012],
        [0.0004, 0.0010],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0005, 0.0010],
        [0.0004, 0.0012],
        [0.0005, 0.0009],
        [0.0003, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0642, 0.0607],
        [0.0602, 0.0647],
        [0.0615, 0.0633],
        [0.0663, 0.0588],
        [0.0624, 0.0625],
        [0.0628, 0.0620],
        [0.0695, 0.0560],
        [0.0686, 0.0568],
        [0.0585, 0.0666],
        [0.0592, 0.0658],
        [0.0622, 0.0627],
        [0.0610, 0.0639],
        [0.0615, 0.0633],
        [0.0580, 0.0672],
        [0.0639, 0.0609],
        [0.0601, 0.0648]], device='cuda:0')
 Batch: 8 of identical_modal classification Duration: 0:00:00.316165
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0009],
        [0.0007, 0.0011],
        [0.0006, 0.0011],
        [0.0002, 0.0004],
        [0.0006, 0.0012],
        [0.0005, 0.0008],
        [0.0003, 0.0007],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0005, 0.0008],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0005, 0.0010],
        [0.0004, 0.0007],
        [0.0008, 0.0013],
        [0.0007, 0.0012]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0631, 0.0618],
        [0.0654, 0.0597],
        [0.0621, 0.0628],
        [0.0601, 0.0650],
        [0.0613, 0.0636],
        [0.0629, 0.0621],
        [0.0590, 0.0662],
        [0.0602, 0.0649],
        [0.0636, 0.0614],
        [0.0630, 0.0619],
        [0.0622, 0.0627],
        [0.0638, 0.0612],
        [0.0619, 0.0631],
        [0.0638, 0.0612],
        [0.0644, 0.0606],
        [0.0631, 0.0618]], device='cuda:0')
 Batch: 9 of identical_modal classification Duration: 0:00:00.551600
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0006, 0.0008],
        [0.0004, 0.0007],
        [0.0003, 0.0008],
        [0.0005, 0.0008],
        [0.0003, 0.0007],
        [0.0004, 0.0006],
        [0.0006, 0.0012],
        [0.0004, 0.0005],
        [0.0004, 0.0011],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0005, 0.0007],
        [0.0004, 0.0010],
        [0.0004, 0.0008],
        [0.0004, 0.0006],
        [0.0002, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0679, 0.0574],
        [0.0634, 0.0614],
        [0.0571, 0.0681],
        [0.0652, 0.0597],
        [0.0601, 0.0648],
        [0.0631, 0.0617],
        [0.0614, 0.0634],
        [0.0669, 0.0582],
        [0.0568, 0.0686],
        [0.0631, 0.0617],
        [0.0614, 0.0634],
        [0.0665, 0.0586],
        [0.0580, 0.0671],
        [0.0618, 0.0630],
        [0.0678, 0.0575],
        [0.0595, 0.0655]], device='cuda:0')
 Batch: 10 of identical_modal classification Duration: 0:00:00.314661
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0004],
        [0.0006, 0.0008],
        [0.0003, 0.0003],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0006, 0.0012],
        [0.0004, 0.0005],
        [0.0004, 0.0007],
        [0.0004, 0.0010],
        [0.0006, 0.0012],
        [0.0002, 0.0004],
        [0.0003, 0.0008],
        [0.0004, 0.0007],
        [0.0003, 0.0006],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0677, 0.0575],
        [0.0657, 0.0592],
        [0.0739, 0.0527],
        [0.0615, 0.0632],
        [0.0598, 0.0650],
        [0.0607, 0.0641],
        [0.0605, 0.0643],
        [0.0676, 0.0576],
        [0.0624, 0.0623],
        [0.0581, 0.0670],
        [0.0609, 0.0639],
        [0.0588, 0.0662],
        [0.0577, 0.0674],
        [0.0638, 0.0609],
        [0.0587, 0.0663],
        [0.0623, 0.0624]], device='cuda:0')
 Batch: 11 of identical_modal classification Duration: 0:00:00.361740
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0003],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0006],
        [0.0001, 0.0005],
        [0.0005, 0.0009]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1182, 0.1313],
        [0.1256, 0.1236],
        [0.1426, 0.1088],
        [0.1270, 0.1222],
        [0.1259, 0.1233],
        [0.1302, 0.1192],
        [0.1054, 0.1473],
        [0.1249, 0.1243]], device='cuda:0')
 Batch: 12 of identical_modal classification Duration: 0:00:00.160570
acc:  0.475
Time taken to execute the en SA task with prompt type identical_modal, variation 8 and batchsize 16: 0:00:04.841087
path ['42', 'en', 'bloom-big', 'SA', 'identical_modal', 'prompt_id_8']
probs_ shape 2 torch.Size([1, 1])
probs_ shape 2 torch.Size([1, 1])
answers_probs before norm: tensor([[0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001],
        [0.0001, 0.0001]], device='cuda:0') torch.Size([104, 2])
answers_probs just softmax dim 0: tensor([[0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096]], device='cuda:0')
tensor([[0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096],
        [0.0096, 0.0096]], device='cuda:0')
----------- 42 en bigscience/bloom-7b1 SA identical_modal 9 200 16 --------------
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0005],
        [0.0006, 0.0010],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0005, 0.0011],
        [0.0002, 0.0003],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0004, 0.0007],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0614, 0.0636],
        [0.0637, 0.0613],
        [0.0690, 0.0565],
        [0.0609, 0.0640],
        [0.0617, 0.0632],
        [0.0625, 0.0624],
        [0.0613, 0.0637],
        [0.0668, 0.0584],
        [0.0606, 0.0643],
        [0.0630, 0.0619],
        [0.0607, 0.0642],
        [0.0602, 0.0648],
        [0.0610, 0.0639],
        [0.0621, 0.0628],
        [0.0616, 0.0634],
        [0.0633, 0.0616]], device='cuda:0')
 Batch: 0 of identical_modal classification Duration: 0:00:00.340448
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0007],
        [0.0006, 0.0010],
        [0.0001, 0.0003],
        [0.0003, 0.0004],
        [0.0002, 0.0004],
        [0.0002, 0.0003],
        [0.0002, 0.0006],
        [0.0003, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0002],
        [0.0004, 0.0007],
        [0.0002, 0.0003],
        [0.0004, 0.0006],
        [0.0006, 0.0007],
        [0.0004, 0.0006],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0648, 0.0601],
        [0.0614, 0.0634],
        [0.0557, 0.0699],
        [0.0653, 0.0596],
        [0.0596, 0.0653],
        [0.0602, 0.0646],
        [0.0565, 0.0688],
        [0.0625, 0.0622],
        [0.0602, 0.0646],
        [0.0729, 0.0534],
        [0.0625, 0.0622],
        [0.0644, 0.0604],
        [0.0629, 0.0619],
        [0.0673, 0.0578],
        [0.0631, 0.0617],
        [0.0608, 0.0640]], device='cuda:0')
 Batch: 1 of identical_modal classification Duration: 0:00:00.359468
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0005],
        [0.0002, 0.0005],
        [0.0005, 0.0007],
        [0.0003, 0.0006],
        [0.0003, 0.0004],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0009],
        [0.0003, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0002, 0.0007],
        [0.0008, 0.0012],
        [0.0004, 0.0007],
        [0.0002, 0.0002],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0592, 0.0657],
        [0.0615, 0.0632],
        [0.0648, 0.0600],
        [0.0599, 0.0649],
        [0.0684, 0.0569],
        [0.0583, 0.0668],
        [0.0622, 0.0626],
        [0.0626, 0.0621],
        [0.0685, 0.0568],
        [0.0645, 0.0603],
        [0.0576, 0.0675],
        [0.0540, 0.0720],
        [0.0651, 0.0598],
        [0.0619, 0.0628],
        [0.0701, 0.0555],
        [0.0615, 0.0632]], device='cuda:0')
 Batch: 2 of identical_modal classification Duration: 0:00:00.435576
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[5.1880e-04, 9.1028e-04],
        [4.3678e-04, 7.4291e-04],
        [4.7207e-04, 6.8665e-04],
        [8.3983e-05, 3.3998e-04],
        [3.2711e-04, 5.3930e-04],
        [3.2783e-04, 6.5231e-04],
        [1.4579e-04, 3.5524e-04],
        [2.9230e-04, 5.6791e-04],
        [2.5749e-04, 4.4513e-04],
        [2.9969e-04, 3.5310e-04],
        [3.3736e-04, 5.4359e-04],
        [3.8314e-04, 6.1226e-04],
        [3.3307e-04, 5.4073e-04],
        [3.3069e-04, 6.9475e-04],
        [4.7636e-04, 6.5136e-04],
        [2.3460e-04, 5.0831e-04]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0628, 0.0620],
        [0.0632, 0.0616],
        [0.0656, 0.0593],
        [0.0532, 0.0732],
        [0.0637, 0.0611],
        [0.0610, 0.0638],
        [0.0584, 0.0667],
        [0.0613, 0.0635],
        [0.0630, 0.0618],
        [0.0691, 0.0564],
        [0.0640, 0.0608],
        [0.0641, 0.0607],
        [0.0639, 0.0609],
        [0.0603, 0.0646],
        [0.0666, 0.0585],
        [0.0599, 0.0650]], device='cuda:0')
 Batch: 3 of identical_modal classification Duration: 0:00:00.486672
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0006],
        [0.0004, 0.0006],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0004, 0.0005],
        [0.0003, 0.0008],
        [0.0003, 0.0006],
        [0.0002, 0.0005],
        [0.0003, 0.0006],
        [0.0005, 0.0011],
        [0.0005, 0.0009],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0646, 0.0603],
        [0.0652, 0.0598],
        [0.0595, 0.0655],
        [0.0636, 0.0614],
        [0.0681, 0.0572],
        [0.0591, 0.0659],
        [0.0628, 0.0621],
        [0.0597, 0.0653],
        [0.0611, 0.0638],
        [0.0617, 0.0632],
        [0.0627, 0.0622],
        [0.0626, 0.0623],
        [0.0599, 0.0651],
        [0.0662, 0.0589],
        [0.0631, 0.0618],
        [0.0600, 0.0650]], device='cuda:0')
 Batch: 4 of identical_modal classification Duration: 0:00:00.316653
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0004],
        [0.0004, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0007],
        [0.0004, 0.0009],
        [0.0004, 0.0006],
        [0.0002, 0.0007],
        [0.0003, 0.0005],
        [0.0002, 0.0005],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0005, 0.0006],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0668, 0.0583],
        [0.0677, 0.0575],
        [0.0614, 0.0634],
        [0.0619, 0.0629],
        [0.0579, 0.0673],
        [0.0638, 0.0610],
        [0.0547, 0.0711],
        [0.0611, 0.0638],
        [0.0588, 0.0662],
        [0.0617, 0.0631],
        [0.0653, 0.0596],
        [0.0687, 0.0566],
        [0.0617, 0.0631],
        [0.0622, 0.0626],
        [0.0648, 0.0601],
        [0.0615, 0.0633]], device='cuda:0')
 Batch: 5 of identical_modal classification Duration: 0:00:00.359229
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0003, 0.0007],
        [0.0004, 0.0006],
        [0.0005, 0.0008],
        [0.0002, 0.0005],
        [0.0002, 0.0003],
        [0.0004, 0.0005],
        [0.0004, 0.0005],
        [0.0002, 0.0005],
        [0.0002, 0.0004],
        [0.0004, 0.0006],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0002, 0.0005],
        [0.0006, 0.0008],
        [0.0005, 0.0006]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0600, 0.0650],
        [0.0586, 0.0665],
        [0.0633, 0.0615],
        [0.0622, 0.0627],
        [0.0577, 0.0675],
        [0.0630, 0.0619],
        [0.0672, 0.0580],
        [0.0674, 0.0578],
        [0.0607, 0.0642],
        [0.0590, 0.0661],
        [0.0626, 0.0622],
        [0.0632, 0.0617],
        [0.0633, 0.0615],
        [0.0587, 0.0664],
        [0.0655, 0.0595],
        [0.0677, 0.0576]], device='cuda:0')
 Batch: 6 of identical_modal classification Duration: 0:00:00.334659
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0006, 0.0009],
        [0.0002, 0.0004],
        [0.0002, 0.0002],
        [0.0005, 0.0008],
        [0.0003, 0.0007],
        [0.0002, 0.0003],
        [0.0004, 0.0006],
        [0.0004, 0.0008],
        [0.0002, 0.0006],
        [0.0003, 0.0005],
        [0.0005, 0.0010],
        [0.0003, 0.0006],
        [0.0003, 0.0007],
        [0.0003, 0.0004],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0601, 0.0647],
        [0.0653, 0.0595],
        [0.0644, 0.0603],
        [0.0730, 0.0532],
        [0.0637, 0.0610],
        [0.0572, 0.0680],
        [0.0660, 0.0589],
        [0.0663, 0.0586],
        [0.0597, 0.0652],
        [0.0544, 0.0714],
        [0.0648, 0.0600],
        [0.0604, 0.0644],
        [0.0594, 0.0655],
        [0.0570, 0.0682],
        [0.0655, 0.0593],
        [0.0629, 0.0618]], device='cuda:0')
 Batch: 7 of identical_modal classification Duration: 0:00:00.367678
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0005, 0.0013],
        [0.0005, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0008],
        [0.0002, 0.0004],
        [0.0006, 0.0010],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0004, 0.0008],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0003],
        [0.0004, 0.0007]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0584, 0.0667],
        [0.0674, 0.0578],
        [0.0617, 0.0631],
        [0.0649, 0.0600],
        [0.0601, 0.0649],
        [0.0584, 0.0667],
        [0.0641, 0.0608],
        [0.0649, 0.0600],
        [0.0606, 0.0643],
        [0.0625, 0.0623],
        [0.0604, 0.0646],
        [0.0602, 0.0648],
        [0.0621, 0.0628],
        [0.0595, 0.0655],
        [0.0705, 0.0553],
        [0.0645, 0.0604]], device='cuda:0')
 Batch: 8 of identical_modal classification Duration: 0:00:00.412728
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0003, 0.0007],
        [0.0003, 0.0009],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0006, 0.0016],
        [0.0002, 0.0005],
        [0.0003, 0.0007],
        [0.0004, 0.0005],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0006],
        [0.0003, 0.0005],
        [0.0004, 0.0005],
        [0.0007, 0.0013],
        [0.0003, 0.0005],
        [0.0004, 0.0005]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0626],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0591, 0.0659],
        [0.0559, 0.0696],
        [0.0617, 0.0631],
        [0.0615, 0.0633],
        [0.0573, 0.0679],
        [0.0626, 0.0621],
        [0.0583, 0.0667],
        [0.0670, 0.0580],
        [0.0646, 0.0602],
        [0.0631, 0.0617],
        [0.0622, 0.0626],
        [0.0613, 0.0634],
        [0.0699, 0.0556],
        [0.0627, 0.0620],
        [0.0620, 0.0628],
        [0.0707, 0.0550]], device='cuda:0')
 Batch: 9 of identical_modal classification Duration: 0:00:00.370331
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0004, 0.0009],
        [0.0002, 0.0003],
        [0.0003, 0.0005],
        [0.0003, 0.0004],
        [0.0005, 0.0011],
        [0.0003, 0.0004],
        [0.0003, 0.0005],
        [0.0003, 0.0007],
        [0.0004, 0.0007],
        [0.0005, 0.0009],
        [0.0004, 0.0006],
        [0.0002, 0.0004],
        [0.0002, 0.0002],
        [0.0002, 0.0004]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0673, 0.0580],
        [0.0614, 0.0635],
        [0.0601, 0.0649],
        [0.0633, 0.0616],
        [0.0643, 0.0607],
        [0.0642, 0.0608],
        [0.0586, 0.0666],
        [0.0633, 0.0616],
        [0.0634, 0.0615],
        [0.0588, 0.0663],
        [0.0631, 0.0618],
        [0.0612, 0.0637],
        [0.0624, 0.0625],
        [0.0632, 0.0617],
        [0.0657, 0.0593],
        [0.0595, 0.0655]], device='cuda:0')
 Batch: 10 of identical_modal classification Duration: 0:00:00.545345
probs_ shape 2 torch.Size([1, 16])
probs_ shape 2 torch.Size([1, 16])
answers_probs before norm: tensor([[0.0004, 0.0008],
        [0.0004, 0.0006],
        [0.0007, 0.0010],
        [0.0004, 0.0007],
        [0.0002, 0.0004],
        [0.0003, 0.0005],
        [0.0004, 0.0006],
        [0.0003, 0.0005],
        [0.0007, 0.0013],
        [0.0005, 0.0008],
        [0.0003, 0.0005],
        [0.0003, 0.0006],
        [0.0004, 0.0009],
        [0.0003, 0.0006],
        [0.0004, 0.0009],
Traceback (most recent call last):
  File "/home/lcur1101/ATCS_group3/src/main.py", line 197, in <module>
        [0.0002, 0.0003]], device='cuda:0') torch.Size([16, 2])
answers_probs just softmax dim 0: tensor([[0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625],
        [0.0625, 0.0625]], device='cuda:0')
tensor([[0.0594, 0.0656],
        [0.0635, 0.0614],
        [0.0634, 0.0616],
        [0.0618, 0.0632],
        [0.0614, 0.0635],
        [0.0652, 0.0598],
        [0.0648, 0.0602],
        [0.0646, 0.0604],
        [0.0602, 0.0647],
        [0.0642, 0.0608],
        [0.0664, 0.0587],
        [0.0607, 0.0643],
        [0.0580, 0.0672],
        [0.0610, 0.0640],
        [0.0601, 0.0649],
        [0.0653, 0.0597]], device='cuda:0')
 Batch: 11 of identical_modal classification Duration: 0:00:00.432707
probs_ shape 2 torch.Size([1, 8])
probs_ shape 2 torch.Size([1, 8])
answers_probs before norm: tensor([[0.0002, 0.0004],
        [0.0003, 0.0006],
        [0.0006, 0.0009],
        [0.0003, 0.0008],
        [0.0003, 0.0004],
        [0.0003, 0.0005],
        [0.0004, 0.0007],
        [0.0003, 0.0005]], device='cuda:0') torch.Size([8, 2])
answers_probs just softmax dim 0: tensor([[0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250],
        [0.1250, 0.1250]], device='cuda:0')
tensor([[0.1187, 0.1314],
        [0.1226, 0.1272],
        [0.1307, 0.1194],
        [0.1182, 0.1320],
        [0.1304, 0.1196],
        [0.1287, 0.1212],
        [0.1224, 0.1275],
        [0.1283, 0.1216]], device='cuda:0')
 Batch: 12 of identical_modal classification Duration: 0:00:00.191114
acc:  0.46
Time taken to execute the en SA task with prompt type identical_modal, variation 9 and batchsize 16: 0:00:04.973596
path ['42', 'en', 'bloom-big', 'SA', 'identical_modal', 'prompt_id_9']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v73.pickle' as a pickle file.

Loading model bigscience/bloomz-7b1-mt
Model bigscience/bloomz-7b1-mt loaded
Available device is cuda
    pipeline(seed, lang, models, tasks, prompt_types, prompt_templates,
  File "/home/lcur1101/ATCS_group3/src/main.py", line 125, in pipeline
    LM = Model(LM_model, train_dataloader.possible_answers)
  File "/home/lcur1101/ATCS_group3/src/models/model.py", line 49, in __init__
    self.model = self.model.cuda()
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 905, in cuda
    return self._apply(lambda t: t.cuda(device))
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 820, in _apply
    param_applied = fn(param)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 905, in <lambda>
    return self._apply(lambda t: t.cuda(device))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 23.65 GiB total capacity; 22.72 GiB already allocated; 29.56 MiB free; 22.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
srun: error: r28n4: task 0: Exited with exit code 1
