task  SA
self.device  cuda
/home/lcur1101/ATCS_group3/marc_data/dataset_fr_train.json
init marc done
num_lines  200000
num_lines  200000
num_lines  200000
num_lines  200000
Batch number: 0 , batch size : 16
Time taken to execute prompt gen: 0:00:00.000031
Time taken to execute mapping: 0:00:00.000122
possible_answers  {'negative', 'positive'}
logits  torch.Size([16, 250002])
answers_probs  torch.Size([16, 2, 1])
answers_probs old  torch.Size([16, 2])
Traceback (most recent call last):
  File "/home/lcur1101/ATCS_group3/code/pipeline_file.py", line 186, in <module>
    acc = pipeline(LM_model, task, prompt_generator)
  File "/home/lcur1101/ATCS_group3/code/pipeline_file.py", line 146, in pipeline
    answers_probs_batch, pred_answer_batch = model(
  File "/home/lcur1101/ATCS_group3/code/main_model.py", line 65, in __call__
    answer_logits = logits[last_token_indices,
RuntimeError: Could not infer dtype of tokenizers.Encoding
srun: error: r29n2: task 0: Exited with exit code 1
