----------- llama SA --------------
Loading model huggyllama/llama-7b
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:12<00:12, 12.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  7.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.22s/it]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
Model huggyllama/llama-7b loaded
Moving model to cuda
Loading MARC dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 216.45it/s]
Using pad_token, but it is not set yet.
MARC dataset loaded
len dataset  4
Batch: 0 , batch size: 2, sample_size: 4
Traceback (most recent call last):
  File "/home/lcur1101/ATCS_group3/src/main.py", line 85, in <module>
    pipeline(args)
  File "/home/lcur1101/ATCS_group3/src/main.py", line 43, in pipeline
    answers_probs_batch, pred_answer_batch = LM(
  File "/home/lcur1101/ATCS_group3/src/models/model.py", line 50, in __call__
    inputs = self.tokenizer(prompt, return_tensors="pt", padding=True, truncation=True)#.to(self.device)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2538, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2624, in _call_one
    return self.batch_encode_plus(
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2806, in batch_encode_plus
    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
  File "/home/lcur1101/.conda/envs/dl2022/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2443, in _get_padding_truncation_strategies
    raise ValueError(
ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.
srun: error: r28n3: task 0: Exited with exit code 1
