Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
****Start Time: 2023-05-22_08-37-08
Loading model bigscience/bloom-560m
Model bigscience/bloom-560m loaded
Available device is cuda
Model device: cuda:0
----------- 42 en bigscience/bloom-560m NLI active 0 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:00<00:00,  3.60it/s]100%|██████████| 3/3 [00:00<00:00,  8.69it/s]100%|██████████| 3/3 [00:00<00:00,  7.61it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type active, variation 0 and batchsize 16: 0:03:00.702239
path ['42', 'en', 'bloom', 'NLI', 'active', 'prompt_id_0']
----------- 42 en bigscience/bloom-560m NLI active 1 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 158.62it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type active, variation 1 and batchsize 16: 0:03:04.012161
path ['42', 'en', 'bloom', 'NLI', 'active', 'prompt_id_1']
----------- 42 en bigscience/bloom-560m NLI active 2 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 233.08it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type active, variation 2 and batchsize 16: 0:02:56.121946
path ['42', 'en', 'bloom', 'NLI', 'active', 'prompt_id_2']
----------- 42 en bigscience/bloom-560m NLI active 3 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 292.88it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type active, variation 3 and batchsize 16: 0:02:56.091120
path ['42', 'en', 'bloom', 'NLI', 'active', 'prompt_id_3']
----------- 42 en bigscience/bloom-560m NLI active 4 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 317.41it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type active, variation 4 and batchsize 16: 0:03:02.143327
path ['42', 'en', 'bloom', 'NLI', 'active', 'prompt_id_4']
----------- 42 en bigscience/bloom-560m NLI active 5 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 279.76it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type active, variation 5 and batchsize 16: 0:02:58.277908
path ['42', 'en', 'bloom', 'NLI', 'active', 'prompt_id_5']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v6.pickle' as a pickle file.
----------- 42 en bigscience/bloom-560m NLI passive 0 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 315.72it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type passive, variation 0 and batchsize 16: 0:02:56.106314
path ['42', 'en', 'bloom', 'NLI', 'passive', 'prompt_id_0']
----------- 42 en bigscience/bloom-560m NLI passive 1 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 305.90it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type passive, variation 1 and batchsize 16: 0:02:59.336109
path ['42', 'en', 'bloom', 'NLI', 'passive', 'prompt_id_1']
----------- 42 en bigscience/bloom-560m NLI passive 2 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 312.50it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type passive, variation 2 and batchsize 16: 0:03:00.304640
path ['42', 'en', 'bloom', 'NLI', 'passive', 'prompt_id_2']
----------- 42 en bigscience/bloom-560m NLI passive 3 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 177.89it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type passive, variation 3 and batchsize 16: 0:02:56.124332
path ['42', 'en', 'bloom', 'NLI', 'passive', 'prompt_id_3']
----------- 42 en bigscience/bloom-560m NLI passive 4 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 310.56it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type passive, variation 4 and batchsize 16: 0:02:57.886160
path ['42', 'en', 'bloom', 'NLI', 'passive', 'prompt_id_4']
----------- 42 en bigscience/bloom-560m NLI passive 5 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 299.46it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type passive, variation 5 and batchsize 16: 0:03:02.006771
path ['42', 'en', 'bloom', 'NLI', 'passive', 'prompt_id_5']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v6.pickle' as a pickle file.
----------- 42 en bigscience/bloom-560m NLI auxiliary 0 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 293.17it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type auxiliary, variation 0 and batchsize 16: 0:02:59.187318
path ['42', 'en', 'bloom', 'NLI', 'auxiliary', 'prompt_id_0']
----------- 42 en bigscience/bloom-560m NLI auxiliary 1 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 313.42it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type auxiliary, variation 1 and batchsize 16: 0:02:58.515530
path ['42', 'en', 'bloom', 'NLI', 'auxiliary', 'prompt_id_1']
----------- 42 en bigscience/bloom-560m NLI auxiliary 2 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 307.94it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type auxiliary, variation 2 and batchsize 16: 0:03:05.159038
path ['42', 'en', 'bloom', 'NLI', 'auxiliary', 'prompt_id_2']
----------- 42 en bigscience/bloom-560m NLI auxiliary 3 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 295.00it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type auxiliary, variation 3 and batchsize 16: 0:02:58.740198
path ['42', 'en', 'bloom', 'NLI', 'auxiliary', 'prompt_id_3']
----------- 42 en bigscience/bloom-560m NLI auxiliary 4 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 296.64it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type auxiliary, variation 4 and batchsize 16: 0:02:56.968748
path ['42', 'en', 'bloom', 'NLI', 'auxiliary', 'prompt_id_4']
----------- 42 en bigscience/bloom-560m NLI auxiliary 5 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 294.40it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type auxiliary, variation 5 and batchsize 16: 0:03:01.822148
path ['42', 'en', 'bloom', 'NLI', 'auxiliary', 'prompt_id_5']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v6.pickle' as a pickle file.
----------- 42 en bigscience/bloom-560m NLI modal 0 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 299.41it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type modal, variation 0 and batchsize 16: 0:02:58.680860
path ['42', 'en', 'bloom', 'NLI', 'modal', 'prompt_id_0']
----------- 42 en bigscience/bloom-560m NLI modal 1 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 296.16it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type modal, variation 1 and batchsize 16: 0:02:58.780344
path ['42', 'en', 'bloom', 'NLI', 'modal', 'prompt_id_1']
----------- 42 en bigscience/bloom-560m NLI modal 2 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 289.80it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type modal, variation 2 and batchsize 16: 0:03:00.363290
path ['42', 'en', 'bloom', 'NLI', 'modal', 'prompt_id_2']
----------- 42 en bigscience/bloom-560m NLI modal 3 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 175.31it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type modal, variation 3 and batchsize 16: 0:03:00.015111
path ['42', 'en', 'bloom', 'NLI', 'modal', 'prompt_id_3']
----------- 42 en bigscience/bloom-560m NLI modal 4 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 306.30it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type modal, variation 4 and batchsize 16: 0:02:58.637610
path ['42', 'en', 'bloom', 'NLI', 'modal', 'prompt_id_4']
----------- 42 en bigscience/bloom-560m NLI modal 5 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 295.73it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type modal, variation 5 and batchsize 16: 0:02:59.465234
path ['42', 'en', 'bloom', 'NLI', 'modal', 'prompt_id_5']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v6.pickle' as a pickle file.
----------- 42 en bigscience/bloom-560m NLI common 0 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 285.29it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type common, variation 0 and batchsize 16: 0:03:04.985442
path ['42', 'en', 'bloom', 'NLI', 'common', 'prompt_id_0']
----------- 42 en bigscience/bloom-560m NLI common 1 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 310.74it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type common, variation 1 and batchsize 16: 0:02:58.376594
path ['42', 'en', 'bloom', 'NLI', 'common', 'prompt_id_1']
----------- 42 en bigscience/bloom-560m NLI common 2 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 273.60it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type common, variation 2 and batchsize 16: 0:02:54.364247
path ['42', 'en', 'bloom', 'NLI', 'common', 'prompt_id_2']
----------- 42 en bigscience/bloom-560m NLI common 3 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 314.08it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type common, variation 3 and batchsize 16: 0:02:55.818949
path ['42', 'en', 'bloom', 'NLI', 'common', 'prompt_id_3']
----------- 42 en bigscience/bloom-560m NLI common 4 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 301.44it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type common, variation 4 and batchsize 16: 0:02:52.140995
path ['42', 'en', 'bloom', 'NLI', 'common', 'prompt_id_4']
----------- 42 en bigscience/bloom-560m NLI common 5 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 319.53it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type common, variation 5 and batchsize 16: 0:02:48.657752
path ['42', 'en', 'bloom', 'NLI', 'common', 'prompt_id_5']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v6.pickle' as a pickle file.
----------- 42 en bigscience/bloom-560m NLI rare_synonyms 0 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 317.93it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type rare_synonyms, variation 0 and batchsize 16: 0:02:52.729100
path ['42', 'en', 'bloom', 'NLI', 'rare_synonyms', 'prompt_id_0']
----------- 42 en bigscience/bloom-560m NLI rare_synonyms 1 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 183.10it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type rare_synonyms, variation 1 and batchsize 16: 0:02:52.806778
path ['42', 'en', 'bloom', 'NLI', 'rare_synonyms', 'prompt_id_1']
----------- 42 en bigscience/bloom-560m NLI rare_synonyms 2 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 332.46it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type rare_synonyms, variation 2 and batchsize 16: 0:02:49.692774
path ['42', 'en', 'bloom', 'NLI', 'rare_synonyms', 'prompt_id_2']
----------- 42 en bigscience/bloom-560m NLI rare_synonyms 3 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 344.44it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type rare_synonyms, variation 3 and batchsize 16: 0:02:48.802708
path ['42', 'en', 'bloom', 'NLI', 'rare_synonyms', 'prompt_id_3']
----------- 42 en bigscience/bloom-560m NLI rare_synonyms 4 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 188.10it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type rare_synonyms, variation 4 and batchsize 16: 0:02:53.013167
path ['42', 'en', 'bloom', 'NLI', 'rare_synonyms', 'prompt_id_4']
----------- 42 en bigscience/bloom-560m NLI rare_synonyms 5 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 346.69it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type rare_synonyms, variation 5 and batchsize 16: 0:02:47.620584
path ['42', 'en', 'bloom', 'NLI', 'rare_synonyms', 'prompt_id_5']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v6.pickle' as a pickle file.
----------- 42 en bigscience/bloom-560m NLI identical_modal 0 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 344.83it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type identical_modal, variation 0 and batchsize 16: 0:02:46.637486
path ['42', 'en', 'bloom', 'NLI', 'identical_modal', 'prompt_id_0']
----------- 42 en bigscience/bloom-560m NLI identical_modal 1 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 331.90it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type identical_modal, variation 1 and batchsize 16: 0:02:49.848741
path ['42', 'en', 'bloom', 'NLI', 'identical_modal', 'prompt_id_1']
----------- 42 en bigscience/bloom-560m NLI identical_modal 2 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 316.55it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type identical_modal, variation 2 and batchsize 16: 0:02:50.386642
path ['42', 'en', 'bloom', 'NLI', 'identical_modal', 'prompt_id_2']
----------- 42 en bigscience/bloom-560m NLI identical_modal 3 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 351.55it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type identical_modal, variation 3 and batchsize 16: 0:02:48.183640
path ['42', 'en', 'bloom', 'NLI', 'identical_modal', 'prompt_id_3']
----------- 42 en bigscience/bloom-560m NLI identical_modal 4 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 357.88it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type identical_modal, variation 4 and batchsize 16: 0:02:48.639316
path ['42', 'en', 'bloom', 'NLI', 'identical_modal', 'prompt_id_4']
----------- 42 en bigscience/bloom-560m NLI identical_modal 5 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 329.05it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type identical_modal, variation 5 and batchsize 16: 0:02:53.144987
path ['42', 'en', 'bloom', 'NLI', 'identical_modal', 'prompt_id_5']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v6.pickle' as a pickle file.
Loading model bigscience/bloomz-560m
Model bigscience/bloomz-560m loaded
Available device is cuda
Model device: cuda:0
----------- 42 en bigscience/bloomz-560m NLI active 0 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 343.12it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type active, variation 0 and batchsize 16: 0:02:49.488888
path ['42', 'en', 'bloomz', 'NLI', 'active', 'prompt_id_0']
----------- 42 en bigscience/bloomz-560m NLI active 1 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 185.95it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type active, variation 1 and batchsize 16: 0:02:49.396179
path ['42', 'en', 'bloomz', 'NLI', 'active', 'prompt_id_1']
----------- 42 en bigscience/bloomz-560m NLI active 2 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 188.03it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type active, variation 2 and batchsize 16: 0:02:52.056192
path ['42', 'en', 'bloomz', 'NLI', 'active', 'prompt_id_2']
----------- 42 en bigscience/bloomz-560m NLI active 3 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 234.18it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type active, variation 3 and batchsize 16: 0:02:52.236505
path ['42', 'en', 'bloomz', 'NLI', 'active', 'prompt_id_3']
----------- 42 en bigscience/bloomz-560m NLI active 4 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 337.67it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type active, variation 4 and batchsize 16: 0:02:49.026741
path ['42', 'en', 'bloomz', 'NLI', 'active', 'prompt_id_4']
----------- 42 en bigscience/bloomz-560m NLI active 5 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 331.65it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type active, variation 5 and batchsize 16: 0:02:49.675446
path ['42', 'en', 'bloomz', 'NLI', 'active', 'prompt_id_5']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v6.pickle' as a pickle file.
----------- 42 en bigscience/bloomz-560m NLI passive 0 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 180.70it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type passive, variation 0 and batchsize 16: 0:02:53.914527
path ['42', 'en', 'bloomz', 'NLI', 'passive', 'prompt_id_0']
----------- 42 en bigscience/bloomz-560m NLI passive 1 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 322.18it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type passive, variation 1 and batchsize 16: 0:02:46.865501
path ['42', 'en', 'bloomz', 'NLI', 'passive', 'prompt_id_1']
----------- 42 en bigscience/bloomz-560m NLI passive 2 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 322.95it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type passive, variation 2 and batchsize 16: 0:02:46.725092
path ['42', 'en', 'bloomz', 'NLI', 'passive', 'prompt_id_2']
----------- 42 en bigscience/bloomz-560m NLI passive 3 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 339.30it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type passive, variation 3 and batchsize 16: 0:02:50.147159
path ['42', 'en', 'bloomz', 'NLI', 'passive', 'prompt_id_3']
----------- 42 en bigscience/bloomz-560m NLI passive 4 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 262.13it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type passive, variation 4 and batchsize 16: 0:02:49.953139
path ['42', 'en', 'bloomz', 'NLI', 'passive', 'prompt_id_4']
----------- 42 en bigscience/bloomz-560m NLI passive 5 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 337.12it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type passive, variation 5 and batchsize 16: 0:02:49.259620
path ['42', 'en', 'bloomz', 'NLI', 'passive', 'prompt_id_5']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v6.pickle' as a pickle file.
----------- 42 en bigscience/bloomz-560m NLI auxiliary 0 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 256.30it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type auxiliary, variation 0 and batchsize 16: 0:02:47.761442
path ['42', 'en', 'bloomz', 'NLI', 'auxiliary', 'prompt_id_0']
----------- 42 en bigscience/bloomz-560m NLI auxiliary 1 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 242.80it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type auxiliary, variation 1 and batchsize 16: 0:02:54.421071
path ['42', 'en', 'bloomz', 'NLI', 'auxiliary', 'prompt_id_1']
----------- 42 en bigscience/bloomz-560m NLI auxiliary 2 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 339.99it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type auxiliary, variation 2 and batchsize 16: 0:02:49.248498
path ['42', 'en', 'bloomz', 'NLI', 'auxiliary', 'prompt_id_2']
----------- 42 en bigscience/bloomz-560m NLI auxiliary 3 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 347.35it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type auxiliary, variation 3 and batchsize 16: 0:02:49.213909
path ['42', 'en', 'bloomz', 'NLI', 'auxiliary', 'prompt_id_3']
----------- 42 en bigscience/bloomz-560m NLI auxiliary 4 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 196.70it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type auxiliary, variation 4 and batchsize 16: 0:02:51.427693
path ['42', 'en', 'bloomz', 'NLI', 'auxiliary', 'prompt_id_4']
----------- 42 en bigscience/bloomz-560m NLI auxiliary 5 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 318.19it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type auxiliary, variation 5 and batchsize 16: 0:02:50.447932
path ['42', 'en', 'bloomz', 'NLI', 'auxiliary', 'prompt_id_5']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v6.pickle' as a pickle file.
----------- 42 en bigscience/bloomz-560m NLI modal 0 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 329.01it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type modal, variation 0 and batchsize 16: 0:02:49.451139
path ['42', 'en', 'bloomz', 'NLI', 'modal', 'prompt_id_0']
----------- 42 en bigscience/bloomz-560m NLI modal 1 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 347.02it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type modal, variation 1 and batchsize 16: 0:02:50.653210
path ['42', 'en', 'bloomz', 'NLI', 'modal', 'prompt_id_1']
----------- 42 en bigscience/bloomz-560m NLI modal 2 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 255.48it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type modal, variation 2 and batchsize 16: 0:02:54.077759
path ['42', 'en', 'bloomz', 'NLI', 'modal', 'prompt_id_2']
----------- 42 en bigscience/bloomz-560m NLI modal 3 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 338.70it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type modal, variation 3 and batchsize 16: 0:02:49.437819
path ['42', 'en', 'bloomz', 'NLI', 'modal', 'prompt_id_3']
----------- 42 en bigscience/bloomz-560m NLI modal 4 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 341.89it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type modal, variation 4 and batchsize 16: 0:02:49.561833
path ['42', 'en', 'bloomz', 'NLI', 'modal', 'prompt_id_4']
----------- 42 en bigscience/bloomz-560m NLI modal 5 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 335.33it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type modal, variation 5 and batchsize 16: 0:02:51.057093
path ['42', 'en', 'bloomz', 'NLI', 'modal', 'prompt_id_5']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v6.pickle' as a pickle file.
----------- 42 en bigscience/bloomz-560m NLI common 0 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 320.58it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type common, variation 0 and batchsize 16: 0:02:50.783385
path ['42', 'en', 'bloomz', 'NLI', 'common', 'prompt_id_0']
----------- 42 en bigscience/bloomz-560m NLI common 1 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 196.22it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type common, variation 1 and batchsize 16: 0:02:48.848785
path ['42', 'en', 'bloomz', 'NLI', 'common', 'prompt_id_1']
----------- 42 en bigscience/bloomz-560m NLI common 2 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 335.22it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type common, variation 2 and batchsize 16: 0:02:51.280752
path ['42', 'en', 'bloomz', 'NLI', 'common', 'prompt_id_2']
----------- 42 en bigscience/bloomz-560m NLI common 3 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 329.27it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type common, variation 3 and batchsize 16: 0:02:53.919431
path ['42', 'en', 'bloomz', 'NLI', 'common', 'prompt_id_3']
----------- 42 en bigscience/bloomz-560m NLI common 4 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 335.22it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type common, variation 4 and batchsize 16: 0:02:49.265751
path ['42', 'en', 'bloomz', 'NLI', 'common', 'prompt_id_4']
----------- 42 en bigscience/bloomz-560m NLI common 5 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 256.69it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type common, variation 5 and batchsize 16: 0:02:46.953877
path ['42', 'en', 'bloomz', 'NLI', 'common', 'prompt_id_5']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v6.pickle' as a pickle file.
----------- 42 en bigscience/bloomz-560m NLI rare_synonyms 0 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 347.81it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type rare_synonyms, variation 0 and batchsize 16: 0:02:52.684396
path ['42', 'en', 'bloomz', 'NLI', 'rare_synonyms', 'prompt_id_0']
----------- 42 en bigscience/bloomz-560m NLI rare_synonyms 1 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 328.87it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type rare_synonyms, variation 1 and batchsize 16: 0:02:48.289828
path ['42', 'en', 'bloomz', 'NLI', 'rare_synonyms', 'prompt_id_1']
----------- 42 en bigscience/bloomz-560m NLI rare_synonyms 2 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 330.47it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type rare_synonyms, variation 2 and batchsize 16: 0:02:47.000974
path ['42', 'en', 'bloomz', 'NLI', 'rare_synonyms', 'prompt_id_2']
----------- 42 en bigscience/bloomz-560m NLI rare_synonyms 3 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 189.58it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type rare_synonyms, variation 3 and batchsize 16: 0:02:49.758023
path ['42', 'en', 'bloomz', 'NLI', 'rare_synonyms', 'prompt_id_3']
----------- 42 en bigscience/bloomz-560m NLI rare_synonyms 4 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 326.02it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type rare_synonyms, variation 4 and batchsize 16: 0:02:53.061024
path ['42', 'en', 'bloomz', 'NLI', 'rare_synonyms', 'prompt_id_4']
----------- 42 en bigscience/bloomz-560m NLI rare_synonyms 5 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 331.75it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type rare_synonyms, variation 5 and batchsize 16: 0:02:49.640621
path ['42', 'en', 'bloomz', 'NLI', 'rare_synonyms', 'prompt_id_5']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v6.pickle' as a pickle file.
----------- 42 en bigscience/bloomz-560m NLI identical_modal 0 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 323.10it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type identical_modal, variation 0 and batchsize 16: 0:02:49.269996
path ['42', 'en', 'bloomz', 'NLI', 'identical_modal', 'prompt_id_0']
----------- 42 en bigscience/bloomz-560m NLI identical_modal 1 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 341.19it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type identical_modal, variation 1 and batchsize 16: 0:02:55.024715
path ['42', 'en', 'bloomz', 'NLI', 'identical_modal', 'prompt_id_1']
----------- 42 en bigscience/bloomz-560m NLI identical_modal 2 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 187.49it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type identical_modal, variation 2 and batchsize 16: 0:02:47.375551
path ['42', 'en', 'bloomz', 'NLI', 'identical_modal', 'prompt_id_2']
----------- 42 en bigscience/bloomz-560m NLI identical_modal 3 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 184.67it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type identical_modal, variation 3 and batchsize 16: 0:02:49.373209
path ['42', 'en', 'bloomz', 'NLI', 'identical_modal', 'prompt_id_3']
----------- 42 en bigscience/bloomz-560m NLI identical_modal 4 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 329.95it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type identical_modal, variation 4 and batchsize 16: 0:02:49.578077
path ['42', 'en', 'bloomz', 'NLI', 'identical_modal', 'prompt_id_4']
----------- 42 en bigscience/bloomz-560m NLI identical_modal 5 200 16 --------------
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 299.67it/s]
NLI dataset loaded
len of entail_examples , neutral_examples, contra_examples:  66 66 66
len dataset  198
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
answer  {'input_ids': [1936], 'attention_mask': [1]}
answer  {'input_ids': [137111], 'attention_mask': [1]}
answers_probs: tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]], device='cuda:0')
acc:  0.3333333333333333
Time taken to execute the en NLI task with prompt type identical_modal, variation 5 and batchsize 16: 0:02:52.512085
path ['42', 'en', 'bloomz', 'NLI', 'identical_modal', 'prompt_id_5']
Dictionary saved to './ATCS_group3/saved_outputs/logits_dict_seed_42_lang_en_v6.pickle' as a pickle file.
****End Time: 2023-05-22 12:40:48.397004 Duraction: 4:03:39.760211
