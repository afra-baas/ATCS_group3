Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
----------- bloom SA --------------
Loading model bigscience/bloom-560m
Model bigscience/bloom-560m loaded
Moving model to cuda
Loading MARC dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 29.30it/s]100%|██████████| 3/3 [00:00<00:00, 29.24it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
MARC dataset loaded
len dataset  200
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__8.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__SA__8.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes')
acc:  0.58
----------- bloom NLI --------------
Loading model bigscience/bloom-560m
Model bigscience/bloom-560m loaded
Moving model to cuda
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s] 33%|███▎      | 1/3 [00:00<00:00,  5.94it/s]100%|██████████| 3/3 [00:00<00:00, 17.02it/s]
NLI dataset loaded
len dataset  200
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
pred_answer ['yes', 'maybe', 'yes', 'yes', 'maybe', 'yes', 'yes', 'yes', 'maybe', 'yes', 'maybe', 'maybe', 'maybe', 'maybe', 'maybe', 'yes'] , label: ('maybe', 'no', 'yes', 'maybe', 'maybe', 'no', 'no', 'maybe', 'maybe', 'no', 'yes', 'yes', 'maybe', 'no', 'yes', 'maybe')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
pred_answer ['maybe', 'yes', 'maybe', 'maybe', 'yes', 'maybe', 'maybe', 'yes', 'maybe', 'yes', 'yes', 'maybe', 'maybe', 'yes', 'yes', 'yes'] , label: ('no', 'yes', 'yes', 'no', 'no', 'maybe', 'yes', 'maybe', 'no', 'maybe', 'yes', 'maybe', 'no', 'maybe', 'yes', 'no')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
pred_answer ['yes', 'maybe', 'maybe', 'yes', 'maybe', 'maybe', 'maybe', 'yes', 'maybe', 'maybe', 'maybe', 'maybe', 'yes', 'maybe', 'maybe', 'maybe'] , label: ('maybe', 'no', 'no', 'no', 'no', 'yes', 'maybe', 'yes', 'maybe', 'no', 'yes', 'no', 'yes', 'yes', 'maybe', 'no')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
pred_answer ['maybe', 'maybe', 'yes', 'yes', 'maybe', 'maybe', 'maybe', 'yes', 'maybe', 'yes', 'maybe', 'yes', 'maybe', 'yes', 'yes', 'yes'] , label: ('no', 'yes', 'yes', 'maybe', 'yes', 'maybe', 'maybe', 'no', 'maybe', 'yes', 'maybe', 'no', 'yes', 'no', 'no', 'yes')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
pred_answer ['maybe', 'maybe', 'yes', 'yes', 'maybe', 'yes', 'yes', 'maybe', 'yes', 'maybe', 'maybe', 'yes', 'maybe', 'maybe', 'maybe', 'yes'] , label: ('no', 'yes', 'no', 'no', 'yes', 'maybe', 'maybe', 'no', 'no', 'yes', 'yes', 'no', 'no', 'maybe', 'yes', 'no')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
pred_answer ['maybe', 'yes', 'maybe', 'yes', 'no', 'maybe', 'maybe', 'yes', 'maybe', 'yes', 'maybe', 'yes', 'yes', 'yes', 'maybe', 'no'] , label: ('maybe', 'no', 'maybe', 'maybe', 'yes', 'yes', 'maybe', 'no', 'no', 'no', 'yes', 'yes', 'no', 'maybe', 'yes', 'maybe')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
pred_answer ['yes', 'yes', 'maybe', 'maybe', 'maybe', 'maybe', 'yes', 'yes', 'maybe', 'yes', 'maybe', 'maybe', 'maybe', 'yes', 'maybe', 'maybe'] , label: ('no', 'maybe', 'yes', 'maybe', 'yes', 'no', 'no', 'no', 'yes', 'maybe', 'no', 'no', 'no', 'maybe', 'yes', 'no')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
pred_answer ['yes', 'yes', 'no', 'maybe', 'maybe', 'maybe', 'yes', 'maybe', 'maybe', 'yes', 'no', 'maybe', 'yes', 'yes', 'maybe', 'yes'] , label: ('maybe', 'no', 'maybe', 'yes', 'no', 'no', 'maybe', 'no', 'yes', 'maybe', 'no', 'maybe', 'yes', 'maybe', 'no', 'maybe')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
pred_answer ['maybe', 'yes', 'yes', 'yes', 'yes', 'maybe', 'yes', 'yes', 'maybe', 'maybe', 'yes', 'yes', 'yes', 'maybe', 'maybe', 'maybe'] , label: ('maybe', 'maybe', 'maybe', 'yes', 'yes', 'no', 'yes', 'yes', 'maybe', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
pred_answer ['yes', 'maybe', 'yes', 'maybe', 'maybe', 'yes', 'maybe', 'yes', 'maybe', 'yes', 'maybe', 'maybe', 'maybe', 'yes', 'yes', 'maybe'] , label: ('no', 'no', 'yes', 'maybe', 'maybe', 'maybe', 'maybe', 'maybe', 'yes', 'yes', 'no', 'maybe', 'maybe', 'yes', 'maybe', 'yes')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
pred_answer ['yes', 'maybe', 'no', 'yes', 'maybe', 'maybe', 'maybe', 'maybe', 'maybe', 'maybe', 'maybe', 'maybe', 'maybe', 'yes', 'maybe', 'yes'] , label: ('maybe', 'yes', 'maybe', 'maybe', 'no', 'maybe', 'maybe', 'maybe', 'yes', 'no', 'no', 'maybe', 'no', 'yes', 'no', 'no')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__16.txt
pred_answer ['yes', 'maybe', 'yes', 'maybe', 'maybe', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'maybe', 'maybe', 'yes', 'maybe'] , label: ('maybe', 'maybe', 'no', 'yes', 'no', 'no', 'maybe', 'maybe', 'yes', 'no', 'no', 'maybe', 'maybe', 'maybe', 'no', 'yes')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
Logits saved to saved_logits/bigscience/bloom-560m__NLI__8.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__8.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloom-560m__NLI__8.txt
pred_answer ['maybe', 'yes', 'maybe', 'yes', 'maybe', 'yes', 'yes', 'maybe'] , label: ('yes', 'maybe', 'no', 'no', 'maybe', 'no', 'yes', 'no')
acc:  0.28
----------- bloomz SA --------------
Loading model bigscience/bloomz-560m
Model bigscience/bloomz-560m loaded
Moving model to cuda
Loading MARC dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 273.36it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
MARC dataset loaded
len dataset  200
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__8.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__SA__8.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no')
acc:  0.58
----------- bloomz NLI --------------
Loading model bigscience/bloomz-560m
Model bigscience/bloomz-560m loaded
Moving model to cuda
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 278.92it/s]
NLI dataset loaded
len dataset  200
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'maybe', 'maybe', 'yes', 'yes', 'yes', 'yes', 'maybe', 'yes', 'yes', 'yes'] , label: ('yes', 'no', 'no', 'yes', 'yes', 'no', 'maybe', 'no', 'no', 'no', 'no', 'no', 'no', 'maybe', 'no', 'yes')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
pred_answer ['yes', 'no', 'maybe', 'yes', 'maybe', 'yes', 'maybe', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'maybe'] , label: ('maybe', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'maybe', 'maybe', 'maybe', 'maybe', 'no', 'yes', 'no')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'maybe', 'yes', 'yes', 'yes', 'maybe', 'maybe'] , label: ('yes', 'yes', 'yes', 'maybe', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'maybe', 'no', 'yes', 'yes', 'maybe', 'yes')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'maybe', 'yes', 'yes'] , label: ('yes', 'no', 'no', 'maybe', 'maybe', 'yes', 'no', 'no', 'yes', 'no', 'maybe', 'yes', 'no', 'no', 'maybe', 'yes')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'maybe', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('maybe', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'maybe', 'maybe', 'maybe', 'maybe', 'yes', 'no', 'maybe', 'no', 'no')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'maybe', 'maybe'] , label: ('maybe', 'maybe', 'no', 'maybe', 'yes', 'maybe', 'maybe', 'maybe', 'no', 'yes', 'yes', 'no', 'maybe', 'yes', 'no', 'no')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'maybe', 'yes', 'yes', 'yes', 'maybe', 'yes', 'yes', 'maybe', 'yes', 'yes', 'maybe', 'maybe', 'yes'] , label: ('maybe', 'yes', 'maybe', 'maybe', 'maybe', 'maybe', 'maybe', 'maybe', 'maybe', 'no', 'maybe', 'no', 'no', 'maybe', 'maybe', 'yes')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'maybe', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'yes', 'maybe', 'no', 'maybe', 'maybe', 'maybe', 'yes', 'no', 'no', 'yes', 'maybe', 'yes', 'maybe', 'yes', 'no')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
pred_answer ['yes', 'yes', 'maybe', 'maybe', 'yes', 'maybe', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'maybe', 'yes', 'yes'] , label: ('maybe', 'yes', 'maybe', 'maybe', 'no', 'no', 'maybe', 'no', 'no', 'maybe', 'yes', 'maybe', 'maybe', 'no', 'no', 'yes')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'maybe', 'yes', 'yes'] , label: ('yes', 'maybe', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'maybe', 'maybe', 'no', 'no', 'maybe', 'no', 'maybe', 'yes')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'maybe', 'yes', 'yes', 'yes', 'yes', 'yes', 'maybe', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'] , label: ('no', 'no', 'maybe', 'no', 'maybe', 'no', 'maybe', 'yes', 'no', 'maybe', 'no', 'no', 'yes', 'maybe', 'maybe', 'no')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__16.txt
pred_answer ['yes', 'yes', 'maybe', 'maybe', 'maybe', 'yes', 'maybe', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'maybe', 'yes', 'yes'] , label: ('no', 'yes', 'maybe', 'maybe', 'maybe', 'no', 'maybe', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'maybe', 'no', 'maybe')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [18260], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__8.txt
answer  {'input_ids': [1936], 'attention_mask': [1]}
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__8.txt
answer  {'input_ids': [137111], 'attention_mask': [1]}
Logits saved to saved_logits/bigscience/bloomz-560m__NLI__8.txt
pred_answer ['yes', 'yes', 'maybe', 'yes', 'maybe', 'yes', 'yes', 'yes'] , label: ('yes', 'maybe', 'no', 'yes', 'yes', 'no', 'yes', 'no')
acc:  0.365
----------- flan SA --------------
Loading model google/flan-t5-base
Model google/flan-t5-base loaded
Moving model to cuda
Loading MARC dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 350.78it/s]
Found cached dataset xnli (/home/lcur1101/.cache/huggingface/datasets/xnli/en/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)
MARC dataset loaded
len dataset  200
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
pred_answer ['yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes'] , label: ('yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
pred_answer ['no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes'] , label: ('no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
pred_answer ['yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no'] , label: ('yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
pred_answer ['yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no'] , label: ('yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
pred_answer ['no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no'] , label: ('no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
pred_answer ['yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no'] , label: ('yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
pred_answer ['no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'no'] , label: ('no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
pred_answer ['no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes'] , label: ('no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
pred_answer ['no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no'] , label: ('no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
pred_answer ['no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no'] , label: ('yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
pred_answer ['yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes'] , label: ('yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__SA__16.txt
pred_answer ['yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no'] , label: ('yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__SA__8.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__SA__8.txt
pred_answer ['no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no'] , label: ('no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes')
acc:  0.82
----------- flan NLI --------------
Loading model google/flan-t5-base
Model google/flan-t5-base loaded
Moving model to cuda
Loading NLI dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 316.77it/s]
NLI dataset loaded
len dataset  200
Batch: 0 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [2087, 1], 'attention_mask': [1, 1]}
id: [2087, 1] -> [2087]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
pred_answer ['no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes'] , label: ('yes', 'maybe', 'maybe', 'maybe', 'maybe', 'no', 'maybe', 'maybe', 'no', 'no', 'no', 'yes', 'no', 'maybe', 'no', 'maybe')
Batch: 1 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [2087, 1], 'attention_mask': [1, 1]}
id: [2087, 1] -> [2087]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
pred_answer ['no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no'] , label: ('maybe', 'no', 'yes', 'yes', 'yes', 'maybe', 'no', 'maybe', 'no', 'maybe', 'no', 'no', 'maybe', 'no', 'no', 'maybe')
Batch: 2 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [2087, 1], 'attention_mask': [1, 1]}
id: [2087, 1] -> [2087]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes'] , label: ('yes', 'yes', 'maybe', 'no', 'no', 'yes', 'no', 'maybe', 'yes', 'no', 'maybe', 'yes', 'yes', 'maybe', 'yes', 'maybe')
Batch: 3 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [2087, 1], 'attention_mask': [1, 1]}
id: [2087, 1] -> [2087]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
pred_answer ['no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no'] , label: ('no', 'yes', 'maybe', 'no', 'maybe', 'no', 'maybe', 'maybe', 'no', 'yes', 'yes', 'maybe', 'no', 'no', 'yes', 'no')
Batch: 4 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [2087, 1], 'attention_mask': [1, 1]}
id: [2087, 1] -> [2087]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
pred_answer ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes'] , label: ('yes', 'no', 'yes', 'no', 'maybe', 'yes', 'maybe', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes')
Batch: 5 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [2087, 1], 'attention_mask': [1, 1]}
id: [2087, 1] -> [2087]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
pred_answer ['no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no'] , label: ('no', 'maybe', 'no', 'maybe', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'maybe', 'yes', 'maybe', 'no')
Batch: 6 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [2087, 1], 'attention_mask': [1, 1]}
id: [2087, 1] -> [2087]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes'] , label: ('yes', 'maybe', 'maybe', 'no', 'no', 'yes', 'maybe', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'maybe', 'no', 'no')
Batch: 7 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [2087, 1], 'attention_mask': [1, 1]}
id: [2087, 1] -> [2087]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
pred_answer ['no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no'] , label: ('maybe', 'no', 'no', 'yes', 'maybe', 'no', 'no', 'no', 'maybe', 'maybe', 'maybe', 'maybe', 'no', 'maybe', 'no', 'no')
Batch: 8 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [2087, 1], 'attention_mask': [1, 1]}
id: [2087, 1] -> [2087]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
pred_answer ['no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes'] , label: ('no', 'no', 'no', 'maybe', 'yes', 'yes', 'yes', 'maybe', 'no', 'maybe', 'yes', 'maybe', 'maybe', 'yes', 'no', 'no')
Batch: 9 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [2087, 1], 'attention_mask': [1, 1]}
id: [2087, 1] -> [2087]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
pred_answer ['yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes'] , label: ('yes', 'maybe', 'maybe', 'maybe', 'yes', 'maybe', 'no', 'maybe', 'yes', 'yes', 'maybe', 'no', 'no', 'maybe', 'maybe', 'no')
Batch: 10 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [2087, 1], 'attention_mask': [1, 1]}
id: [2087, 1] -> [2087]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
pred_answer ['no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no'] , label: ('no', 'maybe', 'no', 'yes', 'maybe', 'no', 'maybe', 'no', 'yes', 'no', 'maybe', 'no', 'no', 'yes', 'yes', 'maybe')
Batch: 11 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
answer  {'input_ids': [2087, 1], 'attention_mask': [1, 1]}
id: [2087, 1] -> [2087]
Logits saved to saved_logits/google/flan-t5-base__NLI__16.txt
pred_answer ['yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no'] , label: ('maybe', 'yes', 'yes', 'maybe', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'maybe', 'yes', 'no', 'maybe', 'no', 'maybe')
Batch: 12 , batch size: 16, sample_size: 200
answer  {'input_ids': [4273, 1], 'attention_mask': [1, 1]}
id: [4273, 1] -> [4273]
Logits saved to saved_logits/google/flan-t5-base__NLI__8.txt
answer  {'input_ids': [150, 1], 'attention_mask': [1, 1]}
id: [150, 1] -> [150]
Logits saved to saved_logits/google/flan-t5-base__NLI__8.txt
answer  {'input_ids': [2087, 1], 'attention_mask': [1, 1]}
id: [2087, 1] -> [2087]
Logits saved to saved_logits/google/flan-t5-base__NLI__8.txt
pred_answer ['no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes'] , label: ('maybe', 'maybe', 'maybe', 'no', 'yes', 'no', 'maybe', 'maybe')
acc:  0.57
----------- llama SA --------------
Loading model huggyllama/llama-7b
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.25s/it]
Found cached dataset amazon_reviews_multi (/home/lcur1101/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)
Model huggyllama/llama-7b loaded
Moving model to cuda
Loading MARC dataset for en
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 308.84it/s]
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 11780190 ON r28n2 CANCELLED AT 2023-05-16T19:18:05 DUE TO TIME LIMIT ***
slurmstepd: error: *** STEP 11780190.0 ON r28n2 CANCELLED AT 2023-05-16T19:18:05 DUE TO TIME LIMIT ***
